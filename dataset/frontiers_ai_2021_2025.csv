title,abstract,year,doi
AI-assisted anatomical structure recognition and segmentation via mamba-transformer architecture in abdominal ultrasound images,"BackgroundAbdominal ultrasonography is a primary diagnostic tool for evaluating medical conditions within the abdominal cavity. Accurate determination of the relative locations of intra-abdominal organs and lesions based on anatomical features in ultrasound images is essential in diagnostic sonography. Recognizing and extracting anatomical landmarks facilitates lesion evaluation and enhances diagnostic interpretation. Recent artificial intelligence (AI) segmentation methods employing deep neural networks (DNNs) and transformers encounter computational efficiency challenges to balance the preservation of feature dependencies information with model efficiency, limiting their clinical applicability.MethodsThe anatomical structure recognition framework, MaskHybrid, was developed using a private dataset comprising 34,711 abdominal ultrasound images of 2,063 patients from CSMUH. The dataset included abdominal organs and vascular structures (hepatic vein, inferior vena cava, portal vein, gallbladder, kidney, pancreas, spleen) and liver lesions (hepatic cyst, tumor). MaskHybrid adopted a mamba-transformer hybrid architecture consisting of an evolved backbone network, encoder, and corresponding decoder to capture long-range spatial dependencies and contextual information effectively, demonstrating improved image segmentation capabilities in visual tasks while mitigating the computational burden associated with the transformer-based attention mechanism.ResultsExperiments on the retrospective dataset achieved a mean average precision (mAP) score of 74.13% for anatomical landmarks segmentation in abdominal ultrasound images. Our proposed framework outperformed baselines across most organ and lesion types and effectively segmented challenging anatomical structures. Moreover, MaskHybrid exhibited a significantly shorter inference time (0.120 ± 0.013 s), achieving 2.5 times faster than large-sized AI models of similar size. Combining Mamba and transformer architectures, this hybrid design was well-suited for the timely analysis of complex anatomical structures segmentation in abdominal ultrasonography, where accuracy and efficiency are critical in clinical practice.ConclusionThe proposed mamba-transformer hybrid recognition framework simultaneously detects and segments multiple abdominal organs and lesions in ultrasound images, achieving superior segmentation accuracy, visualization effect, and inference efficiency, thereby facilitating improved medical image interpretation and near real-time diagnostic sonography that meets clinical needs.",2025,10.3389/frai.2025.1618607
On Consensus-Optimality Trade-offs in Collaborative Deep Learning,"In distributed machine learning, where agents collaboratively learn from diverse private data sets, there is a fundamental tension between consensus and optimality. In this paper, we build on recent algorithmic progresses in distributed deep learning to explore various consensus-optimality trade-offs over a fixed communication topology. First, we propose the incremental consensus-based distributed stochastic gradient descent (i-CDSGD) algorithm, which involves multiple consensus steps (where each agent communicates information with its neighbors) within each SGD iteration. Second, we propose the generalized consensus-based distributed SGD (g-CDSGD) algorithm that enables us to navigate the full spectrum from complete consensus (all agents agree) to complete disagreement (each agent converges to individual model parameters). We analytically establish convergence of the proposed algorithms for strongly convex and nonconvex objective functions; we also analyze the momentum variants of the algorithms for the strongly convex case. We support our algorithms via numerical experiments, and demonstrate significant improvements over existing methods for collaborative deep learning.",2021,10.3389/frai.2021.573731
Reduction of Survey Sites in Dialectology: A New Methodology Based on Clustering,"Many language change studies aim for a partial revisitation, i.e., selecting survey sites from previous dialect studies. The central issue of survey site reduction, however, has often been addressed only qualitatively. Cluster analysis offers an innovative means of identifying the most representative survey sites among a set of original survey sites. In this paper, we present a general methodology for finding representative sites for an intended study, potentially applicable to any collection of data about dialects or linguistic variation. We elaborate the quantitative steps of the proposed methodology in the context of the “Linguistic Atlas of Japan” (LAJ). Next, we demonstrate the full application of the methodology on the “Linguistic Atlas of German-speaking Switzerland” (Germ.:“Sprachatlas der Deutschen Schweiz”—SDS), with the explicit aim of selecting survey sites corresponding to the aims of the current project “Swiss German Dialects Across Time and Space” (SDATS), which revisits SDS 70 years later. We find that depending on the circumstances and requirements of a study, the proposed methodology, introducing cluster analysis into the survey site reduction process, allows for a greater objectivity in comparison to traditional approaches. We suggest, however, that the suitability of any set of candidate survey sites resulting from the proposed methodology be rigorously revised by experts due to potential incongruences, such as the overlap of objectives and variables across the original and intended studies and ongoing dialect change.",2021,10.3389/frai.2021.642505
Reconstructing signal during brain stimulation with Stim-BERT: a self-supervised learning model trained on millions of iEEG files,"Brain stimulation has become a widely accepted treatment for neurological disorders such as epilepsy and Parkinson’s disease. These devices not only deliver therapeutic stimulation but also record brain activity, offering valuable insights into neural dynamics. However, brain recordings during stimulation are often blanked or contaminated by artifact, posing significant challenges for analyzing the acute effects of stimulation. To address these challenges, we propose a transformer-based model, Stim-BERT, trained on a large intracranial EEG (iEEG) dataset to reconstruct brain activity lost during stimulation blanking. To train the Stim-BERT model, 4,653,720 iEEG channels from 380 RNS system patients were tokenized into 3 (or 4) frequency band bins using 1 s non-overlapping windows resulting in a total vocabulary size of 1,000 (or 10,000). Stim-BERT leverages self-supervised learning with masked tokens, inspired by BERT’s success in natural language processing, and shows significant improvements over traditional interpolation methods, especially for longer blanking periods. These findings highlight the potential of transformer models for filling in missing time-series neural data, advancing neural signal processing and our efforts to understand the acute effects of brain stimulation.",2025,10.3389/frai.2025.1502504
Closed-Form Results for Prior Constraints in Sum-Product Networks,"Incorporating constraints is a major concern in probabilistic machine learning. A wide variety of problems require predictions to be integrated with reasoning about constraints, from modeling routes on maps to approving loan predictions. In the former, we may require the prediction model to respect the presence of physical paths between the nodes on the map, and in the latter, we may require that the prediction model respect fairness constraints that ensure that outcomes are not subject to bias. Broadly speaking, constraints may be probabilistic, logical or causal, but the overarching challenge is to determine if and how a model can be learnt that handles a declared constraint. To the best of our knowledge, treating this in a general way is largely an open problem. In this paper, we investigate how the learning of sum-product networks, a newly introduced and increasingly popular class of tractable probabilistic models, is possible with declared constraints. We obtain correctness results about the training of these models, by establishing a relationship between probabilistic constraints and the model's parameters.",2021,10.3389/frai.2021.644062
From data extraction to analysis: a comparative study of ELISE capabilities in scientific literature,"The exponential growth of scientific literature presents challenges for pharmaceutical, biotechnological, and Medtech industries, particularly in regulatory documentation, clinical research, and systematic reviews. Ensuring accurate data extraction, literature synthesis, and compliance with industry standards require AI tools that not only streamline workflows but also uphold scientific rigor. This study evaluates the performance of AI tools designed for bibliographic review, data extraction, and scientific synthesis, assessing their impact on decision-making, regulatory compliance, and research productivity. The AI tools assessed include general-purpose models like ChatGPT and specialized solutions such as ELISE (Elevated LIfe SciencEs), SciSpace/Typeset, Humata, and Epsilon. The evaluation is based on three main criteria: Extraction, Comprehension, and Analysis with Compliance and Traceability (ECACT) as additional dimensions. Human experts established reference benchmarks, while AI Evaluator models ensure objective performance measurement. The study introduces the ECACT score, a structured metric assessing AI reliability in scientific literature analysis, regulatory reporting and clinical documentation. Results demonstrate that ELISE consistently outperforms other AI tools, excelling in precise data extraction, deep contextual comprehension, and advanced content analysis. ELISE’s ability to generate traceable, well-reasoned insights makes it particularly well-suited for high-stakes applications such as regulatory affairs, clinical trials, and medical documentation, where accuracy, transparency, and compliance are paramount. Unlike other AI tools, ELISE provides expert-level reasoning and explainability, ensuring AI-generated insights align with industry best practices. ChatGPT is efficient in data retrieval but lacks precision in complex analysis, limiting its use in high-stakes decision-making. Epsilon, Humata, and SciSpace/Typeset exhibit moderate performance, with variability affecting their reliability in critical applications. In conclusion, while AI tools such as ELISE enhance literature review, regulatory writing, and clinical data interpretation, human oversight remains essential to validate AI outputs and ensure compliance with scientific and regulatory standards. For pharmaceutical, biotechnological, and Medtech industries, AI integration must strike a balance between automation and expert supervision to maintain data integrity, transparency, and regulatory adherence.",2025,10.3389/frai.2025.1587244
Automating updates for scoping reviews on the environmental drivers of human and animal diseases: a comparative analysis of AI methods,"Understanding the environmental factors that facilitate the occurrence and spread of infectious diseases in animals is crucial for risk prediction. As part of the H2020 Monitoring Outbreaks for Disease Surveillance in a Data Science Context (MOOD) project, scoping literature reviews have been conducted for various diseases. However, pathogens continuously mutate and generate variants with different sensitivities to these factors, necessitating regular updates to these reviews. In this paper, we propose to evaluate the potential benefits of artificial intelligence (AI) for updating such scoping reviews. We thus compare different combinations of AI methods for solving this task. These methods utilize generative large language models (LLMs) and lighter language models to automatically identify risk factors in scientific articles.",2025,10.3389/frai.2025.1526820
An improved Dijkstra cross-plane image encryption algorithm based on a chaotic system,"While encrypting information with color images, most encryption schemes treat color images as three different grayscale planes and encrypt each plane individually. These algorithms produce more duplicated operations and are less efficient because they do not properly account for the link between the various planes of color images. In addressing the issue, we propose a scheme that thoroughly takes into account the relationship between pixels across different planes in color images. First, we introduce a new 1D chaotic system. The performance analysis shows the system has good chaotic randomness. Next, we employ a shortest-path cross-plane scrambling algorithm that utilizes an enhanced Dijkstra algorithm. This algorithm effectively shuffles pixels randomly within each channel of a color image. To accomplish cross-plane diffusion, our approach is then integrated into the adaptive diffusion algorithm. The security analysis and simulation results demonstrate that the approach can tackle the issue of picture loss in telemedicine by encrypting color images without any loss of quality. Furthermore, the images we utilize are suitable for both standard RGB and medical images. They incorporate more secure and highly sensitive keys, robustly withstanding various typical ciphertext analysis attacks. This ensures a reliable solution for encrypting original images.",2024,10.3389/frai.2024.1394101
Evolving Musical Sight Reading Exercises Using Expert Models,"Sight reading skills are widely considered to be crucial for all musicians. However, given that sight reading involves playing sheet music without having seen it before, once an exercise has been completed by a student it can no longer be used as a sight reading exercise for them. In this paper we present a novel evolutionary algorithm for generating musical sight reading exercises in the Western art music tradition. Using models based on expert examples, the algorithm generates material suitable for practice which is both technically appropriate and aesthetically pleasing with respect to an instrument and difficulty level. This overcomes the resource constraint in using traditional practice exercises, which are exhausted quickly by students and teachers due to their limited quantity.",2021,10.3389/frai.2020.497530
Pattern recognition in SARS cases: insights from t-SNE and k-means clustering applied to COVID-19 symptomatology,"IntroductionDespite the end of the SARS-CoV-2 pandemic, the medical field continues to address several lasting effects, the most notable being long COVID. However, COVID-19 presents another specific challenge that complicates diagnosis: the similarity of its symptoms with those of other viral diseases, particularly among various SARS strains. This overlap makes it difficult to identify distinct and meaningful symptom patterns as they develop. This study proposes a dimensionality reduction approach combined with a clustering technique to visually analyse structural similarities among SARS-infected individuals, aiming to determine whether aspects such as case progression and diagnosis impact these patterns.MethodsThis analysis utilised the t-Distributed Stochastic Neighbour Embedding (t-SNE) algorithm for dimensionality reduction, combined with Gower's distance to handle categorical data, and k-means clustering. The study focused on symptoms, case progression, and diagnoses of SARS-CoV-2 and unspecified SARS cases using data from the Brazilian SARS dataset for São Paulo State during 2020 and 2021. The process began with a visual analysis aimed at identifying structural patterns in the symptom data, highlighting potential similarities between COVID-19 patients and those diagnosed with unspecified SARS. Following this, an intra-cluster analysis was performed to investigate the common features that defined each cluster, providing insights into shared characteristics among grouped individuals.ResultsThe analysis revealed that both diagnoses share substantial similarities, particularly in the presence or absence of COVID-19-related symptoms, even when the majority of individuals were diagnosed with unspecified SARS.DiscussionThe analysis is crucial, as Brazil was one of the countries most severely affected by the pandemic, experiencing profound impacts across multiple dimensions.",2025,10.3389/frai.2025.1536486
Artificial Interactionism: Avoiding Isolating Perception From Cognition in AI,"We discuss the influence upon the fields of robotics and AI of the manner one conceives the relationships between artificial agents' perception, cognition, and action. We shed some light upon a widespread paradigm we call theisolated perception paradigmthat addresses perception as isolated from cognition and action. By mobilizing the resources of philosophy (phenomenology and epistemology) and cognitive sciences, and by drawing on recent approaches in AI, we explore what it could mean for robotics and AI to take distance from the isolated perception paradigm. We argue that such a renouncement opens interesting ways to explore the possibilities for designing artificial agents with intrinsic motivations and constitutive autonomy. We then propose Artificial Interactionism, our approach that escapes the isolated perception paradigm by drawing on the inversion of the interaction cycle. When the interaction cycle is inverted, input data are not percepts directly received from the environment, but outcomes of control loops. Perception is not received from sensors in isolation from cognition but is actively constructed by the cognitive architecture through interaction. We give an example implementation of artificial interactionism that demonstrates basic intrinsically motivated learning behavior in a dynamic simulated environment.",2022,10.3389/frai.2022.806041
Identifying geopolitical event precursors using attention-based LSTMs,"Forecasting societal events such as civil unrest, mass protests, and violent conflicts is a challenging problem with several important real-world applications in planning and policy making. While traditional forecasting approaches have typically relied on historical time series for generating such forecasts, recent research has focused on using open source surrogate data for more accurate and timely forecasts. Furthermore, leveraging such data can also help to identify precursors of those events that can be used to gain insights into the generated forecasts. The key challenge is to develop a unified framework for forecasting and precursor identification that can deal with missing historical data. Other challenges include sufficient flexibility in handling different types of events and providing interpretable representations of identified precursors. Although existing methods exhibit promising performance for predictive modeling in event detection, these models do not adequately address the above challenges. Here, we propose a unified framework based on an attention-based long short-term memory (LSTM) model to simultaneously forecast events with sequential text datasets as well as identify precursors at different granularity such as documents and document excerpts. The key idea is to leverage word context in sequential and time-stamped documents such as news articles and blogs for learning a rich set of precursors. We validate the proposed framework by conducting extensive experiments with two real-world datasets—military action and violent conflicts in the Middle East and mass protests in Latin America. Our results show that overall, the proposed approach generates more accurate forecasts compared to the existing state-of-the-art methods, while at the same time producing a rich set of precursors for the forecasted events.",2022,10.3389/frai.2022.893875
Sentiment interpretability analysis on Chinese texts employing multi-task and knowledge base,"With the rapid development of deep learning techniques, the applications have become increasingly widespread in various domains. However, traditional deep learning methods are often referred to as “black box” models with low interpretability of their results, posing challenges for their application in certain critical domains. In this study, we propose a comprehensive method for the interpretability analysis of sentiment models. The proposed method encompasses two main aspects: attention-based analysis and external knowledge integration. First, we train the model within sentiment classification and generation tasks to capture attention scores from multiple perspectives. This multi-angle approach reduces bias and provides a more comprehensive understanding of the underlying sentiment. Second, we incorporate an external knowledge base to improve evidence extraction. By leveraging character scores, we retrieve complete sentiment evidence phrases, addressing the challenge of incomplete evidence extraction in Chinese texts. Experimental results on a sentiment interpretability evaluation dataset demonstrate the effectiveness of our method. We observe a notable increase in accuracy by 1.3%, Macro-F1 by 13%, and MAP by 23%. Overall, our approach offers a robust solution for enhancing the interpretability of sentiment models by combining attention-based analysis and the integration of external knowledge.",2024,10.3389/frai.2023.1104064
An intelligence coordination system toward creating the super-intelligent law firm,"A large law firm typically exhibits a collective intelligence comprised of hundreds or thousands of legal minds aimed at simultaneously engaging thousands of active matters across scores of industries and dozens of practice specialties with distinct doctrinal and procedural characteristics. The firm is challenged not only to achieve successful, cost-effective outcomes for its clients, but must also simultaneously, in competition with other firms and alternative service providers, attract and cultivate talent, develop and coordinate capabilities across multiple evolving areas of practice and continually improve a robust collective intelligence to gain a competitive edge. As various types of machine intelligences and tools are introduced, firms must also groom these into the collective. In this paper we explore a human-machine hybrid system for addressing this large scale, multi-dimensional, dynamic optimization challenge to coordinate a collective intelligence of humans and machines. Machine intelligence is needed to handle the computational complexity and it is complemented by human intelligence to help handle exceptions and novel situations. We believe this approach has potential for transforming the collective intelligence that is the large law firm.",2023,10.3389/frai.2023.1145308
Control Sequence Ranking for Critical System Based on Health of Equipment Thanks to Choquet Integral,This paper presents a ranking method of operating sequences based on the actual condition of complex systems. This objective is achieved using the health checkup concept and the multiattribute utility theory. Our contribution is the proposal of sequences ranking process using data and experts’ judgments. The ranking results in a decision-making element; it allows experts to have an objective and concise overall ranking to be used for decision making. A case study is presented based on an experimental platform; it allows us to compare two aggregation operators: the weighted mean and the Choquet integral.,2021,10.3389/frai.2020.614853
HMA-Net: a hybrid mixer framework with multihead attention for breast ultrasound image segmentation,"IntroductionBreast cancer is a severe illness predominantly affecting women, and in most cases, it leads to loss of life if left undetected. Early detection can significantly reduce the mortality rate associated with breast cancer. Ultrasound imaging has been widely used for effectively detecting the disease, and segmenting breast ultrasound images aid in the identification and localization of tumors, thereby enhancing disease detection accuracy. Numerous computer-aided methods have been proposed for the segmentation of breast ultrasound images.MethodsA deep learning-based architecture utilizing a ConvMixer-based encoder and ConvNeXT-based decoder coupled with convolution-enhanced multihead attention has been proposed for segmenting breast ultrasound images. The enhanced ConvMixer modules utilize spatial filtering and channel-wise integration to efficiently capture local and global contextual features, enhancing feature relevance and thus increasing segmentation accuracy through dynamic channel recalibration and residual connections. The bottleneck with the attention mechanism enhances segmentation by utilizing multihead attention to capture long-range dependencies, thus enabling the model to focus on relevant features across distinct regions. The enhanced ConvNeXT modules with squeeze and excitation utilize depthwise convolution for efficient spatial filtering, layer normalization for stabilizing training, and residual connections to ensure the preservation of relevant features for accurate segmentation. A combined loss function, integrating binary cross entropy and dice loss, is used to train the model.ResultsThe proposed model has an exceptional performance in segmenting intricate structures, as confirmed by comprehensive experiments conducted on two datasets, namely the breast ultrasound image dataset (BUSI) dataset and the BrEaST dataset of breast ultrasound images. The model achieved a Jaccard index of 98.04% and 94.84% and a Dice similarity coefficient of 99.01% and 97.35% on the BUSI and BrEaST datasets, respectively.DiscussionThe ConvMixer and ConvNeXT modules are integrated with convolution-enhanced multihead attention, which enhances the model's ability to capture local and global contextual information. The strong performance of the model on the BUSI and BrEaST datasets demonstrates the robustness and generalization capability of the model.",2025,10.3389/frai.2025.1572433
A brain-inspired memory transformation based differentiable neural computer for reasoning-based question answering,"Reasoning and question answering, as fundamental cognitive functions in humans, remain significant hurdles for artificial intelligence. While large language models (LLMs) have achieved notable success, integrating explicit memory with structured reasoning capabilities remains a persistent difficulty. The Differentiable Neural Computer (DNC) model, despite addressing these issues to some extent, still faces challenges such as algorithmic complexity, slow convergence, and limited robustness. Inspired by the brain's learning and memory mechanisms, this paper proposes a Memory Transformation based Differentiable Neural Computer (MT-DNC) model. The MT-DNC integrates two brain-inspired memory modules—a working memory module inspired by the cognitive system that temporarily holds and processes task-relevant information, and a long-term memory module that stores frequently accessed and enduring information—within the DNC framework, enabling the autonomous transformation of acquired experiences between these memory systems. This facilitates efficient knowledge extraction and enhances reasoning capabilities. Experimental results on the bAbI question answering task demonstrate that the proposed method outperforms existing Deep Neural Network (DNN) and DNC models, achieving faster convergence and superior performance. Ablation studies further confirm that the transformation of memory from working memory to long-term memory is critical for improving the robustness and stability of reasoning. This work offers new insights into incorporating brain-inspired memory mechanisms into dialogue and reasoning systems.",2025,10.3389/frai.2025.1635932
Configurations of human-centered AI at work: seven actor-structure engagements in organizations,"PurposeThe discourse on the human-centricity of AI at work needs contextualization. The aim of this study is to distinguish prevalent criteria of human-centricity for AI applications in the scientific discourse and to relate them to the work contexts for which they are specifically intended. This leads to configurations of actor-structure engagements that foster human-centricity in the workplace.Theoretical foundationThe study applies configurational theory to sociotechnical systems’ analysis of work settings. The assumption is that different approaches to promote human-centricity coexist, depending on the stakeholders responsible for their application.MethodThe exploration of criteria indicating human-centricity and their synthesis into configurations is based on a cross-disciplinary literature review following a systematic search strategy and a deductive-inductive qualitative content analysis of 101 research articles.ResultsThe article outlines eight criteria of human-centricity, two of which face challenges of human-centered technology development (trustworthiness and explainability), three challenges of human-centered employee development (prevention of job loss, health, and human agency and augmentation), and three challenges of human-centered organizational development (compensation of systems’ weaknesses, integration of user-domain knowledge, accountability, and safety culture). The configurational theory allows contextualization of these criteria from a higher-order perspective and leads to seven configurations of actor-structure engagements in terms of engagement for (1) data and technostructure, (2) operational process optimization, (3) operators’ employment, (4) employees’ wellbeing, (5) proficiency, (6) accountability, and (7) interactive cross-domain design. Each has one criterion of human-centricity in the foreground. Trustworthiness does not build its own configuration but is proposed to be a necessary condition in all seven configurations.DiscussionThe article contextualizes the overall debate on human-centricity and allows us to specify stakeholder-related engagements and how these complement each other. This is of high value for practitioners bringing human-centricity to the workplace and allows them to compare which criteria are considered in transnational declarations, international norms and standards, or company guidelines.",2023,10.3389/frai.2023.1272159
"Theory of Mind and Preference Learning at the Interface of Cognitive Science, Neuroscience, and AI: A Review","Theory of Mind (ToM)—the ability of the human mind to attribute mental states to others—is a key component of human cognition. In order to understand other people's mental states or viewpoint and to have successful interactions with others within social and occupational environments, this form of social cognition is essential. The same capability of inferring human mental states is a prerequisite for artificial intelligence (AI) to be integrated into society, for example in healthcare and the motoring industry. Autonomous cars will need to be able to infer the mental states of human drivers and pedestrians to predict their behavior. In the literature, there has been an increasing understanding of ToM, specifically with increasing cognitive science studies in children and in individuals with Autism Spectrum Disorder. Similarly, with neuroimaging studies there is now a better understanding of the neural mechanisms that underlie ToM. In addition, new AI algorithms for inferring human mental states have been proposed with more complex applications and better generalisability. In this review, we synthesize the existing understanding of ToM in cognitive and neurosciences and the AI computational models that have been proposed. We focus on preference learning as an area of particular interest and the most recent neurocognitive and computational ToM models. We also discuss the limitations of existing models and hint at potential approaches to allow ToM models to fully express the complexity of the human mind in all its aspects, including values and preferences.",2022,10.3389/frai.2022.778852
Crowdsourcing Team Formation With Worker-Centered Modeling,"Modern crowdsourcing offers the potential to produce solutions for increasingly complex tasks requiring teamwork and collective labor. However, the vast scale of the crowd makes forming project teams an intractable problem to coordinate manually. To date, most crowdsourcing collaborative platforms rely on algorithms to automate team formation based on worker profiling data and task objectives. As a top-down strategy, algorithmic crowd team formation tends to alienate workers causing poor collaboration, interpersonal clashes, and dissatisfaction. In this paper, we investigate different ways that crowd teams can be formed through three team formation models namely bottom-up, top-down, and hybrid. By simulating an open collaboration scenario such as a hackathon, we observe that the bottom-up model forms the most competitive teams with the highest teamwork quality. Furthermore, we note that bottom-up approaches are particularly suitable for populations with high-risk appetites (most workers being lenient toward exploring new team configurations) and high degrees of homophily (most workers preferring to work with similar teammates). Our study highlights the importance of integrating worker agency in algorithm-mediated team formation systems, especially in collaborative/competitive settings, and bears practical implications for large-scale crowdsourcing platforms.",2022,10.3389/frai.2022.818562
Mortality prediction of heart transplantation using machine learning models: a systematic review and meta-analysis,"IntroductionMachine learning (ML) models have been increasingly applied to predict post-heart transplantation (HT) mortality, aiming to improve decision-making and optimize outcomes. This systematic review and meta-analysis evaluates the performance of ML algorithms in predicting mortality and explores factors contributing to model accuracy.MethodA systematic search of PubMed, Scopus, Web of Science, and Embase identified relevant studies, with 17 studies included in the review and 12 in the meta-analysis. The algorithms assessed included random forests, CatBoost, neural networks, and others. Model performance was evaluated using pooled area under the curve (AUC) values, with subgroup analyses for algorithm type, validation methods, and prediction timeframes. The risk of bias was assessed using the QUADAS-2 tool.ResultsThe pooled AUC of all ML algorithms was 0.65 (95% CI: 0.64, 0.67), with no significant difference between machine learning and deep learning models (p = 0.67). Among the algorithms, CatBoost demonstrated the highest accuracy (AUC 0.80, 95% CI: 0.74, 0.86), while K-nearest neighbor had the lowest accuracy (AUC 0.53, 95% CI: 0.50, 0.55). A meta-regression indicated improved model performance with longer post-transplant periods (p = 0.008). When pooling only the best-performing models, the AUC improved to 0.73 (95% CI: 0.68, 0.78). The risk of bias was high in eight studies, with the flow and timing domains most commonly contributing to bias.ConclusionML models demonstrate moderate accuracy in predicting post-HT mortality, with CatBoost achieving the best performance. While ML shows potential for improving predictive precision, significant heterogeneity and biases highlight the need for standardized methods and further external validations to enhance clinical applicability.Systematic review registrationhttps://www.crd.york.ac.uk/PROSPERO/view/CRD42024509630, CRD42024509630",2025,10.3389/frai.2025.1551959
How systemic cognition enables epistemic engineering,"Epistemic engineering arises as systems and their parts develop functionality that is construed as valid knowledge. By hypothesis, epistemic engineering is a basic evolutionary principle. It ensures that not only living systems identify the differences that make differences but also ensure that distributed control enables them to construct epistemic change. In tracking such outcomes in human life, we stress that humans act within poly-centered, distributed systems. Similar to how people can act as inert parts of a system, they also actively bring forth intents and vicariant effects. Human cognitive agents use the systemic function to construct epistemic novelties. In the illustration, we used a published experimental study of a cyborg cockroach to consider how an evoneered system enables a human subject to perform as an adaptor with some “thought control” over the animal. Within a wide system, brains enable the techniques to arise ex novo as they attune to the dictates of a device. Human parts act as adaptors that simplify the task. In scaling up, we turn to a case of organizational cognition. We track how adaptor functions spread when drone-based data are brought to the maintenance department of a Danish utility company. While pivoting on how system operators combine experience with the use of software, their expertise sets off epistemically engineered results across the company and beyond. Vicariant effects emerge under the poly-centered control of brains, persons, equipment, and institutional wholes. As a part of culture, epistemic engineering works by reducing entropy.",2023,10.3389/frai.2022.960384
Prediction of mental effort derived from an automated vocal biomarker using machine learning in a large-scale remote sample,"IntroductionBiomarkers of mental effort may help to identify subtle cognitive impairments in the absence of task performance deficits. Here, we aim to detect mental effort on a verbal task, using automated voice analysis and machine learning.MethodsAudio data from the digit span backwards task were recorded and scored with automated speech recognition using the online platform NeuroVocalixTM, yielding usable data from 2,764 healthy adults (1,022 male, 1,742 female; mean age 31.4 years). Acoustic features were aggregated across each trial and normalized within each subject. Cognitive load was dichotomized for each trial by categorizing trials at &gt;0.6 of each participants' maximum span as “high load.” Data were divided into training (60%), test (20%), and validate (20%) datasets, each containing different participants. Training and test data were used in model building and hyper-parameter tuning. Five classification models (Logistic Regression, Naive Bayes, Support Vector Machine, Random Forest, and Gradient Boosting) were trained to predict cognitive load (“high” vs. “low”) based on acoustic features. Analyses were limited to correct responses. The model was evaluated using the validation dataset, across all span lengths and within the subset of trials with a four-digit span. Classifier discriminant power was examined with Receiver Operating Curve (ROC) analysis.ResultsParticipants reached a mean span of 6.34 out of 8 items (SD = 1.38). The Gradient Boosting classifier provided the best performing model on test data (AUC = 0.98) and showed excellent discriminant power for cognitive load on the validation dataset, across all span lengths (AUC = 0.99), and for four-digit only utterances (AUC = 0.95).DiscussionA sensitive biomarker of mental effort can be derived from vocal acoustic features in remotely administered verbal cognitive tests. The use-case of this biomarker for improving sensitivity of cognitive tests to subtle pathology now needs to be examined.",2023,10.3389/frai.2023.1171652
Understanding heterogeneity of investor sentiment on social media: A structural topic modeling approach,"Investors nowadays post heterogeneous sentiments on social media about financial assets based on their trading preferences. However, existing works typically analyze the sentiment by its content only and do not account for investor profiles and trading preferences in different types of assets. This paper explicitly considers how investor sentiment about financial market events is shaped by the relative discussions of different types of investors. We leverage a large-scale financial social media dataset and employ a structural topic modeling approach to extract topical contents of investor sentiment across multiple finance-specific factors. The identified topics reveal important events related to the financial market and show strong heterogeneity in the social media content in terms of compositions of investor profiles, asset categories, and bullish/bearish sentiment. Results show that investors with different profiles and trading preferences tend to discuss financial markets with heterogeneous beliefs, leading to divergent opinions about those events regarding the topic prevalence and proportion. Moreover, our findings may shed light on the mechanism that underlies the efficient investor sentiment extraction and aggregation while considering the heterogeneity of investor sentiment across different dimensions.",2022,10.3389/frai.2022.884699
Analysis of argument structure constructions in the large language model BERT,"Understanding how language and linguistic constructions are processed in the brain is a fundamental question in cognitive computational neuroscience. In this study, we investigate the processing and representation of Argument Structure Constructions (ASCs) in the BERT language model, extending previous analyses conducted with Long Short-Term Memory (LSTM) networks. We utilized a custom GPT-4 generated dataset comprising 2000 sentences, evenly distributed among four ASC types: transitive, ditransitive, caused-motion, and resultative constructions. BERT was assessed using the various token embeddings across its 12 layers. Our analyses involved visualizing the embeddings with Multidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding (t-SNE), and calculating the Generalized Discrimination Value (GDV) to quantify the degree of clustering. We also trained feedforward classifiers (probes) to predict construction categories from these embeddings. Results reveal that CLS token embeddings cluster best according to ASC types in layers 2, 3, and 4, with diminished clustering in intermediate layers and a slight increase in the final layers. Token embeddings for DET and SUBJ showed consistent intermediate-level clustering across layers, while VERB embeddings demonstrated a systematic increase in clustering from layer 1 to 12. OBJ embeddings exhibited minimal clustering initially, which increased substantially, peaking in layer 10. Probe accuracies indicated that initial embeddings contained no specific construction information, as seen in low clustering and chance-level accuracies in layer 1. From layer 2 onward, probe accuracies surpassed 90 percent, highlighting latent construction category information not evident from GDV clustering alone. Additionally, Fisher Discriminant Ratio (FDR) analysis of attention weights revealed that OBJ tokens had the highest FDR scores, indicating they play a crucial role in differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS, and SEP tokens did not show significant FDR scores. Our study underscores the complex, layered processing of linguistic constructions in BERT, revealing both similarities and differences compared to recurrent models like LSTMs. Future research will compare these computational findings with neuroimaging data during continuous speech perception to better understand the neural correlates of ASC processing. This research demonstrates the potential of both recurrent and transformer-based neural language models to mirror linguistic processing in the human brain, offering valuable insights into the computational and neural mechanisms underlying language understanding.",2025,10.3389/frai.2025.1477246
Multitask connected U-Net: automatic lung cancer segmentation from CT images using PET knowledge guidance,"Lung cancer is a predominant cause of cancer-related mortality worldwide, necessitating precise tumor segmentation of medical images for accurate diagnosis and treatment. However, the intrinsic complexity and variability of tumor morphology pose substantial challenges to segmentation tasks. To address this issue, we propose a multitask connected U-Net model with a teacher-student framework to enhance the effectiveness of lung tumor segmentation. The proposed model and framework integrate PET knowledge into the segmentation process, leveraging complementary information from both CT and PET modalities to improve segmentation performance. Additionally, we implemented a tumor area detection method to enhance tumor segmentation performance. In extensive experiments on four datasets, the average Dice coefficient of 0.56, obtained using our model, surpassed those of existing methods such as Segformer (0.51), Transformer (0.50), and UctransNet (0.43). These findings validate the efficacy of the proposed method in lung tumor segmentation tasks.",2024,10.3389/frai.2024.1423535
Transforming cataract care through artificial intelligence: an evaluation of large language models’ performance in addressing cataract-related queries,"PurposeTo evaluate the performance of five popular large language models (LLMs) in addressing cataract-related queries.MethodsThis comparative evaluation study was conducted at the Eye and ENT Hospital of Fudan University. We performed both qualitative and quantitative assessments of responses from five LLMs: ChatGPT-4, ChatGPT-4o, Gemini, Copilot, and the open-source Llama 3.5. Model outputs were benchmarked against human-generated responses using seven key metrics: accuracy, completeness, conciseness, harmlessness, readability, stability, and self-correction capability. Additional inter-model comparisons were performed across question subgroups categorized by clinical topic type.ResultsIn the information quality assessment, ChatGPT-4o demonstrated the best performance across most metrics, including accuracy score (6.70 ± 0.63), completeness score (4.63 ± 0.63), and harmlessness score (3.97 ± 0.17). Gemini achieved the highest conciseness score (4.00 ± 0.14). Further subgroup analysis showed that all LLMs performed comparably to or better than humans, regardless of the type of question posed. The readability assessment revealed that ChatGPT-4o had the lowest readability score (26.02 ± 10.78), indicating the highest level of reading difficulty. While Copilot recorded a higher readability score (40.26 ± 14.58) than the other LLMs, it still remained lower than that of humans (51.54 ± 13.71). Copilot also exhibited the best stability in reproducibility and stability assessment. All LLMs demonstrated strong self-correction capability when prompted.ConclusionOur study suggested that LLMs exhibited considerable potential in providing accurate and comprehensive responses to common cataract-related clinical issues. Notably, ChatGPT-4o achieved the best scores in accuracy, completeness, and harmlessness. Despite these promising results, clinicians and patients should be aware of the limitations of artificial intelligence (AI) to ensure critical evaluation in clinical practice.",2025,10.3389/frai.2025.1639221
Recognizing protected and anthropogenic patterns in landscapes using interpretable machine learning and satellite imagery,"The accurate and comprehensive mapping of land cover has become a central task in modern environmental research, with increasing emphasis on machine learning approaches. However, a clear technical definition of the land cover class is a prerequisite for learning and applying a machine learning model. One of the challenging classes is naturalness and human influence, yet mapping it is important due to its critical role in biodiversity conservation, habitat assessment, and climate change monitoring. We present an interpretable machine learning approach to map patterns related to territorial protected and anthropogenic areas as proxies of naturalness and human influence using satellite imagery. To achieve this, we train a weakly-supervised convolutional neural network and subsequently apply attribution methods such as Grad-CAM and occlusion sensitivity mapping. We propose a novel network architecture that consists of an image-to-image network and a shallow, task-specific head. Both sub-networks are connected by an intermediate layer that captures high-level features in full resolution, allowing for detailed analysis with a wide range of attribution methods. We further analyze how intermediate layer activations relate to their attributions across the training dataset to establish a consistent relationship. This makes attributions consistent across different scenes and allows for a large-scale analysis of remote sensing data. The results highlight that our approach is a promising way to observe and assess naturalness and territorial protection.",2023,10.3389/frai.2023.1278118
Prediction of PD-L1 tumor positive score in lung squamous cell carcinoma with H&amp;E staining images and deep learning,"BackgroundDetecting programmed death ligand 1 (PD-L1) expression based on immunohistochemical (IHC) staining is an important guide for the treatment of lung cancer with immune checkpoint inhibitors. However, this method has problems such as high staining costs, tumor heterogeneity, and subjective differences among pathologists. Therefore, the application of deep learning models to segment and quantitatively predict PD-L1 expression in digital sections of Hematoxylin and eosin (H&amp;E) stained lung squamous cell carcinoma is of great significance.MethodsWe constructed a dataset comprising H&amp;E-stained digital sections of lung squamous cell carcinoma and used a Transformer Unet (TransUnet) deep learning network with an encoder-decoder design to segment PD-L1 negative and positive regions and quantitatively predict the tumor cell positive score (TPS).ResultsThe results showed that the dice similarity coefficient (DSC) and intersection overunion (IoU) of deep learning for PD-L1 expression segmentation of H&amp;E-stained digital slides of lung squamous cell carcinoma were 80 and 72%, respectively, which were better than the other seven cutting-edge segmentation models. The root mean square error (RMSE) of quantitative prediction TPS was 26.8, and the intra-group correlation coefficients with the gold standard was 0.92 (95% CI: 0.90–0.93), which was better than the consistency between the results of five pathologists and the gold standard.ConclusionThe deep learning model is capable of segmenting and quantitatively predicting PD-L1 expression in H&amp;E-stained digital sections of lung squamous cell carcinoma, which has significant implications for the application and guidance of immune checkpoint inhibitor treatments. And the link to the code is https://github.com/Baron-Huang/PD-L1-prediction-via-HE-image.",2024,10.3389/frai.2024.1452563
Zero-shot stance detection: Paradigms and challenges,"A major challenge in stance detection is the large (potentially infinite) and diverse set of stance topics. Collecting data for such a set is unrealistic due to both the expense of annotation and the continuous creation of new real-world topics (e.g., a new politician runs for office). Furthermore, stancetaking occurs in a wide range of languages and genres (e.g., Twitter, news articles). While zero-shot stance detection in English, where evaluation is on topics not seen during training, has received increasing attention, we argue that this attention should be expanded to multilingual and multi-genre settings. We discuss two paradigms for English zero-shot stance detection evaluation, as well as recent work in this area. We then discuss recent work on multilingual and multi-genre stance detection, which has focused primarily on non-zero-shot settings. We argue that this work should be expanded to multilingual and multi-genre zero-shot stance detection and propose best practices to systematize and stimulate future work in this direction. While domain adaptation techniques are well-suited for work in these settings, we argue that increased care should be taken to improve model explainability and to conduct robust evaluations, considering not only empirical generalization ability but also the understanding of complex language and inferences.",2023,10.3389/frai.2022.1070429
The effects of anthropomorphism and multimodal biometric authentication on the user experience of voice intelligence,"Voice intelligence is a revolutionary “zero-touch” type of human-machine interaction based on spoken language. There has been a recent increase in the number and variations of voice assistants and applications that help users to acquire information. The increased popularity of voice intelligence, however, has not been reflected in the customer value chain. Current research on the socio-technological aspects of human-technology interaction has emphasized the importance of anthropomorphism and user identification in the adoption of the technology. Prior research has also pointed out that user perception toward the technology is key to its adoption. Therefore, this research examines how anthropomorphism and multimodal biometric authentication influence the adoption of voice intelligence through user perception in the customer value chain. In this study we conducted a between-subjects online experiment. We designed a 2 × 2 factorial experiment by manipulating anthropomorphism and multimodal biometric authentication into four conditions, namelywithandwithouta combination of these two factors. Subjects were recruited from Amazon MTurk platform and randomly assigned to one of the four conditions. The results drawn from the empirical study showed a significant direct positive effect of anthropomorphism and multimodal biometric authentication on user adoption of voice intelligence in the customer value chain. Moreover, the effect of anthropomorphism is partially mediated by users' perceived ease of use, perceived usefulness, and perceived security risk. This research contributes to the existing literature on human-computer interaction and voice intelligence by empirically testing the simultaneous impact of anthropomorphism and biometric authentication on users' experience of the technology. The study also provides practitioners who wish to adopt voice intelligence in the commercial environment with insights into the user interface design.",2022,10.3389/frai.2022.831046
Transfer Across Different Machines by Transfer Function Estimation,"A digital twin is a promising evolving tool for prognostic health monitoring. However, in rotating machinery, the transfer function between the rotating components and the sensor distorts the vibration signal, hence, complicating the ability to apply a digital twin to new systems. This paper demonstrates the importance of estimating the transfer function for a successful transfer across different machines (TDM). Furthermore, there are few algorithms in the literature for transfer function estimation. The current algorithms can estimate the magnitude of the transfer function without its original phase. In this study, a new approach is presented that enables the estimation of the transfer function with its phase for a gear signal. The performance of the new algorithm is demonstrated by measured signals and by a simulated transfer function.",2022,10.3389/frai.2022.811073
"Artificial intelligence-, organoid-, and organ-on-chip-powered models to improve pre-clinical animal testing of vaccines and immunotherapeutics: potential, progress, and challenges","Vaccines and immunotherapies against infectious diseases and cancers have been a great success of the medical sciences over the last century. Pre-clinical testing in animal models has played a crucial role in the development of vaccines and immunotherapies, informing subsequent clinical trials. The current practices in pre-clinical animal model research must be approved by committees with strict policies and assessments on animal experiments including the “three Rs”: (1) Replacement, which assesses the scientific justification and rationale for using a live animal in biomedical research; (2) Reduction, which determines whether the number of animals required in an experiment is adequate to achieve scientifically valid results while reducing costs; and (3) Refinement, which ascertains that any given animal procedure will cause no to minimal pain or distress. The recent initiatives by the United States NIH and FDA to reduce or phase out animal testing in biomedical research underscore a growing interest in artificial Intelligence (AI), deep learning (DL), organoid, and organ-on-chip-powered models to slash the time and cost of preclinical animal research. This review highlights the strengths, progress, and limitations of these alternative pre-clinical research approaches, with a focus on vaccine and immunotherapeutic development. While the implementation of AI- and DL-, organoid-, and organ-on-chip-powered models will certainly help accelerate pre-clinical discoveries, modeling the safety, immunogenicity, and protective efficacy of vaccines and immunotherapeutics as they occur
                    in vivo
                    is not yet comprehensive enough to fully replace or replicate the complexity of living systems, in both animals and humans. Thus, these models should be viewed as powerful complementary tools that combine hybrid human and artificial intelligence and must be validated through animal model testing. This review discusses the path forward and the scientific challenges that persist in investing in AI- and DL-human hybrid validation systems, regulatory reforms, and the development of interconnected platforms that bridge digital models with biological reality.",2025,10.3389/frai.2025.1681106
Linking Linguistic and Geographic Distance in Four Semantic Domains: Computational Geo-Analyses of Internal and External Factors in a Dialect Continuum,"Dialectometry studies patterns of linguistic variation through correlations between geographic and aggregate measures of linguistic distance. However, aggregating smooths out the role of semantic characteristics, which have been shown to affect the distribution of lexical variants across dialects. Furthermore, although dialectologists have always been well-aware of other variables like population size, isolation and socio-demographic features, these characteristics are generally only included in dialectometric analyses afterwards for further interpretation of the results rather than as explanatory variables. This study showcases linear mixed-effects modelling as a method that is able to incorporate both language-external and language-internal factors as explanatory variables of linguistic variation in the Limburgish dialect continuum in Belgium and the Netherlands. Covering four semantic domains that vary in their degree of basic vs. cultural vocabulary and their degree of standardization, the study models linguistic distances using a combination of external (e.g., geographic distance, separation by water, population size) and internal (semantic density, salience) sources of variation. The results show that both external and internal factors contribute to variation, but that the exact role of each individual factor differs across semantic domains. These findings highlight the need to incorporate language-internal factors in studies on variation, as well as a need for more comprehensive analysis tools to help better understand its patterns.",2021,10.3389/frai.2021.668035
What is critical for human-centered AI at work? – Toward an interdisciplinary theory,"Human-centered artificial intelligence (HCAI) has gained momentum in the scientific discourse but still lacks clarity. In particular, disciplinary differences regarding the scope of HCAI have become apparent and were criticized, calling for a systematic mapping of conceptualizations—especially with regard to the work context. This article compares how human factors and ergonomics (HFE), psychology, human-computer interaction (HCI), information science, and adult education view HCAI and discusses their normative, theoretical, and methodological approaches toward HCAI, as well as the implications for research and practice. It will be argued that an interdisciplinary approach is critical for developing, transferring, and implementing HCAI at work. Additionally, it will be shown that the presented disciplines are well-suited for conceptualizing HCAI and bringing it into practice since they are united in one aspect: they all place the human being in the center of their theory and research. Many critical aspects for successful HCAI, as well as minimum fields of action, were further identified, such as human capability and controllability (HFE perspective), autonomy and trust (psychology and HCI perspective), learning and teaching designs across target groups (adult education perspective), as much as information behavior and information literacy (information science perspective). As such, the article lays the ground for a theory of human-centered interdisciplinary AI, i.e., the Synergistic Human-AI Symbiosis Theory (SHAST), whose conceptual framework and founding pillars will be introduced.",2023,10.3389/frai.2023.1257057
Emotional prompting amplifies disinformation generation in AI large language models,"IntroductionThe emergence of artificial intelligence (AI) large language models (LLMs), which can produce text that closely resembles human-written content, presents both opportunities and risks. While these developments offer significant opportunities for improving communication, such as in health-related crisis communication, they also pose substantial risks by facilitating the creation of convincing fake news and disinformation. The widespread dissemination of AI-generated disinformation adds complexity to the existing challenges of the ongoing infodemic, significantly affecting public health and the stability of democratic institutions.RationalePrompt engineering is a technique that involves the creation of specific queries given to LLMs. It has emerged as a strategy to guide LLMs in generating the desired outputs. Recent research shows that the output of LLMs depends on emotional framing within prompts, suggesting that incorporating emotional cues into prompts could influence their response behavior. In this study, we investigated how the politeness or impoliteness of prompts affects the frequency of disinformation generation by various LLMs.ResultsWe generated and evaluated a corpus of 19,800 social media posts on public health topics to assess the disinformation generation capabilities of OpenAI’s LLMs, including davinci-002, davinci-003, gpt-3.5-turbo, and gpt-4. Our findings revealed that all LLMs efficiently generated disinformation (davinci-002, 67%; davinci-003, 86%; gpt-3.5-turbo, 77%; and gpt-4, 99%). Introducing polite language to prompt requests yielded significantly higher success rates for disinformation (davinci-002, 79%; davinci-003, 90%; gpt-3.5-turbo, 94%; and gpt-4, 100%). Impolite prompting resulted in a significant decrease in disinformation production across all models (davinci-002, 59%; davinci-003, 44%; and gpt-3.5-turbo, 28%) and a slight reduction for gpt-4 (94%).ConclusionOur study reveals that all tested LLMs effectively generate disinformation. Notably, emotional prompting had a significant impact on disinformation production rates, with models showing higher success rates when prompted with polite language compared to neutral or impolite requests. Our investigation highlights that LLMs can be exploited to create disinformation and emphasizes the critical need for ethics-by-design approaches in developing AI technologies. We maintain that identifying ways to mitigate the exploitation of LLMs through emotional prompting is crucial to prevent their misuse for purposes detrimental to public health and society.",2025,10.3389/frai.2025.1543603
AI Systems and Respect for Human Autonomy,"This study concerns the sociotechnical bases of human autonomy. Drawing on recent literature on AI ethics, philosophical literature on dimensions of autonomy, and on independent philosophical scrutiny, we first propose a multi-dimensional model of human autonomy and then discuss how AI systems can support or hinder human autonomy. What emerges is a philosophically motivated picture of autonomy and of the normative requirements personal autonomy poses in the context of algorithmic systems. Ranging from consent to data collection and processing, to computational tasks and interface design, to institutional and societal considerations, various aspects related to sociotechnical systems must be accounted for in order to get the full picture of potential effects of AI systems on human autonomy. It is clear how human agents can, for example, via coercion or manipulation, hinder each other’s autonomy, or how they can respect each other’s autonomy. AI systems can promote or hinder human autonomy, but can they literally respect or disrespect a person’s autonomy? We argue for a philosophical view according to which AI systems—while not moral agents or bearers of duties, and unable to literally respect or disrespect—are governed by so-called “ought-to-be norms.” This explains the normativity at stake with AI systems. The responsible people (designers, users, etc.) have duties and ought-to-do norms, which correspond to these ought-to-be norms.",2021,10.3389/frai.2021.705164
"Patient-centric knowledge graphs: a survey of current methods, challenges, and applications","Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in healthcare that focuses on individualized patient care by mapping the patient’s health information holistically and multi-dimensionally. PCKGs integrate various types of health data to provide healthcare professionals with a comprehensive understanding of a patient’s health, enabling more personalized and effective care. This literature review explores the methodologies, challenges, and opportunities associated with PCKGs, focusing on their role in integrating disparate healthcare data and enhancing patient care through a unified health perspective. In addition, this review also discusses the complexities of PCKG development, including ontology design, data integration techniques, knowledge extraction, and structured representation of knowledge. It highlights advanced techniques such as reasoning, semantic search, and inference mechanisms essential in constructing and evaluating PCKGs for actionable healthcare insights. We further explore the practical applications of PCKGs in personalized medicine, emphasizing their significance in improving disease prediction and formulating effective treatment plans. Overall, this review provides a foundational perspective on the current state-of-the-art and best practices of PCKGs, guiding future research and applications in this dynamic field.",2024,10.3389/frai.2024.1388479
Machine learning-based prediction of hospital prolonged length of stay admission at emergency department: a Gradient Boosting algorithm analysis,"ObjectiveThis study aims to develop and compare different models to predict the Length of Stay (LoS) and the Prolonged Length of Stay (PLoS) of inpatients admitted through the emergency department (ED) in general patient settings. This aim is not only to promote any specific model but rather to suggest a decision-supporting tool (i.e., a prediction framework).MethodsWe analyzed a dataset of patients admitted through the ED to the “Sant”Orsola Malpighi University Hospital of Bologna, Italy, between January 1 and October 26, 2022. PLoS was defined as any hospitalization with LoS longer than 6 days. We deployed six classification algorithms for predicting PLoS: Random Forest (RF), Support Vector Machines (SVM), Gradient Boosting (GB), AdaBoost, K-Nearest Neighbors (KNN), and logistic regression (LoR). We evaluated the performance of these models with the Brier score, the area under the ROC curve (AUC), accuracy, sensitivity (recall), specificity, precision, and F1-score. We further developed eight regression models for LoS prediction: Linear Regression (LR), including the penalized linear models Least Absolute Shrinkage and Selection Operator (LASSO), Ridge and Elastic-net regression, Support vector regression, RF regression, KNN, and eXtreme Gradient Boosting (XGBoost) regression. The model performances were measured by their mean square error, mean absolute error, and mean relative error. The dataset was randomly split into a training set (70%) and a validation set (30%).ResultsA total of 12,858 eligible patients were included in our study, of whom 60.88% had a PloS. The GB classifier best predicted PloS (accuracy 75%, AUC 75.4%, Brier score 0.181), followed by LoR classifier (accuracy 75%, AUC 75.2%, Brier score 0.182). These models also showed to be adequately calibrated. Ridge and XGBoost regressions best predicted LoS, with the smallest total prediction error. The overall prediction error is between 6 and 7 days, meaning there is a 6–7 day mean difference between actual and predicted LoS.ConclusionOur results demonstrate the potential of machine learning-based methods to predict LoS and provide valuable insights into the risks behind prolonged hospitalizations. In addition to physicians' clinical expertise, the results of these models can be utilized as input to make informed decisions, such as predicting hospitalizations and enhancing the overall performance of a public healthcare system.",2023,10.3389/frai.2023.1179226
A hybrid model of complexity estimation: Evidence from Russian legal texts,"This article proposes a hybrid model for the estimation of the complexity of legal documents in Russian. The model consists of two main modules: linguistic feature extractor and a transformer-based neural encoder. The set of linguistic metrics includes both non-specific metrics traditionally used to predict complexity, as well as style-specific metrics developed in order to deal with the peculiarities of official texts. The model was trained on a dataset constructed from text sequences from Russian textbooks. Training data were collected on either subjects related to the topic of legal documents such as Jurisprudence, Economics, Social Sciences, or subjects characterized by the use of general languages such as Literature, History, and Culturology. The final set of materials used contain 48 thousand selected text blocks having various subjects and level-of-complexity identifiers. We have tested the baseline fine-tuned BERT model, models trained on linguistic features, and models trained on features in combination with BERT predictions. The scores show that a hybrid approach to complexity estimation can provide high-quality results in terms of different metrics. The model has been tested on three sets of legal documents.",2022,10.3389/frai.2022.1008530
A survey on the role of artificial intelligence in managing Long COVID,"In the last years, several techniques of artificial intelligence have been applied to data from COVID-19. In addition to the symptoms related to COVID-19, many individuals with SARS-CoV-2 infection have described various long-lasting symptoms, now termed Long COVID. In this context, artificial intelligence techniques have been utilized to analyze data from Long COVID patients in order to assist doctors and alleviate the considerable strain on care and rehabilitation facilities. In this paper, we explore the impact of the machine learning methodologies that have been applied to analyze the many aspects of Long COVID syndrome, from clinical presentation through diagnosis. We also include the text mining techniques used to extract insights and trends from large amounts of text data related to Long COVID. Finally, we critically compare the various approaches and outline the work that has to be done to create a robust artificial intelligence approach for efficient diagnosis and treatment of Long COVID.",2024,10.3389/frai.2023.1292466
Co-Inference of Data Mislabelings Reveals Improved Models in Genomics and Breast Cancer Diagnostics,"Mislabeling of cases as well as controls in case–control studies is a frequent source of strong bias in prognostic and diagnostic tests and algorithms. Common data processing methods available to the researchers in the biomedical community do not allow for consistent and robust treatment of labeled data in the situations where both, the case and the control groups, contain a non-negligible proportion of mislabeled data instances. This is an especially prominent issue in studies regarding late-onset conditions, where individuals who may convert to cases may populate the control group, and for screening studies that often have high false-positive/-negative rates. To address this problem, we propose a method for a simultaneous robust inference of Lasso reduced discriminative models and of latent group-specific mislabeling risks, not requiring any exactly labeled data. We apply it to a standard breast cancer imaging dataset and infer the mislabeling probabilities (being rates of false-negative and false-positive core-needle biopsies) together with a small set of simple diagnostic rules, outperforming the state-of-the-art BI-RADS diagnostics on these data. The inferred mislabeling rates for breast cancer biopsies agree with the published purely empirical studies. Applying the method to human genomic data from a healthy-ageing cohort reveals a previously unreported compact combination of single-nucleotide polymorphisms that are strongly associated with a healthy-ageing phenotype for Caucasians. It determines that 7.5% of Caucasians in the 1000 Genomes dataset (selected as a control group) carry a pattern characteristic of healthy ageing.",2022,10.3389/frai.2021.739432
Accurate V2X traffic prediction with deep learning architectures,"Vehicle-to-Everything (V2X) communication promises to revolutionize road safety and efficiency. However, challenges in data sharing and network reliability impede its full realization. This paper addresses these challenges by proposing a novel Deep Learning (DL) approach for traffic prediction in V2X environments. We employ Bidirectional Long Short-Term Memory (BiLSTM) networks and compare their performance against other prominent DL architectures, including unidirectional LSTM and Gated Recurrent Unit (GRU). Our findings demonstrate that the BiLSTM model exhibits superior accuracy in predicting traffic patterns. This enhanced prediction capability enables more efficient resource allocation, improved network performance, and enhanced safety for all road users, reducing fuel consumption, decreased emissions, and a more sustainable transportation system.",2025,10.3389/frai.2025.1565287
AI-Based Estimation of End-Systolic Elastance From Arm-Pressure and Systolic Time Intervals,"Left ventricular end-systolic elastance (Ees) is a major determinant of cardiac systolic function and ventricular-arterial interaction. Previous methods for the Ees estimation require the use of the echocardiographic ejection fraction (EF). However, given that EF expresses the stroke volume as a fraction of end-diastolic volume (EDV), accurate interpretation of EF is attainable only with the additional measurement of EDV. Hence, there is still need for a simple, reliable, noninvasive method to estimate Ees. This study proposes a novel artificial intelligence—based approach to estimate Ees using the information embedded in clinically relevant systolic time intervals, namely the pre-ejection period (PEP) and ejection time (ET). We developed a training/testing scheme using virtual subjects (n = 4,645) from a previously validated in-silico model. Extreme Gradient Boosting regressor was employed to model Ees using as inputs arm cuff pressure, PEP, and ET. Results showed that Ees can be predicted with high accuracy achieving a normalized RMSE equal to 9.15% (r = 0.92) for a wide range of Ees values from 1.2 to 4.5 mmHg/ml. The proposed model was found to be less sensitive to measurement errors (±10–30% of the actual value) in blood pressure, presenting low test errors for the different levels of noise (RMSE did not exceed 0.32 mmHg/ml). In contrast, a high sensitivity was reported for measurements errors in the systolic timing features. It was demonstrated that Ees can be reliably estimated from the traditional arm-pressure and echocardiographic PEP and ET. This approach constitutes a step towards the development of an easy and clinically applicable method for assessing left ventricular systolic function.",2021,10.3389/frai.2021.579541
Using machine learning models to predict post-revascularization thrombosis in PAD,"BackgroundGraft/ stent thrombosis after lower extremity revascularization (LER) is a serious complication in patients with peripheral arterial disease (PAD), often leading to amputation. Thus, predicting arterial thrombotic events (ATE) within 1 year is crucial. Given the high rates of thrombosis post-revascularization, this study aimed to develop a machine learning model (MLM) incorporating viscoelastic testing and patient-specific variables to predict ATE following LER.MethodsWe prospectively enrolled PAD patients undergoing LER from 2020 to 2024, collecting demographic, clinical, and intervention-related data alongside perioperative thromboelastography with platelet mapping (TEG-PM) values over 12 months post-revascularization. Univariate analysis identified predictors from 52 candidate variables. Multiple MLMs, including logistic regression, XGBoost, and decision tree algorithms, were developed and evaluated using a 70–30 train-test split and five-fold cross-validation. The Synthetic Minority Oversampling Technique (SMOTE) was employed to address the class imbalance between the primary outcomes (ATE vs. no ATE). Model performance was assessed by area under the curve (AUC), accuracy, sensitivity, specificity, negative predictive value, and positive predictive value.ResultsOf the 308 patients analyzed, 66% were male, 84% were White, and 18.3% experienced an ATE during the one-year post-revascularization follow-up period. The logistic regression MLM demonstrated the best combined descriptive and calibration performance, especially when TEG-PM parameters were used in combination with patient-specific baseline characteristics, with an AUC of 0.76, classification accuracy of 70%, sensitivity of 68%, and specificity of 71%.ConclusionCombining patient-specific characteristics with TEG-PM values in MLMs can effectively predict ATE following LER in PAD patients, enhancing high-risk patient identification and enabling tailored thromboprophylaxis.",2025,10.3389/frai.2025.1540503
Using synthetic dataset for semantic segmentation of the human body in the problem of extracting anthropometric data,"BackgroundThe COVID-19 pandemic highlighted the need for accurate virtual sizing in e-commerce to reduce returns and waste. Existing methods for extracting anthropometric data from images have limitations. This study aims to develop a semantic segmentation model trained on synthetic data that can accurately determine body shape from real images, accounting for clothing.MethodsA synthetic dataset of over 22,000 images was created using NVIDIA Omniverse Replicator, featuring human models in various poses, clothing, and environments. Popular CNN architectures (U-Net, SegNet, DeepLabV3, PSPNet) with different backbones were trained on this dataset for semantic segmentation. Models were evaluated on accuracy, precision, recall, and IoU metrics. The best performing model was tested on real human subjects and compared to actual measurements.ResultsU-Net with EfficientNet backbone showed the best performance, with 99.83% training accuracy and 0.977 IoU score. When tested on real images, it accurately segmented body shape while accounting for clothing. Comparison with actual measurements on 9 subjects showed average deviations of −0.24 cm for neck, −0.1 cm for shoulder, 1.15 cm for chest, −0.22 cm for thallium, and 0.17 cm for hip measurements.DiscussionThe synthetic dataset and trained models enable accurate extraction of anthropometric data from real images while accounting for clothing. This approach has significant potential for improving virtual fitting and reducing returns in e-commerce. Future work will focus on refining the algorithm, particularly for thallium and hip measurements which showed higher variability.",2024,10.3389/frai.2024.1336320
Explainable machine learning for predicting recurrence-free survival in endometrial carcinosarcoma patients,"ObjectivesEndometrial carcinosarcoma is a rare, aggressive high-grade endometrial cancer, accounting for about 5% of all uterine cancers and 15% of deaths from uterine cancers. The treatment can be complex, and the prognosis is poor. Its increasing incidence underscores the urgent requirement for personalized approaches in managing such challenging diseases.MethodIn this work, we designed an explainable machine learning approach to predict recurrence-free survival in patients affected by endometrial carcinosarcoma. For this purpose, we exploited the predictive power of clinical and histopathological data, as well as chemotherapy and surgical information collected for a cohort of 80 patients monitored over time. Among these patients, 32.5% have experienced the appearance of a recurrence.ResultsThe designed model was able to well describe the observed sequence of events, providing a reliable ranking of the survival times based on the individual risk scores, and achieving a C-index equals to 70.00% (95% CI, 59.38–84.74).ConclusionAccordingly, machine learning methods could support clinicians in discriminating between endometrial carcinosarcoma patients at low-risk or high-risk of recurrence, in a non-invasive and inexpensive way. To the best of our knowledge, this is the first study proposing a preliminary approach addressing this task.",2024,10.3389/frai.2024.1388188
From digital traces to public vaccination behaviors: leveraging large language models for big data classification,"IntroductionThe current study leverages large language models (LLMs) to capture health behaviors expressed in social media posts, focusing on COVID-19 vaccine-related content from 2020 to 2021.MethodsTo examine the capabilities of prompt engineering and fine-tuning approaches with LLMs, this study examines the performance of three state-of-the-art LLMs: GPT-4o, GPT-4o-mini, and GPT-4o-mini with fine-tuning, focusing on their ability to classify individuals’ vaccination behavior, intention to vaccinate, and information sharing. We then cross-validate these classifications with nationwide vaccination statistics to assess alignment with observed trends.ResultsGPT-4o-mini with fine-tuning outperformed both GPT-4o and the standard GPT-4o-mini in terms of accuracy, precision, recall, and F1 score. Using GPT-4o-mini with fine-tuning for classification, about 9.84% of the posts (N = 36,912) included personal behavior related to getting the COVID-19 vaccine while a majority of posts (71.45%; N = 267,930) included information sharing about the virus. Lastly, we found a strong correlation (r = 0.76, p &lt; 0.01) between vaccination behaviors expressed on social media and the actual vaccine uptake over time.DiscussionThis study suggests that LLMs can serve as powerful tools for estimating real-world behaviors. Methodological and practical implications of utilizing LLMs in human behavior research are further discussed.",2025,10.3389/frai.2025.1602984
Software engineering education in the era of conversational AI: current trends and future directions,"The developments in conversational AI raised urgent questions about the future direction of many aspects of society, including computing education. The first reactions to the fast-paced evolution of conversational agents were varied: Some announced “the end of programming,” while others considered this “premature obituary of programming.” Some adopted a defensive approach to detecting the use of conversational AI and avoiding an increase in plagiarism, while others questioned, “So what if ChatGPT wrote it?” Nevertheless, questions arise about whether computing education in its current form will still be relevant and fit for purpose in the era of conversational AI. Recognizing these diverse reactions to the advent of conversational AI, this paper aims to contribute to the ongoing discourse by exploring the current state through three perspectives in a dedicated literature review: adoption of conversational AI in (1) software engineering education specifically and (2) computing education in general, and (3) a comparison with software engineering practice. Our results show a gap between software engineering practice and higher education in the pace of adoption and the areas of use and generally identify preliminary research on student experience, teaching, and learning tools for software engineering.",2024,10.3389/frai.2024.1436350
Registerial Adaptation vs. Innovation Across Situational Contexts: 18th Century Women in Transition,"Endeavors to computationally model language variation and change are ever increasing. While analyses of recent diachronic trends are frequently conducted, long-term trends accounting for sociolinguistic variation are less well-studied. Our work sheds light on the temporal dynamics of language use of British 18th century women as a group in transition across two situational contexts. Our findings reveal that in formal contexts women adapt to register conventions, while in informal contexts they act as innovators of change in language use influencing others. While adopted from other disciplines, our methods inform (historical) sociolinguistic work in novel ways. These methods include diachronic periodization by Kullback-Leibler divergence to determine periods of change and relevant features of variation, and event cascades as influencer models.",2021,10.3389/frai.2021.609970
Construction of a diagnostic model for temporal lobe epilepsy using interpretable deep learning: disease-associated markers identification,"Introduction
                    Temporal lobe epilepsy (TLE) represents a significant neurological disorder with complex genetic underpinnings. This study aimed to develop an interpretable deep learning diagnostic model for TLE and identify disease-associated markers.
                  
                  
                    Methods
                    Using RNA-seq and microarray data from 287 samples collected from eight GEO datasets, we constructed multiple machine learning algorithms including Deep Neural Networks (DNN), Extreme Gradient Boosting (XGBoost), Random Forest (RF), Logistic Regression (LR), and K-Nearest Neighbors (KNN) to distinguish TLE from normal. SHapley Additive exPlanations (SHAP) and Kolmogorov-Arnold Networks (KAN) were employed to interpret the model and identify key genes associated with TLE pathogenesis.
                  
                  
                    Results
                    After comparative analysis, a Deep Neural Network (DNN) model with 10 optimized genetic features achieved perfect diagnostic performance (AUC = 1.000, accuracy = 1.000). SHAP interpretation identified DEPDC5, STXBP1, GABRG2, SLC2A1, and LGI1 as the most significant TLE-associated genes. The KAN model revealed complex nonlinear relationships between these genes and TLE status, providing mathematical expressions that capture their contributions. To facilitate clinical application, we developed an online diagnostic platform that delivers interpretable predictions based on gene expression values.
                  
                  
                    Discussion
                    This study advances our understanding of TLE pathogenesis and provides a transparent, interpretable diagnostic model, which combines with traditional diagnostic methods may significantly improve the accuracy of TLE diagnosis, serving as a supplementary tool for clinical assessment.",2025,10.3389/frai.2025.1655338
Leveraging Guided Backpropagation to Select Convolutional Neural Networks for Plant Classification,"The development of state-of-the-art convolutional neural networks (CNN) has allowed researchers to perform plant classification tasks previously thought impossible and rely on human judgment. Researchers often develop complex CNN models to achieve better performances, introducing over-parameterization and forcing the model to overfit on a training dataset. The most popular process for evaluating overfitting in a deep learning model is using accuracy and loss curves. Train and loss curves may help understand the performance of a model but do not provide guidance on how the model could be modified to attain better performance. In this article, we analyzed the relation between the features learned by a model and its capacity and showed that a model with higher representational capacity might learn many subtle features that may negatively affect its performance. Next, we showed that the shallow layers of a deep learning model learn more diverse features than the ones learned by the deeper layers. Finally, we propose SSIM cut curve, a new way to select the depth of a CNN model by using the pairwise similarity matrix between the visualization of the features learned at different depths by using Guided Backpropagation. We showed that our proposed method could potentially pave a new way to select a better CNN model.",2022,10.3389/frai.2022.871162
Advanced driving assistance integration in electric motorcycles: road surface classification with a focus on gravel detection using deep learning,"Riding a motorcycle involves risks that can be minimized through advanced sensing and response systems to assist the rider. The use of camera-collected images to monitor road conditions can aid in the development of tools designed to enhance rider safety and prevent accidents. This paper proposes a method for developing deep learning models designed to operate efficiently on embedded systems like the Raspberry Pi, facilitating real-time decisions that consider the road condition. Our research tests and compares several state-of-the-art convolutional neural network architectures, including EfficientNet and Inception, to determine which offers the best balance between inference time and accuracy. Specifically, we measured top-1 accuracy and inference time on a Raspberry Pi, identifying EfficientNetV2 as the most suitable model due to its optimal trade-off between performance and computational demand. The model's top-1 accuracy significantly outperformed other models while maintaining competitive inference speeds, making it ideal for real-time applications in traffic-dense urban settings.",2025,10.3389/frai.2025.1520557
Detection of cloned voices in realistic forensic voice comparison scenarios,"Deepfakes and synthetic audio significantly degrade the performance of automatic speaker recognition systems commonly used in forensic laboratories. We investigate the effectiveness of Mel-Frequency Cepstral Coefficients (MFCCs) for detecting cloned voices, ultimately concluding that MFCC-based methods are insufficient as a universal anti-spoofing tool due to their inability to generalize across different cloning algorithms. Furthermore, we evaluate the performance of the HIVE AI-deepfake Content Detection tool, noting its vulnerability to babble noise and signal saturation, which are common in real-world forensic recordings. This investigation emphasizes the ongoing competition between voice cloning and detection technologies, underscoring the urgent need for more robust and generalized anti-spoofing systems for forensic applications.",2025,10.3389/frai.2025.1678043
Robots in the moral loop: a field study of AI advisors in ethical military decision-making,"Humans now routinely work alongside AI in environments where the ethical consequences of decisions are profound, yet there remains limited understanding of how long-term collaboration with a robotic teammate shapes individuals’ moral judgment. Prior studies have demonstrated that people can be influenced by a robot’s moral recommendations, but such investigations have largely focused on single dilemmas or brief encounters conducted in laboratory settings. To address this gap, we conducted a three-month teaming program with 62 U.S. military cadets who interacted extensively with a Socially Intelligent and Ethical Mission Assistant (SIEMA) embodied either as a humanoid robot or as a human advisor in a field setting. After this sustained collaboration, cadets completed a graded moral dilemma that required balancing the lives of soldiers against those of civilians, during which they received a written recommendation from their SIEMA promoting a utilitarian option. Each participant recorded an initial judgment, then a second judgment after receiving SIEMA’s advice, and finally a third judgment following an opposing recommendation that emphasized civilian protection. Approximately half of the cadets shifted toward the utilitarian option after advice, regardless of whether the source was robotic or human. When subsequently presented with the recommendation to prioritize civilian protection, most of these cadets shifted again, often returning to their original stance. Qualitative analyses of open-ended explanations revealed that cadets justified their choices by invoking outcome-based reasoning, duties of protection, trust in their teammate, and personal values. Our findings demonstrate that robotic advisors can influence nuanced moral decisions and that such influence contributes to shaping future judgments. Accordingly, moral-AI design should present trade-offs transparently, surface competing values concurrently, and rely on human reflection rather than assuming isolated AI prompts will durably reset moral priorities.",2025,10.3389/frai.2025.1694772
Epistemic limits of local interpretability in self-modulating cognitive architectures,"Introduction
                    Local interpretability methods such as LIME and SHAP are widely used to explain model decisions. However, they rely on assumptions of local continuity that often fail in recursive, self-modulating cognitive architectures.
                  
                  
                    Methods
                    We analyze the limitations of local proxy models through formal reasoning, simulation experiments, and epistemological framing. We introduce constructs such as Modular Cognitive Attention (MCA), the Cognitive Leap Operator (Ψ), and the Internal Narrative Generator (ING).
                  
                  
                    Results
                    Our findings show that local perturbations yield divergent interpretive outcomes depending on internal cognitive states. Narrative coherence emerges from recursive policy dynamics, and traditional attribution methods fail to capture bifurcation points in decision space.
                  
                  
                    Discussion
                    We argue for a shift from post-hoc local approximations to embedded narrative-based interpretability. This reframing supports epistemic transparency in future AGI systems and aligns with cognitive theories of understanding.",2025,10.3389/frai.2025.1677528
Educational Automatic Question Generation Improves Reading Comprehension in Non-native Speakers: A Learner-Centric Case Study,"BackgroundAsking learners manually authored questions about their readings improves their text comprehension. Yet, not all reading materials comprise sufficiently many questions and many informal reading materials do not contain any. Therefore, automatic question generation has great potential in education as it may alleviate the lack of questions. However, currently, there is insufficient evidence on whether or not those automatically generated questions are beneficial for learners' understanding in reading comprehension scenarios.ObjectivesWe investigate the positive and negative effects of automatically generated short-answer questions on learning outcomes in a reading comprehension scenario.MethodsA learner-centric, in between-groups, quasi-experimental reading comprehension case study with 48 college students is conducted. We test two hypotheses concerning positive and negative effects on learning outcomes during the text comprehension of science texts and descriptively explore how the generated questions influenced learners.ResultsThe results show a positive effect of the generated questions on the participants learning outcomes. However, we cannot entirely exclude question-induced adverse side effects on learning of non-questioned information. Interestingly, questions identified as computer-generated by learners nevertheless seemed to benefit their understanding.Take AwayAutomatic question generation positively impacts reading comprehension in the given scenario. In the reported case study, even questions recognized as computer-generated supported reading comprehension.",2022,10.3389/frai.2022.900304
Predicting cardiovascular disease risk using retinal optical coherence tomography imaging,"Introduction
                    Cardiovascular Diseases (CVD) are the leading cause of death globally. Non-invasive, cost-effective imaging techniques play a crucial role in early detection and prevention of CVD. Optical Coherence Tomography (OCT) has gained recognition as a noninvasive method of detecting microvascular alterations that might enable earlier identification and targeting of at-risk patients. In this study, we investigated the potential of OCT as an additional imaging technique to predict future CVD events.
                  
                  
                    Methods
                    We analyzed retinal OCT data from the UK Biobank. The dataset included 612 patients who suffered a Myocardial Infarction (MI) or stroke within five years of imaging and 2,234 controls without CVD (total: 2,846 participants). A self-supervised deep learning approach based on Variational Autoencoders (VAE) was used to extract low-dimensional latent representations from high-dimensional 3D OCT images, capturing structural and morphological features of retinal and choroidal layers. These latent features, along with clinical data, were used to train a Random Forest (RF) classifier to differentiate between patients at risk of future CVD events (MI or stroke) and healthy controls.
                  
                  
                    Results
                    Our model achieved an AUC of 0.75, sensitivity of 0.70, specificity of 0.70, and accuracy of 0.70. The choroidal layer in OCT images was identified as a key predictor of future CVD events, revealed through a novel model explainability approach.
                  
                  
                    Discussion
                    Our findings demonstrate the potential of retinal OCT imaging, when combined with advanced deep learning methods, as a predictive tool for identifying individuals at increased risk of CVD events.",2025,10.3389/frai.2025.1624550
Prediction of unobserved bifurcation by unsupervised extraction of slowly time-varying system parameter dynamics from time series using reservoir computing,"IntroductionNonlinear and non-stationary processes are prevalent in various natural and physical phenomena, where system dynamics can change qualitatively due to bifurcation phenomena. Machine learning methods have advanced our ability to learn and predict such systems from observed time series data. However, predicting the behavior of systems with temporal parameter variations without knowledge of true parameter values remains a significant challenge.MethodsThis study uses reservoir computing framework to address this problem by unsupervised extraction of slowly varying system parameters from time series data. We propose a model architecture consisting of a slow reservoir with long timescale internal dynamics and a fast reservoir with short timescale dynamics. The slow reservoir extracts the temporal variation of system parameters, which are then used to predict unknown bifurcations in the fast dynamics.ResultsThrough experiments on chaotic dynamical systems, our proposed model successfully extracted slowly varying system parameters and predicted bifurcations that were not included in the training data. The model demonstrated robust predictive performance, showing that the reservoir computing framework can handle nonlinear, non-stationary systems without prior knowledge of the system's true parameters.DiscussionOur approach shows potential for applications in fields such as neuroscience, material science, and weather prediction, where slow dynamics influencing qualitative changes are often unobservable.",2024,10.3389/frai.2024.1451926
MAD-Onto: an ontology design for mobile app development,"IntroductionMobile app development has rapidly evolved into a crucial aspect of modern technology, driving innovation across various industries and transforming user experiences globally. The dynamic nature of mobile technology requires developers to navigate a complex landscape of platforms, devices, and user requirements. Effective management and sharing of knowledge are essential to address these challenges, ensuring streamlined development processes and enhanced collaboration among stakeholders.MethodsTo this end, ontologies have emerged as powerful tools for structuring and standardizing domain-specific knowledge. This paper introduces MAD-onto, a comprehensive ontology designed specifically for the mobile app development domain. The ontology is constructed by identifying key concepts, defining classes and their hierarchies, establishing class properties, and creating instances relevant to mobile app development. To ensure robustness, the ontology is evaluated using a multi-criteria evaluation metric, focusing on consistency, completeness, conciseness, expandability, and sensitiveness. Additionally, SWRL rules are applied to validate and enforce logical constraints within the ontology.ResultsThrough these rigorous evaluation methods, MAD-onto demonstrates its utility in providing a structured framework for the mobile app development lifecycle, facilitating better decision-making, collaboration, and efficiency.DiscussionThe findings highlight the significance of ontology-driven approaches in addressing the complexities of mobile app development and set a foundation for future research and advancements in this field.",2025,10.3389/frai.2025.1508225
Discriminative context-aware network for camouflaged object detection,"IntroductionAnimals use camouflage (background matching, disruptive coloration, etc.) for protection, confusing predators and making detection difficult. Camouflage Object Detection (COD) tackles this challenge by identifying objects seamlessly blended into their surroundings. Existing COD techniques struggle with hidden objects due to noisy inferences inherent in natural environments. To address this, we propose the Discriminative Context-aware Network (DiCANet) for improved COD performance.MethodsDiCANet addresses camouflage challenges through a two-stage approach. First, an adaptive restoration block intelligently learns feature weights, prioritizing informative channels and pixels. This enhances convolutional neural networks’ ability to represent diverse data and handle complex camouflage. Second, a cascaded detection module with an enlarged receptive field refines the object prediction map, achieving clear boundaries without post-processing.ResultsWithout post-processing, DiCANet achieves state-of-the-art performance on challenging COD datasets (CAMO, CHAMELEON, COD10K) by generating accurate saliency maps with rich contextual details and precise boundaries.DiscussionDiCANet tackles the challenge of identifying camouflaged objects in noisy environments with its two-stage restoration and cascaded detection approach. This innovative architecture surpasses existing methods in COD tasks, as proven by benchmark dataset experiments.",2024,10.3389/frai.2024.1347898
A conceptual ethical framework to preserve natural human presence in the use of AI systems in education,"In recent years, there has been a remarkable increase of interest in the ethical use of AI systems in education. On one hand, the potential for such systems is undeniable. Used responsibly, they can meaningfully support and enhance the interactive process of teaching and learning. On the other hand, there is a risk that natural human presence may be gradually replaced by arbitrarily created AI systems, particularly due to their rapidly increasing yet partially unguided capabilities. State-of-the-art ethical frameworks suggest high-level principles, requirements, and guidelines, but lack detailed low-level models of concrete processes and according properties of the involved actors in education. In response, this article introduces a detailed Unified Modeling Language (UML)-based ancillary framework that includes a novel set of low-level properties. Whilst not incorporated in related work, particularly the ethical behavior and visual representation of the actors are intended to improve transparency and reduce the potential for misinterpretation and misuse of AIS. The framework primarily focuses on school education, resulting in a more restrictive model, however, reflects on potentials and challenges in terms of improving flexibility toward different educational levels. The article concludes with a discussion of key findings and implications of the presented framework, its limitations, and potential future research directions to sustainably preserve natural human presence in the use of AI systems in education.",2025,10.3389/frai.2024.1377938
Adaptability of AI for safety evaluation in regulatory science: A case study of drug-induced liver injury,"Artificial intelligence (AI) has played a crucial role in advancing biomedical sciences but has yet to have the impact it merits in regulatory science. As the field advances, in silico and in vitro approaches have been evaluated as alternatives to animal studies, in a drive to identify and mitigate safety concerns earlier in the drug development process. Although many AI tools are available, their acceptance in regulatory decision-making for drug efficacy and safety evaluation is still a challenge. It is a common perception that an AI model improves with more data, but does reality reflect this perception in drug safety assessments? Importantly, a model aiming at regulatory application needs to take a broad range of model characteristics into consideration. Among them is adaptability, defined as the adaptive behavior of a model as it is retrained on unseen data. This is an important model characteristic which should be considered in regulatory applications. In this study, we set up a comprehensive study to assess adaptability in AI by mimicking the real-world scenario of the annual addition of new drugs to the market, using a model we previously developed known as DeepDILI for predicting drug-induced liver injury (DILI) with a novel Deep Learning method. We found that the target test set plays a major role in assessing the adaptive behavior of our model. Our findings also indicated that adding more drugs to the training set does not significantly affect the predictive performance of our adaptive model. We concluded that the proposed adaptability assessment framework has utility in the evaluation of the performance of a model over time.",2022,10.3389/frai.2022.1034631
Artificial intelligence-assisted capsule endoscopy for detecting lesions in Crohn’s disease: a systematic review and meta-analysis,"Background and objectivesCrohn’s disease (CD), a complex member of the inflammatory bowel disease spectrum, is characterized by the diversity and skipping distribution of intestinal mucosal lesions, significantly complicating its differential diagnosis with intestinal diseases such as ulcerative colitis and intestinal tuberculosis. With the increasing application of artificial intelligence (AI) in the medical field, its utilization in primary diagnosis has become more widespread. However, there is a lack of systematic evaluation regarding the specific efficacy of AI in identifying CD through capsule endoscopy.MethodsThis study conducted a comprehensive search of PubMed databases, Cochrane, EMBASE, and Web of Science up to May 21, 2024, to collect relevant literature. The Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool was used to rigorously assess the quality of included studies, and detailed information on study characteristics and AI algorithms was extracted. A bivariate mixed-effects model was employed to synthesize and analyze the sensitivity, specificity, and area under the receiver operating characteristic curve (AUC). Additionally, meta-regression and subgroup analyses were conducted to delve into the potential sources of heterogeneity.ResultsUltimately, eight studies encompassing 11 distinct AI models were included in this meta-analysis. The overall area under the curve (AUC) for AI in identifying CD through capsule endoscopy was 99% (95% CI, 100%-0.00), indicating high diagnostic accuracy. Specifically, the pooled sensitivity was 94% (95% CI, 93–96%), specificity was 97% (95% CI, 95–98%), positive likelihood ratio (PLR) was 32.7 (95% CI, 19.9–53.6), negative likelihood ratio (NLR) was 6% (95% CI, 4–7%), and diagnostic odds ratio (DOR) reached 576 (95% CI, 295–1,127). Meta-regression analysis further revealed that AI algorithm type, study population size, and study design might be key sources of heterogeneity.ConclusionThis study demonstrates the significant potential of AI technology in assisting endoscopists in detecting and identifying CD patients through capsule endoscopy. However, given the limitations and heterogeneity of current research, more high-quality, large-sample studies are needed to comprehensively and thoroughly evaluate the practical application value of AI in CD diagnosis, thereby promoting its widespread adoption and optimization in clinical practice.",2025,10.3389/frai.2025.1531362
ProTect: a hybrid deep learning model for proactive detection of cyberbullying on social media,"The emergence of social media has given rise to a variety of networking and communication opportunities, as well as the well-known issue of cyberbullying, which is continuously on the rise in the current world. Researchers have been actively addressing cyberbullying for a long time by applying machine learning and deep learning techniques. However, although these algorithms have performed well on artificial datasets, they do not provide similar results when applied to real-time datasets with high levels of noise and imbalance. Consequently, finding generic algorithms that can work on dynamic data available across several platforms is critical. This study used a unique hybrid random forest-based CNN model for text classification, combining the strengths of both approaches. Real-time datasets from Twitter and Instagram were collected and annotated to demonstrate the effectiveness of the proposed technique. The performance of various ML and DL algorithms was compared, and the RF-based CNN model outperformed them in accuracy and execution speed. This is particularly important for timely detection of bullying episodes and providing assistance to victims. The model achieved an accuracy of 96% and delivered results 3.4 seconds faster than standard CNN models.",2024,10.3389/frai.2024.1269366
An optimized system for predicting energy usage in smart grids using temporal fusion transformer and Aquila optimizer,"This research presents an optimized system for predicting energy usage in smart grids by integrating the Temporal Fusion Transformer (TFT) with the Aquila Optimizer (AO). The study addresses the growing need for accurate energy consumption forecasts in smart grids, driven by the increasing adoption of renewable energy and real-time data collection through smart meters. The TFT model leverages self-attention mechanisms to handle complex time-series data, improving forecasting accuracy across various time horizons. To enhance predictive performance, the Aquila Optimizer, a nature-inspired algorithm, is employed to fine-tune critical hyperparameters, ensuring optimal model convergence and performance. The proposed AO-TFT model is evaluated against traditional models like LSTM and CNN-BiLSTM, demonstrating superior accuracy, lower RMSE, and faster computation times. The research also analyses the impact of various factors, including building types, weather conditions, and load variations on energy prediction. The proposed AO-TFT model achieved a significantly lower RMSE of 0.48 and MAE of 0.31, demonstrating superior accuracy compared to traditional models. Future work is suggested to explore hybrid optimization techniques and real-time adaptive models for dynamic grid management.",2025,10.3389/frai.2025.1542320
ArabBert-LSTM: improving Arabic sentiment analysis based on transformer model and Long Short-Term Memory,"Sentiment analysis also referred to as opinion mining, plays a significant role in automating the identification of negative, positive, or neutral sentiments expressed in textual data. The proliferation of social networks, review sites, and blogs has rendered these platforms valuable resources for mining opinions. Sentiment analysis finds applications in various domains and languages, including English and Arabic. However, Arabic presents unique challenges due to its complex morphology characterized by inflectional and derivation patterns. To effectively analyze sentiment in Arabic text, sentiment analysis techniques must account for this intricacy. This paper proposes a model designed using the transformer model and deep learning (DL) techniques. The word embedding is represented by Transformer-based Model for Arabic Language Understanding (ArabBert), and then passed to the AraBERT model. The output of AraBERT is subsequently fed into a Long Short-Term Memory (LSTM) model, followed by feedforward neural networks and an output layer. AraBERT is used to capture rich contextual information and LSTM to enhance sequence modeling and retain long-term dependencies within the text data. We compared the proposed model with machine learning (ML) algorithms and DL algorithms, as well as different vectorization techniques: term frequency-inverse document frequency (TF-IDF), ArabBert, Continuous Bag-of-Words (CBOW), and skipGrams using four Arabic benchmark datasets. Through extensive experimentation and evaluation of Arabic sentiment analysis datasets, we showcase the effectiveness of our approach. The results underscore significant improvements in sentiment analysis accuracy, highlighting the potential of leveraging transformer models for Arabic Sentiment Analysis. The outcomes of this research contribute to advancing Arabic sentiment analysis, enabling more accurate and reliable sentiment analysis in Arabic text. The findings reveal that the proposed framework exhibits exceptional performance in sentiment classification, achieving an impressive accuracy rate of over 97%.",2024,10.3389/frai.2024.1408845
A Genetic Folding Strategy Based Support Vector Machine to Optimize Lung Cancer Classification,"Cancer is defined as an abnormal growth of human cells classified into benign and malignant. The site makes further classification of cancers of initiation and genomic underpinnings. Lung cancer displays extreme heterogeneity, making genomic classification vital for future targeted therapies. Especially considering lung cancers account for 1.76 million deaths worldwide annually. However, tumors do not always correlate to cancer as they can be benign, severely dysplastic (pre-cancerous), or malignant (cancerous). Lung cancer presents with ambiguous symptoms, thus is difficult to diagnose and is detected later compared to other cancers. Diagnosis relies heavily on radiology and invasive procedures. Different models developed employing Artificial Intelligence (AI), and Machine Learning (ML) have been used to classify various cancers. In this study, the authors propose a Genetic Folding Strategy (GFS) based model to predict lung cancer from a lung cancer dataset. We developed and implemented GF to improve Support Vector Machines (SVM) classification kernel functions and used it to classify lung cancer. We developed and implemented GF to improve SVM classification kernel functions and used it to classify lung cancer. Classification performance evaluations and comparisons between the authors' GFS model and three SVM kernels, linear, polynomial and radial basis function, were conducted thoroughly on real lung cancer datasets. While using GFS in classifying lung cancer, the authors obtained an accuracy of 96.2%. This is the highest current accuracy compared to other kernels.",2022,10.3389/frai.2022.826374
Integrating generative adversarial networks with IoT for adaptive AI-powered personalized elderly care in smart homes,"The need for effective and personalized in-home solutions will continue to rise with the world population of elderly individuals expected to surpass 1.6 billion by the year 2050. The study presents a system that merges Generative Adversarial Network (GAN) with IoT-enabled adaptive artificial intelligence (AI) framework for transforming personalized elderly care within the smart home environment. The reason for the application of GANs is to generate synthetic health data, which in turn addresses the scarcity of data, especially of some rare but critical conditions, and helps enhance the predictive accuracy of the system. Continuous data collection from IoT sensors, including wearable sensors (e.g., heart rate monitors, pulse oximeters) and environmental sensors (e.g., temperature, humidity, and gas detectors), enables the system to track vital indications of health, activities, and environment for early warnings and personalized suggestions through real-time analysis. The AI adapts to the unique pattern of healthy and behavioral habits in every individual’s lifestyle, hence offering personalized prompts, reminders, and sends off emergency alert notifications to the caregiver or health provider, when required. We were showing significant improvements like 30% faster detection of risk conditions in a large-scale real-world test setup, and 25% faster response times compared with other solutions. GANs applied to the synthesis of data enable more robust and accurate predictive models, ensuring privacy with the generation of realistic yet anonymized health profiles. The system merges state-of-the-art AI with GAN technology in advancing elderly care in a proactive, dignified, secure environment that allows improved quality of life and greater independence for the aging individual. The work hence provides a novel framework for the utilization of GAN in personalized healthcare and points out that this will help reshape elderly care in IoT-enabled “smart” homes.",2025,10.3389/frai.2025.1520592
“Better than my professor?” How to develop artificial intelligence tools for higher education,"Artificial Intelligence (AI) tools are currently designed and tested in many fields to improve humans’ ability to make decisions. One of these fields is higher education. For example, AI-based chatbots (“conversational pedagogical agents”) could engage in conversations with students in order to provide timely feedback and responses to questions while the learning process is taking place and to collect data to personalize the delivery of course materials. However, many existent tools are able to perform tasks that human professionals (educators, tutors, professors) could perform, just in a timelier manner. While discussing the possible implementation of AI-based tools in our university’s educational programs, we reviewed the current literature and identified a number of capabilities that future AI solutions may feature, in order to improve higher education processes, with a focus on distance higher education. Specifically, we suggest that innovative tools could influence the methodologies by which students approach learning; facilitate connections and information attainment beyond course materials; support the communication with the professor; and, draw from motivation theories to foster learning engagement, in a personalized manner. Future research should explore high-level opportunities represented by AI for higher education, including their effects on learning outcomes and the quality of the learning experience as a whole.",2024,10.3389/frai.2024.1329605
Active learning for data efficient semantic segmentation of canine bones in radiographs,"X-ray bone semantic segmentation is one crucial task in medical imaging. Due to deep learning's emergence, it was possible to build high-precision models. However, these models require a large quantity of annotated data. Furthermore, semantic segmentation requires pixel-wise labeling, thus being a highly time-consuming task. In the case of hip joints, there is still a need for increased anatomic knowledge due to the intrinsic nature of the femur and acetabulum. Active learning aims to maximize the model's performance with the least possible amount of data. In this work, we propose and compare the use of different queries, including uncertainty and diversity-based queries. Our results show that the proposed methods permit state-of-the-art performance using only 81.02% of the data, with O(1) time complexity.",2022,10.3389/frai.2022.939967
Enhanced sleep staging with artificial intelligence: a validation study of new software for sleep scoring,"Manual sleep staging (MSS) using polysomnography is a time-consuming task, requires significant training, and can lead to significant variability among scorers. STAGER is a software program based on machine learning algorithms that has been developed by Medibio Limited (Savage, MN, USA) to perform automatic sleep staging using only EEG signals from polysomnography. This study aimed to extensively investigate its agreement with MSS performed during clinical practice and by three additional expert sleep technicians. Forty consecutive polysomnographic recordings of patients referred to three US sleep clinics for sleep evaluation were retrospectively collected and analyzed. Three experienced technicians independently staged the recording using the electroencephalography, electromyography, and electrooculography signals according to the American Academy of Sleep Medicine guidelines. The staging initially performed during clinical practice was also considered. Several agreement statistics between the automatic sleep staging (ASS) and MSS, among the different MSSs, and their differences were calculated. Bootstrap resampling was used to calculate 95% confidence intervals and the statistical significance of the differences. STAGER's ASS was most comparable with, or statistically significantly better than the MSS, except for a partial reduction in the positive percent agreement in the wake stage. These promising results indicate that STAGER software can perform ASS of inpatient polysomnographic recordings accurately in comparison with MSS.",2023,10.3389/frai.2023.1278593
Hierarchical structures emerge from the cultural transmission: an iterated learning experiment using a non-linguistic task,"Human language is characterized by complex structural features, such as the hierarchical combination of words to form sentences. Although other animals use communication systems, empirical evidence of hierarchical structures is rare. Computational studies of language evolution have suggested that cultural transmission plays a key role in the emergence of structural features in human languages, including hierarchy. While the previous study demonstrated the emergence of hierarchical structures in non-linguistic systems, we argue that their laboratory study may have overestimated the role of cultural transmission because of a lack of appropriate controls and analyses. To directly test the effect of cultural transmission, we conducted an experiment with no cultural transmission as a control (individual condition) in addition to replicating the previous transmission experiment (transmission condition). Our study has added a quantitative analysis of the hierarchical depth. We found that sequences became more structured as the number of generations increased; however, those produced under the transmission condition were more structured than those under the individual condition. These findings suggest that cultural transmission plays an important role in the emergence of hierarchical structures, which cannot be explained by increased learnability alone. The emergence of complex structural properties in human culture, such as language, technology, and music, may have resulted from information transmission processes between different individuals. In conclusion, this study provides evidence of the crucial role of cultural transmission in the emergence of hierarchical structures in non-linguistic communication systems. Our results contribute to the ongoing debate on the origins of human language and the emergence of complex cultural artifacts. The results of this study have implications for the study of cultural evolution and the role of transmission in shaping the emergence of structural features across diverse domains.",2023,10.3389/frai.2023.1221329
"Rough-set based learning: Assessing patterns and predictability of anxiety, depression, and sleep scores associated with the use of cannabinoid-based medicine during COVID-19","Recently, research is emerging highlighting the potential of cannabinoids' beneficial effects related to anxiety, mood, and sleep disorders as well as pointing to an increased use of cannabinoid-based medicines since COVID-19 was declared a pandemic. The objective of this research is 3 fold: i) to evaluate the relationship of the clinical delivery of cannabinoid-based medicine for anxiety, depression and sleep scores by utilizing machine learning specifically rough set methods; ii) to discover patterns based on patient features such as specific cannabinoid recommendations, diagnosis information, decreasing/increasing levels of clinical assessment tools (CAT) scores over a period of time; and iii) to predict whether new patients could potentially experience either an increase or decrease in CAT scores. The dataset for this study was derived from patient visits to Ekosi Health Centres, Canada over a 2 year period including the COVID timeline. Extensive pre-processing and feature engineering was performed. A class feature indicative of their progress or lack thereof due to the treatment received was introduced. Six Rough/Fuzzy-Rough classifiers as well as Random Forest and RIPPER classifiers were trained on the patient dataset using a 10-fold stratified CV method. The highest overall accuracy, sensitivity and specificity measures of over 99% was obtained using the rule-based rough-set learning model. In this study, we have identified rough-set based machine learning model with high accuracy that could be utilized for future studies regarding cannabinoids and precision medicine.",2023,10.3389/frai.2023.981953
Stochastic and deterministic processes in Asymmetric Tsetlin Machine,"This paper introduces a new approach to enhance the decision-making capabilities of the Tsetlin Machine (TM) through the Stochastic Point Location (SPL) algorithm and the Asymmetric Steps technique. We incorporate stochasticity and asymmetry into the TM's process, along with a decaying normal distribution function that improves adaptability as it converges toward zero over time. We present two methods: the Asymmetric Probabilistic Tsetlin (APT) Machine, influenced by random events, and the Asymmetric Tsetlin (AT) Machine, which transitions from probabilistic to deterministic states. We evaluate these methods against traditional machine learning algorithms and classical Tsetlin (CT) machines across various benchmark datasets. Both AT and APT demonstrate competitive performance, with the AT model notably excelling, especially in complex datasets.",2025,10.3389/frai.2025.1377944
Hammering with the telescope,"The rapid pace in which various Artificial Intelligence and Machine Learning tools are developed, both within the research community and outside of it, often discourages the involved researchers from taking time to consider potential consequences and applications of the technical advances, especially the unintended ones. While there are notable exceptions to this “gold rush” tendency, individuals and groups providing careful analyses and recommendations for future actions, their adoption remains, at best, limited. This essay presents an analysis of the ethical (and not only) challenges connected with the applications of AI/ML methods in the socio-legal domain.",2022,10.3389/frai.2022.1010219
A self-learning multimodal approach for fake news detection,"The rapid growth of social media has resulted in an explosion of online news content, leading to a significant increase in the spread of misleading or false information. While machine learning techniques have been widely applied to detect fake news, the scarcity of labeled datasets remains a critical challenge. Misinformation frequently appears as paired text and images, where a news article or headline is accompanied by a related visuals. In this paper, we introduce a self-learning multimodal model for fake news classification. The model leverages contrastive learning, a robust method for feature extraction that operates without requiring labeled data, and integrates the strengths of Large Language Models (LLMs) to jointly analyze both text and image features. LLMs are excel at this task due to their ability to process diverse linguistic data drawn from extensive training corpora. Our experimental results on a public dataset demonstrate that the proposed model outperforms several state-of-the-art classification approaches, achieving over 85% accuracy, precision, recall, and F1-score. These findings highlight the model's effectiveness in tackling the challenges of multimodal fake news detection.",2025,10.3389/frai.2025.1665798
Explainable online health information truthfulness in Consumer Health Search,"IntroductionPeople are today increasingly relying on health information they find online to make decisions that may impact both their physical and mental wellbeing. Therefore, there is a growing need for systems that can assess the truthfulness of such health information. Most of the current literature solutions use machine learning or knowledge-based approaches treating the problem as a binary classification task, discriminating between correct information and misinformation. Such solutions present several problems with regard to user decision making, among which: (i) the binary classification task provides users with just two predetermined possibilities with respect to the truthfulness of the information, which users should take for granted; indeed, (ii) the processes by which the results were obtained are often opaque and the results themselves have little or no interpretation.MethodsTo address these issues, we approach the problem as anad hocretrieval task rather than a classification task, with reference, in particular, to the Consumer Health Search task. To do this, a previously proposed Information Retrieval model, which considers information truthfulness as a dimension of relevance, is used to obtain a ranked list of both topically-relevant and truthful documents. The novelty of this work concerns the extension of such a model with a solution for the explainability of the results obtained, by relying on a knowledge base consisting of scientific evidence in the form of medical journal articles.Results and discussionWe evaluate the proposed solution both quantitatively, as a standard classification task, and qualitatively, through a user study to examine the “explained” ranked list of documents. The results obtained illustrate the solution's effectiveness and usefulness in making the retrieved results more interpretable by Consumer Health Searchers, both with respect to topical relevance and truthfulness.",2023,10.3389/frai.2023.1184851
Decoding children dental health risks: a machine learning approach to identifying key influencing factors,"Introduction and objectivesThis study investigates key factors influencing dental caries risk in children aged 7 and under using machine learning techniques. By addressing dental caries’ prevalence, it aims to enhance early identification and preventative strategies for high-risk individuals.MethodsData from clinical examinations of 356 children were analyzed using Logistic Regression, Decision Trees, and Random Forests models. These models assessed the influence of dietary habits, fluoride exposure, and socio-economic status on caries risk, emphasizing accuracy, precision, recall, F1 score, and AUC metrics.ResultsPoor oral hygiene, high sugary diet, and low fluoride exposure were identified as significant caries risk factors. The Random Forest model demonstrated superior performance, illustrating the potential of machine learning in complex health data analysis. Our SHAP analysis identified poor oral hygiene, high sugary diet, and low fluoride exposure as significant caries risk factors.ConclusionMachine learning effectively identifies and quantifies dental caries risk factors in children. This approach supports targeted interventions and preventive measures, improving pediatric dental health outcomes.Clinical significanceBy leveraging machine learning to pinpoint crucial caries risk factors, this research lays the groundwork for data-driven preventive strategies, potentially reducing caries prevalence and promoting better dental health in children.",2024,10.3389/frai.2024.1392597
IRC-Safe Graph Autoencoder for Unsupervised Anomaly Detection,"Anomaly detection through employing machine learning techniques has emerged as a novel powerful tool in the search for new physics beyond the Standard Model. Historically similar to the development of jet observables, theoretical consistency has not always assumed a central role in the fast development of algorithms and neural network architectures. In this work, we construct an infrared and collinear safe autoencoder based on graph neural networks by employing energy-weighted message passing. We demonstrate that whilst this approach has theoretically favorable properties, it also exhibits formidable sensitivity to non-QCD structures.",2022,10.3389/frai.2022.943135
Graph neural networks with configuration cross-attention for tensor compilers,"With the recent popularity of neural networks comes the need for efficient serving of inference workloads. A neural network inference workload can be represented as a computational graph with nodes as operators transforming multidimensional tensors. The tensors can be transposed and/or tiled in a combinatorially large number of ways, some configurations leading to accelerated inference. We propose TGraph, a neural graph architecture that allows screening for fast configurations of the target computational graph, thus representing an artificial intelligence (AI) tensor compiler in contrast to traditional heuristic-based compilers. The proposed solution improves mean Kendall's τ across layout collections of TpuGraphs from 29.8% of the reliable baseline to 67.4% of TGraph. We estimate the potential CO2 emission reduction associated with our work to be equivalent to over 50% of the total household emissions in the areas hosting AI-oriented data centers.",2025,10.3389/frai.2025.1605539
Dynamic taxonomy generation for future skills identification using a named entity recognition and relation extraction pipeline,"IntroductionThe labor market is rapidly evolving, leading to a mismatch between existing Knowledge, Skills, and Abilities (KSAs) and future occupational requirements. Reports from organizations like the World Economic Forum and the OECD emphasize the need for dynamic skill identification. This paper introduces a novel system for constructing a dynamic taxonomy using Natural Language Processing (NLP) techniques, specifically Named Entity Recognition (NER) and Relation Extraction (RE), to identify and predict future skills. By leveraging machine learning models, this taxonomy aims to bridge the gap between current skills and future demands, contributing to educational and professional development.MethodsTo achieve this, an NLP-based architecture was developed using a combination of text preprocessing, NER, and RE models. The NER model identifies and categorizes KSAs and occupations from a corpus of labor market reports, while the RE model establishes the relationships between these entities. A custom pipeline was used for PDF text extraction, tokenization, and lemmatization to standardize the data. The models were trained and evaluated using over 1,700 annotated documents, with the training process optimized for both entity recognition and relationship prediction accuracy.ResultsThe NER and RE models demonstrated promising performance. The NER model achieved a best micro-averaged F1-score of 65.38% in identifying occupations, skills, and knowledge entities. The RE model subsequently achieved a best micro-F1 score of 82.2% for accurately classifying semantic relationships between these entities at epoch 1,009. The taxonomy generated from these models effectively identified emerging skills and occupations, offering insights into future workforce requirements. Visualizations of the taxonomy were created using various graph structures, demonstrating its applicability across multiple sectors. The results indicate that this system can dynamically update and adapt to changes in skill demand over time.DiscussionThe dynamic taxonomy model not only provides real-time updates on current competencies but also predicts emerging skill trends, offering a valuable tool for workforce planning. The high recall rates in NER suggest strong entity recognition capabilities, though precision improvements are needed to reduce false positives. Limitations include the need for a larger corpus and sector-specific models. Future work will focus on expanding the corpus, improving model accuracy, and incorporating expert feedback to further refine the taxonomy.",2025,10.3389/frai.2025.1579998
"Survival prediction landscape: an in-depth systematic literature review on activities, methods, tools, diseases, and databases","Survival prediction integrates patient-specific molecular information and clinical signatures to forecast the anticipated time of an event, such as recurrence, death, or disease progression. Survival prediction proves valuable in guiding treatment decisions, optimizing resource allocation, and interventions of precision medicine. The wide range of diseases, the existence of various variants within the same disease, and the reliance on available data necessitate disease-specific computational survival predictors. The widespread adoption of artificial intelligence (AI) methods in crafting survival predictors has undoubtedly revolutionized this field. However, the ever-increasing demand for more sophisticated and effective prediction models necessitates the continued creation of innovative advancements. To catalyze these advancements, it is crucial to bring existing survival predictors knowledge and insights into a centralized platform. The paper in hand thoroughly examines 23 existing review studies and provides a concise overview of their scope and limitations. Focusing on a comprehensive set of 90 most recent survival predictors across 44 diverse diseases, it delves into insights of diverse types of methods that are used in the development of disease-specific predictors. This exhaustive analysis encompasses the utilized data modalities along with a detailed analysis of subsets of clinical features, feature engineering methods, and the specific statistical, machine or deep learning approaches that have been employed. It also provides insights about survival prediction data sources, open-source predictors, and survival prediction frameworks.",2024,10.3389/frai.2024.1428501
"Large language models can help boost food production, but be mindful of their risks","Coverage of ChatGPT-style large language models (LLMs) in the media has focused on their eye-catching achievements, including solving advanced mathematical problems and reaching expert proficiency in medical examinations. But the gradual adoption of LLMs in agriculture, an industry which touches every human life, has received much less public scrutiny. In this short perspective, we examine risks and opportunities related to more widespread adoption of language models in food production systems. While LLMs can potentially enhance agricultural efficiency, drive innovation, and inform better policies, challenges like agricultural misinformation, collection of vast amounts of farmer data, and threats to agricultural jobs are important concerns. The rapid evolution of the LLM landscape underscores the need for agricultural policymakers to think carefully about frameworks and guidelines that ensure the responsible use of LLMs in food production before these technologies become so ingrained that policy intervention becomes challenging.",2024,10.3389/frai.2024.1326153
Accelerating human–computer interaction through convergent conditions for LLM explanation,"The article addresses the accelerating human–machine interaction using the large language model (LLM). It goes beyond the traditional logical paradigms of explainable artificial intelligence (XAI) by considering poor-formalizable cognitive semantical interpretations of LLM. XAI is immersed in a hybrid space, where humans and machines have crucial distinctions during the digitisation of the interaction process. The author’s convergent methodology ensures the conditions for making XAI purposeful and sustainable. This methodology is based on the inverse problem-solving method, cognitive modeling, genetic algorithm, neural network, causal loop dynamics, and eigenform realization. It has been shown that decision-makers need to create unique structural conditions for information processes, using LLM to accelerate the convergence of collective problem solving. The implementations have been carried out during the collective strategic planning in situational centers. The study is helpful for the advancement of explainable LLM in many branches of economy, science and technology.",2024,10.3389/frai.2024.1406773
"Ordinal SuStaIn: Subtype and Stage Inference for Clinical Scores, Visual Ratings, and Other Ordinal Data","Subtype and Stage Inference (SuStaIn) is an unsupervised learning algorithm that uniquely enables the identification of subgroups of individuals with distinct pseudo-temporal disease progression patterns from cross-sectional datasets. SuStaIn has been used to identify data-driven subgroups and perform patient stratification in neurodegenerative diseases and in lung diseases from continuous biomarker measurements predominantly obtained from imaging. However, the SuStaIn algorithm is not currently applicable to discrete ordinal data, such as visual ratings of images, neuropathological ratings, and clinical and neuropsychological test scores, restricting the applicability of SuStaIn to a narrower range of settings. Here we propose ‘Ordinal SuStaIn’, an ordinal version of the SuStaIn algorithm that uses a scored events model of disease progression to enable the application of SuStaIn to ordinal data. We demonstrate the validity of Ordinal SuStaIn by benchmarking the performance of the algorithm on simulated data. We further demonstrate that Ordinal SuStaIn out-performs the existing continuous version of SuStaIn (Z-score SuStaIn) on discrete scored data, providing much more accurate subtype progression patterns, better subtyping and staging of individuals, and accurate uncertainty estimates. We then apply Ordinal SuStaIn to six different sub-scales of the Clinical Dementia Rating scale (CDR) using data from the Alzheimer’s disease Neuroimaging Initiative (ADNI) study to identify individuals with distinct patterns of functional decline. Using data from 819 ADNI1 participants we identified three distinct CDR subtype progression patterns, which were independently verified using data from 790 ADNI2 participants. Our results provide insight into patterns of decline in daily activities in Alzheimer’s disease and a mechanism for stratifying individuals into groups with difficulties in different domains. Ordinal SuStaIn is broadly applicable across different types of ratings data, including visual ratings from imaging, neuropathological ratings and clinical or behavioural ratings data.",2021,10.3389/frai.2021.613261
Federated quantum-inspired anomaly detection using collaborative neural clients,"IntroductionThe fusion of deep-learning-based and federated methods has brought great progress in anomaly detection. Yet the systems of today still suffer from certain glaring issues. First, aggregation of data on a central entity poses dangerous privacy hazards. Second, such models could not scale and adapt to heterogeneous and distributed environments. Lastly, fine consideration has hardly been given to quantum-inspired computational paradigms that may promise to improve both speed and security of such systems. To fill in these gaps, this research proposes a completely novel quantum-inspired federated learning approach to anomaly detection that keeps data private and allows for further implementations of quantum computing applications.MethodsThe proposed system works on a client-server architecture comprising multiple clients, which either run training of local feedforward neural networks on different private subsets of their data or choose to not participate during an iteration. Clients never pass raw data to the server but instead alternate by sending the server the parameters of the trained model. The server aggregates these local updates by the FedAvg algorithm and produces the global model. The present implementation focuses mainly on utilizing classical deep learning; however, the architecture is made flexible enough to intertwine smoothly with quantum machine-learning paradigms in the future, thus enabling quantum technological enhancement down the road without requiring the entire system to be rebuilt.ResultsThe framework could produce up to 79% of anomalous detection accuracy. The system had effective learning across distributed clients whilst ensuring that no piece of private data was being shared or spilled (exposed) between clients. These results ensured that the framework maintained its performance while keeping its privacy intact, a very crucial consideration on which to ever really deploy such in sensitive areas.DiscussionThe approach allows privacy-preserving anomaly detection across multiple domains and serves as a framework for enlarging and scaling the system. Being quantum-inspired compatible allows for future-proofing and further expediting and enhancing security. The system, having the capability to securely work in a distributed manner, can, thus, be utilized in critical information domains like cybersecurity, finance, and healthcare, where privacy of data is deemed extremely important. This work, thereby, offers a useful federated learning approach towards anomaly detection while going a step further towards the incorporation of quantum computing into secure, distributed AI systems.",2025,10.3389/frai.2025.1648609
"Language writ large: LLMs, ChatGPT, meaning, and understanding","Apart from what (little) OpenAI may be concealing from us, we all know (roughly) how Large Language Models (LLMs) such as ChatGPT work (their vast text databases, statistics, vector representations, and huge number of parameters, next-word training, etc.). However, none of us can say (hand on heart) that we are not surprised by what ChatGPT has proved to be able to do with these resources. This has even driven some of us to conclude that ChatGPT actually understands. It is not true that it understands. But it is also not true that we understand how it can do what it can do. I will suggest some hunches about benign “biases”—convergent constraints that emerge at the LLM scale that may be helping ChatGPT do so much better than we would have expected. These biases are inherent in the nature of language itself, at the LLM scale, and they are closely linked to what it is that ChatGPT lacks, which is direct sensorimotor grounding to connect its words to their referents and its propositions to their meanings. These convergent biases are related to (1) the parasitism of indirect verbal grounding on direct sensorimotor grounding, (2) the circularity of verbal definition, (3) the “mirroring” of language production and comprehension, (4) iconicity in propositions at LLM scale, (5) computational counterparts of human “categorical perception” in category learning by neural nets, and perhaps also (6) a conjecture by Chomsky about the laws of thought. The exposition will be in the form of a dialogue with ChatGPT-4.",2025,10.3389/frai.2024.1490698
Deep learning architectures for influenza dynamics and treatment optimization: a comprehensive review,"As a major worldwide health concern, influenza still requires precise modeling of flu dynamics and efficient treatment approaches. Deep learning architectures are increasingly being applied to address the complexities of influenza dynamics and treatment optimization, which remain critical global health challenges. This review explores the utilization of deep learning methods, such as Long Short-Term Memory (LSTM) networks, Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs), transformer architectures, and large language models (LLMs), in modeling influenza virus behavior and enhancing therapeutic strategies. The dynamic nature of influenza viruses, characterized by rapid mutation rates and the emergence of new strains, complicates the development of effective treatments and vaccines. In other words, the discovery of effective treatments and vaccines is severely hampered by the dynamic character of flu viruses, their fast rates of mutation, and the appearance of novel strains. Traditional epidemiological models often fall short due to their reliance on manual data interpretation and limited capacity to analyze large datasets. In contrast, deep learning offers a more automated and objective approach, capable of uncovering intricate patterns within extensive flu-related data, including genetic sequences and patient records. The application of deep learning to comprehend flu dynamics and improve treatment strategies is examined in this review paper. Moreover, this paper discussed relevant research findings, and future directions in leveraging deep learning for improved understanding and management of influenza outbreaks, ultimately aiming for more personalized treatment regimens and enhanced public health responses.",2025,10.3389/frai.2025.1521886
Trends in EEG signal feature extraction applications,"This paper will focus on electroencephalogram (EEG) signal analysis with an emphasis on common feature extraction techniques mentioned in the research literature, as well as a variety of applications that this can be applied to. In this review, we cover single and multi-dimensional EEG signal processing and feature extraction techniques in the time domain, frequency domain, decomposition domain, time-frequency domain, and spatial domain. We also provide pseudocode for the methods discussed so that they can be replicated by practitioners and researchers in their specific areas of biomedical work. Furthermore, we discuss artificial intelligence applications such as assistive technology, neurological disease classification, brain-computer interface systems, as well as their machine learning integration counterparts, to complete the overall pipeline design for EEG signal analysis. Finally, we discuss future work that can be innovated in the feature extraction domain for EEG signal analysis.",2023,10.3389/frai.2022.1072801
Sketching the vision of the Web of Debates,"The exchange of comments, opinions, and arguments in blogs, forums, social media, wikis, and review websites has transformed the Web into a modern agora, a virtual place where all types of debates take place. This wealth of information remains mostly unexploited: due to its textual form, such information is difficult to automatically process and analyse in order to validate, evaluate, compare, combine with other types of information and make it actionable. Recent research in Machine Learning, Natural Language Processing, and Computational Argumentation has provided some solutions, which still cannot fully capture important aspects of online debates, such as various forms of unsound reasoning, arguments that do not follow a standard structure, information that is not explicitly expressed, and non-logical argumentation methods. Tackling these challenges would give immense added-value, as it would allow searching for, navigating through and analyzing online opinions and arguments, obtaining a better picture of the various debates for a well-intentioned user. Ultimately, it may lead to increased participation of Web users in democratic, dialogical interchange of arguments, more informed decisions by professionals and decision-makers, as well as to an easier identification of biased, misleading, or deceptive arguments. This paper presents the vision of the Web of Debates, a more human-centered version of the Web, which aims to unlock the potential of the abundance of argumentative information that currently exists online, offering its users a new generation of argument-based web services and tools that are tailored to their real needs.",2023,10.3389/frai.2023.1124045
Qluster: An easy-to-implement generic workflow for robust clustering of health data,"The exploration of heath data by clustering algorithms allows to better describe the populations of interest by seeking the sub-profiles that compose it. This therefore reinforces medical knowledge, whether it is about a disease or a targeted population in real life. Nevertheless, contrary to the so-called conventional biostatistical methods where numerous guidelines exist, the standardization of data science approaches in clinical research remains a little discussed subject. This results in a significant variability in the execution of data science projects, whether in terms of algorithms used, reliability and credibility of the designed approach. Taking the path of parsimonious and judicious choice of both algorithms and implementations at each stage, this article proposes Qluster, a practical workflow for performing clustering tasks. Indeed, this workflow makes a compromise between (1) genericity of applications (e.g. usable on small or big data, on continuous, categorical or mixed variables, on database of high-dimensionality or not), (2) ease of implementation (need for few packages, few algorithms, few parameters, ...), and (3) robustness (e.g. use of proven algorithms and robust packages, evaluation of the stability of clusters, management of noise and multicollinearity). This workflow can be easily automated and/or routinely applied on a wide range of clustering projects. It can be useful both for data scientists with little experience in the field to make data clustering easier and more robust, and for more experienced data scientists who are looking for a straightforward and reliable solution to routinely perform preliminary data mining. A synthesis of the literature on data clustering as well as the scientific rationale supporting the proposed workflow is also provided. Finally, a detailed application of the workflow on a concrete use case is provided, along with a practical discussion for data scientists. An implementation on the Dataiku platform is available upon request to the authors.",2023,10.3389/frai.2022.1055294
Evaluating LLMs on Kazakhstan's mathematics exam for university admission,"IntroductionThe rapid advancement of large language models (LLMs) has prompted their exploration in educational contexts, particularly in high-stakes standardized tests such as Kazakhstan's Unified National Testing (UNT) mathematics component, which is critical for university admission. While most existing benchmarks for mathematical reasoning focus on English, concerns remain that LLMs may underperform in under-resourced or non-English languages. This study addresses this gap by evaluating LLM performance on 139 UNT multiple-choice mathematics questions administered entirely in Russian.MethodsWe assessed six LLMs-Claude, DeepSeek, Gemini, Llama, Qwen, and o1—on questions covering algebra, functions, geometry, inequalities, and trigonometry. Three evaluation conditions were employed: (1) zero-shot performance, (2) hybrid integration with SymPy for symbolic computation, and (3) a role-specific simulated multi-agent refinement framework that builds on existing self-correction techniques with targeted feedback.ResultsIn zero-shot settings, DeepSeek, Gemini, Qwen, and o1 achieved near-perfect or perfect accuracy (91.2–100%) across all difficulty levels and topics, while Claude and Llama lagged (43.5–76.5%). The hybrid approach significantly improved Claude and Llama's accuracy by 27.4% and 39.9%, respectively. Under the multi-agent refinement condition, Claude showed substantial gains, reaching 97.8% accuracy, which represented a 58.1% improvement over zero-shot performance.DiscussionThese findings provide important empirical evidence that LLMs can perform competitively on mathematics tasks in non-English languages. The results challenge prior assumptions about limited performance in under-resourced linguistic settings and highlight the potential of LLMs to support bilingual education and promote equitable access to higher education.",2025,10.3389/frai.2025.1642570
Refinement of machine learning arterial waveform models for predicting blood loss in canines,"IntroductionHemorrhage remains a leading cause of death in civilian and military trauma. Hemorrhages also extend to military working dogs, who can experience injuries similar to those of the humans they work alongside. Unfortunately, current physiological monitoring is often inadequate for early detection of hemorrhage. Here, we evaluate if features extracted from the arterial waveform can allow for early hemorrhage prediction and improved intervention in canines.MethodsIn this effort, we extracted more than 1,900 features from an arterial waveform in canine hemorrhage datasets prior to hemorrhage, during hemorrhage, and during a shock hold period. Different features were used as input to decision tree machine learning (ML) model architectures to track three model predictors—total blood loss volume, estimated percent blood loss, and area under the time versus hemorrhaged blood volume curve.ResultsML models were successfully developed for total and estimated percent blood loss, with the total blood loss having a higher correlation coefficient. The area predictors were unsuccessful at being directly predicted by decision tree ML models but could be calculated indirectly from the ML prediction models for blood loss. Overall, the area under the hemorrhage curve had the highest sensitivity for detecting hemorrhage at approximately 4 min after hemorrhage onset, compared to more than 45 min before detection based on mean arterial pressure.ConclusionML methods successfully tracked hemorrhage and provided earlier prediction in canines, potentially improving hemorrhage detection and objectifying triage for veterinary medicine. Further, its use can potentially be extended to human use with proper training datasets.",2024,10.3389/frai.2024.1408029
Agent-Supported Peer Collaboration in MOOCs,"While massive open online courses (MOOCs) can be effective in scaling education, orchestrating collaborative learning activities for large audiences remains a non-trivial task that introduces a series of practical challenges, such as the lack of adequate human support. Even when collaboration takes place, there is uncertainty whether meaningful interactions will occur among learners. This work presents the architecture of a prototype system called PeerTalk. The system was created to enable instructors to easily incorporate real-time collaborative learning activities into their online courses. Furthermore, PeerTalk employs a conversational agent service that aims to scaffold students’ online collaboration and provide valuable guidance, which can be configured by the course instructor. In order to investigate the user-acceptance of the system, two evaluation studies took place. The first one involved a group of experts, i.e., MOOC instructors who are expected to use such a system in their course, whereas the second study featured 44 postgraduate students. The study findings were encouraging in terms of the system efficiency and usability levels, laying the foundation for a conversational agent service, which can effectively scale the support of the teaching staff and be easily integrated in MOOC platforms, creating further opportunities for valuable social interaction among learners.",2021,10.3389/frai.2021.710856
Ethical prompting: toward strategies for rapid and inclusive assistance in dual-use AI systems,"Monitoring technologies initially developed for individuals with disabilities carry inherent dual-use risks, especially evident in conflict or emergency scenarios. This article examines the dual-use dilemma posed by technologies whose civilian design objectives can unintentionally facilitate harmful applications in defense contexts. Specifically, we analyze the ethical risks associated with using civilian-generated data and systems, originally intended to enhance care and assistance, for military purposes without adequate safeguards. We argue that effective and ethically sound technological infrastructures require optimized and ethically-informed prompting strategies. These strategies must clearly define how data and system prompts are structured, reducing deployment biases, particularly against vulnerable populations.",2025,10.3389/frai.2025.1646444
Dual-channel deep graph convolutional neural networks,"The dual-channel graph convolutional neural networks based on hybrid features jointly model the different features of networks, so that the features can learn each other and improve the performance of various subsequent machine learning tasks. However, current dual-channel graph convolutional neural networks are limited by the number of convolution layers, which hinders the performance improvement of the models. Graph convolutional neural networks superimpose multi-layer graph convolution operations, which would occur in smoothing phenomena, resulting in performance decreasing as the increasing number of graph convolutional layers. Inspired by the success of residual connections on convolutional neural networks, this paper applies residual connections to dual-channel graph convolutional neural networks, and increases the depth of dual-channel graph convolutional neural networks. Thus, a dual-channel deep graph convolutional neural network (D2GCN) is proposed, which can effectively avoid over-smoothing and improve model performance. D2GCN is verified on CiteSeer, DBLP, and SDBLP datasets, the results show that D2GCN performs better than the comparison algorithms used in node classification tasks.",2024,10.3389/frai.2024.1290491
Machine learning based assessment of hoarseness severity: a multi-sensor approach centered on high-speed videoendoscopy,"IntroductionFunctional voice disorders are characterized by impaired voice production without primary organic changes, posing challenges for standardized assessment. Current diagnostic methods rely heavily on subjective evaluation, suffering from inter-rater variability. High-speed videoendoscopy (HSV) offers an objective alternative by capturing true intra-cycle vocal fold behavior. Integrating time-synchronized acoustic and HSV recordings could allow for an objective visual and acoustic assessment of vocal function based on a single HSV examination. This study investigates a machine learning-based approach for hoarseness severity assessment using synchronous HSV and acoustic recordings, alongside conventional voice examinations.MethodsThree databases comprising 457 HSV recordings of the sustained vowel /i/, 634 HSV-synchronized acoustic recordings, and clinical parameters from 923 visits were analyzed. Subjects were classified into two hoarseness groups based on auditory-perceptual ratings, with predicted scores serving as continuous hoarseness severity ratings. A videoendoscopic model was developed by selecting a suitable classification algorithm and a minimal-optimal subset of glottal parameters. This model was compared against an acoustic model based on HSV-synchronized recordings and a clinical model based on parameters from other examinations. Two ensemble models were constructed by combining the HSV-based models and all models, respectively. Model performance was evaluated on a shared test set based on classification accuracy, correlation with subjective ratings, and correlation between predicted and observed changes in hoarseness severity.ResultsThe videoendoscopic, acoustic, and clinical model achieved correlations of 0.464, 0.512, and 0.638 with subjective hoarseness ratings. Integrating glottal and acoustic parameters into the HSV-based ensemble model improved correlation to 0.603, confirming the complementary nature of time-synchronized HSV and acoustic recordings. The ensemble model incorporating all modalities achieved the highest correlation of 0.752, underscoring the diagnostic value of multimodal objective assessments.DiscussionThis study highlights the potential of synchronous HSV and acoustic recordings for objective hoarseness severity assessment, offering a more comprehensive evaluation of vocal function. While practical challenges remain, the integration of these modalities led to notable improvements, supporting their complementary value in enhancing diagnostic accuracy. Future advancements could include flexible nasal endoscopy to enable more natural phonation and refinement of glottal parameter extraction to improve model robustness under variable recording conditions.",2025,10.3389/frai.2025.1601716
CycleStyleGAN-Based Knowledge Transfer for a Machining Digital Twin,"Digitalisation of manufacturing is a crucial component of the Industry 4.0 transformation. The digital twin is an important tool for enabling real-time digital access to precise information about physical systems and for supporting process optimisation via the translation of the associated big data into actionable insights. Although a variety of frameworks and conceptual models addressing the requirements and advantages of digital twins has been suggested in the academic literature, their implementation has received less attention. The work presented in this paper aims to make a proposition that considers the novel challenges introduced for data analysis in the presence of heterogeneous and dynamic cyber-physical systems in Industry 4.0. The proposed approach defines a digital twin simulation tool that captures the dynamics of a machining vibration signal from a source model and adapts them to a given target environment. This constitutes a flexible approach to knowledge extraction from the existing manufacturing simulation models, as information from both physics-based and data-driven solutions can be elicited this way. Therefore, an opportunity to reuse the costly established systems is made available to the manufacturing businesses, and the paper presents a process optimisation framework for such use case. The proposed approach is implemented as a domain adaptation algorithm based on the generative adversarial network model. The novel CycleStyleGAN architecture extends the CycleGAN model with a style-based signal encoding. The implemented model is validated in an experimental scenario that aims to replicate a real-world manufacturing knowledge transfer problem. The experiment shows that the transferred information enables the reduction of the required target domain data by one order of magnitude.",2021,10.3389/frai.2021.767451
Assessing artificial intelligence’s impact on e-customer loyalty in the Saudi Arabian market,"This study investigated the effect of artificial intelligence on e-customer loyalty in the Saudi Arabian e-commerce market. It evaluates five important variables: social media exposure, product recommendation, brand preference, purchase intention, and e-customer loyalty. The study espoused primary research methodologies by employing a questionnaire and surveying East, West, and Central Saudi Arabia. The sample size was 157 respondents, a blend of males, females, and persons of all ages. We developed a structural equation model based on six hypotheses. Ultimately, the study provided evidence that led to the confirmation of the hypotheses. We obtained credible scores in assessing the measurement model where we considered indicator reliability (0.920), internal consistency—Cronbach’s alpha (0.902), and convergent reliability – measured by Average Variance Extracted (0.765). The model fit indices indicated the model’s chi-square score was 514.355 and a CMIN/DF of 3.117. The study found that AI, particularly social media exposure and product recommendations, strongly influences Saudi e-customer loyalty. The positive association between social media exposure, purchase intention, and brand preference reveals how focused material affects customer behavior. We conclude that the model is statistically significant and that all hypotheses are supported. The implication is that artificial intelligence is a valid strategy for attaining customer loyalty on e-commerce platforms.",2025,10.3389/frai.2025.1541678
Deep learning for accurate B-line detection and localization in lung ultrasound imaging,"IntroductionLung ultrasound (LUS) has become an essential imaging modality for assessing various pulmonary conditions, including the presence of B-line artifacts. These artifacts are commonly associated with conditions such as increased extravascular lung water, decompensated heart failure, dialysis-related chronic kidney disease, interstitial lung disease, and COVID-19 pneumonia. Accurate detection of the B-line in LUS images is crucial for effective diagnosis and treatment. However, interpreting LUS is often subject to observer variability, requiring significant expertise and posing challenges in resource-limited settings with few trained professionals.MethodsTo address these limitations, deep learning models have been developed for automated B-line detection and localization. This study introduces YOLOv5-PBB and YOLOv8-PBB, two modified models based on YOLOv5 and YOLOv8, respectively, designed for precise and interpretable B-line localization using polygonal bounding boxes (PBBs). YOLOv5-PBB was enhanced by modifying the detection head, loss function, non-maximum suppression, and data loader to enable PBB localization. YOLOv8-PBB was customized to convert segmentation masks into polygonal representations, displaying only boundaries while removing the masks. Additionally, an image preprocessing technique was incorporated into the models to enhance LUS image quality. The models were trained on a diverse dataset from a publicly available repository and Ugandan health facilities.ResultsExperimental results showed that YOLOv8-PBB achieved the highest precision (0.947), recall (0.926), and mean average precision (0.957). YOLOv5-PBB, while slightly lower in performance (precision: 0.931, recall: 0.918, mAP: 0.936), had advantages in model size (14 MB vs. 21 MB) and average inference time (33.1 ms vs. 47.7 ms), making it more suitable for real-time applications in low-resource settings.DiscussionThe integration of these models into a mobile LUS screening tool provides a promising solution for B-line localization in resource-limited settings, where accessibility to trained professionals may be scarce. The YOLOv5-PBB and YOLOv8-PBB models offer high performance while addressing challenges related to inference speed and model size, making them ideal candidates for mobile deployment in such environments.",2025,10.3389/frai.2025.1560523
Gamma and vega hedging using deep distributional reinforcement learning,"We show how reinforcement learning can be used in conjunction with quantile regression to develop a hedging strategy for a trader responsible for derivatives that arrive stochastically and depend on a single underlying asset. We assume that the trader makes the portfolio delta-neutral at the end of each day by taking a position in the underlying asset. We focus on how trades in options can be used to manage gamma and vega. The option trades are subject to transaction costs. We consider three different objective functions. We reach conclusions on how the optimal hedging strategy depends on the trader's objective function, the level of transaction costs, and the maturity of the options used for hedging. We also investigate the robustness of the hedging strategy to the process assumed for the underlying asset.",2023,10.3389/frai.2023.1129370
Crop genomic selection with deep learning and environmental data: A survey,"Machine learning techniques for crop genomic selections, especially for single-environment plants, are well-developed. These machine learning models, which use dense genome-wide markers to predict phenotype, routinely perform well on single-environment datasets, especially for complex traits affected by multiple markers. On the other hand, machine learning models for predicting crop phenotype, especially deep learning models, using datasets that span different environmental conditions, have only recently emerged. Models that can accept heterogeneous data sources, such as temperature, soil conditions and precipitation, are natural choices for modeling GxE in multi-environment prediction. Here, we review emerging deep learning techniques that incorporate environmental data directly into genomic selection models.",2023,10.3389/frai.2022.1040295
Dense Paraphrasing for multimodal dialogue interpretation,"Multimodal dialogue involving multiple participants presents complex computational challenges, primarily due to the rich interplay of diverse communicative modalities including speech, gesture, action, and gaze. These modalities interact in complex ways that traditional dialogue systems often struggle to accurately track and interpret. To address these challenges, we extend the textual enrichment strategy of Dense Paraphrasing (DP), by translating each nonverbal modality into linguistic expressions. By normalizing multimodal information into a language-based form, we hope to both simplify the representation for and enhance the computational understanding of situated dialogues. We show the effectiveness of the dense paraphrased language form by evaluating instruction-tuned Large Language Models (LLMs) against the Common Ground Tracking (CGT) problem using a publicly available collaborative problem-solving dialogue dataset. Instead of using multimodal LLMs, the dense paraphrasing technique represents the dialogue information from multiple modalities in a compact and structured machine-readable text format that can be directly processed by the language-only models. We leverage the capability of LLMs to transform machine-readable paraphrases into human-readable paraphrases, and show that this process can further improve the result on the CGT task. Overall, the results show that augmenting the context with dense paraphrasing effectively facilitates the LLMs' alignment of information from multiple modalities, and in turn largely improves the performance of common ground reasoning over the baselines. Our proposed pipeline with original utterances as input context already achieves comparable results to the baseline that utilized decontextualized utterances which contain rich coreference information. When also using the decontextualized input, our pipeline largely improves the performance of common ground reasoning over the baselines. We discuss the potential of DP to create a robust model that can effectively interpret and integrate the subtleties of multimodal communication, thereby improving dialogue system performance in real-world settings.",2024,10.3389/frai.2024.1479905
Neuroimaging data repositories and AI-driven healthcare—Global aspirations vs. ethical considerations in machine learning models of neurological disease,"Neuroimaging data repositories are data-rich resources comprising brain imaging with clinical and biomarker data. The potential for such repositories to transform healthcare is tremendous, especially in their capacity to support machine learning (ML) and artificial intelligence (AI) tools. Current discussions about the generalizability of such tools in healthcare provoke concerns of risk of bias—ML models underperform in women and ethnic and racial minorities. The use of ML may exacerbate existing healthcare disparities or cause post-deployment harms. Do neuroimaging data repositories and their capacity to support ML/AI-driven clinical discoveries, have both the potential to accelerate innovative medicine and harden the gaps of social inequities in neuroscience-related healthcare? In this paper, we examined the ethical concerns of ML-driven modeling of global community neuroscience needs arising from the use of data amassed within neuroimaging data repositories. We explored this in two parts; firstly, in a theoretical experiment, we argued for a South East Asian-based repository to redress global imbalances. Within this context, we then considered the ethical framework toward the inclusion vs. exclusion of the migrant worker population, a group subject to healthcare inequities. Secondly, we created a model simulating the impact of global variations in the presentation of anosmia risks in COVID-19 toward altering brain structural findings; we then performed a mini AI ethics experiment. In this experiment, we interrogated an actual pilot dataset (n = 17; 8 non-anosmic (47%) vs. 9 anosmic (53%) using an ML clustering model. To create the COVID-19 simulation model, we bootstrapped to resample and amplify the dataset. This resulted in three hypothetical datasets: (i) matched (n = 68; 47% anosmic), (ii) predominant non-anosmic (n = 66; 73% disproportionate), and (iii) predominant anosmic (n = 66; 76% disproportionate). We found that the differing proportions of the same cohorts represented in each hypothetical dataset altered not only the relative importance of key features distinguishing between them but even the presence or absence of such features. The main objective of our mini experiment was to understand if ML/AI methodologies could be utilized toward modelling disproportionate datasets, in a manner we term “AI ethics.” Further work is required to expand the approach proposed here into a reproducible strategy.",2024,10.3389/frai.2023.1286266
"Artificial intelligence in biology and medicine, and radioprotection research: perspectives from Jerusalem","While AI is widely used in biomedical research and medical practice, its use is constrained to few specific practical areas, e.g., radiomics. Participants of the workshop on “Artificial Intelligence in Biology and Medicine” (Jerusalem, Feb 14–15, 2023), both researchers and practitioners, aimed to build a holistic picture by exploring AI advancements, challenges and perspectives, as well as to suggest new fields for AI applications. Presentations showcased the potential of large language models (LLMs) in generating molecular structures, predicting protein-ligand interactions, and promoting democratization of AI development. Ethical concerns in medical decision making were also addressed. In biological applications, AI integration of multi-omics and clinical data elucidated the health relevant effects of low doses of ionizing radiation. Bayesian latent modeling identified statistical associations between unobserved variables. Medical applications highlighted liquid biopsy methods for non-invasive diagnostics, routine laboratory tests to identify overlooked illnesses, and AI's role in oral and maxillofacial imaging. Explainable AI and diverse image processing tools improved diagnostics, while text classification detected anorexic behavior in blog posts. The workshop fostered knowledge sharing, discussions, and emphasized the need for further AI development in radioprotection research in support of emerging public health issues. The organizers plan to continue the initiative as an annual event, promoting collaboration and addressing issues and perspectives in AI applications with a focus on low-dose radioprotection research. Researchers involved in radioprotection research and experts in relevant public policy domains are invited to explore the utility of AI in low-dose radiation research at the next workshop.",2024,10.3389/frai.2023.1291136
Optimized design and performance evaluation of long-pressure-short-extraction ventilation and dust removal system based on the Coanda effect,"Mine ventilation and dust control systems are crucial for ensuring occupational safety and health during underground mining operations. Traditional long-pressure short-suction systems face challenges such as inefficient airflow organization, formation of vortex dead zones, high energy consumption, and inadequate adaptability to dynamic conditions in mining faces. This study addresses these limitations by proposing an optimized long-pressure short-suction ventilation and dust control system leveraging the Coandă effect. Through numerical simulations, experimental validation, and machine learning techniques, the study develops a comprehensive system to enhance dust control performance. The Coandă effect was employed to optimize the structural design of ventilation ducts, ensuring airflow attachment to tunnel surfaces, reducing dust dispersion, and achieving high-efficiency airflow with lower power consumption. The key parameters optimized include the spacing between the air supply and exhaust ducts, the pressure-to-suction ratio, and the height of the ventilation duct. The optimal pressure-to-suction ratio was found to be 2:3, which minimizes dust concentration at both the mining machine and downstream locations. Numerical simulations and experimental results demonstrated that the optimized system achieved dust concentration reductions of up to 84.12% in high initial dust conditions (800 mg/m3). These findings provide a solid foundation for intelligent and energy-efficient ventilation and dust control in mining operations, ensuring both safety and energy savings.",2025,10.3389/frai.2025.1565889
Measuring trust in artificial intelligence: validation of an established scale and its short form,"An understanding of the nature and function of human trust in artificial intelligence (AI) is fundamental to the safe and effective integration of these technologies into organizational settings. The Trust in Automation Scale is a commonly used self-report measure of trust in automated systems; however, it has not yet been subjected to comprehensive psychometric validation. Across two studies, we tested the capacity of the scale to effectively measure trust across a range of AI applications. Results indicate that the Trust in Automation Scale is a valid and reliable measure of human trust in AI; however, with 12 items, it is often impractical for contexts requiring frequent and minimally disruptive measurements. To address this limitation, we developed and validated a three-item version of the TIAS, the Short Trust in Automation Scale (S-TIAS). In two further studies, we tested the sensitivity of the S-TIAS to manipulations of the trustworthiness of an AI system, as well as the convergent validity of the scale and its capacity to predict intentions to rely on AI-generated recommendations. In both studies, the S-TIAS also demonstrated convergent validity and significantly predicted intentions to rely on the AI system in patterns similar to the TIAS. This suggests that the S-TIAS is a practical and valid alternative for measuring trust in automation and AI for the purposes of identifying antecedent factors of trust and predicting trust outcomes.",2025,10.3389/frai.2025.1582880
Improving Robotic Hand Prosthesis Control With Eye Tracking and Computer Vision: A Multimodal Approach Based on the Visuomotor Behavior of Grasping,"The complexity and dexterity of the human hand make the development of natural and robust control of hand prostheses challenging. Although a large number of control approaches were developed and investigated in the last decades, limited robustness in real-life conditions often prevented their application in clinical settings and in commercial products. In this paper, we investigate a multimodal approach that exploits the use of eye-hand coordination to improve the control of myoelectric hand prostheses. The analyzed data are from the publicly available MeganePro Dataset 1, that includes multimodal data from transradial amputees and able-bodied subjects while grasping numerous household objects with ten grasp types. A continuous grasp-type classification based on surface electromyography served as both intent detector and classifier. At the same time, the information provided by eye-hand coordination parameters, gaze data and object recognition in first-person videos allowed to identify the object a person aims to grasp. The results show that the inclusion of visual information significantly increases the average offline classification accuracy by up to 15.61 ± 4.22% for the transradial amputees and of up to 7.37 ± 3.52% for the able-bodied subjects, allowing trans-radial amputees to reach average classification accuracy comparable to intact subjects and suggesting that the robustness of hand prosthesis control based on grasp-type recognition can be significantly improved with the inclusion of visual information extracted by leveraging natural eye-hand coordination behavior and without placing additional cognitive burden on the user.",2022,10.3389/frai.2021.744476
Adaptive noise-augmented attention for enhancing Transformer fine-tuning on longitudinal medical data,"Transformer models pre-trained on self-supervised tasks and fine-tuned on downstream objectives have achieved remarkable results across a variety of domains. However, fine-tuning these models for clinical predictions from longitudinal medical data, such as electronic health records (EHR), remains challenging due to limited labeled data and the complex, event-driven nature of medical sequences. While self-attention mechanisms are powerful for capturing relationships within sequences, they may underperform when modeling subtle dependencies between sparse clinical events under limited supervision. We introduce a simple yet effective fine-tuning technique, Adaptive Noise-Augmented Attention (ANAA), which injects adaptive noise directly into the self-attention weights and applies a 2D Gaussian kernel to smooth the resulting attention maps. This mechanism broadens the attention distribution across tokens while refining it to emphasize more informative events. Unlike prior approaches that require expensive modifications to the architecture and pre-training phase, ANAA operates entirely during fine-tuning. Empirical results across multiple clinical prediction tasks demonstrate consistent performance improvements. Furthermore, we analyze how ANAA shapes the learned attention behavior, offering interpretable insights into the model's handling of temporal dependencies in EHR data.",2025,10.3389/frai.2025.1663484
Is Class-Incremental Enough for Continual Learning?,"The ability of a model to learn continually can be empirically assessed in different continual learning scenarios. Each scenario defines the constraints and the opportunities of the learning environment. Here, we challenge the current trend in the continual learning literature to experiment mainly on class-incremental scenarios, where classes present in one experience are never revisited. We posit that an excessive focus on this setting may be limiting for future research on continual learning, since class-incremental scenarios artificially exacerbate catastrophic forgetting, at the expense of other important objectives like forward transfer and computational efficiency. In many real-world environments, in fact, repetition of previously encountered concepts occurs naturally and contributes to softening the disruption of previous knowledge. We advocate for a more in-depth study of alternative continual learning scenarios, in which repetition is integrated by design in the stream of incoming information. Starting from already existing proposals, we describe the advantages such class-incremental with repetition scenarios could offer for a more comprehensive assessment of continual learning models.",2022,10.3389/frai.2022.829842
A review on knowledge and information extraction from PDF documents and storage approaches,"IntroductionAutomating the extraction of information from Portable Document Format (PDF) documents represents a major advancement in information extraction, with applications in various domains such as healthcare, law, or biochemistry. However, existing solutions face challenges related to accuracy, domain adaptability, and implementation complexity.MethodsA systematic review of the literature was conducted using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to examine approaches and trends in PDF information extraction and storage approaches.ResultsThe review revealed three dominant methodological categories: rule-based systems, statistical learning models, and neural network-based approaches. Key limitations include the rigidity of rule-based methods, the lack of annotated domain-specific datasets for learning-based approaches, and issues such as hallucinations in large language models.DiscussionTo overcome these limitations, a conceptual framework is proposed comprising nine core components: project manager, document manager, document pre-processor, ontology manager, information extractor, annotation engine, question-answering tool, knowledge visualizer, and data exporter. This framework aims to improve the accuracy, adaptability, and usability of PDF information extraction systems.",2025,10.3389/frai.2025.1466092
Deriving equivalent symbol-based decision models from feedforward neural networks,"Artificial intelligence (AI) has emerged as a transformative force across industries, driven by advances in deep learning and natural language processing, and fueled by large-scale data and computing resources. Despite its rapid adoption, the opacity of AI systems poses significant challenges to trust and acceptance. This work explores the intersection of connectionist and symbolic approaches to artificial intelligence, focusing on the derivation of interpretable symbolic models, such as decision trees, from feedforward neural networks (FNNs). Decision trees provide a transparent framework for elucidating the operations of neural networks while preserving their functionality. The derivation is presented in a step-by-step approach and illustrated with several examples. A systematic methodology is proposed to bridge neural and symbolic paradigms by exploiting distributed representations in FNNs to identify symbolic components, including fillers, roles, and their interrelationships. The process traces neuron activation values and input configurations across network layers, mapping activations and their underlying inputs to decision tree edges. The resulting symbolic structures effectively capture FNN decision processes and enable scalability to deeper networks through iterative refinement of subpaths for each hidden layer. To validate the theoretical framework, a prototype was developed using Keras .h5-data and emulating TensorFlow within the Java JDK/JavaFX environment. This prototype demonstrates the feasibility of extracting symbolic representations from neural networks, enhancing trust in AI systems, and promoting accountability.",2025,10.3389/frai.2025.1618149
VMDU-net: a dual encoder multi-scale fusion network for polyp segmentation with Vision Mamba and Cross-Shape Transformer integration,"IntroductionRectal cancer often originates from polyps. Early detection and timely removal of polyps are crucial for preventing colorectal cancer and inhibiting its progression to malignancy. While polyp segmentation algorithms are essential for aiding polyp removal, they face significant challenges due to the diverse shapes, unclear boundaries, and varying sizes of polyps. Additionally, capturing long-range dependencies remains difficult, with many existing algorithms struggling to converge effectively, limiting their practical application.MethodsTo address these challenges, we propose a novel Dual Encoder Multi-Scale Feature Fusion Network, termed VMDU-Net. This architecture employs two parallel encoders: one incorporates Vision Mamba modules, and the other integrates a custom-designed Cross-Shape Transformer. To enhance semantic understanding of polyp morphology and boundaries, we design a Mamba-Transformer-Merge (MTM) module that performs attention-weighted fusion across spatial and channel dimensions. Furthermore, Depthwise Separable Convolutions are introduced to facilitate multi-scale feature extraction and improve convergence efficiency by leveraging the inductive bias of convolution.ResultsExtensive experiments were conducted on five widely-used polyp segmentation datasets. The results show that VMDU-Net significantly outperforms existing state-of-the-art methods, especially in terms of segmentation accuracy and boundary detail preservation. Notably, the model achieved a Dice score of 0.934 on the Kvasir-SEG dataset and 0.951 on the CVC-ClinicDB dataset.DiscussionThe proposed VMDU-Net effectively addresses key challenges in polyp segmentation by leveraging complementary strengths of Transformer-based and Mamba-based modules. Its strong performance across multiple datasets highlights its potential for practical clinical application in early colorectal cancer prevention.Code availabilityThe source code is publicly available at: https://github.com/sulayman-lee0212/VMDUNet/tree/4a8b95804178511fa5798af4a7d98fd6e6b1ebf7.",2025,10.3389/frai.2025.1557508
AI-Assisted CT as a Clinical and Research Tool for COVID-19,"There is compelling support for widening the role of computed tomography (CT) for COVID-19 in clinical and research scenarios. Reverse transcription polymerase chain reaction (RT-PCR) testing, the gold standard for COVID-19 diagnosis, has two potential weaknesses: the delay in obtaining results and the possibility of RT-PCR test kits running out when demand spikes or being unavailable altogether. This perspective article discusses the potential use of CT in conjunction with RT-PCR in hospitals lacking sufficient access to RT-PCR test kits. The precedent for this approach is discussed based on the use of CT for COVID-19 diagnosis and screening in the United Kingdom and China. The hurdles and challenges are presented, which need addressing prior to realization of the potential roles for CT artificial intelligence (AI). The potential roles include a more accurate clinical classification, characterization for research roles and mechanisms, and informing clinical trial response criteria as a surrogate for clinical outcomes.",2021,10.3389/frai.2021.590189
NLP-based removal of personally identifiable information from Hungarian electronic health records,"IntroductionElectronic health records (EHR) in text format serve as crucial resources for data-driven medical research. To safeguard patient confidentiality, under the General Data Protection Regulation (GDPR), strict measures are required to ensure personal data is anonymized or pseudonymized to protect individual privacy. Natural language processing has consistently proven effective in automating the de-identification of sensitive information.MethodsWe present spaCy models to recognize personally identifiable information (PII) from a wide range of free-text medical records written in Hungarian, a low-resource language. To develop this model, we compiled a corpus of clinical documents by annotating sensitive information within electronic health records sourced from the University of Debrecen. To simplify the annotation process, we pre-annotated the documents using a rule-based method. The corpora comprises over 15,000 documents and includes more than 90,000 instances of PII. We trained several models using this corpus and also developed a separate validation corpus to assess their performance.ResultsThe performance evaluation of the de-identification models on the developed corpora resulted in F1-scores ranging from 0.9697 to 0.9926. On the validation corpora, the F1-scores ranged from 0.9772 to 0.9867, demonstrating that the models can effectively handle previously unseen examples. Our risk analysis revealed that 99.67% of the sensitive information was successfully removed from the validation dataset.DiscussionThe results indicate that similarly to other state-of-the-art systems our model is highly effective at identifying PII in clinical texts, guaranteeing that sensitive information in clinical documents can be protected without sacrificing the quality or usability of the data for research purposes. Despite these positive outcomes, several areas remain to be improved, such as the conduction of additional testing on diverse datasets, particularly those from different healthcare institutions. With ongoing refinements, these models have the potential to greatly enhance the efficiency of data de-identification processes, ensuring compliance with privacy regulations while promoting the secure sharing of medical data for scientific progress.",2025,10.3389/frai.2025.1585260
"A Community-Based Model of Care During the Fourth Wave of the COVID-19 Outbreak in Ho Chi Minh City, Vietnam","In response to a call for help during a surge in coronavirus disease-19 (COVID-19) cases in Ho Chi Minh City in July 2021, the University of Medicine and Pharmacy at Ho Chi Minh City developed and implemented a community care model for the management of patients with COVID-19. This was based on three main principles: home care; providing monitoring and care at a distance; and providing timely emergency care if needed. One team supported patients at home with frequent contacts and remote monitoring, while a second team transferred and cared for patients requiring treatment at field emergency care facilities. COVID-19-related mortality rates at the two districts where this approach was implemented (0.43% and 0.57%) were substantially lower than the overall rate in Ho Chi Minh City over the same period (4.95%). Thus, utilization of a community care model can increase the number of patients with COVID-19 who can be effectively managed from home, and use of field emergency care facilities limited the number of patients that had to be referred for tertiary care. Importantly, the community care model also markedly reduced the mortality rate compared with traditional methods of COVID-19 patient management.",2022,10.3389/frai.2022.831841
Weaponizing cognitive bias in autonomous systems: a framework for black-box inference attacks,"Autonomous systems operating in high-dimensional environments increasingly rely on prioritization heuristics to allocate attention and assess risk, yet these mechanisms can introduce cognitive biases such as salience, spatial framing, and temporal familiarity that influence decision-making without altering the input or accessing internal states. This study presents Priority Inversion via Operational Reasoning (PRIOR), a black-box, non-perturbative diagnostic framework that employs structurally biased but semantically neutral scenario cues to probe inference-level vulnerabilities without modifying pixel-level, statistical, or surface semantic properties. Given the limited accessibility of embodied vision-based systems, we evaluate PRIOR using large language models (LLMs) as abstract reasoning proxies to simulate cognitive prioritization in constrained textual surveillance scenarios inspired by Unmanned Aerial Vehicle (UAV) operations. Controlled experiments demonstrate that minimal structural cues can consistently induce priority inversions across multiple models, and joint analysis of model justifications and confidence estimates reveals systematic distortions in inferred threat relevance even when inputs are symmetrical. These findings expose the fragility of inference-level reasoning in black-box systems and motivate the development of evaluation strategies that extend beyond output correctness to interrogate internal prioritization logic, with implications for dynamic, embodied, and visually grounded agents in real-world deployments.",2025,10.3389/frai.2025.1623573
Unsupervised domain adaptation for the detection of cardiomegaly in cross-domain chest X-ray images,"In recent years, several deep learning approaches have been successfully applied in the field of medical image analysis. More specifically, different deep neural network architectures have been proposed and assessed for the detection of various pathologies based on chest X-ray images. While the performed assessments have shown very promising results, most of them consist in training and evaluating the performance of the proposed approaches on a single data set. However, the generalization of such models is quite limited in a cross-domain setting, since a significant performance degradation can be observed when these models are evaluated on data sets stemming from different medical centers or recorded under different protocols. The performance degradation is mostly caused by the domain shift between the training set and the evaluation set. To alleviate this problem, different unsupervised domain adaptation approaches are proposed and evaluated in the current work, for the detection of cardiomegaly based on chest X-ray images, in a cross-domain setting. The proposed approaches generate domain invariant feature representations by adapting the parameters of a model optimized on a large set of labeled samples, to a set of unlabeled images stemming from a different data set. The performed evaluation points to the effectiveness of the proposed approaches, since the adapted models outperform optimized models which are directly applied to the evaluation sets without any form of domain adaptation.",2023,10.3389/frai.2023.1056422
Heart rate prediction with contactless active assisted living technology: a smart home approach for older adults,"BackgroundAs global demographics shift toward an aging population, monitoring their heart rate becomes essential, a key physiological metric for cardiovascular health. Traditional methods of heart rate monitoring are often invasive, while recent advancements in Active Assisted Living provide non-invasive alternatives. This study aims to evaluate a novel heart rate prediction method that utilizes contactless smart home technology coupled with machine learning techniques for older adults.MethodsThe study was conducted in a residential environment equipped with various contactless smart home sensors. We recruited 40 participants, each of whom was instructed to perform 23 types of predefined daily living activities across five phases. Concurrently, heart rate data were collected through Empatica E4 wristband as the benchmark. Analysis of data involved five prominent machine learning models: Support Vector Regression, K-nearest neighbor, Random Forest, Decision Tree, and Multilayer Perceptron.ResultsAll machine learning models achieved commendable prediction performance, with an average Mean Absolute Error of 7.329. Particularly, Random Forest model outperformed the other models, achieving a Mean Absolute Error of 6.023 and a Scatter Index value of 9.72%. The Random Forest model also showed robust capabilities in capturing the relationship between individuals' daily living activities and their corresponding heart rate responses, with the highest R2 value of 0.782 observed during morning exercise activities. Environmental factors contribute the most to model prediction performance.ConclusionsThe utilization of the proposed non-intrusive approach enabled an innovative method to observe heart rate fluctuations during different activities. The findings of this research have significant implications for public health. By predicting heart rate based on contactless smart home technologies for individuals' daily living activities, healthcare providers and public health agencies can gain a comprehensive understanding of an individual's cardiovascular health profile. This valuable information can inform the implementation of personalized interventions, preventive measures, and lifestyle modifications to mitigate the risk of cardiovascular diseases and improve overall health outcomes.",2024,10.3389/frai.2023.1342427
Limitations of broadly trained LLMs in interpreting orthopedic Walch glenoid classifications,"Artificial intelligence (AI) integration in medical practice has grown substantially, with physician use nearly doubling from 38% in 2023 to 68% in 2024. Recent advances in large language models (LLMs) include multimodal inputs, showing potential for medical image interpretation and clinical software integrations. This study evaluated the accuracy of two popular LLMs, Claude 3.5 Sonnet and DeepSeek R1, in interpreting glenoid diagrams using Walch glenoid classification in preoperative shoulder reconstruction applications. Test images included seven black-white Walch glenoid diagrams from Radiopedia. LLMs were accessed via Perplexity.ai without specialized medical training. LLMs were tested across multiple conversation threads with prompt instructions of varying length, ranging from 22 to 864 words for DeepSeek and 127 to 840 words for Claude. Performance differed significantly between models. DeepSeek achieved 44% accuracy (7/16), while Claude had 0% accuracy (0/16). DeepSeek showed a mild positive correlation between instruction length and response accuracy. Common errors across both LLMs included misclassifying A2 as either A1 (32%) or B2 (20%). Results highlight limitations in broadly trained LLMs’ ability to interpret even simplified medical diagrams. DeepSeek’s continuous learning feature and open-source dataset integration exhibited superior accuracy, although it was still insufficient for clinical applications. These limitations stem from LLM training data containing primarily text instead of medical images, creating pattern recognition deficiencies when interpreting visual medical information. Despite AI’s growing adoption in healthcare, this study concludes that as of February 2025, publicly available broadly trained LLMs lack the consistency and accuracy necessary for reliable medical image interpretation, emphasizing the need for specialized training before clinical implementation.",2025,10.3389/frai.2025.1644093
Modeling disagreement in automatic data labeling for semi-supervised learning in Clinical Natural Language Processing,"IntroductionComputational models providing accurate estimates of their uncertainty are crucial for risk management associated with decision-making in healthcare contexts. This is especially true since many state-of-the-art systems are trained using the data which have been labeled automatically (self-supervised mode) and tend to overfit.MethodsIn this study, we investigate the quality of uncertainty estimates from a range of current state-of-the-art predictive models applied to the problem of observation detection in radiology reports. This problem remains understudied for Natural Language Processing in the healthcare domain.ResultsWe demonstrate that Gaussian Processes (GPs) provide superior performance in quantifying the risks of three uncertainty labels based on the negative log predictive probability (NLPP) evaluation metric and mean maximum predicted confidence levels (MMPCL), whilst retaining strong predictive performance.DiscussionOur conclusions highlight the utility of probabilistic models applied to “noisy” labels and that similar methods could provide utility for Natural Language Processing (NLP) based automated labeling tasks.",2024,10.3389/frai.2024.1374162
Enhancing prediction of primary site recurrence in head and neck cancer using radiomics and uncertainty estimation,"IntroductionHead and neck squamous cell carcinomas (HNSCC) present a significant clinical challenge due to high recurrence rates despite advances in radiation and chemotherapy. Early detection of recurrence is critical for optimizing treatment outcomes and improving patient survival.MethodsWe developed two artificial intelligence (AI) pipelines—(1) machine learning models trained on radiomic and clinical data and (2) a Vision Transformer-based model directly applied to imaging data—to predict HNSCC recurrence using pre- and post-treatment PET/CT scans from a cohort of 249 patients. We incorporated Test-Time Augmentation (TTA) and Conformal Prediction to quantify prediction uncertainty and enhance model reliability.ResultsThe machine learning models achieved an average AUC of 0.820. The vision transformer model showed moderate performance (AUC = 0.658). Uncertainty quantification enabled the exclusion of ambiguous predictions, improving accuracy among more confident cases.DiscussionOur machine learning models achieved strong performance in predicting HNSCC recurrence from radiomic and clinical features. Incorporating uncertainty quantification further improved predictive performance and reliability.",2025,10.3389/frai.2025.1623393
Modeling the dynamics of contractual relations,"Contracts usually have clauses that enable contracted parties to adjust their contractual positions in time, e.g., to relieve another party from duty or to grant new permission. This is especially important in long-running service relations, which require contracts to be adjusted to accommodate new or unforeseen circumstances. Despite that, the representation of dynamic aspects of contractual relations has not been given enough attention in the literature. In this study, we address this gap by employing the notions of legal power and legal subjection. We propose an ontological analysis of unilateral contractual changes based on a well-founded legal core ontology that adopts a relational perspective for legal positions. We present a case study to show the benefits of representing different types of contractual changes and how these changes can impact contractual dynamics. The case study is based on recent changes to WhatsApp terms of service.",2023,10.3389/frai.2023.1042319
AI for Improving Children’s Health: A Community Case Study,"The Indian health care system lacks the infrastructure to meet the health care demands of the country. Physician and nurse availability is 30 and 50% below WHO recommendations, respectively, and has led to a steep imbalance between the demand for health care and the infrastructure available to support it. Among other concerns, India still struggles with challenges like undernutrition, with 38% of children under the age of five being underweight. Despite these challenges, technological advancements, mobile phone ubiquity and rising patient awareness offers a huge opportunity for artificial intelligence to enable efficient healthcare delivery, by improved targeting of constrained resources. The Saathealth mobile app provides low-middle income parents of young children nflwith interactive children’s health, nutrition and development content in the form of an entertaining video series, a gamified quiz journey and targeted notifications. The app iteratively evolves the user journey based on dynamic data and predictive algorithms, empowering a shift from reactive to proactive care. Saathealth users have registered over 500,000 sessions and over 200 million seconds on-app engagement over a year, comparing favorably with engagement on other digital health interventions in underserved communities. We have used valuable app analytics data and insights from our 45,000 users to build scalable, predictive models that were validated for specific use cases. Using the Random Forest model with heterogeneous data allowed us to predict user churn with a 93% accuracy. Predicting user lifetimes on the mobile app for preliminary insights gave us an RMSE of 25.09 days and an R2 value of 0.91, reflecting closely correlated predictions. These predictive algorithms allow us to incentivize users with optimized offers and omni-channel nudges, to increase engagement with content as well as other targeted online and offline behaviors. The algorithms also optimize the effectiveness of our intervention by augmenting personalized experiences and directing limited health resources toward populations that are most resistant to digital first interventions. These and similar AI powered algorithms will allow us to lengthen and deepen the lifetime relationship with our health consumers, making more of them effective, proactive participants in improving children’s health, nutrition and early cognitive development.",2021,10.3389/frai.2020.544972
Fall risk prediction using temporal gait features and machine learning approaches,"IntroductionFalls have been acknowledged as a major public health issue around the world. Early detection of fall risk is pivotal for preventive measures. Traditional clinical assessments, although reliable, are resource-intensive and may not always be feasible.MethodsThis study explores the efficacy of artificial intelligence (AI) in predicting fall risk, leveraging gait analysis through computer vision and machine learning techniques. Data was collected using the Timed Up and Go (TUG) test and JHFRAT assessment from MMU collaborators and augmented with a public dataset from Mendeley involving older adults. The study introduces a robust approach for extracting and analyzing gait features, such as stride time, step time, cadence, and stance time, to distinguish between fallers and non-fallers.ResultsTwo experimental setups were investigated: one considering separate gait features for each foot and another analyzing averaged features for both feet. Ultimately, the proposed solutions produce promising outcomes, greatly enhancing the model’s ability to achieve high levels of accuracy. In particular, the LightGBM demonstrates a superior accuracy of 96% in the prediction task.DiscussionThe findings demonstrate that simple machine learning models can successfully identify individuals at higher fall risk based on gait characteristics, with promising results that could potentially streamline fall risk assessment processes. However, several limitations were discovered throughout the experiment, including an insufficient dataset and data variation, limiting the model’s generalizability. These issues are raised for future work consideration. Overall, this research contributes to the growing body of knowledge on fall risk prediction and underscores the potential of AI in enhancing public health strategies through the early identification of at-risk individuals.",2024,10.3389/frai.2024.1425713
Redefining digital health interfaces with large language models,"Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their adoption remains comparatively limited due, in part, to challenges surrounding usability and trust. Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, however, as LLMs are susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLM-based systems, with LLMs acting as agents, can utilize external tools and provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLMs in clinical settings, such as hallucinations. We illustrate LLM-based interfaces with examples of cardiovascular disease and stroke risk prediction, quantitatively assessing their performance and highlighting the benefit compared to traditional interfaces for digital tools.",2025,10.3389/frai.2025.1623339
How AI competencies can make B2B marketing smarter: strategies to boost customer lifetime value,"There has been a rapid rise in utilization of artificial intelligence (AI) in many different sectors in the last several years. However, business-to-business (B2B) marketing is one of the more notable examples. The initial assessments emphasize the significant advantages of AI in B2B marketing, including its knack for yielding unique understandings into consumer behaviors, recognizing crucial market trends, and improving operational efficiency. However, there seems to be a limited grasp of the optimal way to develop artificial intelligence competencies (AIC) for B2B marketing and how these attributes inevitably affect customer lifetime value (CLV). Equipped with AIC and B2B marketing literary fiction, this research unveils a theoretical research framework for evaluating the repercussions of AIC on B2B marketing capabilities and, subsequently, on CLV. We analyze the suggested research model using partial least squares structural equation modeling (PLS-SEM), leveraging 367 survey replies from Pakistani companies. The outcomes show a significant relationship that describe the ability to leverage AIC to enhance CLV, and also signifies the mediating role of B2B marketing capabilities to enhance CLV by integrating AIC in internet marketing. The findings of this study provide practical implications for marketers to monetize their marketing skills to enhance CLV and researchers with theoretical underpinnings of integration of AIC into marketing.",2024,10.3389/frai.2024.1451228
Evaluating XAI techniques under class imbalance using CPRD data,"Introduction
                    
                      The need for eXplainable Artificial Intelligence (XAI) in healthcare is more critical than ever, especially as regulatory frameworks such as the European Union Artificial Intelligence (EU AI) Act mandate transparency in clinical decision support systems.
                      Post hoc
                      XAI techniques such as Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP) and Partial Dependence Plots (PDPs) are widely used to interpret Machine Learning (ML) models for disease risk prediction, particularly in tabular Electronic Health Record (EHR) data. However, their reliability under real-world scenarios is not fully understood. Class imbalance is a common challenge in many real-world datasets, but it is rarely accounted for when evaluating the reliability and consistency of XAI techniques.
                    
                  
                  
                    Methods
                    In this study, we design a comparative evaluation framework to assess the impact of class imbalance on the consistency of model explanations generated by LIME, SHAP, and PDPs. Using UK primary care data from the Clinical Practice Research Datalink (CPRD), we train three ML models: XGBoost (XGB), Random Forest (RF), and Multi-layer Perceptron (MLP), to predict lung cancer risk and evaluate how interpretability is affected under class imbalance when compared against a balanced dataset. To our knowledge, this is the first study to evaluate explanation consistency under class imbalance across multiple models and interpretation methods using real-world clinical data.
                  
                  
                    Results
                    Our main finding is that class imbalance in the training data can significantly affect the reliability and consistency of LIME and SHAP explanations when evaluated against models trained on balanced data. To explain these empirical findings, we also present a theoretical analysis of LIME and SHAP to understand why explanations change under different class distributions. It is also found that PDPs exhibit noticeable variation between models trained on imbalanced and balanced datasets with respect to clinically relevant features for predicting lung cancer risk.
                  
                  
                    Discussion
                    These findings highlight a critical vulnerability in current XAI techniques, i.e., their interpretability are significantly affected under skewed class distributions, which is common in medical data and emphasises the importance of consistent model explanations for trustworthy ML deployment in healthcare.",2025,10.3389/frai.2025.1682919
Identification of Suicidal Ideation in the Canadian Community Health Survey—Mental Health Component Using Deep Learning,"Introduction:
                    Suicidal ideation (SI) is prevalent in the general population, and is a risk factor for suicide. Predicting which patients are likely to have SI remains challenging. Deep Learning (DL) may be a useful tool in this context, as it can be used to find patterns in complex, heterogeneous, and incomplete datasets. An automated screening system for SI could help prompt clinicians to be more attentive to patients at risk for suicide.
                  
                  
                    Methods:
                    Using the Canadian Community Health Survey—Mental Health Component, we trained a DL model based on 23,859 survey responses to classify patients with and without SI. Models were created to classify both lifetime SI and SI over the last 12 months. From 582 possible parameters we produced 96- and 21-feature versions of the models. Models were trained using an undersampling procedure that balanced the training set between SI and non-SI; validation was done on held-out data.
                  
                  
                    Results:
                    For lifetime SI, the 96 feature model had an Area under the receiver operating curve (AUC) of 0.79 and the 21 feature model had an AUC of 0.77. For SI in the last 12 months the 96 feature model had an AUC of 0.71 and the 21 feature model had an AUC of 0.68. In addition, sensitivity analyses demonstrated feature relationships in line with existing literature.
                  
                  
                    Discussion:
                    Although further study is required to ensure clinical relevance and sample generalizability, this study is an initial proof of concept for the use of DL to improve identification of SI. Sensitivity analyses can help improve the interpretability of DL models. This kind of model would help start conversations with patients which could lead to improved care and a reduction in suicidal behavior.",2021,10.3389/frai.2021.561528
A robust approach for endotracheal tube localization in chest radiographs,"Precise detection and localization of the Endotracheal tube (ETT) is essential for patients receiving chest radiographs. A robust deep learning model based on U-Net++ architecture is presented for accurate segmentation and localization of the ETT. Different types of loss functions related to distribution and region-based loss functions are evaluated in this paper. Then, various integrations of distribution and region-based loss functions (compound loss function) have been applied to obtain the best intersection over union (IOU) for ETT segmentation. The main purpose of the presented study is to maximize IOU for ETT segmentation, and also minimize the error range that needs to be considered during calculation of distance between the real and predicted ETT by obtaining the best integration of the distribution and region loss functions (compound loss function) for training the U-Net++ model. We analyzed the performance of our model using chest radiograph from the Dalin Tzu Chi Hospital in Taiwan. The results of applying the integration of distribution-based and region-based loss functions on the Dalin Tzu Chi Hospital dataset show enhanced segmentation performance compared to other single loss functions. Moreover, according to the obtained results, the combination of Matthews Correlation Coefficient (MCC) and Tversky loss functions, which is a hybrid loss function, has shown the best performance on ETT segmentation based on its ground truth with an IOU value of 0.8683.",2023,10.3389/frai.2023.1181812
LegNER: a domain-adapted transformer for legal named entity recognition and text anonymization,"The increasing demand for scalable and privacy-preserving processing of legal documents has intensified the need for accurate Named Entity Recognition (NER) systems tailored to the legal domain. In this work, we introduce
                    LegNER
                    , a domain-adapted transformer model designed for both legal NER and text anonymization. The model is trained on a corpus of 1,542 manually annotated court cases and enriched with an extended legal vocabulary, enabling robust recognition of six critical entity types, including
                    PERSON
                    ,
                    ORGANIZATION
                    ,
                    LAW
                    , and
                    CASE_REFERENCE
                    . Built on BERT-base and enhanced through domain-specific pretraining and span-level supervision, LegNER consistently outperforms established legal NER baselines. Experimental results demonstrate significant gains in accuracy (99%), F1 score (over 99%), and inference efficiency (processing more than 12 documents per second), confirming both its precision and scalability. Beyond quantitative improvements, qualitative evaluation highlights LegNERs ability to generate coherent anonymized outputs, a crucial requirement for GDPR-compliant redaction and automated legal analytics. Taken together, these results establish LegNER as a reliable and effective solution for high-precision entity recognition and anonymization in compliance-sensitive legal workflows.",2025,10.3389/frai.2025.1638971
"Enhancing e-commerce recommendation systems through approach of buyer's self-construal: necessity, theoretical ground, synthesis of a six-step model, and research agenda","The current recommendation system predominantly relies on evidential factors such as behavioral outcomes and purchasing history. However, limited research has been conducted to explore the use of psychological data in these algorithms, such as consumers' self-perceived identities. Based on the gap identified and the soaring significance of levering the non-purchasing data, this study presents a methodology to quantify consumers' self-identities to help examine the relationship between these psychological cues and decision-making in an e-commerce context, focusing on the projective self, which has been overlooked in previous research. This research is expected to contribute to a better understanding of the cause of inconsistency in similar studies and provide a basis for further exploration of the impact of self-concepts on consumer behavior. The coding method in grounded theory, in conjunction with the synthesis of literature analysis, was employed to generate the final approach and solution in this study as they provide a robust and rigorous basis for the findings and recommendations presented in this study.",2023,10.3389/frai.2023.1167735
"Multimodal observable cues in mood, anxiety, and borderline personality disorders: a review of reviews to inform explainable AI in mental health","Mental health disorders, such as depression, anxiety, and borderline personality disorder (BPD), are common, often begin early, and can cause profound impairment. Traditional assessments rely heavily on subjective reports and clinical observation, which can be inconsistent and biased. Recent advances in AI offer a promising complement by analyzing objective, observable cues from speech, language, facial expressions, physiological signals, and digital behavior. Explainable AI ensures these patterns remain interpretable and clinically meaningful. A synthesis of 24 recent systematic and scoping reviews shows that depression is linked to self-focused negative language, slowed and monotonous speech, reduced facial expressivity, disrupted sleep and activity, and altered phone or online behavior. Anxiety disorders present with negative language bias, monotone speech with pauses, physiological hyperarousal, and avoidance-related behaviors. BPD exhibits more complex patterns, including impersonal or externally focused language, speech dysregulation, paradoxical facial expressions, autonomic dysregulation, and socially ambivalent behaviors. Some cues, like reduced heart rate variability and flattened speech, appear across conditions, suggesting shared transdiagnostic mechanisms, while BPD’s interpersonal and emotional ambivalence stands out. These findings highlight the potential of observable, digitally measurable cues to complement traditional assessments, enabling earlier detection, ongoing monitoring, and more personalized interventions in psychiatry.",2025,10.3389/frai.2025.1696448
A Machine Learning Approach to Personalize Computerized Cognitive Training Interventions,"Executive functions are a class of cognitive processes critical for purposeful goal-directed behavior. Cognitive training is the adequate stimulation of executive functions and has been extensively studied and applied for more than 20 years. However, there is still a lack of solid consensus in the scientific community about its potential to elicit consistent improvements in untrained domains. Individual differences are considered one of the most important factors of inconsistent reports on cognitive training benefits, as differences in cognitive functioning are both genetic and context-dependent, and might be affected by age and socioeconomic status. We here present a proof of concept based on the hypothesis that baseline individual differences among subjects would provide valuable information to predict the individual effectiveness of a cognitive training intervention. With a dataset from an investigation in which 73 6-year-olds trained their executive functions using an online software with a fixed protocol, freely available at www.matemarote.org.ar, we trained a support vector classifier that successfully predicted (average accuracy = 0.67, AUC = 0.707) whether a child would improve, or not, after the cognitive stimulation, using baseline individual differences as features. We also performed a permutation feature importance analysis that suggested that all features contribute equally to the model's performance. In the long term, this results might allow us to design better training strategies for those players who are less likely to benefit from the current training protocols in order to maximize the stimulation for each child.",2022,10.3389/frai.2022.788605
Automatic modeling of student characteristics with interaction and physiological data using machine learning: A review,"Student characteristics affect their willingness and ability to acquire new knowledge. Assessing and identifying the effects of student characteristics is important for online educational systems. Machine learning (ML) is becoming significant in utilizing learning data for student modeling, decision support systems, adaptive systems, and evaluation systems. The growing need for dynamic assessment of student characteristics in online educational systems has led to application of machine learning methods in modeling the characteristics. Being able to automatically model student characteristics during learning processes is essential for dynamic and continuous adaptation of teaching and learning to each student's needs. This paper provides a review of 8 years (from 2015 to 2022) of literature on the application of machine learning methods for automatic modeling of various student characteristics. The review found six student characteristics that can be modeled automatically and highlighted the data types, collection methods, and machine learning techniques used to model them. Researchers, educators, and online educational systems designers will benefit from this study as it could be used as a guide for decision-making when creating student models for adaptive educational systems. Such systems can detect students' needs during the learning process and adapt the learning interventions based on the detected needs. Moreover, the study revealed the progress made in the application of machine learning for automatic modeling of student characteristics and suggested new future research directions for the field. Therefore, machine learning researchers could benefit from this study as they can further advance this area by investigating new, unexplored techniques and find new ways to improve the accuracy of the created student models.",2022,10.3389/frai.2022.1015660
LMS-ViT: a multi-scale vision transformer approach for real-time smartphone-based skin cancer detection,"Skin cancer is the abnormal growth of skin cells. It occurs mostly in skin exposed to sunlight. To prevent the occurrence of skin cancer, avoid exposing skin to ultraviolet radiation. Skin cancer can be very harmful if found very late. Traditional convolutional neural networks (CNNs) face challenges in fine-grained lesion classification due to their limited ability to extract detailed features. To overcome such limitations, we introduced a novel approach in the form of a lightweight multi-scale vision transformer (LMS-ViT) application for the automated detection of skin cancer using dermoscopic images and the HAM10000 dataset. Unlike CNNs, LMS-ViT employs a multi-scale attention mechanism to capture both global lesion structures and fine-grained textural details, improving classification accuracy. This study combines skin images from the HAM10000 dataset with pictures taken using a smartphone. It uses a compact method to mix important features, which makes the system faster and suitable for real-time use in medical apps. The proposed system enables real-time skin cancer classification via a smartphone camera, making it portable and platform-independent. Experimental results show that LMS-ViT surpasses CNN-based models across all skin lesion categories, achieving 90% accuracy, an 18% improvement over CNN, while reducing computational cost by 30%. LMS-ViT also improves precision, recall, and F1-score, particularly in complex categories such as Vasc (0.96 to 1.01) and Nv (0.94 to 1.01), demonstrating superior classification power. With real-time android implementation, LMS-ViT offers accessible, mobile-friendly diagnostics for early skin cancer detection.",2025,10.3389/frai.2025.1612502
Application of machine learning for lung cancer survival prognostication—A systematic review and meta-analysis,"IntroductionMachine learning (ML) techniques have gained increasing attention in the field of healthcare, including predicting outcomes in patients with lung cancer. ML has the potential to enhance prognostication in lung cancer patients and improve clinical decision-making. In this systematic review and meta-analysis, we aimed to evaluate the performance of ML models compared to logistic regression (LR) models in predicting overall survival in patients with lung cancer.MethodsWe followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) statement. A comprehensive search was conducted in Medline, Embase, and Cochrane databases using a predefined search query. Two independent reviewers screened abstracts and conflicts were resolved by a third reviewer. Inclusion and exclusion criteria were applied to select eligible studies. Risk of bias assessment was performed using predefined criteria. Data extraction was conducted using the Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modeling Studies (CHARMS) checklist. Meta-analytic analysis was performed to compare the discriminative ability of ML and LR models.ResultsThe literature search resulted in 3,635 studies, and 12 studies with a total of 211,068 patients were included in the analysis. Six studies reported confidence intervals and were included in the meta-analysis. The performance of ML models varied across studies, with C-statistics ranging from 0.60 to 0.85. The pooled analysis showed that ML models had higher discriminative ability compared to LR models, with a weighted average C-statistic of 0.78 for ML models compared to 0.70 for LR models.ConclusionMachine learning models show promise in predicting overall survival in patients with lung cancer, with superior discriminative ability compared to logistic regression models. However, further validation and standardization of ML models are needed before their widespread implementation in clinical practice. Future research should focus on addressing the limitations of the current literature, such as potential bias and heterogeneity among studies, to improve the accuracy and generalizability of ML models for predicting outcomes in patients with lung cancer. Further research and development of ML models in this field may lead to improved patient outcomes and personalized treatment strategies.",2024,10.3389/frai.2024.1365777
Leveraging diffusion models for unsupervised out-of-distribution detection on image manifold,"Out-of-distribution (OOD) detection is crucial for enhancing the reliability of machine learning models when confronted with data that differ from their training distribution. In the image domain, we hypothesize that images inhabit manifolds defined by latent properties such as color, position, and shape. Leveraging this intuition, we propose a novel approach to OOD detection using a diffusion model to discern images that deviate from the in-domain distribution. Our method involves training a diffusion model using in-domain images. At inference time, we lift an image from its original manifold using a masking process, and then apply a diffusion model to map it towards the in-domain manifold. We measure the distance between the original and mapped images, and identify those with a large distance as OOD. Our experiments encompass comprehensive evaluation across various datasets characterized by differences in color, semantics, and resolution. Our method demonstrates strong and consistent performance in detecting OOD images across the tested datasets, highlighting its effectiveness in handling images with diverse characteristics. Additionally, ablation studies confirm the significant contribution of each component in our framework to the overall performance.",2024,10.3389/frai.2024.1255566
“Machine replacement” or “job creation”: How does artificial intelligence impact employment patterns in China's manufacturing industry?,"Artificial intelligence (AI), as an important engine for promoting high-quality economic development, should not be overlooked in terms of its impact on the employment of the labor force while promoting the digital and intelligent transformation of industries. In the face of the complex international environment and non-systemic shocks, it is of great significance to explore whether it is “machine replacement” or “job creation” in the process of the integration of AI and industry, as well as the impact of technological progress on the employment pattern of the labor force, in order to promote the economic development, respond to and solve the employment problem. It is of great significance to promote economic development and cope with and solve the employment problem. Based on the task model, this paper analyses the mechanism of the impact of AI on the employment pattern of manufacturing industry. Meanwhile, based on the provincial panel data of China's manufacturing industry from 2011 to 2020, it empirically examines the impact of AI on the total employment, employment structure and employment quality of the labor force, and analyses the multiple responses of AI on the employment pattern of the manufacturing industry. The study shows that: Firstly, the level of development of AI and the total amount of employment is a positive U-shaped relationship, the short term is dominated by the substitution effect, and the long term is dominated by the creation effect; Secondly, with regard to the employment structure, low-skilled labor is more likely to be replaced. The financial, accommodation and catering industries are relatively less affected by the spillover effects of the manufacturing industry; Third, with regard to the employment quality, the gap between urban and rural incomes has eased, with per capita net income of rural residents rising to a higher degree than per capita disposable income of urban residents. Thus, in order to further address the impact of AI on the employment patterns of the labor force, the level of AI development should be increased while expanding employment channels, paying attention to labor force skills training, reinforcing the leading role of developed regions, and accelerating regional integration and urban-rural integration, so as to share the dividends of technological progress.",2024,10.3389/frai.2024.1337264
Impact of Box-Cox Transformation on Machine-Learning Algorithms,"This paper studied the effects of applying the Box-Cox transformation for classification tasks. Different optimization strategies were evaluated, and the results were promising on four synthetic datasets and two real-world datasets. A consistent improvement in accuracy was demonstrated using a grid exploration with cross-validation. In conclusion, applying the Box-Cox transformation could drastically improve the performance by up to a 12% accuracy increase. Moreover, the Box-Cox parameter choice was dependent on the data and the used classifier.",2022,10.3389/frai.2022.877569
Multi-agent systems powered by large language models: applications in swarm intelligence,"This work examines the integration of large language models (LLMs) into multi-agent simulations by replacing the hard-coded programs of agents with LLM-driven prompts. The proposed approach is showcased in the context of two examples of complex systems from the field of swarm intelligence: ant colony foraging and bird flocking. Central to this study is a toolchain that integrates LLMs with the NetLogo simulation platform, leveraging its Python extension to enable communication with GPT-4o via the OpenAI API. This toolchain facilitates prompt-driven behavior generation, allowing agents to respond adaptively to environmental data. For both example applications mentioned above, we employ both structured, rule-based prompts and autonomous, knowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs to study self-organizing processes and induce emergent behaviors within multi-agent environments, paving the way for new approaches to exploring intelligent systems and modeling swarm intelligence inspired by natural phenomena. We provide the code, including simulation files and data at
                    https://github.com/crjimene/swarm_gpt
                    .",2025,10.3389/frai.2025.1593017
Phenotype clustering in health care: A narrative review for clinicians,"Human pathophysiology is occasionally too complex for unaided hypothetical-deductive reasoning and the isolated application of additive or linear statistical methods. Clustering algorithms use input data patterns and distributions to form groups of similar patients or diseases that share distinct properties. Although clinicians frequently perform tasks that may be enhanced by clustering, few receive formal training and clinician-centered literature in clustering is sparse. To add value to clinical care and research, optimal clustering practices require a thorough understanding of how to process and optimize data, select features, weigh strengths and weaknesses of different clustering methods, select the optimal clustering method, and apply clustering methods to solve problems. These concepts and our suggestions for implementing them are described in this narrative review of published literature. All clustering methods share the weakness of finding potential clusters even when natural clusters do not exist, underscoring the importance of applying data-driven techniques as well as clinical and statistical expertise to clustering analyses. When applied properly, patient and disease phenotype clustering can reveal obscured associations that can help clinicians understand disease pathophysiology, predict treatment response, and identify patients for clinical trial enrollment.",2022,10.3389/frai.2022.842306
The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts,"The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models' (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models' performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20× more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts.",2023,10.3389/frai.2023.1279794
"Knowledge, attitude, and practice of artificial intelligence among doctors and medical students in Syria: A cross-sectional online survey","Artificial intelligence has been prevalent recently as its use in the medical field is noticed to be increased. However, middle east countries like Syria are deficient in multiple AI implementation methods in the field of medicine. So, holding these AI implementation methods in the medical field is necessary, which may be incredibly beneficial for making diagnosis more accessible and help in the treatment. This paper intends to determine AI's knowledge, attitude, and practice among doctors and medical students in Syria. A questionnaire conducted an online cross-sectional study on the google form website consisting of demographic data, knowledge, and perception of AI. There were 1,494 responses from both doctors and medical students. We included Syrian medical students and doctors who are currently residing in Syria. Of the 1,494 participants, 255 (16.9%) are doctors, while the other 1,252 (83.1%) are undergraduate medical students. About 1,055 (70%) participants have previous knowledge about AI. However, only 357 (23.7%) participants know about its application in the medical field. Most have shown positive attitudes toward its necessity in the medical field; 689 (45.7%) individuals strongly agree, and 628 (41.7%) agree. The undergraduate students had 3.327 times more adequate knowledge of AI than students in the first year. In contrast, the undergraduate 6th-year students had 2.868 times the attitude toward AI higher than students in the first year. The residents and assistant professors had 2.371 and 4.422 times the practice of AI higher than students, respectively. Although most physicians and medical students do not sufficiently understand AI and its significance in the medical field, they have favorable views regarding using AI in the medical field. Syrian medical authorities and international organizations should suggest including artificial intelligence in the medical field, particularly when training residents and fellowship physicians.",2022,10.3389/frai.2022.1011524
Exploring how AI adoption in the workplace affects employees: a bibliometric and systematic review,"IntroductionThe adoption of artificial intelligence (AI) in the workplace is changing the way organizations function, and profoundly affecting employees. These organizational changes raise crucial questions about the employee’s future and well-being. Our study aims to explore the intersection between artificial intelligence and employee well-being through a bibliometric review and a contextual analysis.MethodologyCarried out in May 2024, our study is divided into two phases. The first phase, dedicated to bibliometric review, was conducted using the PRISMA method, and explored the Scopus and Web of Science databases for the period from 2015 to 2024. A total of 92 articles were selected for quantitative analysis using VOSviewer software. The second phase is based on an in-depth systematic analysis of 25 articles selected from those previously identified. These articles were selected on the basis of their relevance to the research question, and were subjected to in-depth thematic analysis using NVivo software.ResultsThe bibliometric analysis results reveal a significant increase in publications starting from the year 2020, highlighting advancements in research, primarily in the United States and China. The co-occurrence analysis identifies four main clusters: ethics, work autonomy, employee stress, and mental health, thus illustrating the dynamics created by artificial intelligence in the professional environment. Furthermore, the systematic analysis has brought to light theoretical gaps and under-explored areas, such as the need to conduct empirical studies in non-Western cultural contexts and among diverse target groups, including older adults, individuals of different sexes, people with low education levels, and participants from various sectors, including primary and secondary industries, small manufacturing businesses, call centers, as well as public and private healthcare sectors.ConclusionExisting literature emphasize the importance for organizations to implement supportive strategies aimed at mitigating the potential adverse effects of AI on employee well-being, while also leveraging its benefits to enhance workplace autonomy and satisfaction and promote AI-enabled innovation through employee creativity and self-efficacy.",2024,10.3389/frai.2024.1473872
Rise of artificial general intelligence: risks and opportunities,"Artificial intelligence is making extraordinary progress with an unprecedented rate, reaching and surpassing human capabilities in many tasks previously considered unattainable by machines, as language translation, music composition, object detection, medical diagnoses, software programming, and many others. Some people are excited about these results, while others are raising serious concerns for possible negative impacts in our society. This article addresses several questions that are often raised about intelligent machines: Will machines ever surpass human intellectual capacities? What will happen next? What will be the impact in our society? What are the jobs that artificial intelligence puts at risk? Reasoning about these questions is of fundamental importance to predict possible future scenarios and prepare ourselves to face the consequences.",2023,10.3389/frai.2023.1226990
CLIP knows image aesthetics,"Most Image Aesthetic Assessment (IAA) methods use a pretrained ImageNet classification model as a base to fine-tune. We hypothesize that content classification is not an optimal pretraining task for IAA, since the task discourages the extraction of features that are useful for IAA, e.g., composition, lighting, or style. On the other hand, we argue that the Contrastive Language-Image Pretraining (CLIP) model is a better base for IAA models, since it has been trained using natural language supervision. Due to the rich nature of language, CLIP needs to learn a broad range of image features that correlate with sentences describing the image content, composition, environments, and even subjective feelings about the image. While it has been shown that CLIP extracts features useful for content classification tasks, its suitability for tasks that require the extraction of style-based features like IAA has not yet been shown. We test our hypothesis by conducting a three-step study, investigating the usefulness of features extracted by CLIP compared to features obtained from the last layer of a comparable ImageNet classification model. In each step, we get more computationally expensive. First, we engineer natural language prompts that let CLIP assess an image's aesthetic without adjusting any weights in the model. To overcome the challenge that CLIP's prompting only is applicable to classification tasks, we propose a simple but effective strategy to convert multiple prompts to a continuous scalar as required when predicting an image's mean aesthetic score. Second, we train a linear regression on the AVA dataset using image features obtained by CLIP's image encoder. The resulting model outperforms a linear regression trained on features from an ImageNet classification model. It also shows competitive performance with fully fine-tuned networks based on ImageNet, while only training a single layer. Finally, by fine-tuning CLIP's image encoder on the AVA dataset, we show that CLIP only needs a fraction of training epochs to converge, while also performing better than a fine-tuned ImageNet model. Overall, our experiments suggest that CLIP is better suited as a base model for IAA methods than ImageNet pretrained networks.",2022,10.3389/frai.2022.976235
Advanced interpretable diagnosis of Alzheimer's disease using SECNN-RF framework with explainable AI,"Early detection of Alzheimer's disease (AD) is vital for effective treatment, as interventions are most successful in the disease's early stages. Combining Magnetic Resonance Imaging (MRI) with artificial intelligence (AI) offers significant potential for enhancing AD diagnosis. However, traditional AI models often lack transparency in their decision-making processes. Explainable Artificial Intelligence (XAI) is an evolving field that aims to make AI decisions understandable to humans, providing transparency and insight into AI systems. This research introduces the Squeeze-and-Excitation Convolutional Neural Network with Random Forest (SECNN-RF) framework for early AD detection using MRI scans. The SECNN-RF integrates Squeeze-and-Excitation (SE) blocks into a Convolutional Neural Network (CNN) to focus on crucial features and uses Dropout layers to prevent overfitting. It then employs a Random Forest classifier to accurately categorize the extracted features. The SECNN-RF demonstrates high accuracy (99.89%) and offers an explainable analysis, enhancing the model's interpretability. Further exploration of the SECNN framework involved substituting the Random Forest classifier with other machine learning algorithms like Decision Tree, XGBoost, Support Vector Machine, and Gradient Boosting. While all these classifiers improved model performance, Random Forest achieved the highest accuracy, followed closely by XGBoost, Gradient Boosting, Support Vector Machine, and Decision Tree which achieved lower accuracy.",2024,10.3389/frai.2024.1456069
Knowledge sharing in manufacturing using LLM-powered tools: user study and model benchmarking,"Recent advances in natural language processing enable more intelligent ways to support knowledge sharing in factories. In manufacturing, operating production lines has become increasingly knowledge-intensive, putting strain on a factory's capacity to train and support new operators. This paper introduces a Large Language Model (LLM)-based system designed to retrieve information from the extensive knowledge contained in factory documentation and knowledge shared by expert operators. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. We conducted a user study at a factory to assess its potential impact and adoption, eliciting several perceived benefits, namely, enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several commercial and open-sourced LLMs for this system. The current state-of-the-art model, GPT-4, consistently outperformed its counterparts, with open-source models trailing closely, presenting an attractive option given their data privacy and customization benefits. In summary, this work offers preliminary insights and a system design for factories considering using LLM tools for knowledge management.",2024,10.3389/frai.2024.1293084
Artificial Intelligence and Employment: New Cross-Country Evidence,"Recent years have seen impressive advances in artificial intelligence (AI) and this has stoked renewed concern about the impact of technological progress on the labor market, including on worker displacement. This paper looks at the possible links between AI and employment in a cross-country context. It adapts the AI occupational impact measure developed by Felten, Raj and Seamans—an indicator measuring the degree to which occupations rely on abilities in which AI has made the most progress—and extends it to 23 OECD countries. Overall, there appears to be no clear relationship between AI exposure and employment growth. However, in occupations where computer use is high, greater exposure to AI is linked to higher employment growth. The paper also finds suggestive evidence of a negative relationship between AI exposure and growth in average hours worked among occupations where computer use is low. One possible explanation is that partial automation by AI increases productivity directly as well as by shifting the task composition of occupations toward higher value-added tasks. This increase in labor productivity and output counteracts the direct displacement effect of automation through AI for workers with good digital skills, who may find it easier to use AI effectively and shift to non-automatable, higher-value added tasks within their occupations. The opposite could be true for workers with poor digital skills, who may not be able to interact efficiently with AI and thus reap all potential benefits of the technology1.",2022,10.3389/frai.2022.832736
Achieving descriptive accuracy in explanations via argumentation: The case of probabilistic classifiers,"The pursuit of trust in and fairness of AI systems in order to enable human-centric goals has been gathering pace of late, often supported by the use of explanations for the outputs of these systems. Several properties of explanations have been highlighted as critical for achieving trustworthy and fair AI systems, but one that has thus far been overlooked is that of descriptive accuracy (DA), i.e., that the explanation contents are in correspondence with the internal working of the explained system. Indeed, the violation of this core property would lead to the paradoxical situation of systems producing explanations which are not suitably related to how the system actually works: clearly this may hinder user trust. Further, if explanations violate DA then they can be deceitful, resulting in an unfair behavior toward the users. Crucial as the DA property appears to be, it has been somehow overlooked in the XAI literature to date. To address this problem, we consider the questions of formalizing DA and of analyzing its satisfaction by explanation methods. We provide formal definitions of naive, structural and dialectical DA, using the family of probabilistic classifiers as the context for our analysis. We evaluate the satisfaction of our given notions of DA by several explanation methods, amounting to two popular feature-attribution methods from the literature, variants thereof and a novel form of explanation that we propose. We conduct experiments with a varied selection of concrete probabilistic classifiers and highlight the importance, with a user study, of our most demanding notion of dialectical DA, which our novel method satisfies by design and others may violate. We thus demonstrate how DA could be a critical component in achieving trustworthy and fair systems, in line with the principles of human-centric AI.",2023,10.3389/frai.2023.1099407
When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease,"BackgroundArtificial intelligence (AI) is gaining traction in healthcare, especially for patients’ education. Inflammatory bowel diseases (IBD) require continuous engagement, yet the quality of online information accessed by patients is inconsistent. ChatGPT, a generative AI model, has shown promise in medical scenarios, but its role in IBD communication needs further evaluation. The objective of this study was to assess the quality of ChatGPT-4’s responses to common patient questions about IBD, compared to those provided by experienced IBD specialists.MethodsTwenty-five frequently asked questions were collected during routine IBD outpatient visits and categorized into five themes: pregnancy/breastfeeding, diet, vaccinations, lifestyle, and medical therapy/surgery. Each question was answered by ChatGPT-4 and by two expert gastroenterologists. Responses were anonymized and evaluated by 12 physicians (six IBD experts and six non-experts) using a 5-point Likert scale across four dimensions: accuracy, reliability, comprehensibility, and actionability. Evaluators also attempted to identify whether responses were AI- or human-generated.ResultsChatGPT-4 responses received significantly higher overall scores than those from human experts (mean 4.28 vs. 4.05; p &lt; 0.001). The best-rated scenarios were medical therapy and surgery; the diet scenario consistently received lower scores. Only 33% of AI-generated responses were correctly identified as such, indicating strong similarity to human-written answers. Both expert and non-expert evaluators rated AI responses highly, though IBD specialists gave higher ratings overall.ConclusionChatGPT-4 generated high-quality, clear, and actionable responses to IBD-related patient questions, often outperforming human experts. Its outputs were frequently indistinguishable from those written by physicians, suggesting potential as a supportive tool for patient education. Nonetheless, further studies are needed to assess real-world application and ensure appropriate use in personalized clinical care.",2025,10.3389/frai.2025.1678320
Tokenization efficiency of current foundational large language models for the Ukrainian language,"Foundational large language models (LLMs) are deployed in multilingual environments across a range of general and narrow task domains. These models generate text token by token, making them slower and more computationally expensive for low-resource languages that are underrepresented in the tokenizer vocabulary. It also makes their usage more costly in such cases, as pricing usually depends on the number of input and output tokens. This study compares multiple tokenizers of pretrained LLMs for the Ukrainian language. It also provides tokenization fertility measurements for current state-of-the-art (SOTA) models, both in terms of general-purpose language and specific domains, as well as results of experiments with a transliteration approach to make tokenization more efficient without information loss. The results provide insights into the current models’ disadvantages and possible problems in terms of Ukrainian language modeling.",2025,10.3389/frai.2025.1538165
Data augmentation via diffusion model to enhance AI fairness,"IntroductionAI fairness seeks to improve the transparency and explainability of AI systems by ensuring that their outcomes genuinely reflect the best interests of users. Data augmentation, which involves generating synthetic data from existing datasets, has gained significant attention as a solution to data scarcity. In particular, diffusion models have become a powerful technique for generating synthetic data, especially in fields like computer vision.MethodsThis paper explores the potential of diffusion models to generate synthetic tabular data to improve AI fairness. The Tabular Denoising Diffusion Probabilistic Model (Tab-DDPM), a diffusion model adaptable to any tabular dataset and capable of handling various feature types, was utilized with different amounts of generated data for data augmentation. Additionally, reweighting samples from AIF360 was employed to further enhance AI fairness. Five traditional machine learning models—Decision Tree (DT), Gaussian Naive Bayes (GNB), K-Nearest Neighbors (KNN), Logistic Regression (LR), and Random Forest (RF)—were used to validate the proposed approach.Results and discussionExperimental results demonstrate that the synthetic data generated by Tab-DDPM improves fairness in binary classification.",2025,10.3389/frai.2025.1530397
Predicting the risk of hospital readmissions using a machine learning approach: a case study on patients undergoing skin procedures,"IntroductionEven with modern advancements in medical care, one of the persistent challenges hospitals face is the frequent readmission of patients. These recurrent admissions not only escalate healthcare expenses but also amplify mental and emotional strain on patients.MethodsThis research delved into two primary areas: unraveling the pivotal factors causing the readmissions, specifically targeting patients who underwent dermatological treatments, and determining the optimal machine learning algorithms that can foresee potential readmissions with higher accuracy.ResultsAmong the multitude of algorithms tested, including logistic regression (LR), support vector machine (SVM), random forest (RF), Naïve Bayesian (NB), artificial neural network (ANN), xgboost (XG), and k-nearest neighbor (KNN), it was noted that two models—XG and RF—stood out in their prediction prowess. A closer inspection of the data brought to light certain patterns. For instance, male patients and those between the ages of 21 and 40 had a propensity to be readmitted more frequently. Moreover, the months of March and April witnessed a spike in these readmissions, with ~6% of the patients returning within just a month after their first admission.DiscussionUpon further analysis, specific determinants such as the patient's age and the specific hospital where they were treated emerged as key indicators influencing the likelihood of their readmission.",2024,10.3389/frai.2023.1213378
A new framework with convoluted oscillatory neural network for efficient object-based land use and land cover classification on remote sensing images,"Rigorous urbanization leads to unprecedented climate change. Pune area in India has witnessed recent flash floods and landslides due to unplanned rapid urbanization. It, therefore, becomes vital to manage and analyse man-made impact on the environment through effective land use land cover classification (LULC). Accurate LULC classification allows for better planning and effective allocation of resources in urban development. Remote sensing images provide surface reflectance data that are used for accurate mapping and monitoring of land cover. Convolution neural networks (CNN) trained with Relu are conventionally used in classifying different land types. However, every neuron has a single hyperplane decision boundary which restricts the model's capability to generalize. Oscillatory activation functions with their periodic nature have demonstrated that a single neuron can have multiple hyperplanes in the decision boundary which helps in better generalization and accuracy. This study proposes a novel framework with convoluted oscillatory neural networks (CONN) that synergistically combines the periodic, non-monotonic nature of oscillatory activation functions with the deep convoluted architecture of CNNs to accurately map LULC. Results carried out on LANDSAT-8 surface reflectance images for the Pune area indicate that CONN with Decaying Sine Unit achieved an overall train accuracy of 99.999%, test accuracy of 95.979% and outperforms conventional CNN models in precision, recall and User's Accuracy. A thorough ablation study was conducted with various subsets of the feature set to test the performance of the selected models in the absence of data.",2025,10.3389/frai.2025.1696859
A dynamic approach for visualizing and exploring concept hierarchies from textbooks,"In this study, we propose a visualization technique to explore and visualize concept hierarchies generated from a textbook in the legal domain. Through a human-centered design process, we developed a tool that allows users to effectively navigate through and explore complex hierarchical concepts in three kinds of traversal techniques: top-down, middle-out, and bottom-up. Our concept hierarchies offer an overview over a given domain, with increasing level of detail toward the bottom of the hierarchy which is consisting of entities. In the legal use case we considered, the concepts were adapted from section headings in a legal textbook, whereas references to law or legal cases inside the textbook became entities. The design of this tool is refined following various steps such as gathering user needs, pain points of an existing visualization, prototyping, testing, and refining. The resulting interface offers users several key features such as dynamic search and filter, explorable concept nodes, and a preview of leaf nodes at every stage. A high-fidelity prototype was created to test our theory and design. To test our concept, we used the System Usability Scale as a way to measure the prototype's usability, a task-based survey to asses the tool's ability in assisting users in gathering information and interacting with the prototype, and finally mouse tracking to understand user interaction patterns. Along with this, we gathered audio and video footage of users when participating in the study. This footage also helped us in getting feedback when the survey responses required further information. The data collected provided valuable insights to set the directions for extending this study. As a result, we have accounted for varying hierarchy depths, longer text spans than only one to two words in the elements of the hierarchy, searchability, and exploration of the hierarchies. At the same time, we aimed for minimizing visual clutter and cognitive overload. We show that existing approaches are not suitable to visualize the type of data which we support with our visualization.",2024,10.3389/frai.2024.1285026
Interpreting CNN models for musical instrument recognition using multi-spectrogram heatmap analysis: a preliminary study,"IntroductionMusical instrument recognition is a critical component of music information retrieval (MIR), aimed at identifying and classifying instruments from audio recordings. This task poses significant challenges due to the complexity and variability of musical signals.MethodsIn this study, we employed convolutional neural networks (CNNs) to analyze the contributions of various spectrogram representations—STFT, Log-Mel, MFCC, Chroma, Spectral Contrast, and Tonnetz—to the classification of ten different musical instruments. The NSynth database was used for training and evaluation. Visual heatmap analysis and statistical metrics, including Difference Mean, KL Divergence, JS Divergence, and Earth Mover’s Distance, were utilized to assess feature importance and model interpretability.ResultsOur findings highlight the strengths and limitations of each spectrogram type in capturing distinctive features of different instruments. MFCC and Log-Mel spectrograms demonstrated superior performance across most instruments, while others provided insights into specific characteristics.DiscussionThis analysis provides some insights into optimizing spectrogram-based approaches for musical instrument recognition, offering guidance for future model development and improving interpretability through statistical and visual analyses.",2024,10.3389/frai.2024.1499913
Application of human-in-the-loop hybrid augmented intelligence approach in security inspection system,"A security inspection system exemplifies human-machine collaboration, and enhancing its safety and reliability through advanced technology remains a key research priority. While deep learning has incrementally improved the autonomous capabilities of security inspection equipment for automatic contraband detection, a gap persists between current technological capabilities and practical implementation. Recognizing that humans excel at learning, reasoning, and collaborating, while artificial intelligence offers normative, repeatable, and logical processing, we propose a human-in-the-loop hybrid augmented intelligence approach. This approach addresses the practical needs of security inspection systems by introducing a hybrid decision-making method that leverages two distinct strategies: “Reject-priority” and “Clear-priority.” These strategies play complementary roles in bolstering the decision-making process’s overall performance. Comparative experiments on a dataset from a specific security inspection site confirmed the hybrid method’s effectiveness, drawing several conclusions. This “Hybrid decision-making” method not only enhances risk perception, thereby widening the safety margin of the security inspection system, but also reduces the need for human labor, leading to increased efficiency and reduced labor costs. Additionally, it is less time-consuming, further improving the system’s overall efficiency. By integrating human and machine intelligence, this method significantly boosts decision-making effectiveness. Tailored to their unique characteristics, the method based on “Reject-priority” strategy is particularly well-suited for security inspection scenarios that demand stringent safety protocols, while the “Clear-priority” method is ideal for scenarios with high-volume traffic flow, where efficiency is paramount. As the volume of collected data grows, this approach will enable seamless adaptation of the method to evolving application needs.",2025,10.3389/frai.2025.1518850
Application note: TDbasedUFE and TDbasedUFEadv: bioconductor packages to perform tensor decomposition based unsupervised feature extraction,"Motivation
                    Tensor decomposition (TD)-based unsupervised feature extraction (FE) has proven effective for a wide range of bioinformatics applications ranging from biomarker identification to the identification of disease-causing genes and drug repositioning. However, TD-based unsupervised FE failed to gain widespread acceptance due to the lack of user-friendly tools for non-experts.
                  
                  
                    Results
                    We developed two bioconductor packages—TDbasedUFE and TDbasedUFEadv—that enable researchers unfamiliar with TD to utilize TD-based unsupervised FE. The packages facilitate the identification of differentially expressed genes and multiomics analysis. TDbasedUFE was found to outperform two state-of-the-art methods, such as DESeq2 and DIABLO.
                  
                  
                    Availability and implementation
                    
                      TDbasedUFE and TDbasedUFEadv are freely available as R/Bioconductor packages, which can be accessed at
                      https://bioconductor.org/packages/TDbasedUFE
                      and
                      https://bioconductor.org/packages/TDbasedUFEadv
                      , respectively.",2023,10.3389/frai.2023.1237542
The scholarly footprint of ChatGPT: a bibliometric analysis of the early outbreak phase,"This paper presents a comprehensive analysis of the scholarly footprint of ChatGPT, an AI language model, using bibliometric and scientometric methods. The study zooms in on the early outbreak phase from when ChatGPT was launched in November 2022 to early June 2023. It aims to understand the evolution of research output, citation patterns, collaborative networks, application domains, and future research directions related to ChatGPT. By retrieving data from the Scopus database, 533 relevant articles were identified for analysis. The findings reveal the prominent publication venues, influential authors, and countries contributing to ChatGPT research. Collaborative networks among researchers and institutions are visualized, highlighting patterns of co-authorship. The application domains of ChatGPT, such as customer support and content generation, are examined. Moreover, the study identifies emerging keywords and potential research areas for future exploration. The methodology employed includes data extraction, bibliometric analysis using various indicators, and visualization techniques such as Sankey diagrams. The analysis provides valuable insights into ChatGPT's early footprint in academia and offers researchers guidance for further advancements. This study stimulates discussions, collaborations, and innovations to enhance ChatGPT's capabilities and impact across domains.",2024,10.3389/frai.2023.1270749
Constructing Equity Investment Strategies Using Analyst Reports and Regime Switching Models,"This study demonstrates whether analysts' sentiments toward individual stocks are useful for stock investment strategies. This is achieved by using natural language processing to create a polarity index from textual information in analyst reports. In this study, we performed time series forecasting for the created polarity index using deep learning, and clustered the forecasted values by volatility using a regime switching model. In addition, we constructed a portfolio from stock data and rebalanced it at each change point of the regime. Consequently, the investment strategy proposed in this study outperforms the benchmark portfolio in terms of returns. This suggests that the polarity index is useful for constructing stock investment strategies.",2022,10.3389/frai.2022.865950
Error driven synapse augmented neurogenesis,"Capturing the learning capabilities of the brain has the potential to revolutionize artificial intelligence. Humans display an impressive ability to acquire knowledge on the fly and immediately store it in a usable format. Parametric models of learning, such as gradient descent, focus on capturing the statistical properties of a data set. Information is precipitated into a network through repeated updates of connection weights in the direction gradients dictate will lead to less error. This work presents the EDN (Error Driven Neurogenesis) algorithm which explores how neurogenesis coupled with non-linear synaptic activations enables a biologically plausible mechanism to immediately store data in a one-shot, online fashion and readily apply it to a task without the need for parameter updates. Regression (auto-mpg) test error was reduced more than 135 times faster and converged to an error around three times smaller compared to gradient descent using ADAM optimization. EDN also reached the same level of performance in wine cultivar classification 25 times faster than gradient descent and twice as fast when applied to MNIST and the inverted pendulum (reinforcement learning).",2022,10.3389/frai.2022.949707
On automatic decipherment of lost ancient scripts relying on combinatorial optimisation and coupled simulated annealing,"This paper introduces a novel method for addressing the challenge of deciphering ancient scripts. The approach relies on combinatorial optimisation along with coupled simulated annealing, an advanced technique for non-convex optimisation. Encoding solutions through k-permutations facilitates the representation of null, one-to-many, and many-to-one mappings between signs. In comparison to current state-of-the-art systems evaluated on established benchmarks from literature and three new benchmarks introduced in this study, the proposed system demonstrates superior performance in enhancing cognate identification results.",2025,10.3389/frai.2025.1581129
Inferior: The Challenges of Gender Parity in the Artificial Intelligence Ecosystem-A Case for Canada,"Artificial Intelligence (AI) systems are gaining momentum in complementing and/or replacing performing tasks typically done with the aid of human ability. AI systems, inherently human creations, are, however, beset by, wittingly or unwittingly, so-called male chauvinism, despite all the advancements made in the progress of civilization to make inroads for women's equitable participation in the labor force, particularly in relation to the digital economy, and more importantly, AI. In regards to the Canadian context, this perspective has examined the evidence to find research highlighting gender representation in the Canadian AI ecosystem. We found a lack of studies on women and their contribution to AI-related activities. Canadian women's participation in their country's AI sector therefore should go beyond mere instruments such as the Montreal Declaration for a Responsible Development of AI, and disjointed interests. On a more general level, the paucity in a paradigm shift toward AI-female friendly policies from design phase to implementation omits the female voice for adequate representation for action. Advocating for Canadian women in the AI sector requires a voice of unison best achieved through parliamentary action. This perspective is thus issuing a clarion call to attaining gender fairness and equity, global principles under the United Nations (UN) Sustainable Development Goals, to which the Government of Canada is committed.",2022,10.3389/frai.2022.931182
Signal Perceptron: On the Identifiability of Boolean Function Spaces and Beyond,"In a seminal book, Minsky and Papert define the perceptron as a limited implementation of what they called “parallel machines.” They showed that some binary Boolean functions including XOR are not definable in a single layer perceptron due to its limited capacity to learn only linearly separable functions. In this work, we propose a new more powerful implementation of such parallel machines. This new mathematical tool is defined using analytic sinusoids—instead of linear combinations—to form an analytic signal representation of the function that we want to learn. We show that this re-formulated parallel mechanism can learn, with a single layer, any non-linear k-ary Boolean function. Finally, to provide an example of its practical applications, we show that it outperforms the single hidden layer multilayer perceptron in both Boolean function learning and image classification tasks, while also being faster and requiring fewer parameters.",2022,10.3389/frai.2022.770254
Estimating distribution shifts for predicting cross-subject generalization in electroencephalography-based mental workload assessment,"Assessment of mental workload in real-world conditions is key to ensuring the performance of workers executing tasks that demand sustained attention. Previous literature has employed electroencephalography (EEG) to this end despite having observed that EEG correlates of mental workload vary across subjects and physical strain, thus making it difficult to devise models capable of simultaneously presenting reliable performance across users. Domain adaptation consists of a set of strategies that aim at allowing for improving machine learning systems performance on unseen data at training time. Such methods, however, might rely on assumptions over the considered data distributions, which typically do not hold for applications of EEG data. Motivated by this observation, in this work we propose a strategy to estimate two types of discrepancies between multiple data distributions, namely marginal and conditional shifts, observed on data collected from different subjects. Besides shedding light on the assumptions that hold for a particular dataset, the estimates of statistical shifts obtained with the proposed approach can be used for investigating other aspects of a machine learning pipeline, such as quantitatively assessing the effectiveness of domain adaptation strategies. In particular, we consider EEG data collected from individuals performing mental tasks while running on a treadmill and pedaling on a stationary bike and explore the effects of different normalization strategies commonly used to mitigate cross-subject variability. We show the effects that different normalization schemes have on statistical shifts and their relationship with the accuracy of mental workload prediction as assessed on unseen participants at training time.",2022,10.3389/frai.2022.992732
Mixture of prompts learning for vision-language models,"As powerful pre-trained vision-language models (VLMs) like CLIP gain prominence, numerous studies have attempted to combine VLMs for downstream tasks. Among these, prompt learning has been validated as an effective method for adapting to new tasks, which only requires a small number of parameters. However, current prompt learning methods face two challenges: first, a single soft prompt struggles to capture the diverse styles and patterns within a dataset; second, fine-tuning soft prompts is prone to overfitting. To address these challenges, we propose a mixture-of-prompts learning method incorporating a routing module. This module is able to capture a dataset's varied styles and dynamically select the most suitable prompts for each instance. Additionally, we introduce a novel gating mechanism to ensure the router selects prompts based on their similarity to hard prompt templates, which both retains knowledge from hard prompts and improves selection accuracy. We also implement semantically grouped text-level supervision, initializing each soft prompt with the token embeddings of manually designed templates from its group and applying a contrastive loss between the resulted text feature and hard prompt encoded text feature. This supervision ensures that the text features derived from soft prompts remain close to those from their corresponding hard prompts, preserving initial knowledge and mitigating overfitting. Our method has been validated on 11 datasets, demonstrating evident improvements in few-shot learning, domain generalization, and base-to-new generalization scenarios compared to existing baselines. Our approach establishes that multi-prompt specialization with knowledge-preserving routing effectively bridges the adaptability-generalization tradeoff in VLM deployment. The code will be available at https://github.com/dyabel/mocoop.",2025,10.3389/frai.2025.1580973
Ethical-legal implications of AI-powered healthcare in critical perspective,"The increasing utilization of Artificial Intelligence (AI) systems in the field of healthcare, from diagnosis to medical decision making and patient care, necessitates identification of its potential benefits, risks and challenges. This requires an appraisal of AI use from a legal and ethical perspective. A review of the existing literature on AI in healthcare available on PubMed, Oxford Academic and Scopus revealed several common concerns regarding the relationship between AI, ethics, and healthcare—(i) the question of data: the choices inherent in collection, analysis, interpretation, and deployment of data inputted to and outputted by AI systems; (ii) the challenges to traditional patient-doctor relationships and long-held assumptions about privacy, identity and autonomy, as well as to the functioning of healthcare institutions. The potential benefits of AI’s application need to be balanced against the legal-ethical issues emanating from its use—bias, consent, access, privacy and cost—to guard against detrimental effects of uncritical AI use. The authors suggest that a legal framework for AI should adopt a critical and grounded perspective—cognizant of the material political realities of AI and its wider impact on more marginalized communities. The largescale utilization of health datasets often without consent, responsibility or accountability, further necessitates regulation in the field of technology design, given the entwined nature of AI research with advancements in wearables and sensor technology. Taking into account the ‘superhuman’ and ‘subhuman’ traits of AI, regulation should aim to encourage the development of AI systems that augment rather than outrightly replace human effort.",2025,10.3389/frai.2025.1619463
Development and evaluation of multimodal AI for diagnosis and triage of ophthalmic diseases using ChatGPT and anterior segment images: protocol for a two-stage cross-sectional study,"IntroductionArtificial intelligence (AI) technology has made rapid progress for disease diagnosis and triage. In the field of ophthalmic diseases, image-based diagnosis has achieved high accuracy but still encounters limitations due to the lack of medical history. The emergence of ChatGPT enables human-computer interaction, allowing for the development of a multimodal AI system that integrates interactive text and image information.ObjectiveTo develop a multimodal AI system using ChatGPT and anterior segment images for diagnosing and triaging ophthalmic diseases. To assess the AI system's performance through a two-stage cross-sectional study, starting with silent evaluation and followed by early clinical evaluation in outpatient clinics.Methods and analysisOur study will be conducted across three distinct centers in Shanghai, Nanjing, and Suqian. The development of the smartphone-based multimodal AI system will take place in Shanghai with the goal of achieving ≥90% sensitivity and ≥95% specificity for diagnosing and triaging ophthalmic diseases. The first stage of the cross-sectional study will explore the system's performance in Shanghai's outpatient clinics. Medical histories will be collected without patient interaction, and anterior segment images will be captured using slit lamp equipment. This stage aims for ≥85% sensitivity and ≥95% specificity with a sample size of 100 patients. The second stage will take place at three locations, with Shanghai serving as the internal validation dataset, and Nanjing and Suqian as the external validation dataset. Medical history will be collected through patient interviews, and anterior segment images will be captured via smartphone devices. An expert panel will establish reference standards and assess AI accuracy for diagnosis and triage throughout all stages. A one-vs.-rest strategy will be used for data analysis, and a post-hoc power calculation will be performed to evaluate the impact of disease types on AI performance.DiscussionOur study may provide a user-friendly smartphone-based multimodal AI system for diagnosis and triage of ophthalmic diseases. This innovative system may support early detection of ocular abnormalities, facilitate establishment of a tiered healthcare system, and reduce the burdens on tertiary facilities.Trial registrationThe study was registered in ClinicalTrials.gov on June 25th, 2023 (NCT 05930444).",2023,10.3389/frai.2023.1323924
Intrinsic motivation in cognitive architecture: intellectual curiosity originated from pattern discovery,"Studies on reinforcement learning have developed the representation of curiosity, which is a type of intrinsic motivation that leads to high performance in a certain type of tasks. However, these studies have not thoroughly examined the internal cognitive mechanisms leading to this performance. In contrast to this previous framework, we propose a mechanism of intrinsic motivation focused on pattern discovery from the perspective of human cognition. This study deals with intellectual curiosity as a type of intrinsic motivation, which finds novel compressible patterns in the data. We represented the process of continuation and boredom of tasks driven by intellectual curiosity using “pattern matching,” “utility,” and “production compilation,” which are general functions of the adaptive control of thought-rational (ACT-R) architecture. We implemented three ACT-R models with different levels of thinking to navigate multiple mazes of different sizes in simulations, manipulating the intensity of intellectual curiosity. The results indicate that intellectual curiosity negatively affects task completion rates in models with lower levels of thinking, while positively impacting models with higher levels of thinking. In addition, comparisons with a model developed by a conventional framework of reinforcement learning (intrinsic curiosity module: ICM) indicate the advantage of representing the agent's intention toward a goal in the proposed mechanism. In summary, the reported models, developed using functions linked to a general cognitive architecture, can contribute to our understanding of intrinsic motivation within the broader context of human innovation driven by pattern discovery.",2024,10.3389/frai.2024.1397860
Multicenter evaluation of machine and deep learning methods to predict glaucoma surgical outcomes,"Purpose
                    To develop machine learning (ML) and neural network (NN) models to predict glaucoma surgical outcomes, including intraocular pressure (IOP), use of ocular antihypertensive medications, and need for additional glaucoma surgery, using preoperative electronic health records (EHR) from a large multicenter cohort.
                  
                  
                    Methods
                    This cohort study included 9,386 patients who underwent glaucoma surgery across 10 institutions in the Sight Outcomes Research Collaborative (SOURCE). All patients had at least 1 year of follow-up and 2 postoperative visits with IOP measurements. Models were trained using preoperative EHR features to predict surgical failure, defined as any of the following: IOP remaining above 80% of preoperative value beyond the immediate postoperative period, increased postoperative glaucoma medications, or need for additional glaucoma surgery. Model performance was evaluated on two test sets: an internal holdout set from sites seen during training and an external holdout set.
                  
                  
                    Results
                    Of 13,173 surgeries, 8,743 (66.4%) met failure criteria. The best-performing model for overall surgical failure prediction was a one-dimensional convolutional neural network (1D-CNN) with AUROC of 76.4% and accuracy of 71.6% on the internal test set. The top-performing classical ML model was random forest (AUROC 76.2%, accuracy 72.1%). Prediction performance was highest for IOP-related failure (AUROC 82%), followed by increased medication use (80%) and need for an additional surgery (68%). AUROC declined slightly (2–4%) on the external test set.
                  
                  
                    Conclusion
                    ML and DL models can predict glaucoma outcomes using preoperative EHR data. Translational relevance: prediction models may support clinical decision-making by identifying glaucoma patients at risk of poor postoperative outcomes.",2025,10.3389/frai.2025.1636410
Governing AI in Electricity Systems: Reflections on the EU Artificial Intelligence Bill,"The Proposal for an Artificial Intelligence Act, published by the European Commission in April 2021, marks a major step in the governance of artificial intelligence (AI). This paper examines the significance of this Act for the electricity sector, specifically investigating to what extent the current European Union Bill addresses the societal and governance challenges posed by the use of AI that affects the tasks of system operators. For this we identify various options for the use of AI by system operators, as well as associated risks. AI has the potential to facilitate grid management, flexibility asset management and electricity market activities. Associated risks include lack of transparency, decline of human autonomy, cybersecurity, market dominance, and price manipulation on the electricity market. We determine to what extent the current bill pays attention to these identified risks and how the European Union intends to govern these risks. The proposed AI Act addresses well the issue of transparency and clarifying responsibilities, but pays too little attention to risks related to human autonomy, cybersecurity, market dominance and price manipulation. We make some governance suggestions to address those gaps.",2021,10.3389/frai.2021.690237
Foresight for ethical AI,"There is growing expectation that artificial intelligence (AI) developers foresee and mitigate harms that might result from their creations; however, this is exceptionally difficult given the prevalence of emergent behaviors that occur when integrating AI into complex sociotechnical systems. We argue that Naturalistic Decision Making (NDM) principles, models, and tools are well-suited to tackling this challenge. Already applied in high-consequence domains, NDM tools such as the premortem, and others, have been shown to uncover a reasonable set of risks of underlying factors that would lead to ethical harms. Such NDM tools have already been used to develop AI that is more trustworthy and resilient, and can help avoid unintended consequences of AI built with noble intentions. We present predictive policing algorithms as a use case, highlighting various factors that led to ethical harms and how NDM tools could help foresee and mitigate such harms.",2023,10.3389/frai.2023.1143907
Evaluation of large language models under different training background in Chinese medical examination: a comparative study,"BackgroundRecently, Large Language Models have shown impressive potential in medical services. However, the aforementioned research primarily discusses the performance of LLMs developed in English within English-speaking medical contexts, ignoring the LLMs developed under different linguistic environments with respect to their performance in the Chinese clinical medicine field.ObjectiveThrough a comparative analysis of three LLMs developed under different training background, we firstly evaluate their potential as medical service tools in a Chinese language environment. Furthermore, we also point out the limitations in the application of Chinese medical practice.MethodUtilizing the APIs provided by three LLMs, we conducted an automated assessment of their performance in the 2023 CMLE. We not only examined the accuracy of three LLMs across various question, but also categorized the reasons for their errors. Furthermore, we performed repetitive experiments on selected questions to evaluate the stability of the outputs generated by the LLMs.ResultThe accuracy of GPT-4, ERNIE Bot, and DISC-MedLLM in CMLE are 65.2, 61.7, and 25.3%. In error types, the knowledge errors of GPT-4 and ERNIE Bot account for 52.2 and 51.7%, while hallucinatory errors account for 36.4 and 52.6%. In the Chinese text generation experiment, the general LLMs demonstrated high natural language understanding ability and was able to generate clear and standardized Chinese texts. In repetitive experiments, the LLMs showed a certain output stability of 70%, but there were still cases of inconsistent output results.ConclusionGeneral LLMs, represented by GPT-4 and ERNIE Bot, demonstrate the capability to meet the standards of the CMLE. Despite being developed and trained in different linguistic contexts, they exhibit excellence in understanding Chinese natural language and Chinese clinical knowledge, highlighting their broad potential application in Chinese medical practice. However, these models still show deficiencies in mastering specialized knowledge, addressing ethical issues, and maintaining the outputs stability. Additionally, there is a tendency to avoid risk when providing medical advice.",2024,10.3389/frai.2024.1442975
Enabling Training of Neural Networks on Noisy Hardware,"Deep neural networks (DNNs) are typically trained using the conventional stochastic gradient descent (SGD) algorithm. However, SGD performs poorly when applied to train networks on non-ideal analog hardware composed of resistive device arrays with non-symmetric conductance modulation characteristics. Recently we proposed a new algorithm, the Tiki-Taka algorithm, that overcomes this stringent symmetry requirement. Here we build on top of Tiki-Taka and describe a more robust algorithm that further relaxes other stringent hardware requirements. This more robust second version of the Tiki-Taka algorithm (referred to as TTv2) 1. decreases the number of device conductance states requirement from 1000s of states to only 10s of states, 2. increases the noise tolerance to the device conductance modulations by about 100x, and 3. increases the noise tolerance to the matrix-vector multiplication performed by the analog arrays by about 10x. Empirical simulation results show that TTv2 can train various neural networks close to their ideal accuracy even at extremely noisy hardware settings. TTv2 achieves these capabilities by complementing the original Tiki-Taka algorithm with lightweight and low computational complexity digital filtering operations performed outside the analog arrays. Therefore, the implementation cost of TTv2 compared to SGD and Tiki-Taka is minimal, and it maintains the usual power and speed benefits of using analog hardware for training workloads. Here we also show how to extract the neural network from the analog hardware once the training is complete for further model deployment. Similar to Bayesian model averaging, we form analog hardware compatible averages over the neural network weights derived from TTv2 iterates. This model average then can be transferred to another analog or digital hardware with notable improvements in test accuracy, transcending the trained model itself. In short, we describe an end-to-end training and model extraction technique for extremely noisy crossbar-based analog hardware that can be used to accelerate DNN training workloads and match the performance of full-precision SGD.",2021,10.3389/frai.2021.699148
AI integration in nephrology: evaluating ChatGPT for accurate ICD-10 documentation and coding,"BackgroundAccurate ICD-10 coding is crucial for healthcare reimbursement, patient care, and research. AI implementation, like ChatGPT, could improve coding accuracy and reduce physician burden. This study assessed ChatGPT’s performance in identifying ICD-10 codes for nephrology conditions through case scenarios for pre-visit testing.MethodsTwo nephrologists created 100 simulated nephrology cases. ChatGPT versions 3.5 and 4.0 were evaluated by comparing AI-generated ICD-10 codes against predetermined correct codes. Assessments were conducted in two rounds, 2 weeks apart, in April 2024.ResultsIn the first round, the accuracy of ChatGPT for assigning correct diagnosis codes was 91 and 99% for version 3.5 and 4.0, respectively. In the second round, the accuracy of ChatGPT for assigning the correct diagnosis code was 87% for version 3.5 and 99% for version 4.0. ChatGPT 4.0 had higher accuracy than ChatGPT 3.5 (p = 0.02 and 0.002 for the first and second round respectively). The accuracy did not significantly differ between the two rounds (p &gt; 0.05).ConclusionChatGPT 4.0 can significantly improve ICD-10 coding accuracy in nephrology through case scenarios for pre-visit testing, potentially reducing healthcare professionals’ workload. However, the small error percentage underscores the need for ongoing review and improvement of AI systems to ensure accurate reimbursement, optimal patient care, and reliable research data.",2024,10.3389/frai.2024.1457586
Developing a Conversational Agent’s Capability to Identify Structural Wrongness in Arguments Based on Toulmin’s Model of Arguments,"This article discusses the usefulness of Toulmin’s model of arguments as structuring an assessment of different types of wrongness in an argument. We discuss the usability of the model within a conversational agent that aims to support users to develop a good argument. Within the article, we present a study and the development of classifiers that identify the existence of structural components in a good argument, namely a claim, a warrant (underlying understanding), and evidence. Based on a dataset (three sub-datasets with 100, 1,026, 211 responses in each) in which users argue about the intelligence or non-intelligence of entities, we have developed classifiers for these components: The existence and direction (positive/negative) of claims can be detected a weighted average F1 score over all classes (positive/negative/unknown) of 0.91. The existence of a warrant (with warrant/without warrant) can be detected with a weighted F1 score over all classes of 0.88. The existence of evidence (with evidence/without evidence) can be detected with a weighted average F1 score of 0.80. We argue that these scores are high enough to be of use within a conditional dialogue structure based on Bloom’s taxonomy of learning; and show by argument an example conditional dialogue structure that allows us to conduct coherent learning conversations. While in our described experiments, we show how Toulmin’s model of arguments can be used to identify structural problems with argumentation, we also discuss how Toulmin’s model of arguments could be used in conjunction with content-wise assessment of the correctness especially of the evidence component to identify more complex types of wrongness in arguments, where argument components are not well aligned. Owing to having progress in argument mining and conversational agents, the next challenges could be the developing agents that support learning argumentation. These agents could identify more complex type of wrongness in arguments that result from wrong connections between argumentation components.",2021,10.3389/frai.2021.645516
Adoption of artificial intelligence and machine learning in banking systems: a qualitative survey of board of directors,"The aim of the paper is twofold. First to examine the role of the board of directors in facilitating the adoption of AI and ML in Saudi Arabian banking sector. Second, to explore the effectiveness of artificial intelligence and machine learning in protection of Saudi Arabian banking sector from cyberattacks. A qualitative research approach was applied using in-depth interviews with 17 board of directors from prominent Saudi Arabian banks. The present study highlights both the opportunities and challenges of integrating artificial intelligence and machine learning advanced technologies in this highly regulated industry. Findings reveal that advanced artificial intelligence and machine learning technologies offer substantial benefits, particularly in areas like threat detection, fraud prevention, and process automation, enabling banks to meet regulatory standards and mitigate cyber threats efficiently. However, the research also identifies significant barriers, including limited technological infrastructure, a lack of cohesive artificial intelligence strategies, and ethical concerns around data privacy and algorithmic bias. Interviewees emphasized the board of directors’ critical role in providing strategic direction, securing resources, and fostering partnerships with artificial intelligence technology providers. The study further highlights the importance of aligning artificial intelligence and machine learning initiatives with national development goals, such as Saudi Vision 2030, to ensure sustained growth and competitiveness. The findings from the present study offer valuable implications for policymakers in banking in navigating the complexities of artificial intelligence and machine learning adoption in financial services, particularly in emerging markets.",2024,10.3389/frai.2024.1440051
“We are at war”: The military rhetoric of COVID-19 in cross-cultural perspective of discourses,"At the outburst of the COVID-19 pandemic and all throughout its continuation in 2020 and 2021, the metaphor of ‘war' has been one of the most pervasive and recurrent globally. As an international, cross-cultural group of scholars and practitioners, we will analyze critically the communicative strategies enacted and the political agenda that they have meant to serve in Italy, Bulgaria, and Ukraine discussing both the cultural differences and the cross-cultural similarities of such a discourse that has been shaping the perception of our factual reality during the pandemic. Expressions like ‘We are at war', ‘Our heroes are fighting at the forefront', ‘We will win this war' and the like contributed to create symbolical cross-cultural responses that, by playing on emotions such as fear, uncertainty and, in some cases, national pride, contributed to the creation of a new state of reality, that of the “new normality”, calling for specific actions and behaviors. However, the war metaphor assumed different hues according to the country in which it was disseminated, up to the actual appointment of generals as governmental spoke-persons or organizers of the vaccine logistics, often combined with the construction and the mediatization of the archetypical hero fighting against the virus/enemy. To analyze how, all throughout 2020 and 2021, the military rhetoric was implemented and disseminated as the dominant discourse, we draw on Media Representations of the Real, on Rhetoric Studies on Manipulation, on Political Discourse, on Critical Discourse Studies, and on Susan Sontag's fundamental essay Illness as Metaphor. We discuss such rhetorical strategies as they originated from a discussion within our collective project in other words, an online dictionary that, besides critically analyzing contextualized keywords that (re)produce different forms of Otherness, offers creative proposals to reverse such narratives, and can be used as a free resource in different social and educational contexts (www.iowdictionary.org).",2023,10.3389/frai.2023.978096
A distance-based kernel for classification via Support Vector Machines,"Support Vector Machines (SVMs) are a type of supervised machine learning algorithm widely used for classification tasks. In contrast to traditional methods that split the data into separate training and testing sets, here we propose an innovative approach where subsets of the original data are randomly selected to train the model multiple times. This iterative training process aims to identify a representative data subset, leading to improved inferences about the population. Additionally, we introduce a novel distance-based kernel specifically designed for binary-type features based on a similarity matrix that efficiently handles both binary and multi-class classification problems. Computational experiments on publicly available datasets of varying sizes demonstrate that our proposed method significantly outperforms existing approaches in terms of classification accuracy. Furthermore, the distance-based kernel achieves superior performance compared to other well-known kernels from the literature and those used in previous studies on the same datasets. These findings validate the effectiveness of our proposed classification method and distance-based kernel for SVMs. By leveraging random subset selection and a unique kernel design, we achieve notable improvements in classification accuracy. These results have significant implications for diverse classification problems in Machine Learning and data analysis.",2024,10.3389/frai.2024.1287875
Identifying Ingredient Substitutions Using a Knowledge Graph of Food,"People can affect change in their eating patterns by substituting ingredients in recipes. Such substitutions may be motivated by specific goals, like modifying the intake of a specific nutrient or avoiding a particular category of ingredients. Determining how to modify a recipe can be difficult because people need to 1) identify which ingredients can act as valid replacements for the original and 2) figure out whether the substitution is “good” for their particular context, which may consider factors such as allergies, nutritional contents of individual ingredients, and other dietary restrictions. We propose an approach to leverage both explicit semantic information about ingredients, encapsulated in a knowledge graph of food, and implicit semantics, captured through word embeddings, to develop a substitutability heuristic to rank plausible substitute options automatically. Our proposed system also helps determine which ingredient substitution options are “healthy” using nutritional information and food classification constraints. We evaluate our substitutability heuristic, diet-improvement ingredient substitutability heuristic (DIISH), using a dataset of ground-truth substitutions scraped from ingredient substitution guides and user reviews of recipes, demonstrating that our approach can help reduce the human effort required to make recipes more suitable for specific dietary needs.",2021,10.3389/frai.2020.621766
Can artificial intelligence improve the diagnosis and prognosis of disorders of consciousness? A scoping review,"BackgroundArtificial intelligence (AI), in the form of machine learning (ML) or deep learning (DL) models, can aid clinicians in the diagnostic process and/or in the prognosis of critically medical conditions, as for patients with a disorder of consciousness (DoC), in which both aspects are particularly challenging. DoC is a category of neurological impairments that are mainly caused by severe acquired brain injury, like ischemic or hemorrhagic strokes or traumatic injuries. The aim of this scoping review is to map the literature on the role of ML and DL in the field of diagnosis and prognosis of DoCs.Materials and methodsA scoping search, started from 3rd October 2024, was conducted for all peer-reviewed articles published from 2000 to 2024, using the following databases: PubMed, Embase, Scopus and Cochrane Library.ResultsWe found a total of 49,417 articles. After duplicate removal and title/abstract screening, 613 articles met the inclusion criteria, but 592 articles were excluded after full-text review. Therefore, only 21 studies involving DoC subjects were included in the review synthesis.ConclusionAdvancing AI in the field of DoC requires standardized data protocols and consideration of demographic variations. AI could enhance diagnosis, prognosis, and differentiation between states like unresponsive wakefulness syndrome (UWS) and minimally conscious state (MCS). Additionally, AI-based applications personalize rehabilitation by identifying key recovery factors, optimizing patient outcomes.",2025,10.3389/frai.2025.1608778
Enhanced plant disease classification with attention-based convolutional neural network using squeeze and excitation mechanism,"IntroductionTechnology is becoming essential in agriculture, especially with the growth of smart devices and edge computing. These tools help boost productivity by automating tasks and allowing real-time analysis on devices with limited memory and resources. However, many current models struggle with accuracy, size, and speed particularly when handling multi-label classification problems.MethodsThis paper proposes a Convolutional Neural Network with Squeeze and Excitation Enabled Identity Blocks (CNN-SEEIB), a hybrid CNN-based deep learning architecture for multi-label classification of plant diseases. CNN-SEEIB incorporates an attention mechanism in its identity blocks to leverage the visual attention that enhances the classification performance and computational efficiency. PlantVillage dataset containing 38 classes of diseased crop leaves alongside healthy leaves, totaling 54,305 images, is utilized for experimentation.ResultsCNN-SEEIB achieved a classification accuracy of 99.79%, precision of 0.9970, recall of 0.9972, and an F1 score of 0.9971. In addition, the model attained an inference time of 64 milliseconds per image, making it suitable for real-time deployment. The performance of CNNSEEIB is benchmarked against the state-of-the-art deep learning architectures, and resource utilization metrics such as CPU/GPU usage and power consumption are also reported, highlighting the model’s efficiency.DiscussionThe proposed architecture is also validated on a potato leaf disease dataset of 4,062 images from Central Punjab, Pakistan, achieving a 97.77% accuracy in classifying Healthy, Early Blight, and Late Blight classes.",2025,10.3389/frai.2025.1640549
Cultivation of human centered artificial intelligence: culturally adaptive thinking in education (CATE) for AI,"Artificial Intelligence (AI) has become ubiquitous in human society, and yet vast segments of the global population have no, little, or counterproductive information about AI. It is necessary to teach AI topics on a mass scale. While there is a rush to implement academic initiatives, scant attention has been paid to the unique challenges of teaching AI curricula to a global and culturally diverse audience with varying expectations of privacy, technological autonomy, risk preference, and knowledge sharing. Our study fills this void by focusing on AI elements in a new framework titled Culturally Adaptive Thinking in Education for AI (CATE-AI) to enable teaching AI concepts to culturally diverse learners. Failure to contextualize and sensitize AI education to culture and other categorical human-thought clusters, can lead to several undesirable effects including confusion, AI-phobia, cultural biases to AI, increased resistance toward AI technologies and AI education. We discuss and integrate human behavior theories, AI applications research, educational frameworks, and human centered AI principles to articulate CATE-AI. In the first part of this paper, we present the development a significantly enhanced version of CATE. In the second part, we explore textual data from AI related news articles to generate insights that lay the foundation for CATE-AI, and support our findings. The CATE-AI framework can help learners study artificial intelligence topics more effectively by serving as a basis for adapting and contextualizing AI to their sociocultural needs.",2023,10.3389/frai.2023.1198180
"The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype","COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.",2021,10.3389/frai.2021.652669
Computed Tomography Radiomics Kinetics as Early Imaging Correlates of Osteoradionecrosis in Oropharyngeal Cancer Patients,"Osteoradionecrosis (ORN) is a major side-effect of radiation therapy in oropharyngeal cancer (OPC) patients. In this study, we demonstrate that early prediction of ORN is possible by analyzing the temporal evolution of mandibular subvolumes receiving radiation. For our analysis, we use computed tomography (CT) scans from 21 OPC patients treated with Intensity Modulated Radiation Therapy (IMRT) with subsequent radiographically-proven ≥ grade II ORN, at three different time points: pre-IMRT, 2-months, and 6-months post-IMRT. For each patient, radiomic features were extracted from a mandibular subvolume that developed ORN and a control subvolume that received the same dose but did not develop ORN. We used a Multivariate Functional Principal Component Analysis (MFPCA) approach to characterize the temporal trajectories of these features. The proposed MFPCA model performs the best at classifying ORN vs. Control subvolumes with an area under curve (AUC) = 0.74 [95% confidence interval (C.I.): 0.61–0.90], significantly outperforming existing approaches such as a pre-IMRT features model or a delta model based on changes at intermediate time points, i.e., at 2- and 6-month follow-up. This suggests that temporal trajectories of radiomics features derived from sequential pre- and post-RT CT scans can provide markers that are correlates of RT-induced mandibular injury, and consequently aid in earlier management of ORN.",2021,10.3389/frai.2021.618469
Acceptability of artificial intelligence in inclusive education: a TAM2-based study among preservice teachers,"IntroductionThe integration of artificial intelligence (AI) into education is generating growing interest, particularly due to its potential to support inclusive pedagogical practices. This is especially relevant for addressing the needs of students with attention deficit hyperactivity disorder (ADHD). The success of such integration largely depends on the acceptability of AI tools by educators, especially those still in initial training. This study aims to identify the factors influencing the acceptability of AI among pre-service teachers in the specific context of teaching students with ADHD.MethodsGrounded in the Technology Acceptance Model 2 (TAM 2), the study adopts a mixed-methods approach. Quantitative data were collected via structured questionnaires, and qualitative insights were obtained through semi-structured interviews with pre-service teachers in Morocco.ResultsFindings reveal that perceived usefulness is the most influential predictor of AI acceptability, followed by perceived ease of use, voluntariness, and subjective norms. Participants emphasized the potential of AI to enhance pedagogical efficiency and support differentiated instruction. Institutional support and interface simplicity also emerged as key enablers.Discussion/ConclusionThese results highlight the need to incorporate digital literacy into teacher training programs and to develop AI tools specifically adapted to students with special educational needs. They also call for the establishment of a robust ethical and regulatory framework to ensure the responsible, equitable, and secure use of AI in education.",2025,10.3389/frai.2025.1616327
Efficient dataset extension using generative networks for assessing degree of coating degradation around scribe,"A novel methodology for dataset augmentation in the semantic segmentation of coil-coated surface degradation is presented in this study. Deep convolutional generative adversarial networks (DCGAN) are employed to generate synthetic input-target pairs, which closely resemble real-world data, with the goal of expanding an existing dataset. These augmented datasets are used to train two state-of-the-art models, U-net, and DeepLabV3, for the precise detection of degradation areas around scribes. In a series of experiments, it was demonstrated that the introduction of synthetic data improves the models' performance in detecting degradation, especially when the ratio of synthetic to real data is carefully managed. Results indicate that optimal improvements in accuracy and F1-score are achieved when the ratio of synthetic to original data is between 0.2 and 0.5. Moreover, the advantages and limitations of different GAN architectures for dataset expansion are explored, with specific attention to their ability to produce realistic and diverse samples. This work offers a scalable solution to the challenges associated with creating large and diverse annotated datasets for industrial applications of coil coating degradation assessment. The proposed approach provides a significant contribution by improving model generalization and segmentation accuracy while reducing the burden of manual data annotation. These findings have important implications for industries relying on coil coatings, as more efficient and accurate degradation detection methods are enabled.",2024,10.3389/frai.2024.1456844
The Singleton Fallacy: Why Current Critiques of Language Models Miss the Point,"This paper discusses the current critique against neural network-based Natural Language Understanding solutions known as language models. We argue that much of the current debate revolves around an argumentation error that we refer to as the singleton fallacy: the assumption that a concept (in this case, language, meaning, and understanding) refers to a single and uniform phenomenon, which in the current debate is assumed to be unobtainable by (current) language models. By contrast, we argue that positing some form of (mental) “unobtanium” as definiens for understanding inevitably leads to a dualistic position, and that such a position is precisely the original motivation for developing distributional methods in computational linguistics. As such, we argue that language models present a theoretically (and practically) sound approach that is our current best bet for computers to achieve language understanding. This understanding must however be understood as a computational means to an end.",2021,10.3389/frai.2021.682578
Does artificial intelligence kill employment growth: the missing link of corporate AI posture,"IntroductionAn intense debate has been on-going about how artificial intelligence (AI) technology investments have an impact on employment. The debate has often focused on the potential of AI for human task automation, omitting the strategic incentive for firms to cooperate with their workers as to exploit AI technologies for the most relevant benefit of new product and service innovation.MethodWe calibrate an empirical probit regression model of how changes in employment relate to AI diffusion, based on formalizing a game-theoretical model of a firm exploiting the twin role of AI innovation and AI automation for both absolute and competitive advantage.ResultsThe theoretical game-theory prediction is that employment following AI technology adoption is not negative, and ultimately depends on how AI leads to new success in innovation, competition which defines the competitive reward of innovation and profit sharing between workers and firms. Our estimation, is based on a global survey of 3,000 large companies across 10 countries, demonstrates that a firm employment growth depends on two strategic postures, that is, the firm relative maturity of AI adoption as well as its relative bias toward AI-based product innovation.DiscussionThe contribution of this research is to highlight the twin role of firm and workers in shaping how technology will affect employment. AI in particular marries the potential of task automation with even more potential for expansion.",2023,10.3389/frai.2023.1239466
Oral squamous cell carcinoma grading classification using deep transformer encoder assisted dilated convolution with global attention,"In recent years, Oral Squamous Cell Carcinoma (OSCC) has been a common tumor in the orofacial region, affecting areas such as the teeth, jaw, and temporomandibular joint. OSCC is classified into three grades: “well-differentiated, moderately differentiated, and poorly differentiated,” with a high morbidity and mortality rate among patients. Several existing methods, such as AlexNet, CNN, U-Net, and V-Net, have been used for OSCC classification. However, these methods face limitations, including low ACC, poor comparability, insufficient data collection, and prolonged training times. To address these limitations, we introduce a novel Deep Transformer Encoder-Assisted Dilated Convolution with Global Attention (DeTr-DiGAtt) model for OSCC classification. To enhance the dataset and mitigate over-fitting, a GAN model is employed for data augmentation. Additionally, an Adaptive Bilateral Filter (Ad-BF) is used to improve image quality and remove undesirable noise. For accurate identification of the affected region, an Improved Multi-Encoder Residual Squeeze U-Net (Imp-MuRs-Unet) model is utilized for segmentation. The DeTr-DiGAtt model is then applied to classify different OSCC grading levels. Furthermore, an Adaptive Grey Lag Goose Optimization Algorithm (Ad-GreLop) is used for hyperparameter tuning. The proposed method achieves an accuracy (ACC) of 98.59%, a Dice score of 97.97%, and an Intersection over Union (IoU) of 98.08%.",2025,10.3389/frai.2025.1575427
Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation,"IntroductionThe growing complexity of fraudulent activities presents significant challenges in detecting fraud within financial transactions. Accurate and robust detection methods are essential for minimizing financial losses.MethodsThis study evaluates logistic regression, decision tree, and random forest models on real-world credit card datasets, addressing class imbalance and enhancing predictive accuracy. A deep learning model incorporating focal loss was developed to further improve detection performance. The Synthetic Minority Over-Sampling Technique (SMOTE) was applied to mitigate class imbalance, and hyperparameter tuning was conducted to optimize model configurations.ResultsExperimental results show that the random forest model achieved the best overall performance, with an accuracy of 99.95%, F1 score of 0.8256, and ROC-AUC of 0.9759. The deep learning model provided the highest precision, demonstrating its potential in minimizing false positives.DiscussionA key novelty of this work is the integration of focal loss within the deep learning framework, enabling the model to focus on hard-to-classify fraudulent transactions. Unlike many prior studies limited to the Kaggle dataset, our approach was validated on both the Kaggle credit card dataset and the PaySim synthetic mobile money dataset, demonstrating robustness and cross-domain generalizability. These findings highlight the effectiveness of combining data preprocessing, resampling techniques, and model optimization for robust fraud detection.",2025,10.3389/frai.2025.1643292
Artificial intelligence in triage of COVID-19 patients,"In 2019, COVID-19 began one of the greatest public health challenges in history, reaching pandemic status the following year. Systems capable of predicting individuals at higher risk of progressing to severe forms of the disease could optimize the allocation and direction of resources. In this work, we evaluated the performance of different Machine Learning algorithms when predicting clinical outcomes of patients hospitalized with COVID-19, using clinical data from hospital admission alone. This data was collected during a prospective, multicenter cohort that followed patients with respiratory syndrome during the pandemic. We aimed to predict which patients would present mild cases of COVID-19 and which would develop severe cases. Severe cases were defined as those requiring access to the Intensive Care Unit, endotracheal intubation, or even progressing to death. The system achieved an accuracy of 80%, with Area Under Receiver Operating Characteristic Curve (AUC) of 91%, Positive Predictive Value of 87% and Negative Predictive Value of 82%. Considering that only data from hospital admission was used, and that this data came from low-cost clinical examination and laboratory testing, the low false positive rate and acceptable accuracy observed shows that it is feasible to implement prediction systems based on artificial intelligence as an effective triage method.",2024,10.3389/frai.2024.1495074
Feature relevance XAI in anomaly detection: Reviewing approaches and challenges,"With complexity of artificial intelligence systems increasing continuously in past years, studies to explain these complex systems have grown in popularity. While much work has focused on explaining artificial intelligence systems in popular domains such as classification and regression, explanations in the area of anomaly detection have only recently received increasing attention from researchers. In particular, explaining singular model decisions of a complex anomaly detector by highlighting which inputs were responsible for a decision, commonly referred to as local post-hoc feature relevance, has lately been studied by several authors. In this paper, we systematically structure these works based on their access to training data and the anomaly detection model, and provide a detailed overview of their operation in the anomaly detection domain. We demonstrate their performance and highlight their limitations in multiple experimental showcases, discussing current challenges and opportunities for future work in feature relevance XAI for anomaly detection.",2023,10.3389/frai.2023.1099521
Participatory design of teacher dashboards: navigating the tension between teacher input and theories on teacher professional vision,"In the field of AI in education, there is a movement toward human-centered design in which the primary stakeholders are collaborators in establishing the design and functionality of the AI system (participatory design). Several authors have noted that there is a potential tension in participatory design between involving stakeholders and, thus, increasing uptake of the system on the one hand, and the use of educational theory on the other hand. The goal of the present perspective article is to unpack this tension in more detail, focusing on the example of teacher dashboards. Our contribution to theory is to show that insights from the research field of teacher professional vision can help explain why stakeholder involvement may lead to tension. In particular, we discuss that the sources of information that teachers use in their professional vision, and which data sources could be included on dashboards, might differ with respect to whether they actually relate to student learning or not. Using this difference as a starting point for participatory design could help navigate the aforementioned tension. Subsequently, we describe several implications for practice and research that could help move the field of human centered design further.",2023,10.3389/frai.2023.1039739
"A Quantitative Evaluation of Global, Rule-Based Explanations of Post-Hoc, Model Agnostic Methods","Understanding the inferences of data-driven, machine-learned models can be seen as a process that discloses the relationships between their input and output. These relationships consist and can be represented as a set of inference rules. However, the models usually do not explicit these rules to their end-users who, subsequently, perceive them as black-boxes and might not trust their predictions. Therefore, scholars have proposed several methods for extracting rules from data-driven machine-learned models to explain their logic. However, limited work exists on the evaluation and comparison of these methods. This study proposes a novel comparative approach to evaluate and compare the rulesets produced by five model-agnostic, post-hoc rule extractors by employing eight quantitative metrics. Eventually, the Friedman test was employed to check whether a method consistently performed better than the others, in terms of the selected metrics, and could be considered superior. Findings demonstrate that these metrics do not provide sufficient evidence to identify superior methods over the others. However, when used together, these metrics form a tool, applicable to every rule-extraction method and machine-learned models, that is, suitable to highlight the strengths and weaknesses of the rule-extractors in various applications in an objective and straightforward manner, without any human interventions. Thus, they are capable of successfully modelling distinctively aspects of explainability, providing to researchers and practitioners vital insights on what a model has learned during its training process and how it makes its predictions.",2021,10.3389/frai.2021.717899
Clinical validation of an artificial intelligence algorithm for classifying tuberculosis and pulmonary findings in chest radiographs,"BackgroundChest X-ray (CXR) interpretation is critical in diagnosing various lung diseases. However, physicians, not specialists, are often the first ones to read them, frequently facing challenges in accurate interpretation. Artificial Intelligence (AI) algorithms could be of great help, but using real-world data is crucial to ensure their effectiveness in diverse healthcare settings. This study evaluates a deep learning algorithm designed for CXR interpretation, focusing on its utility for non-specialists in thoracic radiology physicians.PurposeTo assess the performance of a Convolutional Neural Networks (CNNs)-based AI algorithm in interpreting CXRs and compare it with a team of physicians, including thoracic radiologists, who served as the gold-standard.MethodsA retrospective study from January 2021 to July 2023 evaluated an algorithm with three independent models for Lung Abnormality, Radiological Findings, and Tuberculosis. The algorithm's performance was measured using accuracy, sensitivity, and specificity. Two groups of physicians validated the model: one with varying specialties and experience levels in interpreting chest radiographs (Group A) and another of board-certified thoracic radiologists (Group B). The study also assessed the agreement between the two groups on the algorithm's heatmap and its influence on their decisions.ResultsIn the internal validation, the Lung Abnormality and Tuberculosis models achieved an AUC of 0.94, while the Radiological Findings model yielded a mean AUC of 0.84. During the external validation, utilizing the ground truth generated by board-certified thoracic radiologists, the algorithm achieved better sensitivity in 6 out of 11 classes than physicians with varying experience levels. Furthermore, Group A physicians demonstrated higher agreement with the algorithm in identifying markings in specific lung regions than Group B (37.56% Group A vs. 21.75% Group B). Additionally, physicians declared that the algorithm did not influence their decisions in 93% of the cases.ConclusionThis retrospective clinical validation study assesses an AI algorithm's effectiveness in interpreting Chest X-rays (CXR). The results show the algorithm's performance is comparable to Group A physicians, using gold-standard analysis (Group B) as the reference. Notably, both Groups reported minimal influence of the algorithm on their decisions in most cases.",2025,10.3389/frai.2025.1512910
Navigating the unseen peril: safeguarding medical imaging in the age of AI,"In response to the increasing significance of artificial intelligence (AI) in healthcare, there has been increased attention – including a Presidential executive order to create an AI Safety Institute – to the potential threats posed by AI. While much attention has been given to the conventional risks AI poses to cybersecurity, and critical infrastructure, here we provide an overview of some unique challenges of AI for the medical community. Above and beyond obvious concerns about vetting algorithms that impact patient care, there are additional subtle yet equally important things to consider: the potential harm AI poses to its own integrity and the broader medical information ecosystem. Recognizing the role of healthcare professionals as both consumers and contributors to AI training data, this article advocates for a proactive approach in understanding and shaping the data that underpins AI systems, emphasizing the need for informed engagement to maximize the benefits of AI while mitigating the risks.",2024,10.3389/frai.2024.1400732
A longitudinal study on artificial intelligence adoption: understanding the drivers of ChatGPT usage behavior change in higher education,"As the field of artificial intelligence (AI) continues to progress, the use of AI-powered chatbots, such as ChatGPT, in higher education settings has gained significant attention. This paper addresses a well-defined problem pertaining to the critical need for a comprehensive examination of students' ChatGPT adoption in higher education. To examine such adoption, it is imperative to focus on measuring actual user behavior. While measuring students' ChatGPT usage behavior at a specific point in time can be valuable, a more holistic approach is necessary to understand the temporal dynamics of AI adoption. To address this need, a longitudinal survey was conducted, examining how students' ChatGPT usage behavior changes over time among students, and unveiling the drivers of such behavior change. The empirical examination of 222 Dutch higher education students revealed a significant decline in students' ChatGPT usage behavior over an 8 month period. This period was defined by two distinct data collection phases: the initial phase (T1) and a follow-up phase conducted 8 months later (T2). Furthermore, the results demonstrate that changes in trust, emotional creepiness, and Perceived Behavioral Control significantly predicted the observed change in usage behavior. The findings of this research carry significant academic and managerial implications, as they advance our comprehension of the temporal aspects of AI adoption in higher education. The findings also provide actionable guidance for AI developers and educational institutions seeking to optimize student engagement with AI technologies.",2024,10.3389/frai.2023.1324398
Backpropagation-Based Decoding for Multimodal Machine Translation,"People are able to describe images using thousands of languages, but languages share only one visual world. The aim of this work is to use the learned intermediate visual representations from a deep convolutional neural network to transfer information across languages for which paired data is not available in any form. Our work proposes using backpropagation-based decoding coupled with transformer-based multilingual-multimodal language models in order to obtain translations between any languages used during training. We particularly show the capabilities of this approach in the translation of German-Japanese and Japanese-German sentence pairs, given a training data of images freely associated with text in English, German, and Japanese but for which no single image contains annotations in both Japanese and German. Moreover, we demonstrate that our approach is also generally useful in the multilingual image captioning task when sentences in a second language are available at test time. The results of our method also compare favorably in the Multi30k dataset against recently proposed methods that are also aiming to leverage images as an intermediate source of translations.",2022,10.3389/frai.2021.736722
A convolutional neural network with image and numerical data to improve farming of edible crickets as a source of food—A decision support system,"Crickets (Gryllus bimaculatus) produce sounds as a natural means to communicate and convey various behaviors and activities, including mating, feeding, aggression, distress, and more. These vocalizations are intricately linked to prevailing environmental conditions such as temperature and humidity. By accurately monitoring, identifying, and appropriately addressing these behaviors and activities, the farming and production of crickets can be enhanced. This research implemented a decision support system that leverages machine learning (ML) algorithms to decode and classify cricket songs, along with their associated key weather variables (temperature and humidity). Videos capturing cricket behavior and weather variables were recorded. From these videos, sound signals were extracted and classified such as calling, aggression, and courtship. Numerical and image features were extracted from the sound signals and combined with the weather variables. The extracted numerical features, i.e., Mel-Frequency Cepstral Coefficients (MFCC), Linear Frequency Cepstral Coefficients, and chroma, were used to train shallow (support vector machine, k-nearest neighbors, and random forest (RF)) ML algorithms. While image features, i.e., spectrograms, were used to train different state-of-the-art deep ML models, i,e., convolutional neural network architectures (ResNet152V2, VGG16, and EfficientNetB4). In the deep ML category, ResNet152V2 had the best accuracy of 99.42%. The RF algorithm had the best accuracy of 95.63% in the shallow ML category when trained with a combination of MFCC+chroma and after feature selection. In descending order of importance, the top 6 ranked features in the RF algorithm were, namely humidity, temperature, C#, mfcc11, mfcc10, and D. From the selected features, it is notable that temperature and humidity are necessary for growth and metabolic activities in insects. Moreover, the songs produced by certain cricket species naturally align to musical tones such as C# and D as ranked by the algorithm. Using this knowledge, a decision support system was built to guide farmers about the optimal temperature and humidity ranges and interpret the songs (calling, aggression, and courtship) in relation to weather variables. With this information, farmers can put in place suitable measures such as temperature regulation, humidity control, addressing aggressors, and other relevant interventions to minimize or eliminate losses and enhance cricket production.",2024,10.3389/frai.2024.1403593
Predicting food prices in Kenya using machine learning: a hybrid model approach with XGBoost and gradient boosting,"Introduction
                    Food price volatility continues to be a significant concern in Kenya's economic development, posing challenges to the country's economic stability.
                  
                  
                    Methodology
                    This study examines the application of machine learning methods, employing a hybrid approach that combines XGBoost and gradient boosting, to predict food prices in Kenya. The food prices data from the World Food Programme, covering the period from January 2006 to September 2024, as well as currency exchange rates data from the Central Bank of Kenya in US dollars (USD) and inflation rates data, were collated and preprocessed to be ready for analytics and machine learning. The augmented data were preprocessed and transformed, then used to train XGBoost, gradient boosting, LightGBM, decision tree, random forest, and linear regression. A hybrid model was then developed by stacking XGBoost and gradient boosting as the base models, with linear regression serving as the meta-model used to combine their predictions.
                  
                  
                    Results
                    This model was then tuned using the hyperparameter random search method, achieving a mean absolute error of 0.1050, a mean squared error of 0.0261, a root mean square error of 0.1615, and an R-squared value of 0.9940, thereby surpassing the performance of all standalone models. We then applied cross-validation using 5-fold cross-validation and Diebold-Mariano tests to check for model overfitting and to perform model superiority analysis. Feature importance analysis using SHapley Additive exPlanations (SHAP) revealed that intuitive features influencing food prices are unit quantity, price type, commodity, and currency, while geographical factors such as county have a lesser impact. Finally, the model and its important features were saved as pickle files to facilitate the deployment of the model on a web application for food price predictions.
                  
                  
                    Discussion
                    This data-driven decision support system can help policymakers and agricultural stakeholders (such as the Kenyan government) plan for future trends in food prices, potentially helping to prevent food insecurity in Kenya.",2025,10.3389/frai.2025.1661989
"Use of AI to assess COVID-19 variant impacts on hospitalization, ICU, and death","The rapid spread of COVID-19 and its variants have devastated communities worldwide, and as the highly transmissible Omicron variant becomes the dominant strain of the virus in late 2021, the need to characterize and understand the difference between the new variant and its predecessors has been an increasing priority for public health authorities. Artificial Intelligence has played a significant role in the analysis of various facets of COVID-19 since the early stages of the pandemic. This study proposes the use of AI, specifically an XGBoost model, to quantify the impact of various medical risk factors (or “population features”) on the possibility of a patient outcome resulting in hospitalization, ICU admission, or death. The results are compared between the Delta and Omicron COVID-19 variants. Results indicated that older age and an unvaccinated patient status most consistently correspond as the most significant population features contributing to all three scenarios (hospitalization, ICU, death). The top 15 features for each variant-outcome scenario were determined, which most frequently included diabetes, cardiovascular disease, chronic kidney disease, and complications of pneumonia as highly significant population features contributing to serious illness outcomes. The Delta/Hospitalization model returned the highest performance metric scores for the area under the receiver operating characteristic (AUROC), F1, and Recall, while Omicron/ICU and Omicron/Hospitalization had the highest accuracy and precision values, respectively. The recall was found to be above 0.60 in most cases (with only two exceptions), indicating that the total number of false positives was generally minimized (accounting for more of the people who would theoretically require medical care).",2022,10.3389/frai.2022.927203
Factors associated with citations of articles on circular economy in the Web of Science: modeling for main publishers,"IntroductionThe publication of articles on the circular economy has different associated factors to explain the citations registered in the Web of Science.MethodArticles from the publishers Elsevier, MDPI, Taylor &amp; Francis, Wiley, and Springer Nature were evaluated.ResultsIt was expected that the older the article was, the more citations it had received, but this was not always the case. It was also recognized that there was a lower number of citations if the articles were too large or if they had too many references.DiscussionThis analysis helps to establish the factors that must be addressed in order to publish in journals that have a high citation rate. Conclusion: Based on speci?c articles and with speci?c references, it will be possible to increase the probability of citations.",2023,10.3389/frai.2023.1217210
Sentence-level complexity in Russian: An evaluation of BERT and graph neural networks,"IntroductionSentence-level complexity evaluation (SCE) can be formulated as assigning a given sentence a complexity score: either as a category, or a single value. SCE task can be treated as an intermediate step for text complexity prediction, text simplification, lexical complexity prediction, etc. What is more, robust prediction of a single sentence complexity needs much shorter text fragments than the ones typically required to robustly evaluate text complexity. Morphosyntactic and lexical features have proved their vital role as predictors in the state-of-the-art deep neural models for sentence categorization. However, a common issue is the interpretability of deep neural network results.MethodsThis paper presents testing and comparing several approaches to predict both absolute and relative sentence complexity in Russian. The evaluation involves Russian BERT, Transformer, SVM with features from sentence embeddings, and a graph neural network. Such a comparison is done for the first time for the Russian language.Results and discussionPre-trained language models outperform graph neural networks, that incorporate the syntactical dependency tree of a sentence. The graph neural networks perform better than Transformer and SVM classifiers that employ sentence embeddings. Predictions of the proposed graph neural network architecture can be easily explained.",2022,10.3389/frai.2022.1008411
How the Brain Dynamically Constructs Sentence-Level Meanings From Word-Level Features,"How are words connected to the thoughts they help to express? Recent brain imaging studies suggest that word representations are embodied in different neural systems through which the words are experienced. Building on this idea, embodied approaches such as the Concept Attribute Representations (CAR) theory represents concepts as a set of semantic features (attributes) mapped to different brain systems. An intriguing challenge to this theory is that people weigh concept attributes differently based on context, i.e., they construct meaning dynamically according to the combination of concepts that occur in the sentence. This research addresses this challenge through the Context-dEpendent meaning REpresentations in the BRAin (CEREBRA) neural network model. Based on changes in the brain images, CEREBRA quantifies the effect of sentence context on word meanings. Computational experiments demonstrated that words in different contexts have different representations, the changes observed in the concept attributes reveal unique conceptual combinations, and that the new representations are more similar to the other words in the sentence than to the original representations. Behavioral analysis further confirmed that the changes produced by CEREBRA are actionable knowledge that can be used to predict human responses. These experiments constitute a comprehensive evaluation of CEREBRA's context-based representations, showing that CARs can be dynamic and change based on context. Thus, CEREBRA is a useful tool for understanding how word meanings are represented in the brain, providing a framework for future interdisciplinary research on the mental lexicon.",2022,10.3389/frai.2022.733163
Small pre-trained model for background understanding in multi-round question answering,"Multi-round Q&amp;A based on background text needs to infer the answer to the question through the current question, historical Q&amp;A pairs, and background text. The pre-trained model has proved its effectiveness in this task; however, the existing model has many problems such as too many parameters and high resource consumption. We propose a knowledge transfer method that combines knowledge distillation, co-learning of similar datasets, and fine-tuning of similar tasks. Through multi-knowledge cooperative training from large model to small model, between different data sets, and between different tasks, the performance of the small model with low resource consumption can match or surpass that of the large model.",2025,10.3389/frai.2024.1308206
Semi-supervised active learning using convolutional auto- encoder and contrastive learning,"Active learning is a field of machine learning that seeks to find the most efficient labels to annotate with a given budget, particularly in cases where obtaining labeled data is expensive or infeasible. This is becoming increasingly important with the growing success of learning-based methods, which often require large amounts of labeled data. Computer vision is one area where active learning has shown promise in tasks such as image classification, semantic segmentation, and object detection. In this research, we propose a pool-based semi-supervised active learning method for image classification that takes advantage of both labeled and unlabeled data. Many active learning approaches do not utilize unlabeled data, but we believe that incorporating these data can improve performance. To address this issue, our method involves several steps. First, we cluster the latent space of a pre-trained convolutional autoencoder. Then, we use a proposed clustering contrastive loss to strengthen the latent space's clustering while using a small amount of labeled data. Finally, we query the samples with the highest uncertainty to annotate with an oracle. We repeat this process until the end of the given budget. Our method is effective when the number of annotated samples is small, and we have validated its effectiveness through experiments on benchmark datasets. Our empirical results demonstrate the power of our method for image classification tasks in accuracy terms.",2024,10.3389/frai.2024.1398844
Data quality challenges of AIGC application in smart agriculture,"In recent years, China’s agricultural development has gradually shifted from digital agriculture to smart agriculture. At the same time, with the participation of AIGC, the decision-making system of smart agriculture is also facing numerous data challenges. In this study, we employed a comprehensive quality improvement approach to ad-dress these challenges. The methodology involves three phases: (1) Detection and removal of data noise through advanced cleaning techniques and preprocessing methods; (2) Unified data standards and formats to ensure seamless integration across di-verse data sources; and (3) Strengthening agricultural infrastructure to prevent data islands and promote equitable data distribution. Our analysis reveals that data noise significantly impacts precision agriculture, leading to biased decisions and resource wastage. Data fog, resulting from heterogeneous data sources and weak inter-source correlations, complicates decision-making processes. Additionally, data islands hinder data sharing and integration, exacerbated by uneven data development across regions. Systematic implementation of standardized quality control protocols is essential for enhancing smart agricultural systems and ensuring sustainable development. This study offers a novel perspective on enhancing data quality in AIGC-driven smart agriculture by integrating the Juran quality improvement model.",2025,10.3389/frai.2025.1640805
Universal medical image segmentation via in-context cross-attention,"Semantic segmentation is critical in medical image processing, with traditional specialist models facing adaptation challenges to new tasks or distribution shifts. While both generalist pre-trained models and universal segmentation approaches have emerged as solutions, universal methods offer advantages in versatility, sample efficiency, and integration ease into annotation pipelines. We introduce a novel universal segmentation method based on the premise that pre-selecting relevant regions from support sets improves segmentation accuracy. Our approach implements cross-attention between query images and support set images, coupled with an innovative attention up-scaling mechanism that efficiently computes cross-attention on small-scale features with upscaling to higher resolutions. The design inherently supports explainability by allowing inspection of relevant support set locations for each input region. Extensive evaluation across 29 medical datasets spanning 9 imaging modalities and 135 segmentation tasks demonstrates consistent performance improvements, even with lightweight models. Our experiments show proportional gains in segmentation performance as support set size increases, with the cross-attention mechanism effectively selecting the most relevant support images from larger annotation pools. Additionally, our explainability module demonstrates competitive or improved interpretability when compared to established methods like LayerCAM.",2025,10.3389/frai.2025.1698324
Sentiment analysis for measuring hope and fear from Reddit posts during the 2022 Russo-Ukrainian conflict,"This article proposes a novel lexicon-based unsupervised sentiment analysis method to measure the “hope” and “fear” for the 2022 Ukrainian-Russian Conflict. Reddit.com is utilized as the main source of human reactions to daily events during nearly the first 3 months of the conflict. The top 50 “hot” posts of six different subreddits about Ukraine and news (Ukraine, worldnews, Ukraina, UkrainianConflict, UkraineWarVideoReport, and UkraineWarReports) along with their relative comments are scraped every day between 10th of May and 28th of July, and a novel data set is created. On this corpus, multiple analyzes, such as (1) public interest, (2) Hope/Fear score, and (3) stock price interaction, are employed. We use a dictionary approach, which scores the hopefulness of every submitted user post. The Latent Dirichlet Allocation (LDA) algorithm of topic modeling is also utilized to understand the main issues raised by users and what are the key talking points. Experimental analysis shows that the hope strongly decreases after the symbolic and strategic losses of Azovstal (Mariupol) and Severodonetsk. Spikes in hope/fear, both positives and negatives, are present not only after important battles, but also after some non-military events, such as Eurovision and football games.",2023,10.3389/frai.2023.1163577
Mutual human-robot understanding for a robot-enhanced society: the crucial development of shared embodied cognition,"The conception of autonomous, intelligent, collaborative robots has been the subject of science fiction rather than science in the second half of the previous century, with practical applications limited to industrial machines without any level of autonomous, intelligent, and collaborative capacity. The new century is facing the challenge of pressing industrial and social revolutions (4, 5, 6, …) with the prospect of infiltrating robots in every sector of human society; however, this dissemination will be possible if and only if acceptable degrees of autonomy, intelligence, and collaborative capacity can be achieved. Scientific and technological innovations are needed within a highly multidisciplinary framework, with a critical integration strategy and functional characterization that must ask a fundamental question: the design of autonomous, intelligent, collaborative robots should aim at a unified single template to be mass-produced including a standard setup procedure for the functional adaptation of any single prototype, or should the design aim at “baby” robots with a minimal set of sensory-motor-cognitive capabilities as the starting point of a training and educational process in close connection with human companions (masters, partners, final users)? The former alternative is supported by EAI, i.e., the Embodied variant of the Artificial Intelligence family of computational tools based on large foundation models. The latter alternative is bio-inspired; namely, it attempts to replicate the computational structure of Embodied Cognitive Science. Both formulations imply embodiment as a core issue. Still, we think this concept has a markedly different meaning and practical implications in the two cases, although we are still far away from the practical implementations of either roadmap. In this opinion paper, we explain why we think the bio-inspired approach is better than the EAI approach in providing a feasible roadmap for developing autonomous, intelligent, collaborative robots. In particular, we focus on the importance of collaborative human-robot interactions conceived in a general sense, ranging from haptic interactions in joint physical efforts (e.g., loading/unloading) to cognitive interactions for joint strategic planning of complex tasks. We envision this type of collaboration only made possible by a deep human-robot mutual understanding based on a structural equivalence of their embodied cognitive architecture, based on an active, first-person acquisition of experience rather than a passive download of third-person knowledge.",2025,10.3389/frai.2025.1608014
InGSA: integrating generalized self-attention in CNN for Alzheimer's disease classification,"Alzheimer's disease (AD) is an incurable neurodegenerative disorder that slowly impair the mental abilities. Early diagnosis, nevertheless, can greatly reduce the symptoms that are associated with the condition. Earlier techniques of diagnosing the AD from the MRI scans have been adopted by traditional machine learning technologies. However, such traditional methods involve depending on feature extraction that is usually complex, time-consuming, and requiring substantial effort from the medical personnel. Furthermore, these methods are usually not very specific as far as diagnosis is concerned. In general, traditional convolutional neural network (CNN) architectures have a problem with identifying AD. To this end, the developed framework consists of a new contrast enhancement approach, named haze-reduced local-global (HRLG). For multiclass AD classification, we introduce a global CNN-transformer model InGSA. The proposed InGSA is based on the InceptionV3 model which is pre-trained, and it encompasses an additional generalized self-attention (GSA) block at top of the network. This GSA module is capable of capturing the interaction not only in terms of the spatial relations within the feature space but also over the channel dimension it is capable of picking up fine detailing of the AD information while suppressing the noise. Furthermore, several GSA heads are used to exploit other dependency structures of global features as well. Our evaluation of InGSA on a two benchmark dataset, using various pre-trained networks, demonstrates the GSA's superior performance.",2025,10.3389/frai.2025.1540646
Wearable sensors based on artificial intelligence models for human activity recognition,"Human motion detection technology holds significant potential in medicine, health care, and physical exercise. This study introduces a novel approach to human activity recognition (HAR) using convolutional neural networks (CNNs) designed for individual sensor types to enhance the accuracy and address the challenge of diverse data shapes from accelerometers, gyroscopes, and barometers. Specific CNN models are constructed for each sensor type, enabling them to capture the characteristics of their respective sensors. These adapted CNNs are designed to effectively process varying data shapes and sensor-specific characteristics to accurately classify a wide range of human activities. The late-fusion technique is employed to combine predictions from various models to obtain comprehensive estimates of human activity. The proposed CNN-based approach is compared to a standard support vector machine (SVM) classifier using the one-vs-rest methodology. The late-fusion CNN model showed significantly improved performance, with validation and final test accuracies of 99.35 and 94.83% compared to the conventional SVM classifier at 87.07 and 83.10%, respectively. These findings provide strong evidence that combining multiple sensors and a barometer and utilizing an additional filter algorithm greatly improves the accuracy of identifying different human movement patterns.",2024,10.3389/frai.2024.1424190
Lung cancer risk prediction using augmented machine learning pipelines with explainable AI,"Lung cancer remains the leading cause of cancer-related deaths worldwide, making early and precise diagnosis is critical for improving the patient survival rates. Machine learning has shown promising results in predictive analysis for lung cancer prediction. However, class imbalance in clinical datasets negatively impacts the performance of Machine Learning classifiers, leading to biased predictions and reduced accuracy. In an attempt to address this issue, various data augmentation techniques were applied alongside classification models to enhance predictive performance. This study evaluates data augmentation techniques paired with machine learning classifiers to address class imbalance in a small lung cancer dataset. A comparative analysis was conducted to assess the impact of different augmentation techniques with classification models. Experimental findings demonstrate that K-Means SMOTE, combined with a Multi-Layer Perceptron classifier, achieves the highest accuracy of 93.55% and an AUC-ROC score of 96.76%, surpassing other augmentation-classifier combinations. These results underscore the importance of selecting optimal augmentation methods to improve classification performance. Furthermore, to ensure model interpretability and transparency in medical decision-making, LIME is utilized to provide insights into model predictions. The study highlights the significance of advanced augmentation techniques in addressing data imbalance, ultimately enhancing lung cancer risk prediction through machine learning. The findings contribute to the growing field of AI-driven healthcare by emphasizing the necessity of selecting effective augmentation-classifier pairs to develop more accurate and reliable diagnostic models. Due to the dataset’s high cancer prevalence (87.45%) and limited size, this work is a preliminary methodological comparison, not a clinical tool. Findings emphasize the importance of augmentation for imbalanced data and lay the groundwork for future validation with larger, representative datasets.",2025,10.3389/frai.2025.1602775
"Brain organoids and organoid intelligence from ethical, legal, and social points of view","Human brain organoids, aka cerebral organoids or earlier “mini-brains”, are 3D cellular models that recapitulate aspects of the developing human brain. They show tremendous promise for advancing our understanding of neurodevelopment and neurological disorders. However, the unprecedented ability to model human brain development and function in vitro also raises complex ethical, legal, and social challenges. Organoid Intelligence (OI) describes the ongoing movement to combine such organoids with Artificial Intelligence to establish basic forms of memory and learning. This article discusses key issues regarding the scientific status and prospects of brain organoids and OI, conceptualizations of consciousness and the mind–brain relationship, ethical and legal dimensions, including moral status, human–animal chimeras, informed consent, and governance matters, such as oversight and regulation. A balanced framework is needed to allow vital research while addressing public perceptions and ethical concerns. Interdisciplinary perspectives and proactive engagement among scientists, ethicists, policymakers, and the public can enable responsible translational pathways for organoid technology. A thoughtful, proactive governance framework might be needed to ensure ethically responsible progress in this promising field.",2024,10.3389/frai.2023.1307613
Ethical implications of ChatGPT and other large language models in academia,"The rapid advancement of technology in the digital age has significantly transformed human communication and knowledge exchange. At the forefront of this transformation are Large Language Models (LLMs), powerful neural networks trained on vast text corpora to perform a wide range of Natural Language Processing (NLP) tasks. While LLMs offer promising benefits such as enhanced productivity and human-like text generation, their integration into academic settings raises pressing ethical concerns. This study investigates the ethical dimensions surrounding the use of LLMs in academia, driven by their increasing prevalence and the need for responsible adoption. A mixed-methods approach was employed, combining surveys, semi-structured interviews, and focus groups with key stakeholders, including students, faculty, administrators, and AI developers. The findings reveal a high level of LLM adoption accompanied by concerns related to plagiarism, bias, authenticity, and academic integrity. In response, the study proposes concrete strategies for ethical integration, including: (1) the establishment of transparent usage policies, (2) the incorporation of LLM literacy training into academic curricula, (3) the development of institutional review frameworks for AI-generated content, and (4) ongoing stakeholder dialogue to adapt policies as the technology evolves. These recommendations aim to support the responsible and informed use of LLMs in scholarly environments. The widespread influence of technological advancement has notably transformed communication and knowledge sharing, with LLMs playing a central role. These advanced neural networks, trained on extensive text datasets, have become valuable tools for generating human-like text and improving efficiency. However, their growing use in academic contexts raises significant ethical concerns. This study investigates these issues, focusing on the implications of LLM integration in scholarly environments. Using mixed methods, including surveys, semi-structured interviews, and focus groups, the research gathered insights from students, faculty, administrators, and AI developers. The findings highlight substantial adoption of LLMs alongside concerns about plagiarism, bias, and academic integrity. Based on this input, the study proposes guidelines for their responsible and ethical use in academia.",2025,10.3389/frai.2025.1615761
Autonomous Tool for Monitoring Multi-Morbidity Health Conditions in UAE and India,"Multi-morbidity is the presence of two or more long-term health conditions, including defined physical or mental health conditions, such as diabetes or schizophrenia. One of the regular and critical health cases is an elderly person with a multi-morbid health condition and special complications who lives alone. These patients are typically not familiar with advanced Information and Communications Technology (ICT), but they are comfortable using smart devices such as wearable watches and mobile phones. The use of ICT improves medical quality, promotes patient security and data security, lowers operational and administrative costs, and gives the people in charge to make informed decisions. Additionally, the use of ICT in healthcare practices greatly reduces human errors, enhances clinical outcomes, ramps up care coordination, boosts practice efficiencies, and helps in collecting data over time. The proposed research concept provides a natural technique to implement preventive health care innovative solutions since several health sensors are embedded in devices that autonomously monitor the patients' health conditions in real-time. This enhances the elder's limited ability to predict and respond to critical health situations. Autonomous monitoring can alert doctors and patients themselves of unexpected health conditions. Real-time monitoring, modeling, and predicting health conditions can trigger swift responses by doctors and health officials in case of emergencies. This study will use data science to stimulate discoveries and breakthroughs in the United Arab Emirates (UAE) and India, which will then be reproduced in other world areas to create major gains in health for people, communities, and populations.",2022,10.3389/frai.2022.865792
"The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: a single-center, retrospective, observational study","BackgroundAutoimmune encephalitis (AIE) is challenging to diagnose, especially in primary hospitals in China with limited medical resources. DeepSeek, a newly developed AI, shows potential as a cost-effective tool for improving diagnostic efficiency. However, no studies have evaluated the diagnostic accuracy of DeepSeek for AIE.MethodsThis retrospective study included 100 patients with anti-neuronal antibody-positive AIE treated at Ruijin Hospital, Shanghai Jiao Tong University School of Medicine. After removing personally identifiable information, antibody results, and history of immunotherapy from patients’ medical histories, the following information was sequentially input into DeepSeek: sex, age, chief complaint, medical history, EEG findings, head MRI description, and cerebrospinal fluid (CSF) results. The positive rates of AIE diagnoses predicted by DeepSeek were then categorized as most likely diagnosis, differential diagnosis, and total diagnosis.ResultsUsing DeepSeek, the probabilities of AIE appearing as the most likely diagnosis and total diagnosis accuracy were 49 and 65%. When patient data were input stepwise, both the total diagnosis accuracy and the most likely diagnosis accuracy did not significantly increase. AIE patients with anti-MOG and anti-GABAbR positivity had predicted total diagnostic positivity rates of 88 and 100%, respectively. Patients presenting with headache and epilepsy were more likely to be diagnosed with AIE (96 and 100%).ConclusionDeepSeek shows limited positive diagnostic accuracy for predicting the diagnosis of AIE. The application of this new AI technology could be used to promote early screening for AIE in primary hospitals in China, improve medical education, and lead to research advances in AIE.",2025,10.3389/frai.2025.1638904
Spectral Entropic Radiomics Feature Extraction (SERFE): an adaptive approach for glioblastoma disease classification,"IntroductionRadiomics-based glioblastoma classification demands feature extraction techniques that can effectively capture tumor heterogeneity while maintaining computational efficiency. Conventional tools such as PyRadiomics and CaPTk rely on extensive handcrafted feature sets, which often result in redundancy and necessitate further optimization steps.MethodsThis study proposes a novel framework, Spectral Entropic Radiomics Feature Extraction (SERFE), which integrates spectral frequency decomposition, entropy-driven feature selection, and graph-based spatial encoding. SERFE decomposes voxel intensity fluctuations into spectral signatures, employs entropy-based weighting to prioritize informative features, and preserves spatial topology through graph-based modeling. The method was evaluated using the public TCIA glioblastoma dataset.ResultsSERFE generated a refined feature set of 350 radiomic features from an initial pool of 2,260, achieving a 92% stability score and 91.7% classification accuracy. This performance surpasses traditional radiomics methods in both predictive accuracy and feature compactness.DiscussionThe results demonstrate SERFE’s capacity to enhance tumor characterization and streamline radiomics pipelines without requiring post-extraction feature reduction. Its compatibility with existing clinical workflows makes it a promising tool for future neuro-oncology applications.",2025,10.3389/frai.2025.1583079
Artificial intelligence-driven approach for patient-focused drug development,"Patients' increasing digital participation provides an opportunity to pursue patient-centric research and drug development by understanding their needs. Social media has proven to be one of the most useful data sources when it comes to understanding a company's potential audience to drive more targeted impact. Navigating through an ocean of information is a tedious task where techniques such as artificial intelligence and text analytics have proven effective in identifying relevant posts for healthcare business questions. Here, we present an enterprise-ready, scalable solution demonstrating the feasibility and utility of social media-based patient experience data for use in research and development through capturing and assessing patient experiences and expectations on disease, treatment options, and unmet needs while creating a playbook for roll-out to other indications and therapeutic areas.",2023,10.3389/frai.2023.1237124
Preventing Failures by Dataset Shift Detection in Safety-Critical Graph Applications,"Dataset shift refers to the problem where the input data distribution may change over time (e.g., between training and test stages). Since this can be a critical bottleneck in several safety-critical applications such as healthcare, drug-discovery, etc., dataset shift detection has become an important research issue in machine learning. Though several existing efforts have focused on image/video data, applications with graph-structured data have not received sufficient attention. Therefore, in this paper, we investigate the problem of detecting shifts in graph structured data through the lens of statistical hypothesis testing. Specifically, we propose a practical two-sample test based approach for shift detection in large-scale graph structured data. Our approach is very flexible in that it is suitable for both undirected and directed graphs, and eliminates the need for equal sample sizes. Using empirical studies, we demonstrate the effectiveness of the proposed test in detecting dataset shifts. We also corroborate these findings using real-world datasets, characterized by directed graphs and a large number of nodes.",2021,10.3389/frai.2021.589632
Scaling transformers to high-dimensional sparse data: a Reformer-BERT approach for large-scale classification,"Objective
                    The precise identification of human cell types and their intricate interactions is of fundamental importance in biological research. Confronted with the challenges inherent in manual cell type annotation from the high-dimensional molecular feature data generated by single-cell RNA sequencing (scRNA-seq)—a technology that has otherwise opened new avenues for such explorations—this study aimed to develop and evaluate a robust, large-scale pre-trained model designed for automated cell type classification, with a focus on major cell categories in this initial study.
                  
                  
                    Methods
                    A novel methodology for cell type classification, named scReformer-BERT, was developed, leveraging a BERT (Bidirectional Encoder Representations from Transformers) architecture that integrates Reformer encoders. This framework was subjected to extensive self-supervised pre-training on substantial scRNA-seq datasets, after which supervised fine-tuning and rigorous five-fold cross-validation was performed to optimize the model for predictive accuracy on targeted first-tier cell type classification tasks. A comprehensive ablation study was also conducted to dissect the contributions of each architectural component, and SHAP (SHapley Additive exPlanations) analysis was used to interpret the model’s decisions.
                  
                  
                    Results
                    The performance of the proposed model was rigorously evaluated through a series of experiments. These evaluations, conducted on scRNA-seq data, consistently revealed the superior efficacy of our approach in accurately classifying major cell categories when compared against several established baseline methods and the inherent difficulties in the field.
                  
                  
                    Conclusion
                    Considering these outcomes, the developed large-scale pre-trained model, which synergizes Reformer encoders with a BERT architecture, presents a potent, effective and interpretable solution for automated cell type classification derived from scRNA-seq data. Its notable performance suggests considerable utility in improving both the efficiency and precision of cellular identification in high-throughput genomic investigations.",2025,10.3389/frai.2025.1661318
Text summarization method of argumentative discourse by combining the BERT-transformer model,"Summarization of texts have been considered as essential practice nowadays with the careful presentation of the main ideas of a text. The current study aims to provide a methodology of summarizing complex texts such as argumentative discourse. Extractive and abstractive summarization techniques have recently gained significant attention. Each has its own limitations that reduce efficiency in the coverage of the main points of the summary, but by combining them, we can use the positive points of each to improve both summarization performance and summary generation quality. This paper presents a novel extractive-abstractive text summarization method that ensures coverage of the main points of the entire text. It is based on combining Bidirectional Encoder Representations from Transformers (BERT) and transfer learning. Using a dataset comprising two UK parliamentary debates, the study shows that the proposed method effectively summarizes the main points. Comparing extractive and abstractive summarization, the experiment used Recall-Oriented Understudy for Gisting Evaluation (ROUGE) sets of metrics and achieved scores of 30.1, 9.60, and 27.9 for the first debate, and 36.2, 11.80, and 31.5 for the second, using ROUGE-1, ROUGE-2, and ROUGE-L metrics, respectively.",2025,10.3389/frai.2025.1654496
Transfer learning for predicting of gross domestic product growth based on remittance inflows using RNN-LSTM hybrid model: a case study of The Gambia,"Insights into the magnitude and performance of an economy are crucial, with the growth rate of real GDP frequently used as a key indicator of economic health, highlighting the importance of the Gross Domestic Product (GDP). Additionally, remittances have drawn considerable global interest in recent years, particularly in The Gambia. This study introduces an innovative model, a hybrid of recurrent neural network and long-short-term memory (RNN-LSTM), to predict GDP growth based on remittance inflows in The Gambia. The model integrates data sourced both from the World Bank Development Indicators and the Central Bank of The Gambia (1966–2022). Pearson’s correlation was applied to detect and choose the variables that exhibit the strongest relationship with GDP and remittances. Furthermore, a parameter transfer learning technique was employed to enhance the model’s predictive accuracy. The hyperparameters of the model were fine-tuned through a random search process, and its effectiveness was assessed using RMSE, MAE, MAPE, and R2 metrics. The research results show, first, that it has good generalization capacity, with stable applicability in predicting GDP growth based on remittance inflows. Second, as compared to standalone models the suggested model surpassed in term of predicting accuracy attained the highest R2 score of 91.285%. Third, the predicted outcomes further demonstrated a strong and positive relationship between remittances and short-term economic growth. This paper addresses a critical research gap by employing artificial intelligence (AI) techniques to forecast GDP based on remittance inflows.",2025,10.3389/frai.2025.1510341
Self-Organising Map Based Framework for Investigating Accounts Suspected of Money Laundering,"There has been an emerging interest by financial institutions to develop advanced systems that can help enhance their anti-money laundering (AML) programmes. In this study, we present a self-organising map (SOM) based approach to predict which bank accounts are possibly involved in money laundering cases, given their financial transaction histories. Our method takes advantage of the competitive and adaptive properties of SOM to represent the accounts in a lower-dimensional space. Subsequently, categorising the SOM and the accounts into money laundering risk levels and proposing investigative strategies enables us to measure the classification performance. Our results indicate that our framework is well capable of identifying suspicious accounts already investigated by our partner bank, using both proposed investigation strategies. We further validate our model by analysing the performance when modifying different parameters in our dataset.",2021,10.3389/frai.2021.761925
The Test Pyramid 2.0: AI-assisted testing across the pyramid,"Ensuring robust test coverage, high code quality, and a strong security posture are persistent challenges in modern industrial software development, especially as systems grow in complexity and release cycles accelerate with recent Artificial Intelligence (AI) related productivity gains. This paper introduces a conceptual framework, ""The Test Pyramid 2.0"", which offers a clear and actionable path to integrate the latest advances in AI and DevSecOps principles into engineering workflows to achieve greater efficiency, reduce defect leakage, and create more resilient systems. We examine how AI enhances each layer of the test pyramid through capabilities such as automated test generation, coverage analysis, test data synthesis, anomaly detection, and intelligent UI exploration. In parallel, we embed DevSecOps practices directly into the pyramid by aligning security controls with each testing layer, ranging from static analysis and policy enforcement to dynamic testing, misconfiguration detection, and adversarial simulation. We also explore how AI strengthens these security practices through adaptive learning, risk prioritization, and context-aware detection. Together, these advances create a holistic, AI-augmented, and security-conscious testing strategy that supports the speed of modern development without compromising quality or safety.",2025,10.3389/frai.2025.1695965
A unified Foot and Mouth Disease dataset for Uganda: evaluating machine learning predictive performance degradation under varying distributions,"In Uganda, the absence of a unified dataset for constructing machine learning models to predict Foot and Mouth Disease outbreaks hinders preparedness. Although machine learning models exhibit excellent predictive performance for Foot and Mouth Disease outbreaks under stationary conditions, they are susceptible to performance degradation in non-stationary environments. Rainfall and temperature are key factors influencing these outbreaks, and their variability due to climate change can significantly impact predictive performance. This study created a unified Foot and Mouth Disease dataset by integrating disparate sources and pre-processing data using mean imputation, duplicate removal, visualization, and merging techniques. To evaluate performance degradation, seven machine learning models were trained and assessed using metrics including accuracy, area under the receiver operating characteristic curve, recall, precision and F1-score. The dataset showed a significant class imbalance with more non-outbreaks than outbreaks, requiring data augmentation methods. Variability in rainfall and temperature impacted predictive performance, causing notable degradation. Random Forest with borderline SMOTE was the top-performing model in a stationary environment, achieving 92% accuracy, 0.97 area under the receiver operating characteristic curve, 0.94 recall, 0.90 precision, and 0.92 F1-score. However, under varying distributions, all models exhibited significant performance degradation, with random forest accuracy dropping to 46%, area under the receiver operating characteristic curve to 0.58, recall to 0.03, precision to 0.24, and F1-score to 0.06. This study underscores the creation of a unified Foot and Mouth Disease dataset for Uganda and reveals significant performance degradation in seven machine learning models under varying distributions. These findings highlight the need for new methods to address the impact of distribution variability on predictive performance.",2024,10.3389/frai.2024.1446368
Inference-Optimized AI and High Performance Computing for Gravitational Wave Detection at Scale,"We introduce an ensemble of artificial intelligence models for gravitational wave detection that we trained in the Summit supercomputer using 32 nodes, equivalent to 192 NVIDIA V100 GPUs, within 2 h. Once fully trained, we optimized these models for accelerated inference using NVIDIA TensorRT. We deployed our inference-optimized AI ensemble in the ThetaGPU supercomputer at Argonne Leadership Computer Facility to conduct distributed inference. Using the entire ThetaGPU supercomputer, consisting of 20 nodes each of which has 8 NVIDIA A100 Tensor Core GPUs and 2 AMD Rome CPUs, our NVIDIA TensorRT-optimized AI ensemble processed an entire month of advanced LIGO data (including Hanford and Livingston data streams) within 50 s. Our inference-optimized AI ensemble retains the same sensitivity of traditional AI models, namely, it identifies all known binary black hole mergers previously identified in this advanced LIGO dataset and reports no misclassifications, while also providing a 3X inference speedup compared to traditional artificial intelligence models. We used time slides to quantify the performance of our AI ensemble to process up to 5 years worth of advanced LIGO data. In this synthetically enhanced dataset, our AI ensemble reports an average of one misclassification for every month of searched advanced LIGO data. We also present the receiver operating characteristic curve of our AI ensemble using this 5 year long advanced LIGO dataset. This approach provides the required tools to conduct accelerated, AI-driven gravitational wave detection at scale.",2022,10.3389/frai.2022.828672
Machine Learning Applied to the Search for Nonlinear Features in Breeding Populations,"Large plant breeding populations are traditionally a source of novel allelic diversity and are at the core of selection efforts for elite material. Finding rare diversity requires a deep understanding of biological interactions between the genetic makeup of one genotype and its environmental conditions. Most modern breeding programs still rely on linear regression models to solve this problem, generalizing the complex genotype by phenotype interactions through manually constructed linear features. However, the identification of positive alleles vs. background can be addressed using deep learning approaches that have the capacity to learn complex nonlinear functions for the inputs. Machine learning (ML) is an artificial intelligence (AI) approach involving a range of algorithms to learn from input data sets and predict outcomes in other related samples. This paper describes a variety of techniques that include supervised and unsupervised ML algorithms to improve our understanding of nonlinear interactions from plant breeding data sets. Feature selection (FS) methods are combined with linear and nonlinear predictors and compared to traditional prediction methods used in plant breeding. Recent advances in ML allowed the construction of complex models that have the capacity to better differentiate between positive alleles and the genetic background. Using real plant breeding program data, we show that ML methods have the ability to outperform current approaches, increase prediction accuracies, decrease the computing time drastically, and improve the detection of important alleles involved in qualitative or quantitative traits.",2022,10.3389/frai.2022.876578
Algorithmic discrimination: examining its types and regulatory measures with emphasis on US legal practices,"IntroductionAlgorithmic decision-making systems are widely used in various sectors, including criminal justice, employment, and education. While these systems are celebrated for their potential to enhance efficiency and objectivity, they also pose risks of perpetuating and amplifying societal biases and discrimination. This paper aims to provide an indepth analysis of the types of algorithmic discrimination, exploring both the challenges and potential solutions.MethodsThe methodology includes a systematic literature review, analysis of legal documents, and comparative case studies across different geographic regions and sectors. This multifaceted approach allows for a thorough exploration of the complexity of algorithmic bias and its regulation.ResultsWe identify five primary types of algorithmic bias: bias by algorithmic agents, discrimination based on feature selection, proxy discrimination, disparate impact, and targeted advertising. The analysis of the U.S. legal and regulatory framework reveals a landscape of principled regulations, preventive controls, consequential liability, self-regulation, and heteronomy regulation. A comparative perspective is also provided by examining the status of algorithmic fairness in the EU, Canada, Australia, and Asia.ConclusionReal-world impacts are demonstrated through case studies focusing on criminal risk assessments and hiring algorithms, illustrating the tangible effects of algorithmic discrimination. The paper concludes with recommendations for interdisciplinary research, proactive policy development, public awareness, and ongoing monitoring to promote fairness and accountability in algorithmic decision-making. As the use of AI and automated systems expands globally, this work highlights the importance of developing comprehensive, adaptive approaches to combat algorithmic discrimination and ensure the socially responsible deployment of these powerful technologies.",2024,10.3389/frai.2024.1320277
Intelligent weight prediction of cows based on semantic segmentation and back propagation neural network,"Accurate prediction of cattle weight is essential for enhancing the efficiency and sustainability of livestock management practices. However, conventional methods often involve labor-intensive procedures and lack instant and non-invasive solutions. This study proposed an intelligent weight prediction approach for cows based on semantic segmentation and Back Propagation (BP) neural network. The proposed semantic segmentation method leveraged a hybrid model which combined ResNet-101-D with the Squeeze-and-Excitation (SE) attention mechanism to obtain precise morphological features from cow images. The body size parameters and physical measurements were then used for training the regression-based machine learning models to estimate the weight of individual cattle. The comparative analysis methods revealed that the BP neural network achieved the best results with an MAE of 13.11 pounds and an RMSE of 22.73 pounds. By eliminating the need for physical contact, this approach not only improves animal welfare but also mitigates potential risks. The work addresses the specific needs of welfare farming and aims to promote animal welfare and advance the field of precision agriculture.",2024,10.3389/frai.2024.1299169
DeepHeartCT: A fully automatic artificial intelligence hybrid framework based on convolutional neural network and multi-atlas segmentation for multi-structure cardiac computed tomography angiography image segmentation,"Cardiac computed tomography angiography (CTA) is an emerging imaging modality for assessing coronary artery as well as various cardiovascular structures. Recently, deep learning (DL) methods have been successfully applied to many applications of medical image analysis including cardiac CTA structure segmentation. However, DL requires a large amounts of data and high-quality labels for training which can be burdensome to obtain due to its labor-intensive nature. In this study, we aim to develop a fully automatic artificial intelligence (AI) system, named DeepHeartCT, for accurate and rapid cardiac CTA segmentation based on DL. The proposed system was trained using a large clinical dataset with computer-generated labels to segment various cardiovascular structures including left and right ventricles (LV, RV), left and right atria (LA, RA), and LV myocardium (LVM). This new system was trained directly using high-quality computer labels generated from our previously developed multi-atlas based AI system. In addition, a reverse ranking strategy was proposed to assess the segmentation quality in the absence of manual reference labels. This strategy allowed the new framework to assemble optimal computer-generated labels from a large dataset for effective training of a deep convolutional neural network (CNN). A large clinical cardiac CTA studies (n = 1,064) were used to train and validate our framework. The trained model was then tested on another independent dataset with manual labels (n = 60). The Dice score, Hausdorff distance and mean surface distance were used to quantify the segmentation accuracy. The proposed DeepHeartCT framework yields a high median Dice score of 0.90 [interquartile range (IQR), 0.90–0.91], a low median Hausdorff distance of 7 mm (IQR, 4–15 mm) and a low mean surface distance of 0.80 mm (IQR, 0.57–1.29 mm) across all segmented structures. An additional experiment was conducted to evaluate the proposed DL-based AI framework trained with a small vs. large dataset. The results show our framework also performed well when trained on a small optimal training dataset (n = 110) with a significantly reduced training time. These results demonstrated that the proposed DeepHeartCT framework provides accurate and rapid cardiac CTA segmentation that can be readily generalized for handling large-scale medical imaging applications.",2022,10.3389/frai.2022.1059007
Supervised machine learning models for depression sentiment analysis,"IntroductionGlobally, the prevalence of mental health problems, especially depression, is at an all-time high. The objective of this study is to utilize machine learning models and sentiment analysis techniques to predict the level of depression earlier in social media users' posts.MethodsThe datasets used in this research were obtained from Twitter posts. Four machine learning models, namely extreme gradient boost (XGB) Classifier, Random Forest, Logistic Regression, and support vector machine (SVM), were employed for the prediction task.ResultsThe SVM and Logistic Regression models yielded the most accurate results when applied to the provided datasets. However, the Logistic Regression model exhibited a slightly higher level of accuracy compared to SVM. Importantly, the logistic regression model demonstrated the advantage of requiring less execution time.DiscussionThe findings of this study highlight the potential of utilizing machine learning models and sentiment analysis techniques for early detection of depression in social media users. The effectiveness of SVM and Logistic Regression models, with Logistic Regression being more efficient in terms of execution time, suggests their suitability for practical implementation in real-world scenarios.",2023,10.3389/frai.2023.1230649
Explainability as the key ingredient for AI adoption in Industry 5.0 settings,"Explainable Artificial Intelligence (XAI) has gained significant attention as a means to address the transparency and interpretability challenges posed by black box AI models. In the context of the manufacturing industry, where complex problems and decision-making processes are widespread, the XMANAI platform emerges as a solution to enable transparent and trustworthy collaboration between humans and machines. By leveraging advancements in XAI and catering the prompt collaboration between data scientists and domain experts, the platform enables the construction of interpretable AI models that offer high transparency without compromising performance. This paper introduces the approach to building the XMANAI platform and highlights its potential to resolve the “transparency paradox” of AI. The platform not only addresses technical challenges related to transparency but also caters to the specific needs of the manufacturing industry, including lifecycle management, security, and trusted sharing of AI assets. The paper provides an overview of the XMANAI platform main functionalities, addressing the challenges faced during the development and presenting the evaluation framework to measure the performance of the delivered XAI solutions. It also demonstrates the benefits of the XMANAI approach in achieving transparency in manufacturing decision-making, fostering trust and collaboration between humans and machines, improving operational efficiency, and optimizing business value.",2023,10.3389/frai.2023.1264372
Investigating generative AI models and detection techniques: impacts of tokenization and dataset size on identification of AI-generated text,"Generative AI models, including ChatGPT, Gemini, and Claude, are increasingly significant in enhancing K–12 education, offering support across various disciplines. These models provide sample answers for humanities prompts, solve mathematical equations, and brainstorm novel ideas. Despite their educational value, ethical concerns have emerged regarding their potential to mislead students into copying answers directly from AI when completing assignments, assessments, or research papers. Current detectors, such as GPT-Zero, struggle to identify modified AI-generated texts and show reduced reliability for English as a Second Language learners. This study investigates detection of academic cheating by use of generative AI in high-stakes writing assessments. Classical machine learning models, including logistic regression, XGBoost, and support vector machine, are used to distinguish between AI-generated and student-written essays. Additionally, large language models including BERT, RoBERTa, and Electra are examined and compared to traditional machine learning models. The analysis focuses on prompt 1 from the ASAP Kaggle competition. To evaluate the effectiveness of various detection methods and generative AI models, we include ChatGPT, Claude, and Gemini in their base, pro, and latest versions. Furthermore, we examine the impact of paraphrasing tools such as GPT-Humanizer and QuillBot and introduce a new method of using synonym information to detect humanized AI texts. Additionally, the relationship between dataset size and model performance is explored to inform data collection in future research.",2024,10.3389/frai.2024.1469197
Overview and commentary of the CDEI's extended roadmap to an effective AI assurance ecosystem,"In recent years, the field of ethical artificial intelligence (AI), or AI ethics, has gained traction and aims to develop guidelines and best practices for the responsible and ethical use of AI across sectors. As part of this, nations have proposed AI strategies, with the UK releasing both national AI and data strategies, as well as a transparency standard. Extending these efforts, the Centre for Data Ethics and Innovation (CDEI) has published an AI Assurance Roadmap, which is the first of its kind and provides guidance on how to manage the risks that come from the use of AI. In this article, we provide an overview of the document's vision for a “mature AI assurance ecosystem” and how the CDEI will work with other organizations for the development of regulation, industry standards, and the creation of AI assurance practitioners. We also provide a commentary of some key themes identified in the CDEI's roadmap in relation to (i) the complexities of building “justified trust”, (ii) the role of research in AI assurance, (iii) the current developments in the AI assurance industry, and (iv) convergence with international regulation.",2022,10.3389/frai.2022.932358
Considering Performance in the Automated and Manual Coding of Sociolinguistic Variables: Lessons From Variable (ING),"Impressionistic coding of sociolinguistic variables like English (ING), the alternation between pronunciations liketalkin'andtalking, has been a central part of the analytic workflow in studies of language variation and change for over a half-century. Techniques for automating the measurement and coding for a wide range of sociolinguistic data have been on the rise over recent decades but procedures for coding some features, especially those without clearly defined acoustic correlates like (ING), have lagged behind others, such as vowels and sibilants. This paper explores computational methods for automatically coding variable (ING) in speech recordings, examining the use of automatic speech recognition procedures related to forced alignment (using the Montreal Forced Aligner) as well as supervised machine learning algorithms (linear and radial support vector machines, and random forests). Considering the automated coding of pronunciation variables like (ING) raises broader questions for sociolinguistic methods, such as how much different human analysts agree in their impressionistic codes for such variables and what data might act as the “gold standard” for training and testing of automated procedures. This paper explores several of these considerations in automated, and manual, coding of sociolinguistic variables and provides baseline performance data for automated and manual coding methods. We consider multiple ways of assessing algorithms' performance, including agreement with human coders, as well as the impact on the outcome of an analysis of (ING) that includes linguistic and social factors. Our results show promise for automated coding methods but also highlight that variability in results should be expected even with careful human coded data. All data for our study come from the public Corpus of Regional African American Language and code and derivative datasets (including our hand-coded data) are available with the paper.",2021,10.3389/frai.2021.648543
Training neural networks with universal adiabatic quantum computing,"The training of neural networks (NNs) is a computationally intensive task requiring significant time and resources. This article presents a novel approach to NN training using adiabatic quantum computing (AQC), a paradigm that leverages the principles of adiabatic evolution to solve optimization problems. We propose a universal AQC method that can be implemented on gate quantum computers, allowing for a broad range of Hamiltonians and thus enabling the training of expressive neural networks. We apply this approach to various neural networks with continuous, discrete, and binary weights. The study results indicate that AQC can very efficiently evaluate the global minimum of the loss function, offering a promising alternative to classical training methods.",2024,10.3389/frai.2024.1368569
Developing and comparing deep learning and machine learning algorithms for osteoporosis risk prediction,"IntroductionOsteoporosis, characterized by low bone mineral density (BMD), is an increasingly serious public health issue. So far, several traditional regression models and machine learning (ML) algorithms have been proposed for predicting osteoporosis risk. However, these models have shown relatively low accuracy in clinical implementation. Recently proposed deep learning (DL) approaches, such as deep neural network (DNN), which can discover knowledge from complex hidden interactions, offer a new opportunity to improve predictive performance. In this study, we aimed to assess whether DNN can achieve a better performance in osteoporosis risk prediction.MethodsBy utilizing hip BMD and extensive demographic and routine clinical data of 8,134 subjects with age more than 40 from the Louisiana Osteoporosis Study (LOS), we developed and constructed a novel DNN framework for predicting osteoporosis risk and compared its performance in osteoporosis risk prediction with four conventional ML models, namely random forest (RF), artificial neural network (ANN), k-nearest neighbor (KNN), and support vector machine (SVM), as well as a traditional regression model termed osteoporosis self-assessment tool (OST). Model performance was assessed by area under ‘receiver operating curve’ (AUC) and accuracy.ResultsBy using 16 discriminative variables, we observed that the DNN approach achieved the best predictive performance (AUC = 0.848) in classifying osteoporosis (hip BMD T-score ≤ −1.0) and non-osteoporosis risk (hip BMD T-score &gt; −1.0) subjects, compared to the other approaches. Feature importance analysis showed that the top 10 most important variables identified by the DNN model were weight, age, gender, grip strength, height, beer drinking, diastolic pressure, alcohol drinking, smoke years, and economic level. Furthermore, we performed subsampling analysis to assess the effects of varying number of sample size and variables on the predictive performance of these tested models. Notably, we observed that the DNN model performed equally well (AUC = 0.846) even by utilizing only the top 10 most important variables for osteoporosis risk prediction. Meanwhile, the DNN model can still achieve a high predictive performance (AUC = 0.826) when sample size was reduced to 50% of the original dataset.ConclusionIn conclusion, we developed a novel DNN model which was considered to be an effective algorithm for early diagnosis and intervention of osteoporosis in the aging population.",2024,10.3389/frai.2024.1355287
Spectroscopy Approaches for Food Safety Applications: Improving Data Efficiency Using Active Learning and Semi-supervised Learning,"The past decade witnessed rapid development in the measurement and monitoring technologies for food science. Among these technologies, spectroscopy has been widely used for the analysis of food quality, safety, and nutritional properties. Due to the complexity of food systems and the lack of comprehensive predictive models, rapid and simple measurements to predict complex properties in food systems are largely missing. Machine Learning (ML) has shown great potential to improve the classification and prediction of these properties. However, the barriers to collecting large datasets for ML applications still persists. In this paper, we explore different approaches of data annotation and model training to improve data efficiency for ML applications. Specifically, we leverage Active Learning (AL) and Semi-Supervised Learning (SSL) and investigate four approaches: baseline passive learning, AL, SSL, and a hybrid of AL and SSL. To evaluate these approaches, we collect two spectroscopy datasets: predicting plasma dosage and detecting foodborne pathogen. Our experimental results show that, compared to the de facto passive learning approach, advanced approaches (AL, SSL, and the hybrid) can greatly reduce the number of labeled samples, with some cases decreasing the number of labeled samples by more than half.",2022,10.3389/frai.2022.863261
Infusing Expert Knowledge Into a Deep Neural Network Using Attention Mechanism for Personalized Learning Environments,"Machine learning models are biased toward data seen during the training steps. The models will tend to give good results in classes where there are many examples and poor results in those with few examples. This problem generally occurs when the classes to predict are imbalanced and this is frequent in educational data where for example, there are skills that are very difficult or very easy to master. There will be less data on students that correctly answered questions related to difficult skills and who incorrectly answered those related to skills easy to master. In this paper, we tackled this problem by proposing a hybrid architecture combining Deep Neural Network architectures— especially Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNN)—with expert knowledge for user modeling. The proposed solution uses attention mechanism to infuse expert knowledge into the Deep Neural Network. It has been tested in two contexts: knowledge tracing in an intelligent tutoring system (ITS) called Logic-Muse and prediction of socio-moral reasoning in a serious game called MorALERT. The proposed solution is compared to state-of-the-art machine learning solutions and experiments show that the resulting model can accurately predict the current student's knowledge state (in Logic-Muse) and thus enable an accurate personalization of the learning process. Other experiments show that the model can also be used to predict the level of socio-moral reasoning skills (in MorALERT). Our findings suggest the need for hybrid neural networks that integrate prior expert knowledge (especially when it is necessary to compensate for the strong dependency—of deep learning methods—on data size or the possible unbalanced datasets). Many domains can benefit from such an approach to building models that allow generalization even when there are small training data.",2022,10.3389/frai.2022.921476
Navigating AI ethics: ANN and ANFIS for transparent and accountable project evaluation amidst contesting AI practices and technologies,"IntroductionThe rapid evolution of Artificial Intelligence (AI) necessitates robust ethical frameworks to ensure responsible project deployment. This study addresses the challenge of quantifying ethical criteria in AI projects amidst contesting communicative practices, organizational structures, and enabling technologies, which shape AI’s societal implications.MethodsWe propose a novel framework integrating Artificial Neural Networks (ANN) and Adaptive Neuro-Fuzzy Inference Systems (ANFIS) to evaluate AI project performance and model ethical uncertainties using Fuzzy logic. A Fuzzy weighted average approach quantifies critical ethical dimensions: transparency, fairness, accountability, privacy, security, explainability, human involvement, and societal impact.ResultsThe framework enables a structured assessment of AI projects, enhancing transparency and accountability by mapping ethical criteria to project outcomes. ANN evaluates performance metrics, while ANFIS models uncertainties, providing a comprehensive ethical evaluation under complex conditions.DiscussionBy combining ANN and ANFIS, this study advances the understanding of AI’s ethical dimensions, offering a scalable approach for accountable AI systems. It reframes organizational communication and decision-making, embedding ethics within AI’s technological and structural contexts. This work contributes to responsible AI innovation, fostering trust and societal alignment in AI deployments.",2025,10.3389/frai.2025.1535845
Emotion Analysis of Arabic Tweets: Language Models and Available Resources,"One of the most popular social media platforms is Twitter. Emotion analysis and classification of tweets have become a significant research topic recently. The Arabic language faces challenges for emotion classification on Twitter, requiring more preprocessing than other languages. This article provides a practical overview and detailed description of a material that can help in developing an Arabic language model for emotion classification of Arabic tweets. An emotion classification of Arabic tweets using NLP, overall current practical practices, and available resources are highlighted to provide a guideline and overview sight to facilitate future studies. Finally, the article presents some challenges and issues that can be future research directions.",2022,10.3389/frai.2022.843038
Psychological assessment of AI-based decision support systems: tool development and expected benefits,"This study aimed to develop an evaluation tool that assesses the use of AI-based decision support systems (DSSs) in professional practice from a human-centered perspective. Following the International Organization for Standardization, this perspective aims to ensure that the use of interactive technologies improves users' psychological load experience and behavior, e.g., in the form of reduced stress experience or increased performance. Concomitantly, this perspective attempts to proactively prevent or detect and correct the potential negative effects of these technologies on user load, such as impaired satisfaction and engagement, as early as possible. Based on this perspective, we developed and validated a questionnaire instrument, the Psychological Assessment of AI-based DSSs (PAAI), for the user-centered evaluation of the use of AI-based DSSs in practice. In particular, the instrument considers central design characteristics of AI-based DSSs and the corresponding work situation, which have a significant impact on users' psychological load. The instrument was tested in two independent studies. In Study 1, N = 223 individuals were recruited. Based on the results of item and scale analyses and an exploratory factor analysis, the newly developed instrument was refined, and the final version was tested using a confirmatory factor analysis. Findings showed acceptable-to-good fit indices, confirming the factorial validity of the PAAI. This was confirmed in a second study, which had N = 471 participants. Again, the CFA yielded acceptable-to-good fit indices. The validity was further confirmed using convergent and criterion validity analyses.",2023,10.3389/frai.2023.1249322
Governing Ethical AI Transformation: A Case Study of AuroraAI,"How can the public sector use AI ethically and responsibly for the benefit of people? The sustainable development and deployment of artificial intelligence (AI) in the public sector requires dialogue and deliberation between developers, decision makers, deployers, end users, and the public. This paper contributes to the debate on how to develop persuasive government approaches for steering the development and use of AI. We examine the ethical issues and the role of the public in the debate on developing public sector governance of socially and democratically sustainable and technology-intensive societies. To concretize this discussion, we study the co-development of a Finnish national AI program AuroraAI, which aims to provide citizens with tailored and timely services for different life situations, utilizing AI. With the help of this case study, we investigate the challenges posed by the development and use of AI in the service of public administration. We draw particular attention to the efforts made by the AuroraAI Ethics Board in deliberating the AuroraAI solution options and working toward a sustainable and inclusive AI society.",2022,10.3389/frai.2022.836557
The potential of Logistics 4.0 technologies: a case study through business intelligence framing by applying the Delphi method,"IntroductionThe growing competitiveness and the importance of data availability for organizations have created a demand for intelligent information systems capable of analyzing data to support strategy and decision-making. Organizations are generating more and more data due to new technologies associated with Industry 4.0 and Logistics 4.0, making it essential to transform this data into relevant information to streamline decision-making processes. This paper examines the influence of these technologies on gaining a competitive advantage, specifically in a logistics company, which is scarce in the literature.MethodsA case study was conducted in a Portuguese company using the Delphi method with 61 participants—employees who use the company’s integrated BI tool daily. The participants were presented with a questionnaire via the online platform Welphi, requiring qualitative responses to various statements based on the literature review and the results of semi-structured meetings with the company.ResultsThe study aimed to identify areas where employees believe more investment/ development is needed to optimize processes and improve the use of the BI tool in the future. The results indicate that BI is a crucial technology when aligned with a company’s objectives and needs, highlighting the necessity of top management’s involvement in optimizing the BI tool. Encouraging employees to use the BI tool emerged as a significant factor, underscoring the importance of leadership in innovative projects to achieve greater competitive advantage for the company.DiscussionThis study aims to understand the importance of Business Intelligence (BI) and how its functionalities should be adapted according to a company’s strategy and objectives to optimize decision-making processes. Thereby, the discussion focused on the essential role of BI technologies in leveraging the company’s competitive advantage.",2024,10.3389/frai.2024.1469958
A comparative study of Arabic syntactic analyzers,"Syntactic analysis stands at the heart of Natural Language Processing (NLP), serving as the cornerstone upon which deeper linguistic understanding is built—particularly for morphologically complex languages such as Arabic. This paper delivers a comprehensive comparative study of contemporary syntactic analyzers designed explicitly for Arabic, dissecting the strengths and limitations of rule-based, statistical, machine learning, and hybrid methodologies, and recent neural network and transformer-based models. Given Arabic's intricate morphological structure and rich syntactic variation, accurately capturing syntactic relationships poses a significant challenge. To address this complexity, our study meticulously evaluates existing algorithms, highlighting advancements, performance gaps, and practical trade-offs. In addition, recognizing that robust syntactic parsing is anchored in high-quality annotated datasets, we provide a thorough overview of available Arabic treebanks and annotated corpora, emphasizing their critical role and contribution to syntactic parsing advancements. By synthesizing current efforts in the domain, this comparative analysis not only offers clarity on the state-of-the-art but also guides future research directions. Ultimately, our work seeks to empower NLP practitioners and researchers with nuanced insights, enabling more informed choices in the development of powerful, accurate, and linguistically insightful Arabic syntactic analyzers.",2025,10.3389/frai.2025.1638743
No silver bullet: interpretable ML models must be explained,"Recent years witnessed a number of proposals for the use of the so-called interpretable models in specific application domains. These include high-risk, but also safety-critical domains. In contrast, other works reported some pitfalls of machine learning model interpretability, in part justified by the lack of a rigorous definition of what an interpretable model should represent. This study proposes to relate interpretability with the ability of a model to offer explanations of why a prediction is made given some point in feature space. Under this general goal of offering explanations to predictions, this study reveals additional limitations of interpretable models. Concretely, this study considers application domains where the purpose is to help human decision makers to understand why some prediction was made or why was not some other prediction made, and where irreducible (and so minimal) information is sought. In such domains, this study argues that answers to such why (or why not) questions can exhibit arbitrary redundancy, i.e., the answers can be simplified, as long as these answers are obtained by human inspection of the interpretable ML model representation.",2023,10.3389/frai.2023.1128212
Metropolis-Hastings algorithm in joint-attention naming game: experimental semiotics study,"We explore the emergence of symbols during interactions between individuals through an experimental semiotic study. Previous studies have investigated how humans organize symbol systems through communication using artificially designed subjective experiments. In this study, we focused on a joint-attention-naming game (JA-NG) in which participants independently categorized objects and assigned names while assuming their joint attention. In the Metropolis-Hastings naming game (MHNG) theory, listeners accept provided names according to the acceptance probability computed using the Metropolis-Hastings (MH) algorithm. The MHNG theory suggests that symbols emerge as an approximate decentralized Bayesian inference of signs, which is represented as a shared prior variable if the conditions of the MHNG are satisfied. This study examines whether human participants exhibit behavior consistent with the MHNG theory when playing the JA-NG. By comparing human acceptance decisions of a partner's naming with acceptance probabilities computed in the MHNG, we tested whether human behavior is consistent with the MHNG theory. The main contributions of this study are twofold. First, we reject the null hypothesis that humans make acceptance judgments with a constant probability, regardless of the acceptance probability calculated by the MH algorithm. The results of this study show that the model with acceptance probability computed by the MH algorithm predicts human behavior significantly better than the model with a constant probability of acceptance. Second, the MH-based model predicted human acceptance/rejection behavior more accurately than four other models (i.e., Constant, Numerator, Subtraction, Binary). Among the models compared, the model using the MH algorithm, which is the only model with the mathematical support of decentralized Bayesian inference, predicted human behavior most accurately, suggesting that symbol emergence in the JA-NG can be explained by the MHNG.",2023,10.3389/frai.2023.1235231
Unsupervised learning and natural language processing highlight research trends in a superbug,"IntroductionAntibiotic-resistant Acinetobacter baumannii is a very important nosocomial pathogen worldwide. Thousands of studies have been conducted about this pathogen. However, there has not been any attempt to use all this information to highlight the research trends concerning this pathogen.MethodsHere we use unsupervised learning and natural language processing (NLP), two areas of Artificial Intelligence, to analyse the most extensive database of articles created (5,500+ articles, from 851 different journals, published over 3 decades).ResultsK-means clustering found 113 theme clusters and these were defined with representative terms automatically obtained with topic modelling, summarising different research areas. The biggest clusters, all with over 100 articles, are biased toward multidrug resistance, carbapenem resistance, clinical treatment, and nosocomial infections. However, we also found that some research areas, such as ecology and non-human infections, have received very little attention. This approach allowed us to study research themes over time unveiling those of recent interest, such as the use of Cefiderocol (a recently approved antibiotic) against A. baumannii.DiscussionIn a broader context, our results show that unsupervised learning, NLP and topic modelling can be used to describe and analyse the research themes for important infectious diseases. This strategy should be very useful to analyse other ESKAPE pathogens or any other pathogens relevant to Public Health.",2024,10.3389/frai.2024.1336071
Forecasting global monthly cotton prices: the superiority of NNAR models over traditional models,"Accurate forecasting of agricultural commodity prices is essential for informed decision-making by farmers, traders, and policymakers. This study evaluates and compares the predictive performance of traditional statistical and machine learning models in forecasting global monthly cotton prices. Price volatility and nonlinear patterns in cotton markets present challenges for conventional models such as the Auto Regressive Integrated Moving Average (ARIMA), which often fail to capture complex dynamics. The novelty of this research lies in systematically comparing traditional statistical models (ARIMA, ETS, STL, TBATS, Theta), machine learning models (Neural Network Auto-Regressive [NNAR]), and hybrid approaches to determine the best forecasting tool. Performance was evaluated using Root Mean Square Error (RMSE), Mean Error (ME), Mean Absolute Error (MAE), Mean Percentage Error (MPE), and Mean Absolute Percentage Error (MAPE). Results revealed that the NNAR (26, 1, 14) [12] model outperformed all models, achieving the lowest RMSE (1.16383774), MAE (0.832275572), and MAPE (1.19%), indicating high predictive accuracy and minimal bias. The 30-month forecast for cotton prices using the NNAR model indicates fluctuations between approximately $0.66 and $0.74 per pound, following a cyclical pattern without a clear long-term trend. These findings highlight the strength of advanced machine learning techniques, particularly NNAR, in capturing complex nonlinear patterns, improving forecasting reliability, and supporting effective decision-making in volatile cotton markets. This study provides practical insights for stakeholders seeking to anticipate cotton price changes and make informed decisions in the global market.",2025,10.3389/frai.2025.1628744
The impact of text topic and assumed human vs. AI authorship on competence and quality assessment,"BackgroundWhile Large Language Models (LLMs) are considered positively with respect to technological progress and abilities, people are rather opposed to machines making moral decisions. But the circumstances under which algorithm aversion or algorithm appreciation are more likely to occur with respect to LLMs have not yet been sufficiently investigated. Therefore, the aim of this study was to investigate how texts with moral or technological topics, allegedly written either by a human author or by ChatGPT, are perceived.MethodsIn a randomized controlled experiment, n = 164 participants read six texts, three of which had a moral and three a technological topic (predictor text topic). The alleged author of each text was randomly either labeled “ChatGPT” or “human author” (predictor authorship). We captured three dependent variables: assessment of author competence, assessment of content quality, and participants' intention to submit the text in a hypothetical university course (sharing intention). We hypothesized interaction effects, that is, we expected ChatGPT to score lower than alleged human authors for moral topics and higher than alleged human authors for technological topics and vice versa.ResultsWe only found a small interaction effect for perceived author competence, p = 0.004, d = 0.40, but not for the other dependent variables. However, ChatGPT was consistently devalued compared to alleged human authors across all dependent variables: there were main effects of authorship for assessment of the author competence, p &lt; 0.001, d = 0.95; for assessment of content quality, p &lt; 0.001, d = 0.39; as well as for sharing intention, p &lt; 0.001, d = 0.57. There was also a small main effect of text topic on the assessment of text quality, p = 0.002, d = 0.35.ConclusionThese results are more in line with previous findings on algorithm aversion than with algorithm appreciation. We discuss the implications of these findings for the acceptance of the use of LLMs for text composition.",2024,10.3389/frai.2024.1412710
Application of hybrid fuzzy interval-based machine learning models on financial time series — A case study of Taiwan biotech index during the epidemic period,"In recent years, the use of machine learning to predict stock market indices has emerged as a vital concern in the FinTech domain. However, the inherent nature of point estimation in traditional supervised machine learning models leads to an almost negligible probability of achieving perfect predictions, significantly constraining the applicability of machine learning prediction models. This study employs 4 machine learning models, namely BPN, LSTM, RF, and ELM, to establish predictive models for the Taiwan biotech index during the COVID-19 period. Additionally, it integrates the Gaussian membership function MF from fuzzy theory to develop 4 hybrid fuzzy interval-based machine learning models, evaluating their predictive accuracy through empirical analysis and comparing them with conventional point estimation models. The empirical data is sourced from the financial time series of the “M1722 Listed Biotechnology and Medical Care Index” compiled by the Taiwan Economic Journal during the outbreak of the COVID-19 pandemic, aiming to understand the effectiveness of machine learning models in the face of significant disruptive factors like the pandemic. The findings demonstrate that despite the influence of COVID-19, machine learning remains effective. LSTM performs the best among the models, both in traditional mode and after fuzzy interval enhancement, followed by the ELM and RF models. The predictive results of these three models reach a certain level of accuracy and all outperform the BPN model. Fuzzy-LSTM effectively predicts at a 68% confidence level, while Fuzzy-ELM and Fuzzy-RF yield better results at a 95% confidence level. Fuzzy-BPN exhibits the lowest predictive accuracy. Overall, the fuzzy interval-based LSTM excels in time series prediction, suggesting its potential application in forecasting time series data in financial markets to enhance the efficacy of investment analysis for investors.",2024,10.3389/frai.2023.1283741
Enhancing one-year mortality prediction in STEMI patients post-PCI: an interpretable machine learning model with risk stratification,"BackgroundST-elevation myocardial infarction (STEMI) poses a significant threat to global mortality and disability. Advances in percutaneous coronary intervention (PCI) have reduced in-hospital mortality, highlighting the importance of post-discharge management. Machine learning (ML) models have shown promise in predicting adverse clinical outcomes. However, a systematic approach that combines high predictive accuracy with model simplicity is still lacking.MethodsThis retrospective study applied three data processing and ML algorithms to address class imbalance and support model development. ML models were trained to predict one-year mortality in STEMI patients post-PCI, with performance evaluated using accuracy, sensitivity, precision, F1-score, area under the receiver operating characteristic curve (AUROC), and the area under the precision-recall curve (AUPRC).ResultsWe analyzed data from 1,274 patients, incorporating 46 clinical and laboratory features. Using the Random Forest (RF) algorithm, we achieved an AUROC of 0.94 (95% confidence interval (CI): 0.90–0.98), an AUPRC of 0.44 (95% CI:0.15–0.76) in the internal validation set, identifying five key predictors: cardiogenic shock, creatinine, NT-proBNP, diastolic blood pressure, and left ventricular ejection fraction. By integrating risk stratification, the model’s performance improved, achieving an AUROC of 0.97 (95% CI: 0.96–0.99) and an AUPRC of 0.74 (95% CI: 0.60–0.84).ConclusionThis study highlights the feasibility of constructing accurate and interpretable ML models using a minimal set of predictors, supplemented by risk stratification, to improve long-term outcome prediction in STEMI patients.",2025,10.3389/frai.2025.1618492
Collocations in Parsing and Translation,"Proper identification of collocations (and more generally of multiword expressions (MWEs), is an important qualitative step for several NLP applications and particularly so for translation. Since many MWEs cannot be translated literally, failure to identify them yields at best inaccurate translation. This paper is mostly be concerned with collocations. We will show how they differ from other types of MWEs and how they can be successfully parsed and translated by means of a grammar-based parser and translator.",2022,10.3389/frai.2022.765695
Classification of elderly pain severity from automated video clip facial action unit analysis: A study from a Thai data repository,"Data from 255 Thais with chronic pain were collected at Chiang Mai Medical School Hospital. After the patients self-rated their level of pain, a smartphone camera was used to capture faces for 10 s at a one-meter distance. For those unable to self-rate, a video recording was taken immediately after the move that causes the pain. The trained assistant rated each video clip for the pain assessment in advanced dementia (PAINAD). The pain was classified into three levels: mild, moderate, and severe. OpenFace© was used to convert the video clips into 18 facial action units (FAUs). Five classification models were used, including logistic regression, multilayer perception, naïve Bayes, decision tree, k-nearest neighbors (KNN), and support vector machine (SVM). Out of the models that only used FAU described in the literature (FAU 4, 6, 7, 9, 10, 25, 26, 27, and 45), multilayer perception is the most accurate, at 50%. The SVM model using FAU 1, 2, 4, 7, 9, 10, 12, 20, 25, and 45, and gender had the best accuracy of 58% among the machine learning selection features. Our open-source experiment for automatically analyzing video clips for FAUs is not robust for classifying pain in the elderly. The consensus method to transform facial recognition algorithm values comparable to the human ratings, and international good practice for reciprocal sharing of data may improve the accuracy and feasibility of the machine learning's facial pain rater.",2022,10.3389/frai.2022.942248
Creating a list of word alignments from parallel Russian simplification data,"This work describes the development of a list of monolingual word alignments taken from parallel Russian simplification data. This word lists can be used in such lexical simplification tasks as rule-based simplification applications and lexically constrained decoding for neural machine translation models. Moreover, they constitute a valuable source of information for developing educational materials for teaching Russian as a second/foreign language. In this work, a word list was compiled automatically and post-edited by human experts. The resulting list contains 1409 word pairs in which each “complex” word has an equivalent “simpler” (shorter, more frequent, modern, international) synonym. We studied the contents of the word list by comparing the frequencies of the words in the pairs and their levels in the special CEFR-graded vocabulary lists for learners of Russian as a foreign language. The evaluation demonstrated that lexical simplification by means of single-word synonym replacement does not occur often in the adapted texts. The resulting list also illustrates the peculiarities of the lexical simplification task for L2 learners, such as the choice of a less frequent but international word.",2022,10.3389/frai.2022.984759
Detecting and identifying the reasons for deleted tweets before they are posted,"Social media platforms empower us in several ways, from information dissemination to consumption. While these platforms are useful in promoting citizen journalism, public awareness, etc., they have misuse potential. Malicious users use them to disseminate hate speech, offensive content, rumor, etc. to promote social and political agendas or to harm individuals, entities, and organizations. Oftentimes, general users unconsciously share information without verifying it or unintentionally post harmful messages. Some of such content often gets deleted either by the platform due to the violation of terms and policies or by users themselves for different reasons, e.g., regret. There is a wide range of studies in characterizing, understanding, and predicting deleted content. However, studies that aim to identify the fine-grained reasons (e.g., posts are offensive, hate speech, or no identifiable reason) behind deleted content are limited. In this study, we address an existing gap by identifying and categorizing deleted tweets, especially within the Arabic context. We label them based on fine-grained disinformation categories. We have curated a dataset of 40K tweets, annotated with both coarse and fine-grained labels. Following this, we designed models to predict the likelihood of tweets being deleted and to identify the potential reasons for their deletion. Our experiments, conducted using a variety of classic and transformer models, indicate that performance surpasses the majority baseline (e.g., 25% absolute improvement for fine-grained labels). We believe that such models can assist in moderating social media posts even before they are published.",2023,10.3389/frai.2023.1219767
Reliable and Interpretable Mortality Prediction With Strong Foresight in COVID-19 Patients: An International Study From China and Germany,"Cohort-independent robust mortality prediction model in patients with COVID-19 infection is not yet established. To build up a reliable, interpretable mortality prediction model with strong foresight, we have performed an international, bi-institutional study from China (Wuhan cohort, collected from January to March) and Germany (Würzburg cohort, collected from March to September). A Random Forest-based machine learning approach was applied to 1,352 patients from the Wuhan cohort, generating a mortality prediction model based on their clinical features. The results showed that five clinical features at admission, including lymphocyte (%), neutrophil count, C-reactive protein, lactate dehydrogenase, and α-hydroxybutyrate dehydrogenase, could be used for mortality prediction of COVID-19 patients with more than 91% accuracy and 99% AUC. Additionally, the time-series analysis revealed that the predictive model based on these clinical features is very robust over time when patients are in the hospital, indicating the strong association of these five clinical features with the progression of treatment as well. Moreover, for different preexisting diseases, this model also demonstrated high predictive power. Finally, the mortality prediction model has been applied to the independent Würzburg cohort, resulting in high prediction accuracy (with above 90% accuracy and 85% AUC) as well, indicating the robustness of the model in different cohorts. In summary, this study has established the mortality prediction model that allowed early classification of COVID-19 patients, not only at admission but also along the treatment timeline, not only cohort-independent but also highly interpretable. This model represents a valuable tool for triaging and optimizing the resources in COVID-19 patients.",2021,10.3389/frai.2021.672050
ROA: A Rapid Learning Scheme for In-Situ Memristor Networks,"Memristors show great promise in neuromorphic computing owing to their high-density integration, fast computing and low-energy consumption. However, the non-ideal update of synaptic weight in memristor devices, including nonlinearity, asymmetry and device variation, still poses challenges to thein-situlearning of memristors, thereby limiting their broad applications. Although the existing offline learning schemes can avoid this problem by transferring the weight optimization process into cloud, it is difficult to adapt to unseen tasks and uncertain environments. Here, we propose a bi-level meta-learning scheme that can alleviate the non-ideal update problem, and achieve fast adaptation and high accuracy, named Rapid One-step Adaption (ROA). By introducing a special regularization constraint and a dynamic learning rate strategy forin-situlearning, the ROA method effectively combines offline pre-training and online rapid one-step adaption. Furthermore, we implemented it on memristor-based neural networks to solve few-shot learning tasks, proving its superiority over the pure offline and online schemes under noisy conditions. This method can solvein-situlearning in non-ideal memristor networks, providing potential applications of on-chip neuromorphic learning and edge computing.",2021,10.3389/frai.2021.692065
Making sense of transformer success,"This article provides an epistemological analysis of current attempts of explaining how the relatively simple algorithmic components of neural language models (NLMs) provide them with genuine linguistic competence. After introducing the Transformer architecture, at the basis of most of current NLMs, the paper firstly emphasizes how the central question in the philosophy of AI has been shifted from “can machines think?”, as originally put by Alan Turing, to “how can machines think?”, pointing to an explanatory gap for NLMs. Subsequently, existing explanatory strategies for the functioning of NLMs are analyzed to argue that they, however debated, do not differ from the explanatory strategies used in cognitive science to explain intelligent behaviors of humans. In particular, available experimental studies turned to test the theory of mind, discourse entity tracking, and property induction in NLMs are examined under the light of the functional analysis in the philosophy of cognitive science; the so-called copying algorithm and the induction head phenomenon of a Transformer are shown to provide a mechanist explanation of in-context learning; finally, current pioneering attempts to use NLMs to predict brain activation patterns when processing language are here shown to involve what we call a co-simulation, in which a NLM and the brain are used to simulate and understand each other.",2025,10.3389/frai.2025.1509338
Contestable AI for criminal intelligence analysis: improving decision-making through semantic modeling and human oversight,"Criminal investigation analysis involves processing large amounts of data, making manual analysis impractical. Artificial intelligence (AI)-driven information extraction systems can assist investigators in handling this data, leading to significant improvements in effectiveness and efficiency. However, the use of AI in criminal investigations also poses significant risks to individuals, requiring the integration of contestability into systems and processes. To meet this challenge, contestability requirements must be tailored to specific contexts. In this work, we analyzed and adapted existing requirements for criminal investigation analysis, focusing on the retrospective analysis of police reports. For this purpose, we introduced a novel information extraction pipeline based on three language modeling tasks, which we refer to as semantic modeling. Building on this concept, we evaluated contestability requirements and integrated them into our system. As a proof of concept, we developed an AI-driven information extraction system that incorporates contestability features and provides multiple functionalities for data analysis. Our findings highlight three key perspectives essential for contestability in AI-driven investigations: information provision, interactive controls, and quality assurance. This work contributes to the development of more transparent, accountable, and adaptable AI systems for law enforcement applications.",2025,10.3389/frai.2025.1602998
"Predictive Modelling of Susceptibility to Substance Abuse, Mortality and Drug-Drug Interactions in Opioid Patients","Objective: Opioids are a class of drugs that are known for their use as pain relievers. They bind to opioid receptors on nerve cells in the brain and the nervous system to mitigate pain. Addiction is one of the chronic and primary adverse events of prolonged usage of opioids. They may also cause psychological disorders, muscle pain, depression, anxiety attacks etc. In this study, we present a collection of predictive models to identify patients at risk of opioid abuse and mortality by using their prescription histories. Also, we discover particularly threatening drug-drug interactions in the context of opioid usage.Methods and Materials: Using a publicly available dataset from MIMIC-III, two models were trained, Logistic Regression with L2 regularization (baseline) and Extreme Gradient Boosting (enhanced model), to classify the patients of interest into two categories based on their susceptibility to opioid abuse. We’ve also used K-Means clustering, an unsupervised algorithm, to explore drug-drug interactions that might be of concern.Results: The baseline model for classifying patients susceptible to opioid abuse has an F1 score of 76.64% (accuracy 77.16%) while the enhanced model has an F1 score of 94.45% (accuracy 94.35%). These models can be used as a preliminary step towards inferring the causal effect of opioid usage and can help monitor the prescription practices to minimize the opioid abuse.Discussion and Conclusion: Results suggest that the enhanced model provides a promising approach in preemptive identification of patients at risk for opioid abuse. By discovering and correlating the patterns contributing to opioid overdose or abuse among a variety of patients, machine learning models can be used as an efficient tool to help uncover the existing gaps and/or fraudulent practices in prescription writing. To quote an example of one such incidental finding, our study discovered that insulin might possibly be interacting with opioids in an unfavourable way leading to complications in diabetic patients. This indicates that diabetic patients under long term opioid usage might need to take increased amounts of insulin to make it more effective. This observation backs up prior research studies done on a similar aspect. To increase the translational value of our work, the predictive models and the associated software code are made available under the MIT License.",2021,10.3389/frai.2021.742723
Food/Non-Food Classification of Real-Life Egocentric Images in Low- and Middle-Income Countries Based on Image Tagging Features,"Malnutrition, including both undernutrition and obesity, is a significant problem in low- and middle-income countries (LMICs). In order to study malnutrition and develop effective intervention strategies, it is crucial to evaluate nutritional status in LMICs at the individual, household, and community levels. In a multinational research project supported by the Bill &amp; Melinda Gates Foundation, we have been using a wearable technology to conduct objective dietary assessment in sub-Saharan Africa. Our assessment includes multiple diet-related activities in urban and rural families, including food sources (e.g., shopping, harvesting, and gathering), preservation/storage, preparation, cooking, and consumption (e.g., portion size and nutrition analysis). Our wearable device (“eButton” worn on the chest) acquires real-life images automatically during wake hours at preset time intervals. The recorded images, in amounts of tens of thousands per day, are post-processed to obtain the information of interest. Although we expect future Artificial Intelligence (AI) technology to extract the information automatically, at present we utilize AI to separate the acquired images into two binary classes: images with (Class 1) and without (Class 0) edible items. As a result, researchers need only to study Class-1 images, reducing their workload significantly. In this paper, we present a composite machine learning method to perform this classification, meeting the specific challenges of high complexity and diversity in the real-world LMIC data. Our method consists of a deep neural network (DNN) and a shallow learning network (SLN) connected by a novel probabilistic network interface layer. After presenting the details of our method, an image dataset acquired from Ghana is utilized to train and evaluate the machine learning system. Our comparative experiment indicates that the new composite method performs better than the conventional deep learning method assessed by integrated measures of sensitivity, specificity, and burden index, as indicated by the Receiver Operating Characteristic (ROC) curve.",2021,10.3389/frai.2021.644712
Bibliometric analysis for artificial intelligence in the internet of medical things: mapping and performance analysis,"The development of computer technology has revolutionized how people live and interact in society. The Internet of Things (IoT) has enabled the development of the Internet of Medical Things (IoMT) to transform healthcare delivery. Artificial intelligence has been used to improve the IoMT. Despite the significance of bibliometric analysis in a research area, to the best of the authors' knowledge, based on searches conducted in academic databases, no bibliometric analysis on artificial intelligence (AI) for the IoMT has been conducted. To address this gap, this study proposes performing a comprehensive bibliometric analysis of AI applications in the IoMT. A bibliometric analysis of top literature sources, main disciplines, countries, prolific authors, trending topics, authorship, citations, author-keywords, and co-keywords was conducted. In addition, the structural development of AI in the IoMT highlights its growing popularity. This study found that security and privacy issues are serious concerns hindering the massive adoption of the IoMT. Future research directions on the IoMT, including perspectives on artificial general intelligence, generative artificial intelligence, and explainable artificial intelligence, have been outlined and discussed.",2024,10.3389/frai.2024.1347815
Artificial intelligence adoption and corporate ESG performance: evidence from a refined large language model,"Introduction
                    The convergence of artificial intelligence (AI) and Environmental, Social, and Governance (ESG) objectives has attracted growing academic and policy interest but remains empirically underexplored due to challenges in accurately measuring firm-level AI adoption.
                  
                  
                    Methods
                    This study refines the LLM-based framework by employing a domain-adapted model (Qwen2.5-72B) and a granular classification scheme to distinguish genuine “Applied” AI technologies from rhetorical mentions in corporate disclosures. Using data from Chinese A-share listed firms between 2009 and 2022, we construct a credible indicator of AI adoption and examine its impact on ESG performance.
                  
                  
                    Results and discussion
                    The results reveal a robust positive relationship between AI adoption and ESG outcomes, primarily driven by enhanced green innovation and improved internal control quality. These effects are more pronounced among large and technology-intensive firms. Consistent with the Resource-Based View and the Technology–Organization–Environment framework, our findings underscore the importance of complementary assets and absorptive capacity in realizing the sustainability potential of AI. This study provides credible evidence on how and for whom AI fosters corporate sustainability, introduces a transparent approach to measuring authentic technology adoption, and highlights the emerging “digital ESG divide” with implications for targeted policy interventions.",2025,10.3389/frai.2025.1691468
Computational Modeling of Stereotype Content in Text,"Stereotypes are encountered every day, in interpersonal communication as well as in entertainment, news stories, and on social media. In this study, we present a computational method to mine large, naturally occurring datasets of text for sentences that express perceptions of a social group of interest, and then map these sentences to the two-dimensional plane of perceivedwarmthandcompetencefor comparison and interpretation. This framework is grounded in established social psychological theory, and validated against both expert annotation and crowd-sourced stereotype data. Additionally, we present two case studies of how the model might be used to answer questions using data “in-the-wild,” by collecting Twitter data about women and older adults. Using the data about women, we are able to observe how sub-categories of women (e.g., Black women and white women) are described similarly and differently from each other, and from the superordinate group of women in general. Using the data about older adults, we show evidence that the terms people use to label a group (e.g., old people vs. senior citizens) are associated with different stereotype content. We propose that this model can be used by other researchers to explore questions of how stereotypes are expressed in various large text corpora.",2022,10.3389/frai.2022.826207
A Unifying Framework for Reinforcement Learning and Planning,"Sequential decision making, commonly formalized as optimization of a Markov Decision Process, is a key challenge in artificial intelligence. Two successful approaches to MDP optimization arereinforcement learningandplanning, which both largely have their own research communities. However, if both research fields solve the same problem, then we might be able to disentangle the common factors in their solution approaches. Therefore, this paper presents a unifying algorithmic framework for reinforcement learning and planning (FRAP), which identifies underlying dimensions on which MDP planning and learning algorithms have to decide. At the end of the paper, we compare a variety of well-known planning, model-free and model-based RL algorithms along these dimensions. Altogether, the framework may help provide deeper insight in the algorithmic design space of planning and reinforcement learning.",2022,10.3389/frai.2022.908353
Stacked ensemble deep learning for pancreas cancer classification using extreme gradient boosting,"Ensemble learning aims to improve prediction performance by combining several models or forecasts. However, how much and which ensemble learning techniques are useful in deep learning-based pipelines for pancreas computed tomography (CT) image classification is a challenge. Ensemble approaches are the most advanced solution to many machine learning problems. These techniques entail training multiple models and combining their predictions to improve the predictive performance of a single model. This article introduces the idea of Stacked Ensemble Deep Learning (SEDL), a pipeline for classifying pancreas CT medical images. The weak learners are Inception V3, VGG16, and ResNet34, and we employed a stacking ensemble. By combining the first-level predictions, an input train set for XGBoost, the ensemble model at the second level of prediction, is created. Extreme Gradient Boosting (XGBoost), employed as a strong learner, will make the final classification. Our findings showed that SEDL performed better, with a 98.8% ensemble accuracy, after some adjustments to the hyperparameters. The Cancer Imaging Archive (TCIA) public access dataset consists of 80 pancreas CT scans with a resolution of 512 * 512 pixels, from 53 male and 27 female subjects. A sample of two hundred and twenty-two images was used for training and testing data. We concluded that implementing the SEDL technique is an effective way to strengthen the robustness and increase the performance of the pipeline for classifying pancreas CT medical images. Interestingly, grouping like-minded or talented learners does not make a difference.",2023,10.3389/frai.2023.1232640
Domain Adaptation Using Convolutional Autoencoder and Gradient Boosting for Adverse Events Prediction in the Intensive Care Unit,"More than 5 million patients have admitted annually to intensive care units (ICUs) in the United States. The leading causes of mortality are cardiovascular failures, multi-organ failures, and sepsis. Data-driven techniques have been used in the analysis of patient data to predict adverse events, such as ICU mortality and ICU readmission. These models often make use of temporal or static features from a single ICU database to make predictions on subsequent adverse events. To explore the potential of domain adaptation, we propose a method of data analysis using gradient boosting and convolutional autoencoder (CAE) to predict significant adverse events in the ICU, such as ICU mortality and ICU readmission. We demonstrate our results from a retrospective data analysis using patient records from a publicly available database called Multi-parameter Intelligent Monitoring in Intensive Care-II (MIMIC-II) and a local database from Children's Healthcare of Atlanta (CHOA). We demonstrate that after adopting novel data imputation on patient ICU data, gradient boosting is effective in both the mortality prediction task and the ICU readmission prediction task. In addition, we use gradient boosting to identify top-ranking temporal and non-temporal features in both prediction tasks. We discuss the relationship between these features and the specific prediction task. Lastly, we indicate that CAE might not be effective in feature extraction on one dataset, but domain adaptation with CAE feature extraction across two datasets shows promising results.",2022,10.3389/frai.2022.640926
A systematic review of Machine Learning and Deep Learning approaches in Mexico: challenges and opportunities,"This systematic review provides a state-of-art of Artificial Intelligence (AI) models such as Machine Learning (ML) and Deep Learning (DL) development and its applications in Mexico in diverse fields. These models are recognized as powerful tools in many fields due to their capability to carry out several tasks such as forecasting, image classification, recognition, natural language processing, machine translation, etc. This review article aimed to provide comprehensive information on the Machine Learning and Deep Learning algorithms applied in Mexico. A total of 120 original research papers were included and details such as trends in publication, spatial location, institutions, publishing issues, subject areas, algorithms applied, and performance metrics were discussed. Furthermore, future directions and opportunities are presented. A total of 15 subject areas were identified, where Social Sciences and Medicine were the main application areas. It observed that Artificial Neural Networks (ANN) models were preferred, probably due to their capability to learn and model non-linear and complex relationships in addition to other popular models such as Random Forest (RF) and Support Vector Machines (SVM). It identified that the selection and application of the algorithms rely on the study objective and the data patterns. Regarding the performance metrics applied, accuracy and recall were the most employed. This paper could assist the readers in understanding the several Machine Learning and Deep Learning techniques used and their subject area of application in the Artificial Intelligence field in the country. Moreover, the study could provide significant knowledge in the development and implementation of a national AI strategy, according to country needs.",2025,10.3389/frai.2024.1479855
Hate speech detection with ADHAR: a multi-dialectal hate speech corpus in Arabic,"Hate speech detection in Arabic poses a complex challenge due to the dialectal diversity across the Arab world. Most existing hate speech datasets for Arabic cover only one dialect or one hate speech category. They also lack balance across dialects, topics, and hate/non-hate classes. In this paper, we address this gap by presenting ADHAR—a comprehensive multi-dialect, multi-category hate speech corpus for Arabic. ADHAR contains 70,369 words and spans four language variants: Modern Standard Arabic (MSA), Egyptian, Levantine, Gulf and Maghrebi. It covers four key hate speech categories: nationality, religion, ethnicity, and race. A major contribution is that ADHAR is carefully curated to maintain balance across dialects, categories, and hate/non-hate classes to enable unbiased dataset evaluation. We describe the systematic data collection methodology, followed by a rigorous annotation process involving multiple annotators per dialect. Extensive qualitative and quantitative analyses demonstrate the quality and usefulness of ADHAR. Our experiments with various classical and deep learning models demonstrate that our dataset enables the development of robust hate speech classifiers for Arabic, achieving accuracy and F1-scores of up to 90% for hate speech detection and up to 92% for category detection. When trained with Arabert, we achieved an accuracy and F1-score of 94% for hate speech detection, as well as 95% for the category detection.",2024,10.3389/frai.2024.1391472
Countering AI-powered disinformation through national regulation: learning from the case of Ukraine,"Advances in the use of AI have led to the emergence of a greater variety of forms disinformation can take and channels for its proliferation. In this context, the future of legal mechanisms to address AI-powered disinformation remains to be determined. Additional complexity for legislators working in the field arises from the need to harmonize national legal frameworks of democratic states with the need for regulation of potentially dangerous digital content. In this paper, we review and analyze some of the recent discussions concerning the use of legal regulation in addressing AI-powered disinformation and present the national case of Ukraine as an example of developments in the field. We develop the discussion through an analysis of the existing counter-disinformation ecosystems, the EU and US legislation, and the emerging regulations of AI systems. We show how the Ukrainian Law on Counter Disinformation, developed as an emergency response to internationally recognized Russian military aggression and hybrid warfare tactics, underscores the crucial need to align even emergency measures with international law and principles of free speech. Exemplifying the Ukrainian case, we argue that the effective actions necessary for countering AI-powered disinformation are prevention, detection, and implementation of a set of response actions. The latter are identified and listed in this review. The paper argues that there is still a need for scaling legal mechanisms that might enhance top-level challenges in countering AI-powered disinformation.",2025,10.3389/frai.2024.1474034
Persuasive Apps for Sustainable Waste Management: A Comparative Systematic Evaluation of Behavior Change Strategies and State-of-the-Art,"With the proliferation of ubiquitous computing and mobile technologies, mobile apps are tailored to support users to perform target behaviors in various domains, including a sustainable future. This article provides a systematic evaluation of mobile apps for sustainable waste management to deconstruct and compare the persuasive strategies employed and their implementations. Specifically, it targeted apps that support various sustainable waste management activities such as personal tracking, recycling, conference management, data collection, food waste management, do-it-yourself (DIY) projects, games, etc. The authors who are persuasive technology researchers retrieved a total of 244 apps from App Store and Google Play, out of which 148 apps were evaluated. Two researchers independently analyzed and coded the apps and a third researcher was involved to resolve any disagreement. They coded the apps based on the persuasive strategies of the persuasive system design framework. Overall, the findings uncover that out of the 148 sustainable waste management apps evaluated, primary task support was the most employed category by 89% (n = 131) apps, followed by system credibility support implemented by 76% (n = 112) apps. The dialogue support was implemented by 71% (n = 105) apps and social support was the least utilized strategy by 34% (n = 51) apps. Specifically, Reduction (n = 97), personalization (n = 90), real-world feel (n = 83), surface credibility (n = 83), reminder (n = 73), and self-monitoring (n = 50) were the most commonly employed persuasive strategies. The findings established that there is a significant association between the number of persuasive strategies employed and the apps’ effectiveness as indicated by user ratings of the apps. How the apps are implemented differs depending on the kind of sustainable waste management activities it was developed for. Based on the findings, this paper offers design implications for personalizing sustainable waste management apps to improve their persuasiveness and effectiveness.",2021,10.3389/frai.2021.748454
Enhancing portfolio management using artificial intelligence: literature review,"Building an investment portfolio is a problem that numerous researchers have addressed for many years. The key goal has always been to balance risk and reward by optimally allocating assets such as stocks, bonds, and cash. In general, the portfolio management process is based on three steps: planning, execution, and feedback, each of which has its objectives and methods to be employed. Starting from Markowitz's mean-variance portfolio theory, different frameworks have been widely accepted, which considerably renewed how asset allocation is being solved. Recent advances in artificial intelligence provide methodological and technological capabilities to solve highly complex problems, and investment portfolio is no exception. For this reason, the paper reviews the current state-of-the-art approaches by answering the core question of how artificial intelligence is transforming portfolio management steps. Moreover, as the use of artificial intelligence in finance is challenged by transparency, fairness and explainability requirements, the case study of post-hoc explanations for asset allocation is demonstrated. Finally, we discuss recent regulatory developments in the European investment business and highlight specific aspects of this business where explainable artificial intelligence could advance transparency of the investment process.",2024,10.3389/frai.2024.1371502
Targeting resources efficiently and justifiably by combining causal machine learning and theory,"IntroductionEfficient allocation of limited resources relies on accurate estimates of potential incremental benefits for each candidate. These heterogeneous treatment effects (HTE) can be estimated with properly specified theory-driven models and observational data that contain all confounders. Using causal machine learning to estimate HTE from big data offers higher benefits with limited resources by identifying additional heterogeneity dimensions and fitting arbitrary functional forms and interactions, but decisions based on black-box models are not justifiable.MethodsOur solution is designed to increase resource allocation efficiency, enhance the understanding of the treatment effects, and increase the acceptance of the resulting decisions with a rationale that is in line with existing theory. The case study identifies the right individuals to incentivize for increasing their physical activity to maximize the population's health benefits due to reduced diabetes and heart disease prevalence. We leverage large-scale data from multi-wave nationally representative health surveys and theory from the published global meta-analysis results. We train causal machine learning ensembles, extract the heterogeneity dimensions of the treatment effect, sign, and monotonicity of its moderators with explainable AI, and incorporate them into the theory-driven model with our generalized linear model with the qualitative constraint (GLM_QC) method.ResultsThe results show that the proposed methodology improves the expected health benefits for diabetes by 11% and for heart disease by 9% compared to the traditional approach of using the model specification from the literature and estimating the model with large-scale data. Qualitative constraints not only prevent counter-intuitive effects but also improve achieved benefits by regularizing the model.",2022,10.3389/frai.2022.1015604
Generative AI with WGAN-GP for boosting seizure detection accuracy,"BackgroundImbalanced datasets pose challenges for developing accurate seizure detection systems based on electroencephalogram (EEG) data. Generative AI techniques may help augment minority class data to facilitate automatic epileptic seizure detection.New methodThis study investigates the impact of various data augmentation (DA) approaches, including Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), Vanilla GAN, Conditional GAN (CGAN), and Cramer GAN, on classification performance with Random Forest models. The best-performing GAN variant, WGAN-GP, was then integrated with a bidirectional Long Short-Term Memory (LSTM) architecture and compared against traditional and synthetic oversampling methods.ResultsThe evaluation of different GAN variants for data augmentation with Random Forest classifiers identified WGAN-GP as the most effective approach. The integration of WGAN-GP with bidirectional LSTM yielded substantial performance improvements, outperforming traditional oversampling methods and achieving an accuracy of 91.73% on the augmented data, compared to 86% accuracy on real data without augmentation.Comparison with existing methodsThe proposed generative AI approach combining WGAN-GP and recurrent neural network models outperforms comparative synthetic oversampling methods on metrics relevant for reliable seizure detection from imbalanced EEG datasets.ConclusionsIncorporating the WGAN-GP generative AI technique for data augmentation and integrating it with bidirectional LSTM elevates seizure detection accuracy for imbalanced EEG datasets, surpassing the performance of traditional oversampling and class weight adjustment methods. This approach shows promise for improving epilepsy monitoring and management through enhanced automated detection system effectiveness.",2024,10.3389/frai.2024.1437315
Deep learning and explainable AI for classification of potato leaf diseases,"The accurate classification of potato leaf diseases plays a pivotal role in ensuring the health and productivity of crops. This study presents a unified approach for addressing this challenge by leveraging the power of Explainable AI (XAI) and transfer learning within a deep Learning framework. In this research, we propose a transfer learning-based deep learning model that is tailored for potato leaf disease classification. Transfer learning enables the model to benefit from pre-trained neural network architectures and weights, enhancing its ability to learn meaningful representations from limited labeled data. Additionally, Explainable AI techniques are integrated into the model to provide interpretable insights into its decision-making process, contributing to its transparency and usability. We used a publicly available potato leaf disease dataset to train the model. The results obtained are 97% for validation accuracy and 98% for testing accuracy. This study applies gradient-weighted class activation mapping (Grad-CAM) to enhance model interpretability. This interpretability is vital for improving predictive performance, fostering trust, and ensuring seamless integration into agricultural practices.",2025,10.3389/frai.2024.1449329
Automated facial characterization and image retrieval by convolutional neural networks,"IntroductionDeveloping efficient methods to infer relations among different faces consisting of numerous expressions or on the same face at different times (e.g., disease progression) is an open issue in imaging related research. In this study, we present a novel method for facial feature extraction, characterization, and identification based on classical computer vision coupled with deep learning and, more specifically, convolutional neural networks.MethodsWe describe the hybrid face characterization system named FRetrAIval (FRAI), which is a hybrid of the GoogleNet and the AlexNet Neural Network (NN) models. Images analyzed by the FRAI network are preprocessed by computer vision techniques such as the oriented gradient-based algorithm that can extract only the face region from any kind of picture. The Aligned Face dataset (AFD) was used to train and test the FRAI solution for extracting image features. The Labeled Faces in the Wild (LFW) holdout dataset has been used for external validation.Results and discussionOverall, in comparison to previous techniques, our methodology has shown much better results on k-Nearest Neighbors (KNN) by yielding the maximum precision, recall, F1, and F2 score values (92.00, 92.66, 92.33, and 92.52%, respectively) for AFD and (95.00% for each variable) for LFW dataset, which were used as training and testing datasets. The FRAI model may be potentially used in healthcare and criminology as well as many other applications where it is important to quickly identify face features such as fingerprint for a specific identification target.",2023,10.3389/frai.2023.1230383
"A bibliometric review of deep learning in crop monitoring: trends, challenges, and future perspectives","Global agricultural systems face unprecedented challenges from climate change, resource scarcity, and rising food demand, requiring transformative solutions. Artificial intelligence (AI), particularly deep learning (DL), has emerged as a critical tool for agricultural monitoring, yet a systematic synthesis of its applications remains understudied. This paper presents a comprehensive bibliometric and knowledge graph analysis of 650 + publications (2000–2024) to map AI’s role in agricultural information identification, with emphasis on DL and remote sensing integration (e.g., UAVs, satellites). Results highlight Convolutional Neural Networks (CNNs) as the dominant technology for real-time crop monitoring but reveal three persistent barriers: (1) scarcity of annotated datasets, (2) poor model generalization across environments, and (3) challenges in fusing multi-source data. Crucially, interdisciplinary collaboration—though vital for scalability—is identified as an underdeveloped research frontier. It is concluded that while AI can revolutionize agriculture, its potential hinges on improving data quality, developing environment-adaptive models, and fostering cross-domain partnerships. This study provides a strategic framework to accelerate AI’s integration into global agricultural systems, addressing both technical gaps and policy needs for future food security.",2025,10.3389/frai.2025.1636898
One or two things we know about concept drift—a survey on monitoring in evolving environments. Part A: detecting concept drift,"The world surrounding us is subject to constant change. These changes, frequently described as concept drift, influence many industrial and technical processes. As they can lead to malfunctions and other anomalous behavior, which may be safety-critical in many scenarios, detecting and analyzing concept drift is crucial. In this study, we provide a literature review focusing on concept drift in unsupervised data streams. While many surveys focus on supervised data streams, so far, there is no work reviewing the unsupervised setting. However, this setting is of particular relevance for monitoring and anomaly detection which are directly applicable to many tasks and challenges in engineering. This survey provides a taxonomy of existing work on unsupervised drift detection. In addition to providing a comprehensive literature review, it offers precise mathematical definitions of the considered problems and contains standardized experiments on parametric artificial datasets allowing for a direct comparison of different detection strategies. Thus, the suitability of different schemes can be analyzed systematically, and guidelines for their usage in real-world scenarios can be provided.",2024,10.3389/frai.2024.1330257
Application progress of artificial intelligence in tumor diagnosis and treatment,"The rapid advancement of artificial intelligence (AI) has introduced transformative opportunities in oncology, enhancing the precision and efficiency of tumor diagnosis and treatment. This review examines recent advancements in AI applications across tumor imaging diagnostics, pathological analysis, and treatment optimization, with a particular focus on breast cancer, lung cancer, and liver cancer. By synthesizing findings from peer-reviewed studies published over the past decade, this paper analyzes the role of AI in enhancing diagnostic accuracy, streamlining therapeutic decision-making, and personalizing treatment strategies. Additionally, this paper addresses challenges related to AI integration into clinical workflows and regulatory compliance. As AI continues to evolve, its applications in oncology promise further improvements in patient outcomes, though additional research is needed to address its limitations and ensure ethical and effective deployment.",2025,10.3389/frai.2024.1487207
MoSViT: a lightweight vision transformer framework for efficient disease detection via precision attention mechanism,"Maize, a globally essential staple crop, suffers significant yield losses due to diseases. Traditional diagnostic methods are often inefficient and subjective, posing challenges for timely and accurate pest management. This study introduces MoSViT, an innovative classification model leveraging advanced machine learning and computer vision technologies. Built on the MobileViT V2 framework, MoSViT integrates the CLA focus mechanism, DRB module, MoSViT Block, and the LeakyRelu6 activation function to enhance feature extraction accuracy while reducing computational complexity. Trained on a dataset of 3,850 images encompassing Blight, Common Rust, Gray Leaf Spot, and Healthy conditions, MoSViT achieves exceptional performance, with classification accuracy, Precision, Recall, and F1 Score of 98.75%, 98.73%, 98.72%, and 98.72%, respectively. These results surpass leading models such as Swin Transformer V2, DenseNet121, and EfficientNet V2 in both accuracy and parameter efficiency. Additionally, the model's interpretability is enhanced through heatmap analysis, providing insights into its decision-making process. Testing on small sample datasets further demonstrates MoSViT's generalization capability and potential for small-sample detection scenarios.",2025,10.3389/frai.2025.1498025
From Llama to language: prompt-engineering allows general-purpose artificial intelligence to rate narratives like expert psychologists,"IntroductionArtificial intelligence (AI) has tremendous potential for use in psychology. Among the many applications that may benefit from development of AI applications is narrative-personality assessment. Use of these tools and research methods is notably time-consuming and resource intensive. AI has potential to address these issues in ways that would greatly reduce clinician and researcher burden. Nonetheless, it is unclear if current AI models are sufficiently sophisticated to perform the complex downstream tasks, such as narrative assessment.MethodologyThe purpose of this study is to explore if an expert-refined prompt generation process can enable AI-empowered chatbots to reliably and accurately rate narratives using the Social Cognition and Object Relations scales – Global Rating Method (SCORS-G). Experts generated prompt inputs by engaging in a detailed review of SCORS-G training materials. Prompts were then improved using an systematic process in which experts worked with Llama-2-70b to refine prompts. The utility of the prompts was then tested on two AI-empowered chatbots, ChatGPT-4 (OpenAI, 2023) and CLAUDE-2-100k, that were not used in the prompt refinement process.ResultsResults showed that the refined prompts allowed chatbots to reliably rate narratives at the global level, though accuracy varied across subscales. Averaging ratings from two chatbots notably improved reliability for the global score and all subscale scores. Experimentation indicated that expert-refined prompts outperformed basic prompts regarding interrater reliability and absolute agreement with gold standard ratings. Only the expert-refined prompts were able to generate acceptable single-rater interrater reliability estimates.DiscussionFindings suggest that AI could significantly reduce the time and resource burdens on clinicians and researchers using narrative rating systems like the SCORS-G. Limitations and implications for future research are discussed.",2025,10.3389/frai.2025.1398885
Diagnostic performance of AI-based models versus physicians among patients with hepatocellular carcinoma: a systematic review and meta-analysis,"BackgroundHepatocellular carcinoma (HCC) is a common primary liver cancer that requires early diagnosis due to its poor prognosis. Recent advances in artificial intelligence (AI) have facilitated hepatocellular carcinoma detection using multiple AI models; however, their performance is still uncertain.AimThis meta-analysis aimed to compare the diagnostic performance of different AI models with that of clinicians in the detection of hepatocellular carcinoma.MethodsWe searched the PubMed, Scopus, Cochrane Library, and Web of Science databases for eligible studies. The R package was used to synthesize the results. The outcomes of various studies were aggregated using fixed-effect and random-effects models. Statistical heterogeneity was evaluated using I-squared (I2) and chi-square statistics.ResultsWe included seven studies in our meta-analysis;. Both physicians and AI-based models scored an average sensitivity of 93%. Great variation in sensitivity, accuracy, and specificity was observed depending on the model and diagnostic technique used. The region-based convolutional neural network (RCNN) model showed high sensitivity (96%). Physicians had the highest specificity in diagnosing hepatocellular carcinoma(100%); furthermore, models-based convolutional neural networks achieved high sensitivity. Models based on AI-assisted Contrast-enhanced ultrasound (CEUS) showed poor accuracy (69.9%) compared to physicians and other models. The leave-one-out sensitivity revealed high heterogeneity among studies, which represented true differences among the studies.ConclusionModels based on Faster R-CNN excel in image classification and data extraction, while both CNN-based models and models combining contrast-enhanced ultrasound (CEUS) with artificial intelligence (AI) had good sensitivity. Although AI models outperform physicians in diagnosing HCC, they should be utilized as supportive tools to help make more accurate and timely decisions.",2024,10.3389/frai.2024.1398205
Experiments with LDA and Top2Vec for embedded topic discovery on social media data—A case study of cystic fibrosis,"Social media has become an important resource for discussing, sharing, and seeking information pertinent to rare diseases by patients and their families, given the low prevalence in the extraordinarily sparse populations. In our previous study, we identified prevalent topics from Reddit via topic modeling for cystic fibrosis (CF). While we were able to derive/access concerns/needs/questions of patients with CF, we observed challenges and issues with the traditional techniques of topic modeling, e.g., Latent Dirichlet Allocation (LDA), for fulfilling the task of topic extraction. Thus, here we present our experiments to extend the previous study with an aim of improving the performance of topic modeling, by experimenting with LDA model optimization and examination of the Top2Vec model with different embedding models. With the demonstrated results with higher coherence and qualitatively higher human readability of derived topics, we implemented the Top2Vec model with doc2vec as the embedding model as our final model to extract topics from a subreddit of CF (“r/CysticFibrosis”) and proposed to expand its use with other types of social media data for other rare diseases for better assessing patients' needs with social media data.",2022,10.3389/frai.2022.948313
A step-by-step method for cultural annotation by LLMs,"Building on the growing body of research highlighting the capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT), this paper presents a structured pipeline for the annotation of cultural (big) data through such LLMs, offering a detailed methodology for leveraging GPT’s computational abilities. Our approach provides researchers across various fields with a method for efficient and scalable analysis of cultural phenomena, showcasing the potential of LLMs in the empirical study of human cultures. LLMs proficiency in processing and interpreting complex data finds relevance in tasks such as annotating descriptions of non-industrial societies, measuring the importance of specific themes in stories, or evaluating psychological constructs in texts across societies or historical periods. These applications demonstrate the model’s versatility in serving disciplines like cultural anthropology, cultural psychology, cultural history, and cultural sciences at large.",2024,10.3389/frai.2024.1365508
Population health management through human phenotype ontology with policy for ecosystem improvement,"AimThe manuscript “Population Health Management (PHM) Human Phenotype Ontology (HPO) Policy for Ecosystem Improvement” steward safe science and secure technology in medical reform. The digital HPO policy advances Biological Modelling (BM) capacity and capability in a series of fair classifications. Public trust in the PHM of HPO is a vision of public health and patient safety, with a primary goal of socioeconomic success sustained by citizen privacy and trust within an ecosystem of predictor equality and intercept parity.MethodScience and technology security evaluation, resource allocation, and appropriate regulation are essential for establishing a solid foundation in a safe ecosystem. The AI Security Institute collaborates with higher experts to assess BM cybersecurity and privacy. Within this ecosystem, resources are allocated to the Genomic Medical Sciences Cluster and AI metrics that support safe HPO transformations. These efforts ensure that AI digital regulation acts as a service appropriate to steward progressive PHM.RecommendationsThe manuscript presents a five-point mission for the effective management of population health. A comprehensive national policy for phenotype ontology with Higher Expert Medical Science Safety stewards reform across sectors. It emphasizes developing genomic predictors and intercepts, authorizing predictive health pre-eXams and precise care eXams, adopting Generative Artificial Intelligence classifications, and expanding the PHM ecosystem in benchmark reforms.DiscussionDiscussions explore medical reform focusing on public health and patient safety. The nation's safe space expansions with continual improvements include stewards developing, authorizing, and adopting digital BM twins. The manuscript addresses international classifications where the global development of PHM enables nations to choose what to authorize for BM points of need. These efforts promote channels for adopting HPO uniformity, transforming research findings into routine phenotypical primary care practices.ConclusionThis manuscript charts the UK's and global PHM's ecosystem expansion, designing HPO policies that steward the modeling of biology in personal classifications. It develops secure, safe, fair, and explainable BM for public trust in authorized classifiers and promotes informed choices regarding what nations and individuals adopt in a cooperative PHM progression. Championing equitable classifications in a robust ecosystem sustains advancements in population health outcomes for economic growth and public health betterment.",2025,10.3389/frai.2025.1496937
Using machine learning for healthcare treatment planning,"We present a methodology for using machine learning for planning treatments. As a case study, we apply the proposed methodology to Breast Cancer. Most of the application of Machine Learning to breast cancer has been on diagnosis and early detection. By contrast, our paper focuses on applying Machine Learning to suggest treatment plans for patients with different disease severity. While the need for surgery and even its type is often obvious to a patient, the need for chemotherapy and radiation therapy is not as obvious to the patient. With this in mind, the following treatment plans were considered in this study: chemotherapy, radiation, chemotherapy with radiation, and none of these options (only surgery). We use real data from more than 10,000 patients over 6 years that includes detailed cancer information, treatment plans, and survival statistics. Using this data set, we construct Machine Learning classifiers to suggest treatment plans. Our emphasis in this effort is not only on suggesting the treatment plan but on explaining and defending a particular treatment choice to the patient.",2023,10.3389/frai.2023.1124182
In the Pursuit of Privacy: The Promises and Predicaments of Federated Learning in Healthcare,"Artificial Intelligence and its subdomain, Machine Learning (ML), have shown the potential to make an unprecedented impact in healthcare. Federated Learning (FL) has been introduced to alleviate some of the limitations of ML, particularly the capability to train on larger datasets for improved performance, which is usually cumbersome for an inter-institutional collaboration due to existing patient protection laws and regulations. Moreover, FL may also play a crucial role in circumventing ML’s exigent bias problem by accessing underrepresented groups’ data spanning geographically distributed locations. In this paper, we have discussed three FL challenges, namely: privacy of the model exchange, ethical perspectives, and legal considerations. Lastly, we have proposed a model that could aide in assessing data contributions of a FL implementation. In light of the expediency and adaptability of using the Sørensen–Dice Coefficient over the more limited (e.g., horizontal FL) and computationally expensive Shapley Values, we sought to demonstrate a new paradigm that we hope, will become invaluable for sharing any profit and responsibilities that may accompany a FL endeavor.",2021,10.3389/frai.2021.746497
Impact on bias mitigation algorithms to variations in inferred sensitive attribute uncertainty,"Concerns about the trustworthiness, fairness, and privacy of AI systems are growing, and strategies for mitigating these concerns are still in their infancy. One approach to improve trustworthiness and fairness in AI systems is to use bias mitigation algorithms. However, most bias mitigation algorithms require data sets that contain sensitive attribute values to assess the fairness of the algorithm. A growing number of real world data sets do not make sensitive attribute information readily available to researchers. One solution is to infer the missing sensitive attribute information and apply an existing bias mitigation algorithm using this inferred knowledge. While researchers are beginning to explore this question, it is still unclear how robust existing bias mitigation algorithms are to different levels of inference accuracy. This paper explores this question by investigating the impact of different levels of accuracy of the inferred sensitive attribute on the performance of different bias mitigation strategies. We generate variation in sensitive attribute accuracy using both simulation and construction of neural models for the inference task. We then assess the quality of six bias mitigation algorithms that are deployed across different parts of our learning life cycle: pre-processing, in-processing, and post-processing. We find that the disparate impact remover is the least sensitive bias mitigation strategy and that if we apply the bias mitigation algorithms using an inferred sensitive attribute with reasonable accuracy, the fairness scores are higher than the best standard model and the balanced accuracy is similar to that of the standard model. These findings open the door for improving fairness of black box AI systems using some bias mitigation strategies.",2025,10.3389/frai.2025.1520330
Subtle changes on electrocardiogram in severe patients with COVID-19 may be predictors of treatment outcome,"BackgroundTwo years after the COVID-19 pandemic, it became known that one of the complications of this disease is myocardial injury. Electrocardiography (ECG) and cardiac biomarkers play a vital role in the early detection of cardiovascular complications and risk stratification. The study aimed to investigate the value of a new electrocardiographic metric for detecting minor myocardial injury in patients during COVID-19 treatment.MethodsThe study was conducted in 2021. A group of 26 patients with verified COVID-19 diagnosis admitted to the intensive care unit for infectious diseases was examined. The severity of a patient’s condition was calculated using the NEWS score. The digital ECGs were repeatedly recorded (at the beginning and 2–4 times during the treatment). A total of 240 primary and composite ECG parameters were analyzed for each electrocardiogram. Among these patients, 6 patients died during treatment. Cluster analysis was used to identify subgroups of patients that differed significantly in terms of disease severity (NEWS), SрО2 and integral ECG index (an indicator of the state of the cardiovascular system).ResultsUsing analysis of variance (ANOVA repeated measures), a statistical assessment of changes of indicators in subgroups at the end of treatment was given. These subgroup differences persisted at the end of the treatment. To identify potential predictors of mortality, critical clinical and ECG parameters of surviving (S) and non-surviving patients (D) were compared using parametric and non-parametric statistical tests. A decision tree model to classify survival in patients with COVID-19 was constructed based on partial ECG parameters and NEWS score.ConclusionA comparison of potential mortality predictors showed no significant differences in vital signs between survivors and non-survivors at the beginning of treatment. A set of ECG parameters was identified that were significantly associated with treatment outcomes and may be predictors of COVID-19 mortality: T-wave morphology (SVD), Q-wave amplitude, and R-wave amplitude (lead I).",2025,10.3389/frai.2025.1561079
Cross Country Determinants of Investors' Sentiments Prediction in Emerging Markets Using ANN,"The paper models investor sentiments (IS) to attract investments for Health Sector and Growth in emerging markets, viz., India, Mainland China, and the UAE, by asking questions such as: What specific healthcare sector opportunities are available in the three markets? Are the USA-IS key IS predictors in the three economies? How important are macroeconomic and sociocultural factors in predicting IS in these markets? How important are economic crises and pandemic events in predicting IS in these markets? Is there contemporaneous relation in predicting IS across the three countries in terms of USA-IS, and, if yes, is the magnitude of the impact of USA-IS uniform across the three countries' IS? The artificial neural network (ANN) model is applied to weekly time-series data from January 2003 to December 2020 to capture behavioral elements in the investors' decision-making in these emerging economies. The empirical findings confirmed the superiority of the ANN framework over the traditional logistic model in capturing the cognitive behavior of investors. Health predictor—current health expenditure as a percentage of GDP, USA IS predictor—spread, and Macro-factor GDP—annual growth % are the common predictors across the 3 economies that positively impacted the emerging markets' IS behavior. USA (S&amp;P 500) return is the only common predictor across the three economies that negatively impacted the emerging markets' IS behavior. However, the magnitude of both positive and negative impacts varies across the countries, signifying unique, diverse socioeconomic, cultural, and market features in each of the 3 economies. The results have four key implications: Firstly, US market sentiments are an essential factor influencing stock markets in these countries. Secondly, there is a need for developing a robust sentiment proxy on similar lines to the USA in the three countries. Thirdly, investment opportunities in the healthcare sector in these economies have been identified for potential investments by the investors. Fourthly, this study is the first study to investigate investors' sentiments in these three fast-emerging economies to attract investments in the Health Sector and Growth in the backdrop of UN's 2030 SDG 3 and SDG 8 targets to be achieved by these economies.",2022,10.3389/frai.2022.912403
Regulating Ruminative Web Browsing Based on the Counterbalance Modeling Approach,"Even though the web environment facilitates our daily life, emotional problems caused by its incompatibility with human cognition are becoming increasingly serious. To alleviate negative emotions during web use, we developed a browser extension that presents memorized product images to users in the form of web advertisements. This system utilizes the cognitive architecture Adaptive Control of Thought-Rational (ACT-R) as a model of human memory and emotion. A heart rate sensor attached to the user modulates the ACT-R model parameters, and the emotional states represented by the model are synchronized (following the chameleon effect) or counterbalanced (following the homeostasis regulation) with the physiological state of the user. An experiment demonstrates that the counterbalanced model suppresses negative ruminative web browsing. The authors claim that this approach, utilizing a cognitive model, is advantageous in terms of explainability.",2022,10.3389/frai.2022.741610
Generating rhythm game music with jukebox,"Music has always been thought of as a “human” endeavor- when praising a piece of music, we emphasize the composer’s creativity and the emotions the music invokes. Because music also heavily relies on patterns and repetition in the form of recurring melodic themes and chord progressions, artificial intelligence has increasingly been able to replicate music in a human-like fashion. This research investigated the capabilities of Jukebox, an open-source commercially available neural network, to accurately replicate two genres of music often found in rhythm games, artcore and orchestral. A Google Colab notebook provided the computational resources necessary to sample and extend a total of 16 piano arrangements of both genres. A survey containing selected samples was distributed to a local youth orchestra to gauge people’s perceptions of the musicality of AI and human-generated music. Even though humans preferred human-generated music, Jukebox’s slightly high rating showed that it was somewhat capable at mimicking the styles of both genres. Despite limitations of Jukebox only using raw audio and a relatively small sample size, it shows promise for the future of AI as a collaborative tool in music production.",2024,10.3389/frai.2024.1296034
Dynamic-budget superpixel active learning for semantic segmentation,"IntroductionActive learning can significantly decrease the labeling cost of deep learning workflows by prioritizing the limited labeling budget to high-impact data points that have the highest positive impact on model accuracy. Active learning is especially useful for semantic segmentation tasks where we can selectively label only a few high-impact regions within these high-impact images. Most established regional active learning algorithms deploy a static-budget querying strategy where a fixed percentage of regions are queried in each image. A static budget could result in over- or under-labeling images as the number of high-impact regions in each image can vary.MethodsIn this paper, we present a novel dynamic-budget superpixel querying strategy that can query the optimal numbers of high-uncertainty superpixels in an image to improve the querying efficiency of regional active learning algorithms designed for semantic segmentation.ResultsFor two distinct datasets, we show that by allowing a dynamic budget for each image, the active learning algorithm is more effective compared to static-budget querying at the same low total labeling budget. We investigate both low- and high-budget scenarios and the impact of superpixel size on our dynamic active learning scheme. In a low-budget scenario, our dynamic-budget querying outperforms static-budget querying by 5.6% mIoU on a specialized agriculture field image dataset and 2.4% mIoU on Cityscapes.DiscussionThe presented dynamic-budget querying strategy is simple, effective, and can be easily adapted to other regional active learning algorithms to further improve the data efficiency of semantic segmentation tasks.",2025,10.3389/frai.2024.1498956
Accurately predicting hit songs using neurophysiology and machine learning,"Identifying hit songs is notoriously difficult. Traditionally, song elements have been measured from large databases to identify the lyrical aspects of hits. We took a different methodological approach, measuring neurophysiologic responses to a set of songs provided by a streaming music service that identified hits and flops. We compared several statistical approaches to examine the predictive accuracy of each technique. A linear statistical model using two neural measures identified hits with 69% accuracy. Then, we created a synthetic set data and applied ensemble machine learning to capture inherent non-linearities in neural data. This model classified hit songs with 97% accuracy. Applying machine learning to the neural response to 1st min of songs accurately classified hits 82% of the time showing that the brain rapidly identifies hit music. Our results demonstrate that applying machine learning to neural data can substantially increase classification accuracy for difficult to predict market outcomes.",2023,10.3389/frai.2023.1154663
SeismoQuakeGNN: a hybrid framework for spatio-temporal earthquake prediction with transformer-enhanced models,"Accurate predictions of earthquakes are crucial for disaster preparedness and risk mitigation. Conventional machine learning models like Random Forest, SVR, and XGBoost are frequently used for seismic forecasting; however, capturing the intricate spatiotemporal relationships in earthquake data remains a challenge. To overcome this issue, we propose SeismoQuakeGNN, a novel Graph Neural Network (GNN) and Transformer-based hybrid framework that integrates spatial and temporal learning for improved seismic forecasting. Unlike existing GNN-based models, SeismoQuakeGNN introduces an optimized spatial encoding mechanism to dynamically learn seismic interdependencies, coupled with a Transformer-driven attention module to capture long-range temporal correlations. Furthermore, initial experiments with XGBoost demonstrated its limitations in learning earthquake patterns, reinforcing the need for deep spatial–temporal modeling. The new SeismoQuakeGNN method is capable of substantial and efficient data processing of relationships in both space and time, as well as providing superior transfer to different seismic areas, thereby qualifying as a dependable starting point to extensive earthquake forecasting and hazard evaluation.",2025,10.3389/frai.2025.1690476
Who are the haters? A corpus-based demographic analysis of authors of hate speech,"IntroductionWe examine the profiles of hate speech authors in a multilingual dataset of Facebook reactions to news posts discussing topics related to migrants and the LGBT+ community. The included languages are English, Dutch, Slovenian, and Croatian.MethodsFirst, all utterances were manually annotated as hateful or acceptable speech. Next, we used binary logistic regression to inspect how the production of hateful comments is impacted by authors' profiles (i.e., their age, gender, and language).ResultsOur results corroborate previous findings: in all four languages, men produce more hateful comments than women, and people produce more hate speech as they grow older. But our findings also add important nuance to previously attested tendencies: specific age and gender dynamics vary slightly in different languages or cultures, suggesting that distinct (e.g., socio-political) realities are at play.DiscussionFinally, we discuss why author demographics are important in the study of hate speech: the profiles of prototypical “haters” can be used for hate speech detection, for sensibilization on and for counter-initiatives to the spread of (online) hatred.",2023,10.3389/frai.2023.986890
Functional partitioning through competitive learning,"Datasets often incorporate various functional patterns related to different aspects or regimes, which are typically not equally present throughout the dataset. We propose a novel partitioning algorithm that utilizes competition between models to detect and separate these functional patterns. This competition is induced by multiple models iteratively submitting their predictions for the dataset, with the best prediction for each data point being rewarded with training on that data point. This reward mechanism amplifies each model's strengths and encourages specialization in different patterns. The specializations can then be translated into a partitioning scheme. We validate our concept with datasets with clearly distinct functional patterns, such as mechanical stress and strain data in a porous structure. Our partitioning algorithm produces valuable insights into the datasets' structure, which can serve various further applications. As a demonstration of one exemplary usage, we set up modular models consisting of multiple expert models, each learning a single partition, and compare their performance on more than twenty popular regression problems with single models learning all partitions simultaneously. Our results show significant improvements, with up to 56% loss reduction, confirming our algorithm's utility.",2025,10.3389/frai.2025.1661444
BioVDB: biological vector database for high-throughput gene expression meta-analysis,"High-throughput sequencing has created an exponential increase in the amount of gene expression data, much of which is freely, publicly available in repositories such as NCBI's Gene Expression Omnibus (GEO). Querying this data for patterns such as similarity and distance, however, becomes increasingly challenging as the total amount of data increases. Furthermore, vectorization of the data is commonly required in Artificial Intelligence and Machine Learning (AI/ML) approaches. We present BioVDB, a vector database for storage and analysis of gene expression data, which enhances the potential for integrating biological studies with AI/ML tools. We used a previously developed approach called Automatic Label Extraction (ALE) to extract sample labels from metadata, including age, sex, and tissue/cell-line. BioVDB stores 438,562 samples from eight microarray GEO platforms. We show that it allows for efficient querying of data using similarity search, which can also be useful for identifying and inferring missing labels of samples, and for rapid similarity analysis.",2024,10.3389/frai.2024.1366273
Multi-scale and deeply supervised network for image splicing localization,"When maliciously tampered images are disseminated in the media, they can potentially cause adverse effects and even jeopardize national security. Therefore, it is necessary to investigate effective methods to detect tampered images. As a challenging task, the localization of image splicing tampering investigates whether an image contains tampered regions spliced from another image. Given the lack of global information interactions in existing methods, a multi-scale, deeply supervised image splicing tampering localization network is proposed. The proposed network is based on an encoder–decoder architecture, where the decoder uses different levels of feature maps to supervise the locations of splicing, enabling pixel-wise prediction of tampered regions. Moreover, a multi-scale feature extraction module is utilized between the encoder and decoder, which expands the global view of the network, thereby enabling more effective differentiation between tampered and non-tampered regions. F1 scores of 0.891 and 0.864 were achieved using the CASIA and COLUMB datasets, respectively; and the proposed model was able to accurately locate tampered regions.",2025,10.3389/frai.2025.1655073
Diversity-enhanced reconstruction as plug-in defenders against adversarial perturbations,"Deep learning models are susceptible to adversarial examples. In large-scale deployed services, plug-in defenders efficiently defend against such attacks. Plug-in defenders take two approaches to mitigate adversarial effects: input reconstruction and random transformations. Existing plug-in defense lacks diversity in transformation formulation due to the inherent feature preservation nature, which leads to vulnerability under adaptive attacks. To address this issue, we propose a novel plug-in defense named Diversity-enhanced Reconstruction (DeR). DeR counters adversarial attacks by frequency-aware reconstructors with enhanced diversity. Specifically, we design the reconstructors as a U-Net backbone with additional frequency components. The reconstructors are trained on the proposed DeR loss, which optimizes the reconstruction and diversity objectives jointly. Once trained, DeR can produce heterogeneous gradients and be applied as a plug-in defense. We conduct extensive experiments on three datasets and four classifier architectures under strict adversarial settings. The results demonstrate the superior robustness of DeR compared to state-of-the-art plug-in defense and the efficiency of DeR in real-time processing.",2025,10.3389/frai.2025.1665106
Efficient spatio-temporal modeling for sign language recognition using CNN and RNN architectures,"Computer vision has been identified as one of the solutions to bridge communication barriers between speech-impaired populations and those without impairment as most people are unaware of the sign language used by speech-impaired individuals. Numerous studies have been conducted to address this challenge. However, recognizing word signs, which are usually dynamic and involve more than one frame per sign, remains a challenge. This study used Tanzania Sign Language datasets collected using mobile phone selfie cameras to investigate the performance of deep learning algorithms that capture spatial and temporal relationships features of video frames. The study used CNN-LSTM and CNN-GRU architectures, where CNN-GRU with an ELU activation function is proposed to enhance learning efficiency and performance. The findings indicate that the proposed CNN-GRU model with ELU activation achieved an accuracy of 94%, compared to 93% for the standard CNN-GRU model and CNN-LSTM. In addition, the study evaluated performance of the proposed model in a signer-independent setting, where the results varied significantly across individual signers, with the highest accuracy reaching 66%. These results show that more effort is required to improve signer independence performance, including the challenges of hand dominance by optimizing spatial features.",2025,10.3389/frai.2025.1630743
Enzyme catalytic efficiency prediction: employing convolutional neural networks and XGBoost,"IntroductionIn the intricate realm of enzymology, the precise quantification of enzyme efficiency, epitomized by the turnover number (kcat), is a paramount yet elusive objective. Existing methodologies, though sophisticated, often grapple with the inherent stochasticity and multifaceted nature of enzymatic reactions. Thus, there arises a necessity to explore avant-garde computational paradigms.MethodsIn this context, we introduce “enzyme catalytic efficiency prediction (ECEP),” leveraging advanced deep learning techniques to enhance the previous implementation, TurNuP, for predicting the enzyme catalase kcat. Our approach significantly outperforms prior methodologies, incorporating new features derived from enzyme sequences and chemical reaction dynamics. Through ECEP, we unravel the intricate enzyme-substrate interactions, capturing the nuanced interplay of molecular determinants.ResultsPreliminary assessments, compared against established models like TurNuP and DLKcat, underscore the superior predictive capabilities of ECEP, marking a pivotal shift in silico enzymatic turnover number estimation. This study enriches the computational toolkit available to enzymologists and lays the groundwork for future explorations in the burgeoning field of bioinformatics. This paper suggested a multi-feature ensemble deep learning-based approach to predict enzyme kinetic parameters using an ensemble convolution neural network and XGBoost by calculating weighted-average of each feature-based model’s output to outperform traditional machine learning methods. The proposed “ECEP” model significantly outperformed existing methodologies, achieving a mean squared error (MSE) reduction of 0.35 from 0.81 to 0.46 and R-squared score from 0.44 to 0.54, thereby demonstrating its superior accuracy and effectiveness in enzyme catalytic efficiency prediction.DiscussionThis improvement underscores the model’s potential to enhance the field of bioinformatics, setting a new benchmark for performance.",2024,10.3389/frai.2024.1446063
Artificial intelligence technology application and corporate ESG performance—evidence from national pilot zones for artificial intelligence innovation and application,"This study empirically examines the impact of artificial intelligence (AI) technology on corporate ESG performance using data from Chinese listed companies from 2011 to 2022 and a multi-period difference-in-differences (DID) model. The results reveal that AI significantly enhances overall corporate ESG performance by alleviating financing constraints, promoting green innovation, and strengthening information disclosure. These effects are particularly pronounced in the environmental (E) and governance (G) dimensions. Further analysis indicates that equity concentration, media attention, and data availability positively moderate the relationship between AI adoption and ESG performance. Based on these findings, this study suggests expanding AI application scenarios to facilitate the formulation of more targeted ESG strategies, deepen the integration of AI and ESG practices, and support high-quality economic development. The conclusions provide theoretical and empirical support for technology-driven corporate sustainable transformation.",2025,10.3389/frai.2025.1643684
Argumentation and explanation in the law,"This article investigates the conceptual connection between argumentation and explanation in the law and provides a formal account of it. To do so, the methods used are conceptual analysis from legal theory and formal argumentation from AI. The contribution and results are twofold. On the one hand, we offer a critical reconstruction of the concept of legal argument, justification, and explanation of decision-making as it has been elaborated in legal theory and, above all, in AI and law. On the other hand, we propose some definitions of explanation in the context of formal legal argumentation, showing a connection between formal justification and explanation. We also investigate the notion of stable normative explanation developed elsewhere in Defeasible Logic and extend some complexity results. Our contribution is thus mainly conceptual, and it is meant to show how notions of explanation from literature on explainable AI and legal theory can be modeled in an argumentation framework with structured arguments.",2023,10.3389/frai.2023.1130559
Optimizing surface defect detection with YOLOv9: the role of advanced backbone models,"IntroductionYOLO algorithmic models are widely utilized for detecting surface defects, offering a robust and efficient approach to identifying various flaws and imperfections on material surfaces.MethodsIn this study, we explore the integration of six distinct backbone networks within the YOLOv9 framework to optimize surface defect detection in steel strips. Specifically, we improve the YOLOv9 framework by integrating six representative backbones-ResNet50, GhostNet, MobileNetV4, FasterNet, StarNet, and RepViT-and conduct a systematic evaluation on the NEU-DET dataset and the GC10-DET dataset. Using YOLOv9-C as the baseline, we compare these backbones in terms of detection accuracy, computational complexity, and model efficiency.ResultsResults show that RepViT achieves the best overall performance with an mAP50 of 68.8%, F1-score of 0.65, and a balanced precision-recall profile, while GhostNet offers superior computational efficiency with only 41.2 M parameters and 190.2 GFLOPs. Further validation on YOLOv5-m confirms the consistency of the results.DiscussionThe study offers practical guidance for backbone selection in surface defect detection tasks, highlighting the advantages of lightweight architectures for real-time industrial applications.",2025,10.3389/frai.2025.1675154
Machine Learning Analysis of Hydrologic Exchange Flows and Transit Time Distributions in a Large Regulated River,"Hydrologic exchange between river channels and adjacent subsurface environments is a key process that influences water quality and ecosystem function in river corridors. High-resolution numerical models were often used to resolve the spatial and temporal variations of exchange flows, which are computationally expensive. In this study, we adopt Random Forest (RF) and Extreme Gradient Boosting (XGB) approaches for deriving reduced order models of hydrologic exchange flows and associated transit time distributions, with integrated field observations (e.g., bathymetry) and hydrodynamic simulation data (e.g., river velocity, depth). The setup allows an improved understanding of the influences of various physical, spatial, and temporal factors on the hydrologic exchange flows and transit times. The predictors also contain those derived using hybrid clustering, leveraging our previous work on river corridor system hydromorphic classification. The machine learning-based predictive models are developed and validated along the Columbia River Corridor, and the results show that the top parameters are the thickness of the top geological formation layer, the flow regime, river velocity, and river depth; the RF and XGB models can achieve 70% to 80% accuracy and therefore are effective alternatives to the computational demanding numerical models of exchange flows and transit time distributions. Each machine learning model with its favorable configuration and setup have been evaluated. The transferability of the models to other river reaches and larger scales, which mostly depends on data availability, is also discussed.",2021,10.3389/frai.2021.648071
"NC 4.0, a Novel Approach to Nonconformities Management: Prioritizing Events With Risk Management Tools","Quality 4.0, the correspondent quality practice fit to address the Industry 4.0 mindset, is expected to provide models and processes endorsed by continuous improvement and data-driven proofs, especially given the exponential growth in available data. The research consolidates the reality of big data availability (part of Quality 4.0) with a generic aspect of quality—managing nonconformities. Its purpose is to suggest a model to improve the initiation step for dealing with nonconformity by prioritizing these events. The new concept in the model suggested is incorporating the risk management method of prioritizing into the nonconformity’s management. These tools are designed to transform qualitative data into quantitative ones and enable easier decision-making, in this case, choosing which issue to deal with first. The research approach is developing and testing the suggested model as a pilot in a real production environment to establish its impact and define key guidelines for utilizing it in various processes and, in addition, to conduct a survey among quality experts from different organizations for reference. Two main outcomes were achieved during the research: The quality experts’ survey welcomed the model concept as a structured tool based on the solid risk management methodology. Implementing the model on actual production lines resulted in a significant reduction of NC financial impact as the events were solved as per their impact.",2021,10.3389/frai.2021.752520
Machine learning-guided clinical pharmacist interventions improve treatment outcomes in tuberculosis patients: a precision medicine approach,"Background
                    The heterogeneity in tuberculosis (TB) treatment responses necessitates a precision medicine approach. This study employed machine learning techniques to identify patient subtypes and optimize clinical pharmacist interventions.
                  
                  
                    Methods
                    
                      We conducted a prospective cohort study involving 467 TB patients (218 in the intervention group receiving machine learning-guided pharmacist care and 249 in the control group receiving standard care). Primary outcomes included time to sputum conversion (smear, culture, TB-RNA) and duration of hospitalization; secondary outcomes encompassed adverse event rates (hepatotoxicity, renal impairment, etc.), cost-effectiveness, and biomarker dynamics. Patient stratification was performed using unsupervised learning (k-means/PCA) on clinical and laboratory parameters. Treatment outcomes were assessed via Kaplan–Meier survival analysis and Cox proportional hazards modeling, with prespecified subgroup analyses by risk clusters.
                      Post hoc
                      analyses (e.g., correlation heatmaps of biomarkers) were explicitly labeled as exploratory. Cost-effectiveness was evaluated using incremental cost per quality-adjusted hospital day saved (ICER).
                    
                  
                  
                    Results
                    
                      Machine learning identified 2 distinct patient subtypes (inflammatory vs. immunologic profiles). The intervention group showed significantly shorter hospital stays (primary outcome: median 49.0 vs. 57.0 days; log-rank
                      p
                       = 0.040). Adverse event rates were lower in the intervention group (26.1% vs. 27.7%). Cost analysis demonstrated potential savings of 5,000 CNY per patient in the intervention group. Limitations: Single-center design and modest sample size may limit generalizability. Unmeasured confounders (e.g., socioeconomic factors) could influence outcomes.
                      Post hoc
                      biomarker correlations require validation in independent cohorts.
                    
                  
                  
                    Conclusion
                    Machine learning-guided pharmacist interventions improved TB treatment outcomes and reduced costs. Future multicenter studies should validate subtype-specific benefits.
                  
                  
                    Clinical trial registration
                    
                      https://www.chictr.org.cn/
                      identifier ChiCTR2300074328.",2025,10.3389/frai.2025.1679837
A decision support system to recommend appropriate therapy protocol for AML patients,"IntroductionAcute Myeloid Leukemia (AML) is one of the most aggressive hematological neoplasms, emphasizing the critical need for early detection and strategic treatment planning. The association between prompt intervention and enhanced patient survival rates underscores the pivotal role of therapy decisions. To determine the treatment protocol, specialists heavily rely on prognostic predictions that consider the response to treatment and clinical outcomes. The existing risk classification system categorizes patients into favorable, intermediate, and adverse groups, forming the basis for personalized therapeutic choices. However, accurately assessing the intermediate-risk group poses significant challenges, potentially resulting in treatment delays and deterioration of patient conditions.MethodsThis study introduces a decision support system leveraging cutting-edge machine learning techniques to address these issues. The system automatically recommends tailored oncology therapy protocols based on outcome predictions.ResultsThe proposed approach achieved a high performance close to 0.9 in F1-Score and AUC. The model generated with gene expression data exhibited superior performance.DiscussionOur system can effectively support specialists in making well-informed decisions regarding the most suitable and safe therapy for individual patients. The proposed decision support system has the potential to not only streamline treatment initiation but also contribute to prolonged survival and improved quality of life for individuals diagnosed with AML. This marks a significant stride toward optimizing therapeutic interventions and patient outcomes.",2024,10.3389/frai.2024.1343447
Supporting long-term condition management: a workflow framework for the co-development and operationalization of machine learning models using electronic health record data insights,"The prevalence of long-term conditions such as cardiovascular disease, chronic obstructive pulmonary disease (COPD), asthma, and diabetes mellitus is rising. These conditions are leading sources of premature mortality, hospital admission, and healthcare expenditure. Machine learning approaches to improve the management of these conditions have been widely explored, with data-driven insights demonstrating the potential to support earlier diagnosis, triage, and treatment selection. The translation of this research into tools used in live clinical practice has however been limited, with many projects lacking clinical involvement and planning beyond the initial model development stage. To support the move toward a more coordinated and collaborative working process from concept to investigative use in a live clinical environment, we present a multistage workflow framework for the co-development and operationalization of machine learning models which use routine clinical data derived from electronic health records. The approach outlined in this framework has been informed by our multidisciplinary team’s experience of co-developing and operationalizing risk prediction models for COPD within NHS Greater Glasgow &amp; Clyde. In this paper, we provide a detailed overview of this framework, alongside a description of the development and operationalization of two of these risk-prediction models as case studies of this approach.",2024,10.3389/frai.2024.1458508
Mitigating Issues With/of/for True Personalization,"A common but false perception persists about the level and type of personalization in the offerings of contemporary software, information systems, and services, known as Personalization Myopia: this involves a tendency for researchers to think that there are many more personalized services than there genuinely are, for the general audience to think that they are offered personalized services when they really are not, and for practitioners to have a mistaken idea of what makes a service personalized. And yet in an era, which mashes up large amounts of data, business analytics, deep learning, and persuasive systems, true personalization is a most promising approach for innovating and developing new types of systems and services—including support for behavior change. The potential of true personalization is elaborated in this article, especially with regards to persuasive software features and the oft-neglected fact that users change over time.",2022,10.3389/frai.2022.844817
EQRbot: A chatbot delivering EQR argument-based explanations,"Recent years have witnessed the rise of several new argumentation-based support systems, especially in the healthcare industry. In the medical sector, it is imperative that the exchange of information occurs in a clear and accurate way, and this has to be reflected in any employed virtual systems. Argument Schemes and their critical questions represent well-suited formal tools for modeling such information and exchanges since they provide detailed templates for explanations to be delivered. This paper details the EQR argument scheme and deploys it to generate explanations for patients' treatment advice using a chatbot (EQRbot). The EQR scheme (devised as a pattern of Explanation-Question-Response interactions between agents) comprises multiple premises that can be interrogated to disclose additional data. The resulting explanations, obtained as instances of the employed argumentation reasoning engine and the EQR template, will then feed the conversational agent that will exhaustively convey the requested information and answers to follow-on users' queries as personalized Telegram messages. Comparisons with a previous baseline and existing argumentation-based chatbots illustrate the improvements yielded by EQRbot against similar conversational agents.",2023,10.3389/frai.2023.1045614
The Relationship Between Performance and Trust in AI in E-Finance,"Artificial intelligence (AI) is fundamentally changing how people work in nearly every field, including online finance. However, our ability to interact with AI is moderated by factors such as performance, complexity, and trust. The work presented in this study analyzes the effect of performance on trust in a robo-advisor (AI which assists in managing investments) through an empirical investment simulation. Results show that for applications where humans and AI have comparable capabilities, the difference in performance (between the human and AI) is a moderate indicator of change in trust; however, human or AI performance individually were weak indicators. Additionally, results indicate that biases typically seen in human-human interactions may also occur in human-AI interactions when AI transparency is low.",2022,10.3389/frai.2022.891529
Explanatory machine learning for justified trust in human-AI collaboration: Experiments on file deletion recommendations,"In the digital age, saving and accumulating large amounts of digital data is a common phenomenon. However, saving does not only consume energy, but may also cause information overload and prevent people from staying focused and working effectively. We present and systematically examine an explanatory AI system (Dare2Del), which supports individuals to delete irrelevant digital objects. To give recommendations for the optimization of related human-computer interactions, we vary different design features (explanations, familiarity, verifiability) within and across three experiments (N1= 61,N2= 33,N3= 73). Moreover, building on the concept of distributed cognition, we check possible cross-connections between external (digital) and internal (human) memory. Specifically, we examine whether deleting external files also contributes to human forgetting of the related mental representations. Multilevel modeling results show the importance of presenting explanations for the acceptance of deleting suggestions in all three experiments, but also point to the need of their verifiability to generate trust in the system. However, we did not find clear evidence that deleting computer files contributes to human forgetting of the related memories. Based on our findings, we provide basic recommendations for the design of AI systems that can help to reduce the burden on people and the digital environment, and suggest directions for future research.",2022,10.3389/frai.2022.919534
A novel framework for automated warehouse layout generation,"Optimizing warehouse layouts is crucial due to its significant impact on efficiency and productivity. We present an AI-driven framework for automated warehouse layout generation. This framework employs constrained beam search to derive optimal layouts within given spatial parameters, adhering to all functional requirements. The feasibility of the generated layouts is verified based on criteria such as item accessibility, required minimum clearances, and aisle connectivity. A scoring function is then used to evaluate the feasible layouts considering the number of storage locations, access points, and accessibility costs. We demonstrate our method's ability to produce feasible, optimal layouts for a variety of warehouse dimensions and shapes, diverse door placements, and interconnections. This approach, currently being prepared for deployment, will enable human designers to rapidly explore and confirm options, facilitating the selection of the most appropriate layout for their use-case.",2024,10.3389/frai.2024.1465186
Fog computing: a platform for big-data marketing analytics,"Marketing science embraces a wider variety of data types and measurement tools necessary for strategy, research, and applied decision making. Managing the marketing data generated by internet of things (IoT) sensors and actuators is one of the biggest challenges faced by marketing managers when deploying an IoT system. This short note shows how traditional cloud-based IoT systems are challenged by the large scale, heterogeneity, and high latency witnessed in some cloud ecosystems. It introduces researchers to one recent breakthrough, fog computing, an emerging concept that decentralizes applications, strategies, and data analytics into the network itself using a distributed and federated computing model. It transforms centralized cloud to distributed fog by bringing storage and computation closer to the user end. Fog computing is considered a novel marketplace phenomenon which can support AI and management strategies, especially for the design of “smart marketing”.",2023,10.3389/frai.2023.1242574
The sociolinguistic foundations of language modeling,"In this article, we introduce a sociolinguistic perspective on language modeling. We claim that language models in general are inherently modeling varieties of language, and we consider how this insight can inform the development and deployment of language models. We begin by presenting a technical definition of the concept of a variety of language as developed in sociolinguistics. We then discuss how this perspective could help us better understand five basic challenges in language modeling: social bias, domain adaptation, alignment, language change, and scale. We argue that to maximize the performance and societal value of language models it is important to carefully compile training corpora that accurately represent the specific varieties of language being modeled, drawing on theories, methods, and descriptions from the field of sociolinguistics.",2025,10.3389/frai.2024.1472411
Multimodal deep learning for liver cancer applications: a scoping review,"BackgroundHepatocellular carcinoma is a malignant neoplasm of the liver and a leading cause of cancer-related deaths worldwide. The multimodal data combines several modalities, such as medical images, clinical parameters, and electronic health record (EHR) reports, from diverse sources to accomplish the diagnosis of liver cancer. The introduction of deep learning models with multimodal data can enhance the diagnosis and improve physicians' decision-making for cancer patients.ObjectiveThis scoping review explores the use of multimodal deep learning techniques (i.e., combining medical images and EHR data) in diagnosing and prognosis of hepatocellular carcinoma (HCC) and cholangiocarcinoma (CCA).MethodologyA comprehensive literature search was conducted in six databases along with forward and backward references list checking of the included studies. PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) extension for scoping review guidelines were followed for the study selection process. The data was extracted and synthesized from the included studies through thematic analysis.ResultsTen studies were included in this review. These studies utilized multimodal deep learning to predict and diagnose hepatocellular carcinoma (HCC), but no studies examined cholangiocarcinoma (CCA). Four imaging modalities (CT, MRI, WSI, and DSA) and 51 unique EHR records (clinical parameters and biomarkers) were used in these studies. The most frequently used medical imaging modalities were CT scans followed by MRI, whereas the most common EHR parameters used were age, gender, alpha-fetoprotein AFP, albumin, coagulation factors, and bilirubin. Ten unique deep-learning techniques were applied to both EHR modalities and imaging modalities for two main purposes, prediction and diagnosis.ConclusionThe use of multimodal data and deep learning techniques can help in the diagnosis and prediction of HCC. However, there is a limited number of works and available datasets for liver cancer, thus limiting the overall advancements of AI for liver cancer applications. Hence, more research should be undertaken to explore further the potential of multimodal deep learning in liver cancer applications.",2023,10.3389/frai.2023.1247195
Developing and testing a prediction model for periodontal disease using machine learning and big electronic dental record data,"Despite advances in periodontal disease (PD) research and periodontal treatments, 42% of the US population suffer from periodontitis. PD can be prevented if high-risk patients are identified early to provide preventive care. Prediction models can help assess risk for PD before initiation and progression; nevertheless, utilization of existing PD prediction models is seldom because of their suboptimal performance. This study aims to develop and test the PD prediction model using machine learning (ML) and electronic dental record (EDR) data that could provide large sample sizes and up-to-date information. A cohort of 27,138 dental patients and grouped PD diagnoses into: healthy control, mild PD, and severe PD was generated. The ML model (XGBoost) was trained (80% training data) and tested (20% testing data) with a total of 74 features extracted from the EDR. We used a five-fold cross-validation strategy to identify the optimal hyperparameters of the model for this one-vs.-all multi-class classification task. Our prediction model differentiated healthy patients vs. mild PD cases and mild PD vs. severe PD cases with an average area under the curve of 0.72. New associations and features compared to existing models were identified that include patient-level factors such as patient anxiety, chewing problems, speaking trouble, teeth grinding, alcohol consumption, injury to teeth, presence of removable partial dentures, self-image, recreational drugs (Heroin and Marijuana), medications affecting periodontium, and medical conditions such as osteoporosis, cancer, neurological conditions, infectious diseases, endocrine conditions, cardiovascular diseases, and gastroenterology conditions. This pilot study demonstrated promising results in predicting the risk of PD using ML and EDR data. The model may provide new information to the clinicians about the PD risks and the factors responsible for the disease progression to take preventive approaches. Further studies are warned to evaluate the prediction model's performance on the external dataset and determine its usability in clinical settings.",2022,10.3389/frai.2022.979525
“I don’t Think These Devices are Very Culturally Sensitive.”—Impact of Automated Speech Recognition Errors on African Americans,"Automated speech recognition (ASR) converts language into text and is used across a variety of applications to assist us in everyday life, from powering virtual assistants, natural language conversations, to enabling dictation services. While recent work suggests that there are racial disparities in the performance of ASR systems for speakers of African American Vernacular English, little is known about the psychological and experiential effects of these failures paper provides a detailed examination of the behavioral and psychological consequences of ASR voice errors and the difficulty African American users have with getting their intents recognized. The results demonstrate that ASR failures have a negative, detrimental impact on African American users. Specifically, African Americans feel othered when using technology powered by ASR—errors surface thoughts about identity, namely about race and geographic location—leaving them feeling that the technology was not made for them. As a result, African Americans accommodate their speech to have better success with the technology. We incorporate the insights and lessons learned from sociolinguistics in our suggestions for linguistically responsive ways to build more inclusive voice systems that consider African American users’ needs, attitudes, and speech patterns. Our findings suggest that the use of a diary study can enable researchers to best understand the experiences and needs of communities who are often misunderstood by ASR. We argue this methodological framework could enable researchers who are concerned with fairness in AI to better capture the needs of all speakers who are traditionally misheard by voice-activated, artificially intelligent (voice-AI) digital systems.",2021,10.3389/frai.2021.725911
AI revolution in insurance: bridging research and reality,"This paper comprehensively reviews artificial intelligence (AI) applications in the insurance industry. We focus on the automotive, health, and property insurance domains. To conduct this study, we followed the PRISMA guidelines for systematic reviews. This rigorous methodology allowed us to examine recent academic research and industry practices thoroughly. This study also identifies several key challenges that must be addressed to mitigate operational and underwriting risks, including data quality issues that could lead to biased risk assessments, regulatory compliance requirements for risk governance, ethical considerations in automated decision-making, and the need for explainable AI systems to ensure transparent risk evaluation and pricing models. This review highlights important research gaps by comparing academic studies with real-world industry implementations. It also explores emerging areas where AI can improve efficiency and drive innovation in the insurance sector. The insights gained from this work provide valuable guidance for researchers, policymakers, and insurance industry practitioners.",2025,10.3389/frai.2025.1568266
Disembodied AI and the limits to machine understanding of students' embodied interactions,"The embodiment turn in the Learning Sciences has fueled growth of multimodal learning analytics to understand embodied interactions and make consequential educational decisions about students more rapidly, more accurately, and more personalized than ever before. Managing demands of complexity and speed is leading to growing reliance by education systems on disembodied artificial intelligence (dAI) programs, which, ironically, are inherently incapable of interpreting students' embodied interactions. This is fueling a potential crisis of complexity. Augmented intelligence systems offer promising avenues for managing this crisis by integrating the strengths of omnipresent dAI to detect complex patterns of student behavior from multimodal datastreams, with the strengths of humans to meaningfully interpret embodied interactions in service of consequential decision making to achieve a balance between complexity, interpretability, and accountability for allocating education resources to children.",2023,10.3389/frai.2023.1148227
Ethics dumping in artificial intelligence,"Artificial Intelligence (AI) systems encode not just statistical models and complex algorithms designed to process and analyze data, but also significant normative baggage. This ethical dimension, derived from the underlying code and training data, shapes the recommendations given, behaviors exhibited, and perceptions had by AI. These factors influence how AI is regulated, used, misused, and impacts end-users. The multifaceted nature of AI’s influence has sparked extensive discussions across disciplines like Science and Technology Studies (STS), Ethical, Legal and Social Implications (ELSI) studies, public policy analysis, and responsible innovation—underscoring the need to examine AI’s ethical ramifications. While the initial wave of AI ethics focused on articulating principles and guidelines, recent scholarship increasingly emphasizes the practical implementation of ethical principles, regulatory oversight, and mitigating unforeseen negative consequences. Drawing from the concept of “ethics dumping” in research ethics, this paper argues that practices surrounding AI development and deployment can, unduly and in a very concerning way, offload ethical responsibilities from developers and regulators to ill-equipped users and host environments. Four key trends illustrating such ethics dumping are identified: (1) AI developers embedding ethics through coded value assumptions, (2) AI ethics guidelines promoting broad or unactionable principles disconnected from local contexts, (3) institutions implementing AI systems without evaluating ethical implications, and (4) decision-makers enacting ethical governance frameworks disconnected from practice. Mitigating AI ethics dumping requires empowering users, fostering stakeholder engagement in norm-setting, harmonizing ethical guidelines while allowing flexibility for local variation, and establishing clear accountability mechanisms across the AI ecosystem.",2024,10.3389/frai.2024.1426761
Segmentation of Lung Nodules on CT Images Using a Nested Three-Dimensional Fully Connected Convolutional Network,"In computer-aided diagnosis systems for lung cancer, segmentation of lung nodules is important for analyzing image features of lung nodules on computed tomography (CT) images and distinguishing malignant nodules from benign ones. However, it is difficult to accurately and robustly segment lung nodules attached to the chest wall or with ground-glass opacities using conventional image processing methods. Therefore, this study aimed to develop a method for robust and accurate three-dimensional (3D) segmentation of lung nodule regions using deep learning. In this study, a nested 3D fully connected convolutional network with residual unit structures was proposed, and designed a new loss function. Compared with annotated images obtained under the guidance of a radiologist, the Dice similarity coefficient (DS) and intersection over union (IoU) were 0.845 ± 0.008 and 0.738 ± 0.011, respectively, for 332 lung nodules (lung adenocarcinoma) obtained from 332 patients. On the other hand, for 3D U-Net and 3D SegNet, the DS was 0.822 ± 0.009 and 0.786 ± 0.011, respectively, and the IoU was 0.711 ± 0.011 and 0.660 ± 0.012, respectively. These results indicate that the proposed method is significantly superior to well-known deep learning models. Moreover, we compared the results obtained from the proposed method with those obtained from conventional image processing methods, watersheds, and graph cuts. The DS and IoU results for the watershed method were 0.628 ± 0.027 and 0.494 ± 0.025, respectively, and those for the graph cut method were 0.566 ± 0.025 and 0.414 ± 0.021, respectively. These results indicate that the proposed method is significantly superior to conventional image processing methods. The proposed method may be useful for accurate and robust segmentation of lung nodules to assist radiologists in the diagnosis of lung nodules such as lung adenocarcinoma on CT images.",2022,10.3389/frai.2022.782225
An AI-powered framework for assessing teacher performance in classroom interactions: a deep learning approach,"IntroductionTeacher performance evaluation is essential for improving instructional quality and guiding professional development, yet traditional observation-based methods can be subjective, labor-intensive, and inconsistently reliable. This study proposes an AI-powered framework to objectively assess classroom interactions.MethodsWe developed and evaluated a computer-vision framework using three state-of-the-art object detectors—YOLOv8, Faster R-CNN, and RetinaNet—to identify eleven classroom interaction categories. A labeled dataset of 7,259 images collected from real classroom settings was annotated and used for training and evaluation. Performance was assessed using mean Average Precision (mAP).ResultsYOLOv8 achieved the best performance among the evaluated models, with an mAP of 85.8%, indicating strong accuracy in detecting diverse classroom interactions. Faster R-CNN and RetinaNet performed competitively but were outperformed by YOLOv8.Discussion/ConclusionThe results demonstrate that modern deep learning–based detection can provide more objective and reliable insights into teacher–student interactions than traditional approaches. The proposed framework supports evidence-based evaluation and has the potential to enhance feedback and outcomes in educational practice.].",2025,10.3389/frai.2025.1553051
Enhancing diagnostic accuracy in symptom-based health checkers: a comprehensive machine learning approach with clinical vignettes and benchmarking,"IntroductionThe development of machine learning models for symptom-based health checkers is a rapidly evolving area with significant implications for healthcare. Accurate and efficient diagnostic tools can enhance patient outcomes and optimize healthcare resources. This study focuses on evaluating and optimizing machine learning models using a dataset of 10 diseases and 9,572 samples.MethodsThe dataset was divided into training and testing sets to facilitate model training and evaluation. The following models were selected and optimized: Decision Tree, Random Forest, Naive Bayes, Logistic Regression and K-Nearest Neighbors. Evaluation metrics included accuracy, F1 scores, and 10-fold cross-validation. ROC-AUC and precision-recall curves were also utilized to assess model performance, particularly in scenarios with imbalanced datasets. Clinical vignettes were employed to gauge the real-world applicability of the models.ResultsThe performance of the models was evaluated using accuracy, F1 scores, and 10-fold cross-validation. The use of ROC-AUC curves revealed that model performance improved with increasing complexity. Precision-recall curves were particularly useful in evaluating model sensitivity in imbalanced dataset scenarios. Clinical vignettes demonstrated the robustness of the models in providing accurate diagnoses.DiscussionThe study underscores the importance of comprehensive model evaluation techniques. The use of clinical vignette testing and analysis of ROC-AUC and precision-recall curves are crucial in ensuring the reliability and sensitivity of symptom-based health checkers. These techniques provide a more nuanced understanding of model performance and highlight areas for further improvement.ConclusionThis study highlights the significance of employing diverse evaluation metrics and methods to ensure the robustness and accuracy of machine learning models in symptom-based health checkers. The integration of clinical vignettes and the analysis of ROC-AUC and precision-recall curves are essential steps in developing reliable and sensitive diagnostic tools.",2024,10.3389/frai.2024.1397388
A Perspective on Building Ethical Datasets for Children's Conversational Agents,"Artificial intelligence (AI)-powered technologies are becoming an integral part of youth's environments, impacting how they socialize and learn. Children (12 years of age and younger) often interact with AI through conversational agents (e.g., Siri and Alexa) that they speak with to receive information about the world. Conversational agents can mimic human social interactions, and it is important to develop socially intelligent agents appropriate for younger populations. Yet it is often unclear what data are curated to power many of these systems. This article applies a sociocultural developmental approach to examine child-centric intelligent conversational agents, including an overview of how children's development influences their social learning in the world and how that relates to AI. Examples are presented that reflect potential data types available for training AI models to generate children's conversational agents' speech. The ethical implications for building different datasets and training models using them are discussed as well as future directions for the use of social AI-driven technology for children.",2021,10.3389/frai.2021.637532
"“Snake flu,” “killer bug,” and “Chinese virus”: A corpus-assisted critical discourse analysis of lexical choices in early UK press coverage of the COVID-19 pandemic","Now mostly known as “COVID-19” (or simply “Covid”), early discourse around the pandemic was characterized by a particularly large variation in naming choices (ranging from “new coronavirus” and “new respiratory disease” to “killer bug” and the racist term “Chinese virus”). The current study is situated within corpus-assisted discourse studies and analyses these naming choices in UK newspaper coverage (January–March 2020), focusing on terminology deemed “inappropriate” as per WHO guidelines on naming infectious diseases. The results show that 9% of all terms referring to COVID-19 or the virus causing it are “inappropriate” overall, with “inappropriate” naming being more prevalent (1) in tabloids than broadsheets and (2) in the period before compared to the period after the virus was officially named on 11th February, 2020. Selected examples within each of the categories of “inappropriate” names are explored in more detail [terms (1) inciting undue fear, (2) containing geographic locations, and (3) containing species of animals], and the findings are discussed with regard to the contribution of lexical choices to the reproduction of (racist and otherwise problematic) ideologies in mainstream media.",2022,10.3389/frai.2022.970972
Examining the impact of green technological specialization and the integration of AI technologies on green innovation performance: evidence from China,"China's commitment to achieving carbon neutrality by 2060 has sparked scholars' interest in examining the environmental ramifications of green technologies in the digital era. While plenty of them provide eco-efficiency policy such as increasing R&amp;D investment or stimulating green exports, little attention has been paid to the firm-level technological management and recombination strategies such as differentiation/specialization of green portfolios along with AI integration, which can significantly impact the pace of net-zero transitions. To address these gaps, this study investigates the moderating effect of technological specialization on levels of AI integration into green technologies estimated by green-AI technological distance and enterprises' innovation performance in Chinese contemporary contexts. Regression results of fixed-effect model in Chinese patent data (2011–2020) indicate that enterprises' green innovation performance is significantly improved as AI integrates more into the green technologies due to the legitimacy and the inability to appropriate more green values. Interestingly, specialized green-technological enterprises demonstrate superior performance in integrating distant AI technologies. This occurrence could potentially be driven by the governments' incentives and the organization's risk attitudes, shaping green innovation outcomes. Hence, the study underscores the importance of considering both the AI integration and green specialization in shaping innovation outcomes amidst green transitions.",2024,10.3389/frai.2023.1237285
Transparency of AI in Healthcare as a Multilayered System of Accountabilities: Between Legal Requirements and Technical Limitations,"The lack of transparency is one of the artificial intelligence (AI)'s fundamental challenges, but the concept of transparency might be even more opaque than AI itself. Researchers in different fields who attempt to provide the solutions to improve AI's transparency articulate different but neighboring concepts that include, besides transparency, explainability and interpretability. Yet, there is no common taxonomy neither within one field (such as data science) nor between different fields (law and data science). In certain areas like healthcare, the requirements of transparency are crucial since the decisions directly affect people's lives. In this paper, we suggest an interdisciplinary vision on how to tackle the issue of AI's transparency in healthcare, and we propose a single point of reference for both legal scholars and data scientists on transparency and related concepts. Based on the analysis of the European Union (EU) legislation and literature in computer science, we submit that transparency shall be considered the “way of thinking” and umbrella concept characterizing the process of AI's development and use. Transparency shall be achieved through a set of measures such as interpretability and explainability, communication, auditability, traceability, information provision, record-keeping, data governance and management, and documentation. This approach to deal with transparency is of general nature, but transparency measures shall be always contextualized. By analyzing transparency in the healthcare context, we submit that it shall be viewed as a system of accountabilities of involved subjects (AI developers, healthcare professionals, and patients) distributed at different layers (insider, internal, and external layers, respectively). The transparency-related accountabilities shall be built-in into the existing accountability picture which justifies the need to investigate the relevant legal frameworks. These frameworks correspond to different layers of the transparency system. The requirement of informed medical consent correlates to the external layer of transparency and the Medical Devices Framework is relevant to the insider and internal layers. We investigate the said frameworks to inform AI developers on what is already expected from them with regards to transparency. We also discover the gaps in the existing legislative frameworks concerning AI's transparency in healthcare and suggest the solutions to fill them in.",2022,10.3389/frai.2022.879603
Short-Term Nationwide Airport Throughput Prediction With Graph Attention Recurrent Neural Network,"With the dynamic air traffic demand and the constrained capacity resources, accurately predicting airport throughput is essential to ensure the efficiency and resilience of air traffic operations. Many research efforts have been made to predict traffic throughputs or flight delays at an airport or over a network. However, it is still a challenging problem due to the complex spatiotemporal dynamics of the highly interacted air transportation systems. To address this challenge, we propose a novel deep learning model, graph attention neural network stacking with a Long short-term memory unit (GAT-LSTM), to predict the short-term airport throughput over a national air traffic network. LSTM layers are included to extract the temporal correlations in the data, while the graph attention mechanism is used to capture the spatial dependencies. For the graph attention mechanism, two graph modeling methods, airport-based graph and OD-pair graph are explored in this study. We tested the proposed model using real-world air traffic data involving 65 major airports in China over 3 months in 2017 and compared its performance with other state-of-the-art models. Results showed that the temporal pattern was the dominate factor, compared to the spatial pattern, in predicting airport throughputs over an air traffic network. Among the prediction models that we compared, both the proposed model and LSTM performed well on prediction accuracy over the entire network. Better performance of the proposed model was observed when focusing on airports with larger throughputs. We also conducted an analysis on model interpretability. We found that spatiotemporal correlations in the data were learned and shown via the model parameters, which helped us to gain insights into the topology and the dynamics of the air traffic network.",2022,10.3389/frai.2022.884485
MedAlmighty: enhancing disease diagnosis with large vision model distillation,"IntroductionAccurate disease diagnosis is critical in the medical field, yet it remains a challenging task due to the limited, heterogeneous, and complex nature of medical data. These challenges are particularly pronounced in multimodal tasks requiring the integration of diverse data sources. While lightweight models offer computational efficiency, they often lack the comprehensive understanding necessary for reliable clinical predictions. Conversely, large vision models, trained on extensive general-domain datasets, provide strong generalization but fall short in specialized medical applications due to domain mismatch and limited medical data availability.MethodsTo bridge the gap between general and specialized performance, we propose MedAlmighty, a knowledge distillation-based framework that synergizes the strengths of both large and small models. In this approach, we utilize DINOv2—a pre-trained large vision model—as a frozen teacher, and a lightweight convolutional neural network (CNN) as the trainable student. The student model is trained using both hard labels from the ground truth and soft targets generated by the teacher model. We adopt a hybrid loss function that combines cross-entropy loss (for classification accuracy) and Kullback-Leibler divergence (for distillation), enabling the student model to capture rich semantic features while remaining efficient and domain-aware.ResultsExperimental evaluations reveal that MedAlmighty significantly improves disease diagnosis performance across datasets characterized by sparse and diverse medical data. The proposed model outperforms baselines by effectively integrating the generalizable representations of large models with the specialized knowledge from smaller models. The results confirm improved robustness and accuracy in complex diagnostic scenarios.DiscussionThe MedAlmighty framework demonstrates that incorporating general-domain representations via frozen large vision models—when guided by task-specific distillation strategies—can enhance the performance of lightweight medical models. This approach offers a promising solution to data scarcity and domain gap issues in medical imaging. Future work may explore extending this distillation strategy to other medical modalities and incorporating multimodal alignment for even richer representation learning.",2025,10.3389/frai.2025.1527980
Systematic analysis of hepatotoxicity: combining literature mining and AI language models,"BackgroundThe body of toxicological knowledge and literature is expanding at an accelerating pace. This rapid growth presents significant challenges for researchers, who must stay abreast with latest studies while also synthesizing the vast amount of published information.GoalOur goal is to automatically identify potential hepatoxicants from over 50,000 compounds using the wealth of scientific publications and knowledge.MethodsWe employ and compare three distinct methods for automatic information extraction from unstructured text: (1) text mining (2) word embeddings and (3) large language models. These approaches are combined to calculate a hepatotoxicity score for over 50,000 compounds. We assess the performance of the different methods with a use case on Drug-Induced Liver Injury (DILI).ResultsWe evaluated hepatotoxicity for over 50,000 compounds and calculated a hepatotoxicity score for each compound. Our results indicate that text mining is effective for this purpose, achieving an Area Under the Curve (AUC) of 0.8 in DILI validation. Large language models performed even better, with an AUC of 0.85, thanks to their ability to interpret the semantic context accurately. Combining these methods further improved performance, yielding an AUC of 0.87 in DILI validation. All findings are available for download to support further research on toxicity assessment.ConclusionsWe demonstrated that automated text mining is able to successfully assess the toxicity of compounds. A text mining approach seems to be superior to word embeddings. However, the application of a large language model with prompt engineering showed the best performance.",2025,10.3389/frai.2025.1561292
Machine learning techniques for predicting neurodevelopmental impairments in premature infants: a systematic review,"Background and objectiveVery preterm infants are highly susceptible to Neurodevelopmental Impairments (NDIs), including cognitive, motor, and language deficits. This paper presents a systematic review of the application of Machine Learning (ML) techniques to predict NDIs in premature infants.MethodsThis review presents a comparative analysis of existing studies from January 2018 to December 2023, highlighting their strengths, limitations, and future research directions.ResultsWe identified 26 studies that fulfilled the inclusion criteria. In addition, we explore the potential of ML algorithms and discuss commonly used data sources, including clinical and neuroimaging data. Furthermore, the inclusion of omics data as a contemporary approach employed, in other diagnostic contexts is proposed.ConclusionsWe identified limitations and emphasized the significance of employing multimodal data models and explored various alternatives to address the limitations identified in the reviewed studies. The insights derived from this review guide researchers and clinicians toward improving early identification and intervention strategies for NDIs in this vulnerable population.",2025,10.3389/frai.2025.1481338
Enhanced fingerprint classification through modified PCA with SVD and invariant moments,"This research introduces a novel MOMENTS-SVD vector for fingerprint identification, combining invariant moments and SVD (Singular Value Decomposition), enhanced by a modified PCA (Principal Component Analysis). Our method extracts unique fingerprint features using SVD and invariant moments, followed by classification with Euclidean distance and neural networks. The MOMENTS-SVD vector reduces computational complexity by outperforming current models. Using the Equal Error Rate (EER) and ROC curve, a comparative study across databases (CASIA V5, FVC 2002, 2004, 2006) assesses our method against ResNet, VGG19, Neuro Fuzzy, DCT Features, and Invariant Moments, proving enhanced accuracy and robustness.",2024,10.3389/frai.2024.1433494
Enhancing accessibility: a multi-level platform for visual question answering in diabetic retinopathy for individuals with disabilities,"Individuals with visual disabilities possess impairments that affect their ability to perceive visual information, ranging from partial to complete vision loss. Visual disabilities affect about 2.2 billion people globally. In this paper, we introduce a new multi-level Visual Questioning Answering (VQA) framework for visually disabled people that leverages the strengths of various VQA models of the multi-level components to enhance system performance. The model relies on a bi-level architecture that employs two distinct layers. In the first level, the model classifies the question type. This classification guides the visual question to the appropriate component model in the second level. This bi-level architecture incorporates a switch function that enables the system to select the optimal VQA model for each specific question, hence enhancing overall accuracy. The experimental findings indicate that the multi-level VQA technique is significantly effective. The bi-level VQA model enhances the overall accuracy over the state-of-the-art from 87.41% to 88.41%. This finding suggests the use of multiple levels with different models can boost the VQA systems' performance. This research presents a promising direction for developing advanced, multi-level VQA systems. Future work may explore optimizing and experimenting with various model levels to enhance performance further.",2025,10.3389/frai.2025.1646176
Topological Data Analysis of C. elegans Locomotion and Behavior,"We apply topological data analysis to the behavior of C. elegans, a widely studied model organism in biology. In particular, we use topology to produce a quantitative summary of complex behavior which may be applied to high-throughput data. Our methods allow us to distinguish and classify videos from various environmental conditions and we analyze the trade-off between accuracy and interpretability. Furthermore, we present a novel technique for visualizing the outputs of our analysis in terms of the input. Specifically, we use representative cycles of persistent homology to produce synthetic videos of stereotypical behaviors.",2021,10.3389/frai.2021.668395
Behind the Leaves: Estimation of Occluded Grapevine Berries With Conditional Generative Adversarial Networks,"The need for accurate yield estimates for viticulture is becoming more important due to increasing competition in the wine market worldwide. One of the most promising methods to estimate the harvest is berry counting, as it can be approached non-destructively, and its process can be automated. In this article, we present a method that addresses the challenge of occluded berries with leaves to obtain a more accurate estimate of the number of berries that will enable a better estimate of the harvest. We use generative adversarial networks, a deep learning-based approach that generates a highly probable scenario behind the leaves exploiting learned patterns from images with non-occluded berries. Our experiments show that the estimate of the number of berries after applying our method is closer to the manually counted reference. In contrast to applying a factor to the berry count, our approach better adapts to local conditions by directly involving the appearance of the visible berries. Furthermore, we show that our approach can identify which areas in the image should be changed by adding new berries without explicitly requiring information about hidden areas.",2022,10.3389/frai.2022.830026
Radical Knowledge Management: Using Lessons Learned From Artists to Create Sustainable Workplaces,"This study weaves together research that has been published over the last 20 years and creates a narrative about how we can change our organisations so that they are fit-for-purpose in the 21st century. Using knowledge management as the starting point, the question “How do we move forward in a sustainable, holistic way to create organisations that are healthy and balanced among social, environmental, and financial performance (triple bottom line)?” needs to be answered. This brand new form of knowledge management is called radical knowledge management (radical KM).",2021,10.3389/frai.2021.598807
Co-Learning: code learning for multi-agent reinforcement collaborative framework with conversational natural language interfaces,"Online question-and-answer (Q&amp;A) systems based on the Large Language Model (LLM) have progressively diverged from recreational to professional use. However, beginners in programming often struggle to correct code errors independently, limiting their learning efficiency. This paper proposed a Multi-Agent framework with environmentally reinforcement learning (E-RL) for code correction called Code Learning (Co-Learning) community, assisting beginners to correct code errors independently. It evaluates the performance of multiple LLMs from an original dataset with 702 error codes, uses it as a reward or punishment criterion for E-RL; Analyzes input error codes by the current agent; selects the appropriate LLM-based agent to achieve optimal error correction accuracy and reduce correction time. Experiment results showed that 3% improvement in Precision score and 15% improvement in time cost as compared with no E-RL method respectively. The results indicate that integrating E-RL with a multi-agent selection strategy can effectively enhance both the accuracy and efficiency of LLM-based code correction systems, making them more practical for educational and professional programming support scenarios.",2025,10.3389/frai.2025.1431003
Development of machine learning algorithms to predict viral load suppression among HIV patients in Conakry (Guinea),"BackgroundViral load (VL) suppression is key to ending the global HIV epidemic, and predicting it is critical for healthcare providers and people living with HIV (PLHIV). Traditional research has focused on statistical analysis, but machine learning (ML) is gradually influencing HIV clinical care. While ML has been used in various settings, there’s a lack of research supporting antiretroviral therapy (ART) programs, especially in resource-limited settings like Guinea. This study aims to identify the most predictive variables of VL suppression and develop ML models for PLHIV in Conakry (Guinea).MethodsAnonymized data from HIV patients in eight Conakry health facilities were pre-processed, including variable recoding, record removal, missing value imputation, grouping small categories, creating dummy variables, and oversampling the smallest target class. Support vector machine (SVM), logistic regression (LR), naïve Bayes (NB), random forest (RF), and four stacked models were developed. Optimal parameters were determined through two cross-validation loops using a grid search approach. Sensitivity, specificity, predictive positive value (PPV), predictive negative value (PNV), F-score, and area under the curve (AUC) were computed on unseen data to assess model performance. RF was used to determine the most predictive variables.ResultsRF (94% F-score, 82% AUC) and NB (89% F-score, 82% AUC) were the most optimal models to detect VL suppression and non-suppression when applied to unseen data. The optimal parameters for RF were 1,000 estimators and no maximum depth (Random state = 40), and it identified Regimen schedule_6-Month, Duration on ART (months), Last ART CD4, Regimen schedule_Regular, and Last Pre-ART CD4 as top predictors for VL suppression.ConclusionThis study demonstrated the capability to predict VL suppression but has some limitations. The results are dependent on the quality of the data and are specific to the Guinea context and thus, there may be limitations with generalizability. Future studies may be to conduct a similar study in a different context and develop the most optimal model into an application that can be tested in a clinical context.",2025,10.3389/frai.2025.1446876
Leveraging psychedelic neuroscience to boost human creativity using artificial intelligence,"Psychedelics, such as LSD and psilocybin, disrupt entrenched cognitive patterns by facilitating novel insights and new associations. This paper considers how AI can potentially mimic these psychedelic-induced cognitive disruptions to augment and enhance human creativity. Psychedelics likely enhance creativity by altering brain function, notably the activity of the Default Mode Network, which leads to changes in cognition. Psychologically, they may reduce latent inhibition, increase divergent thinking, and promote implicit learning. Similarly, AI systems can replicate these creative enhancements by introducing novel associations, reframing familiar information, and facilitating unconscious cognitive shifts. The risks associated with AI use are also compared to psychedelics, including dependency, ethical concerns, and homogenization of outputs due to bias. Integrating the cognitive mechanisms activated by psychedelics into AI design provides promising pathways for creativity enhancement. Carefully designed AI could act as a cognitive catalyst, fostering innovative thought processes and adaptive problem-solving while addressing identified ethical and practical concerns.",2025,10.3389/frai.2025.1589086
A machine learning framework to classify musculoskeletal injury risk groups in military service members,"BackgroundMusculoskeletal injuries (MSKIs) are endemic in military populations. Thus, it is essential to identify and mitigate MSKI risks. Time-to-event machine learning models utilizing self-reported questionnaires or existing data (e.g., electronic health records) may aid in creating efficient risk screening tools.MethodsA total of 4,222 U.S. Army Service members completed a self-report MSKI risk screen as part of their unit's standard in-processing. Additionally, participants' MSKI and demographic data were abstracted from electronic health record data. Survival machine learning models (Cox proportional hazard regression (COX), COX with splines, conditional inference trees, and random forest) were deployed to develop a predictive model on the training data (75%; n = 2,963) for MSKI risk over varying time horizons (30, 90, 180, and 365 days) and were evaluated on the testing data (25%; n = 987). Probability of predicted risk (0.00–1.00) from the final model stratified Service members into quartiles based on MSKI risk.ResultsThe COX model demonstrated the best model performance over the time horizons. The time-dependent area under the curve ranged from 0.73 to 0.70 at 30 and 180 days. The index prediction accuracy (IPA) was 12% better at 180 days than the IPA of the null model (0 variables). Within the COX model, “other” race, more self-reported pain items during the movement screens, female gender, and prior MSKI demonstrated the largest hazard ratios. When predicted probability was binned into quartiles, at 180 days, the highest risk bin had an MSKI incidence rate of 2,130.82 ± 171.15 per 1,000 person-years and incidence rate ratio of 4.74 (95% confidence interval: 3.44, 6.54) compared to the lowest risk bin.ConclusionSelf-reported questionnaires and existing data can be used to create a machine learning algorithm to identify Service members' MSKI risk profiles. Further research should develop more granular Service member-specific MSKI screening tools and create MSKI risk mitigation strategies based on these screenings.",2024,10.3389/frai.2024.1420210
"More polished, not necessarily more learned: LLMs and perceived text quality in higher education","The use of Large Language Models (LLMs) such as ChatGPT is a prominent topic in higher education, prompting debate over their educational impact. Studies on the effect of LLMs on learning in higher education often rely on self-reported data, leaving an opening for complimentary methodologies. This study contributes by analysing actual course grades as well as ratings by fellow students to investigate how LLMs can affect academic outcomes. We investigated whether using LLMs affected students’ learning by allowing them to choose one of three options for a written assignment: (1) composing the text without LLM assistance; (2) writing a first draft and using an LLM for revisions; or (3) generating a first draft with an LLM and then revising it themselves. Students’ learning was measured by their scores on a mid-course exam and final course grades. Additionally, we assessed how the students rate the quality of fellow students’ texts for each of the three conditions. Finally we examined how accurately fellow students could identify which LLM option (1–3) was used for a given text. Our results indicate only a weak effect of LLM use. However, writing a first draft and using an LLM for revisions compared favourably to the ‘no LLM’ baseline in terms of final grades. Ratings for fellow students’ texts was higher for texts created using option 3, specifically regarding how well-written they were judged to be. Regarding text classification, students most accurately predicted the ‘no LLM’ baseline, but were unable to identify texts that were generated by an LLM and then edited by a student at a rate better than chance.",2025,10.3389/frai.2025.1653992
Political ideology shapes support for the use of AI in policy-making,"In a world grappling with technological advancements, the concept of Artificial Intelligence (AI) in governance is becoming increasingly realistic. While some may find this possibility incredibly alluring, others may see it as dystopian. Society must account for these varied opinions when implementing new technologies or regulating and limiting them. This study (N = 703) explored Leftists’ (liberals) and Rightists’ (conservatives) support for using AI in governance decision-making amidst an unprecedented political crisis that washed through Israel shortly after the proclamation of the government’s intentions to initiate reform. Results indicate that Leftists are more favorable toward AI in governance. While legitimacy is tied to support for using AI in governance among both, Rightists’ acceptance is also tied to perceived norms, whereas Leftists’ approval is linked to perceived utility, political efficacy, and warmth. Understanding these ideological differences is crucial, both theoretically and for practical policy formulation regarding AI’s integration into governance.",2024,10.3389/frai.2024.1447171
First impressions of a financial AI assistant: differences between high trust and low trust users,"Calibrating appropriate trust of non-expert users in artificial intelligence (AI) systems is a challenging yet crucial task. To align subjective levels of trust with the objective trustworthiness of a system, users need information about its strengths and weaknesses. The specific explanations that help individuals avoid over- or under-trust may vary depending on their initial perceptions of the system. In an online study, 127 participants watched a video of a financial AI assistant with varying degrees of decision agency. They generated 358 spontaneous text descriptions of the system and completed standard questionnaires from the Trust in Automation and Technology Acceptance literature (including perceived system competence, understandability, human-likeness, uncanniness, intention of developers, intention to use, and trust). Comparisons between a high trust and a low trust user group revealed significant differences in both open-ended and closed-ended answers. While high trust users characterized the AI assistant as more useful, competent, understandable, and humanlike, low trust users highlighted the system's uncanniness and potential dangers. Manipulating the AI assistant's agency had no influence on trust or intention to use. These findings are relevant for effective communication about AI and trust calibration of users who differ in their initial levels of trust.",2023,10.3389/frai.2023.1241290
Enhancing structured data generation with GPT-4o evaluating prompt efficiency across prompt styles,"Large language models (LLMs), such as GPT-4o, provide versatile techniques for generating and formatting structured data. However, prompt style plays a critical role in determining the accuracy, efficiency, and token cost of the generated outputs. This paper explores the effectiveness of three specific prompt styles–JSON, YAML, and Hybrid CSV/Prefix–for structured data generation across diverse applications. We focus on scenarios such as personal stories, receipts, and medical records, using randomized datasets to evaluate each prompt style's impact. Our analysis examines these prompt styles across three key metrics: accuracy in preserving data attributes, token cost associated with output generation, and processing time required for completion. By incorporating structured validation and comparative analysis, we ensure precise evaluation of each prompt style's performance. Results are visualized through metrics-based comparisons, such as Prompt Style vs. Accuracy, Prompt Style vs. Token Cost, and Prompt Style vs. Processing Time. Our findings reveal trade-offs between prompt style complexity and performance, with JSON providing high accuracy for complex data, YAML offering a balance between readability and efficiency, and Hybrid CSV/Prefix excelling in token and time efficiency for flat data structures. This paper explores the pros and cons of applying the GPT-4o LLM to generate structured data. It also provides practical recommendations for selecting prompt styles tailored to specific requirements, such as data integrity, cost-effectiveness, and real-time processing needs. Our findings contribute to research on how prompt engineering can optimize structured data generation for AI-driven applications, as well as documenting limitations that motivate future work needed to improve LLMs for complex tasks.",2025,10.3389/frai.2025.1558938
Transfer learning-based hybrid VGG16-machine learning approach for heart disease detection with explainable artificial intelligence,"Heart disease is a leading cause of mortality worldwide, making accurate early detection essential for effective treatment and management. This study introduces a novel hybrid machine-learning approach that combines transfer learning using the VGG16 convolutional neural network (CNN) with various machine-learning classifiers for heart disease detection. A conditional tabular generative adversarial network (CTGAN) was employed to generate synthetic data samples from actual datasets; these were evaluated using statistical metrics, correlation analysis, and domain expert assessments to ensure the quality of the synthetic datasets. The dataset comprises tabular data with 13 features, which are reshaped into an image-like format and resized to 224x224x3 to meet the input requirements of the VGG16 model. Feature extraction is performed using VGG16, and the extracted features are then fused with the original tabular data. This combined feature set is then used to train various machine learning models, including Support Vector Machines (SVM), Gradient Boosting, Random Forest, Logistic Regression, K-nearest neighbors (KNN), and Decision Trees. Among these models, the VGG16-Random Forest hybrid achieved notable results across all evaluation metrics, including 92% accuracy, 91.3% precision, 92.2% recall, 91.82% specificity, 92.2% sensitivity, and 91.75% F1-score. The hybrid models were also evaluated using unseen datasets to assess the generalizability of the proposed approaches, with the VGG16-Random Forest combination showing relatively promising results. Additionally, explainability is integrated into the model using SHAP values, providing insights into the contribution of each feature to the model’s predictions. This hybrid VGG16-ML approach demonstrates the potential for highly accurate and interpretable heart disease detection, offering valuable support in clinical decision-making processes.",2025,10.3389/frai.2025.1504281
Masking important information to assess the robustness of a multimodal classifier for emotion recognition,"Deep neural networks have been proven effective in classifying human interactions into emotions, especially by encoding multiple input modalities. In this work, we assess the robustness of a transformer-based multimodal audio-text classifier for emotion recognition, by perturbing the input at inference time using attacks which we design specifically to corrupt information deemed important for emotion recognition. To measure the impact of the attacks on the classifier, we compare between the accuracy of the classifier on the perturbed input and on the original, unperturbed input. Our results show that the multimodal classifier is more resilient to perturbation attacks than the equivalent unimodal classifiers, suggesting that the two modalities are encoded in a way that allows the classifier to benefit from one modality even when the other one is slightly damaged.",2023,10.3389/frai.2023.1091443
Legal linguistic templates and the tension between legal knowledge representation and reasoning,"There is an inherent tension between knowledge representation and reasoning. For an optimal representation and validation, an expressive language should be used. For an optimal automated reasoning, a simple one is preferred. Which language should we choose for our legal knowledge representation if our goal is to apply automated legal reasoning? In this paper, we investigate the properties and requirements of each of these two applications. We suggest that by using Legal Linguistic Templates, one can solve the above tension in some practical situations.",2023,10.3389/frai.2023.1136263
Interpretable neural networks: principles and applications,"In recent years, with the rapid development of deep learning technology, great progress has been made in computer vision, image recognition, pattern recognition, and speech signal processing. However, due to the black-box nature of deep neural networks (DNNs), one cannot explain the parameters in the deep network and why it can perfectly perform the assigned tasks. The interpretability of neural networks has now become a research hotspot in the field of deep learning. It covers a wide range of topics in speech and text signal processing, image processing, differential equation solving, and other fields. There are subtle differences in the definition of interpretability in different fields. This paper divides interpretable neural network (INN) methods into the following two directions: model decomposition neural networks, and semantic INNs. The former mainly constructs an INN by converting the analytical model of a conventional method into different layers of neural networks and combining the interpretability of the conventional model-based method with the powerful learning capability of the neural network. This type of INNs is further classified into different subtypes depending on which type of models they are derived from, i.e., mathematical models, physical models, and other models. The second type is the interpretable network with visual semantic information for user understanding. Its basic idea is to use the visualization of the whole or partial network structure to assign semantic information to the network structure, which further includes convolutional layer output visualization, decision tree extraction, semantic graph, etc. This type of method mainly uses human visual logic to explain the structure of a black-box neural network. So it is a post-network-design method that tries to assign interpretability to a black-box network structure afterward, as opposed to the pre-network-design method of model-based INNs, which designs interpretable network structure beforehand. This paper reviews recent progress in these areas as well as various application scenarios of INNs and discusses existing problems and future development directions.",2023,10.3389/frai.2023.974295
Exploring the role of generative AI in international students’ sociocultural adaptation: a cognitive-affective model,"Against the backdrop of increasing global educational exchanges, the sociocultural adaptation of international students has attracted significant attention. The rise of Generative Artificial Intelligence has brought new perspectives to research in this field, yet existing studies have insufficiently explored the mechanisms through which GenAI influences the sociocultural adaptation of international students. Drawing on the cognitive-affective personality system theory and conservation of resources theory, this study employed a three-stage time-lagged questionnaire survey to collect 329 valid responses from international students at three universities in North, South, and East China. The research aims to investigate how GenAI use impacts students’ sociocultural adaptation, while examining the mediating roles of positive reappraisal and perceived empathy, as well as the moderating effect of AI anthropomorphism. The findings reveal that GenAI use is significantly positively associated with international students’ sociocultural adaptation. Positive reappraisal and users’ subjective perceived empathy mediate the relationship between GenAI use and sociocultural adaptation. Additionally, the degree of AI anthropomorphism positively moderates the relationships between GenAI use and both positive reappraisal and perceived empathy, enhancing the indirect effects of these mediating variables on the relationship between GenAI use and sociocultural adaptation. This study enriches the technological premises of cross-cultural adaptation for international students and provides GenAI-based intervention strategies for their educational management.",2025,10.3389/frai.2025.1615113
On the use of sentiment analysis for linguistics research. Observations on sentiment polarity and the use of the progressive in Italian,"This article offers a conceptual and methodological contribution to linguistics by exploring the potential value of using sentiment analysis (SA) for research in this field. Firstly, it discusses the limitations and advantages of using SA for linguistics research including the wider epistemological implications of its application outside of its original conception as a product reviews analysis tool. Methodologically, it tests its applicability against an established linguistic case: the correlation between subjective attitudes such as surprise, irritation and discontent and the use of the progressive. The language example is Italian for which this function of the progressive form has not been analyzed yet. The analysis applies FEEL-IT, a state-of-the-art transformer-based machine learning model for emotion and sentiment classification in Italian on language samples from various sources as collected in Evalita-2014 (238,556 words). The results show statistically significant correlations between negative subjective attitudes and the use of the progressive in line with previous accounts in other languages. The article concludes with a few additional propositions for practitioners and researchers using SA.",2023,10.3389/frai.2023.1101364
A hybrid framework for enhanced segmentation and classification of colorectal cancer histopathology,"IntroductionColorectal cancer (CRC) remains one of the leading causes of cancer-related deaths globally. Early detection and precise diagnosis are crucial in improving patient outcomes. Traditional histological evaluation through manual inspection of stained tissue slides is time-consuming, prone to observer variability, and susceptible to inconsistent diagnoses.MethodsTo address these challenges, we propose a hybrid deep learning system combining Swin Transformer, EfficientNet, and ResUNet-A. This model integrates self-attention, compound scaling, and residual learning to enhance feature extraction, global context modeling, and spatial categorization. The model was trained and evaluated using a histopathological dataset that included serrated adenoma, polyps, adenocarcinoma, high-grade and low-grade intraepithelial neoplasia, and normal tissues.ResultsOur hybrid model achieved impressive results, with 93% accuracy, 92% precision, 93% recall, and 93% F1-score. It outperformed individual architectures in both segmentation and classification tasks. Expert annotations and segmentation masks closely matched, demonstrating the model’s reliability.DiscussionThe proposed hybrid design proves to be a robust tool for the automated analysis of histopathological features in CRC, showing significant promise for improving diagnostic accuracy and efficiency in clinical settings.",2025,10.3389/frai.2025.1647074
Data-driven pit stop decision support for Formula 1 using deep learning models,"In Formula 1, which is among the most competitive motorsports in the world, the timing of a pit stop can make the difference between winning and losing a race. Conventional methods based on human judgment can be erratic, especially in rapidly changing race conditions. This work proposes a datadriven framework based on deep learning models to predict optimal pit stop timings using raw telemetry data extracted from FastF1 API. To improve the robustness of the models, advanced preprocessing techniques such as normalization, imputation, and class balancing with Synthetic Minority Over-sampling Technique (SMOTE) were implemented. Five different deep learning architectures, including Bi-LSTM, TCN-GRU, GRU, InceptionTime, and CNN-BiLSTM, were trained and evaluated employing precision, recall, and F1-score as metrics. Of these, the Bi-LSTM model achieved the overall best performance which can be explained by its capability to model long-range dependencies in both forward and backward temporal directions. The Bi-LSTM achieved a precision of 0.77, recall of 0.86, and an F1-score of 0.81 on the test set, demonstrating strong predictive accuracy under real-race conditions. Additionally, a historical race visualization interface was developed to visualize the model's predictions.",2025,10.3389/frai.2025.1673148
Opinions and attitudes toward artificial intelligence among operating room nurses: a descriptive meta-analysis based on the comparative studies of the different opinions,"Background
                    Artificial intelligence (AI) is defined as the capability of machines to perform tasks that typically require human intelligence. Robots have major roles during surgeries as well as in the operating rooms (ORs). Therefore, it is expected for nurses working in ORs to be knowledgeable about those new technologies and the preparation of robots for surgeries. In this analysis, we aimed to represent the opinions and attitudes of ORs nurses toward AI.
                  
                  
                    Methods
                    Online databases were searched for relevant publications. AI based questions were asked to the ORs nurses and the percentage of participants who agreed or disagreed to specific questions were recorded. The RevMan application was used to carry out statistical analysis, whereby odds ratios (OR) and 95% confidence intervals (CI) were used to represent the results.
                  
                  
                    Results
                    
                      Six studies consisting of a total number of 1,197 participants were included. ORs nurses believe that AI and robotic nursing applications will significantly reduce the workload of nurses with OR: 75.73, 95% CI: 8.28–692.86;
                      p
                       = 0.0001. In addition, a majority of ORs nurses significantly accepted the application of AI in nursing (OR: 63.70, 95% CI: 2.15–1890.57;
                      p
                       = 0.02) and significantly believed that AI will revolutionize in the field of nursing (OR: 15.27, 95% CI: 3.47–67.15;
                      p
                       = 0.0003). In addition, they significantly agreed that robotic technologies are very important (OR: 12.57, 95% CI: 6.44–24.54;
                      p
                       = 0.00001). The ORs nurses significantly disagreed to the fact that robotic technologies are too expensive and unnecessary (OR: 0.02, 95% CI: 0.01–0.04;
                      p
                       = 0.00001). Nevertheless, even though majority of the ORs nurses agree that robotic checking system is time consuming, the result was not significant (OR: 1.38, 95% CI: 0.79–2.40;
                      p
                       = 0.26).
                    
                  
                  
                    Conclusion
                    Majority of the nurses believe that AI and robotic nursing applications will significantly reduce the workload of nurses, they believe that AI will significantly revolutionize in the field of nursing, and they believe that robotic technologies are very important. However, due to the several limitations from this analysis, the results should be considered with caution.",2025,10.3389/frai.2025.1681994
From service design thinking to the third generation of activity theory: a new model for designing AI-based decision-support systems,"IntroductionThe rise of Artificial Intelligence (AI), particularly machine learning, has brought a significant transformation in decision-making (DM) processes within organizations, with AI gradually assuming responsibilities that were traditionally performed by humans. However, as shown by recent findings, the acceptance of AI-based solutions in DM remains a concern as individuals still strongly prefer human intervention. This resistance can be attributed to psychological factors and other trust-related issues. To address these challenges, recent studies show that practical guidelines for user-centered design of AI are needed to promote justified trust in AI-based systems.Methods and resultsTo this aim, our study bridges Service Design Thinking and the third generation of Activity Theory to create a model which serves as a set of practical guidelines for the user centered design of Multi-Actor AI-based DSS. This model is created through the qualitative study of human activity as a unit of analysis. Nevertheless, it holds the potential for further enhancement through the application of quantitative methods to explore its diverse dimensions more extensively. As an illustrative example, we used a case study in the field of human capital investments, with a particular focus on organizational development, which involves managers, professionals, coaches and other significant actors. As a result, the qualitative methodology employed in our study can be characterized as a “pre-quantitative” investigation.DiscussionThis framework aims at locating the contribution of AI in complex human activity and identifying the potential role of quantitative data in it.",2024,10.3389/frai.2024.1303691
What Makes Artificial Intelligence Exceptional in Health Technology Assessment?,"The application of artificial intelligence (AI) may revolutionize the healthcare system, leading to enhance efficiency by automatizing routine tasks and decreasing health-related costs, broadening access to healthcare delivery, targeting more precisely patient needs, and assisting clinicians in their decision-making. For these benefits to materialize, governments and health authorities must regulate AI, and conduct appropriate health technology assessment (HTA). Many authors have highlighted that AI health technologies (AIHT) challenge traditional evaluation and regulatory processes. To inform and support HTA organizations and regulators in adapting their processes to AIHTs, we conducted a systematic review of the literature on the challenges posed by AIHTs in HTA and health regulation. Our research question was: What makes artificial intelligence exceptional in HTA? The current body of literature appears to portray AIHTs as being exceptional to HTA. This exceptionalism is expressed along 5 dimensions: 1) AIHT’s distinctive features; 2) their systemic impacts on health care and the health sector; 3) the increased expectations towards AI in health; 4) the new ethical, social and legal challenges that arise from deploying AI in the health sector; and 5) the new evaluative constraints that AI poses to HTA. Thus, AIHTs are perceived as exceptional because of their technological characteristics and potential impacts on society at large. As AI implementation by governments and health organizations carries risks of generating new, and amplifying existing, challenges, there are strong arguments for taking into consideration the exceptional aspects of AIHTs, especially as their impacts on the healthcare system will be far greater than that of drugs and medical devices. As AIHTs begin to be increasingly introduced into the health care sector, there is a window of opportunity for HTA agencies and scholars to consider AIHTs’ exceptionalism and to work towards only deploying clinically, economically, socially acceptable AIHTs in the health care system.",2021,10.3389/frai.2021.736697
Knowledge and attitudes of medical students in Lebanon toward artificial intelligence: A national survey study,"PurposeThis study assesses the knowledge and attitudes of medical students in Lebanon toward Artificial Intelligence (AI) in medical education. It also explores the students' perspectives regarding the role of AI in medical education as a subject in the curriculum and a teaching tool.MethodsThis is a cross-sectional study using an online survey consisting of close-ended questions. The survey targets medical students at all medical levels across the 7 medical schools in Lebanon.ResultsA total of 206 medical students responded. When assessing AI knowledge sources (81.1%) got their information from the media as compared to (9.7%) from medical school curriculum. However, Students who learned the basics of AI as part of the medical school curriculum were more knowledge about AI than their peers who did not. Students in their clinical years appear to be more knowledgeable about AI in medicine. The advancements in AI affected the choice of specialty of around a quarter of the students (26.8%). Finally, only a quarter of students (26.5%) want to be assessed by AI, even though the majority (57.7%) reported that assessment by AI is more objective.ConclusionsEducation about AI should be incorporated in the medical school curriculum to improve the knowledge and attitudes of medical students. Improving AI knowledge in medical students will in turn increase acceptance of AI as a tool in medical education, thus unlocking its potential in revolutionizing medical education.",2022,10.3389/frai.2022.1015418
Developing and validating a drug recommendation system based on tumor microenvironment and drug fingerprint,"IntroductionTumor heterogeneity significantly complicates the selection of effective cancer treatments, as patient responses to drugs can vary widely. Personalized cancer therapy has emerged as a promising strategy to enhance treatment effectiveness and precision. This study aimed to develop a personalized drug recommendation model leveraging genomic profiles to optimize therapeutic outcomes.MethodsA content-based filtering algorithm was implemented to predict drug sensitivity. Patient features were characterized by the tumor microenvironment (TME), and drug features were represented by drug fingerprints. The model was trained and validated using the Genomics of Drug Sensitivity in Cancer (GDSC) database, followed by independent validation with the Cancer Cell Line Encyclopedia (CCLE) dataset. Clinical application was assessed using The Cancer Genome Atlas (TCGA) dataset, with Best Overall Response (BOR) serving as the clinical efficacy measure. Two multilayer perceptron (MLP) models were built to predict IC50 values for 542 tumor cell lines across 18 drugs.ResultsThe model exhibited high predictive accuracy, with correlation coefficients (R) of 0.914 in the training set and 0.902 in the test set. Predictions for cytotoxic drugs, including Docetaxel (R = 0.72) and Cisplatin (R = 0.71), were particularly robust, whereas predictions for targeted therapies were less accurate (R &lt; 0.3). Validation with CCLE (MFI as the endpoint) showed strong correlations (R = 0.67). Application to TCGA data successfully predicted clinical outcomes, including a significant association with 6-month progression-free survival (PFS, P = 0.007, AUC = 0.793).DiscussionThe model demonstrates strong performance across preclinical datasets, showing its potential for real-world application in personalized cancer therapy. By bridging preclinical IC50 and clinical BOR endpoints, this approach provides a promising tool for optimizing patient-specific treatments.",2025,10.3389/frai.2024.1444127
A Modified AUC for Training Convolutional Neural Networks: Taking Confidence Into Account,"Receiver operating characteristic (ROC) curve is an informative tool in binary classification and Area Under ROC Curve (AUC) is a popular metric for reporting performance of binary classifiers. In this paper, first we present a comprehensive review of ROC curve and AUC metric. Next, we propose a modified version of AUC that takes confidence of the model into account and at the same time, incorporates AUC into Binary Cross Entropy (BCE) loss used for training a Convolutional neural Network for classification tasks. We demonstrate this on three datasets: MNIST, prostate MRI, and brain MRI. Furthermore, we have published GenuineAI, a new python library, which provides the functions for conventional AUC and the proposed modified AUC along with metrics including sensitivity, specificity, recall, precision, and F1 for each point of the ROC curve.",2021,10.3389/frai.2021.582928
Nudging Healthy Choices in Food Search Through Visual Attractiveness,"Recipe websites are becoming increasingly popular to support people in their home cooking. However, most of these websites prioritize popular recipes, which tend to be unhealthy. Drawing upon research on visual biases and nudges, this paper investigates whether healthy food choices can be supported in food search by depicting attractive images alongside recipes, as well as by re-ranking search results on health. After modelling the visual attractiveness of recipe images, we asked 239 users to search for specific online recipes and to select those they liked the most. Our analyses revealed that users tended to choose a healthier recipe if a visually attractive image was depicted alongside it, as well as if it was listed at the top of a list of search results. Even though less popular recipes were promoted this way, it did not come at the cost of a user’s level of satisfaction.",2021,10.3389/frai.2021.621743
Behaviour Recognition with Kinodynamic Planning Over Continuous Domains,We investigate the application of state-of-the-art goal recognition techniques forbehaviourrecognition over complex continuous domains using model predictive control (MPC) for trajectory generation. We formally define the problem of kinodynamic behaviour recognition and establish a set of baseline behaviours and performance measures in the complex domain of unmanned aerial maneuvers. We evaluate how well our approach performs over a range of standard aerial maneuvers and representative initial configurations of varying complexity. The work also highlights future research directions in compound model-based behaviour recognition and team behaviour recognition where multiple agents may be acting simultaneously.,2021,10.3389/frai.2021.717003
"Hate speech detection in the Arabic language: corpus design, construction, and evaluation","Hate Speech Detection in Arabic presents a multifaceted challenge due to the broad and diverse linguistic terrain. With its multiple dialects and rich cultural subtleties, Arabic requires particular measures to address hate speech online successfully. To address this issue, academics and developers have used natural language processing (NLP) methods and machine learning algorithms adapted to the complexities of Arabic text. However, many proposed methods were hampered by a lack of a comprehensive dataset/corpus of Arabic hate speech. In this research, we propose a novel multi-class public Arabic dataset comprised of 403,688 annotated tweets categorized as extremely positive, positive, neutral, or negative based on the presence of hate speech. Using our developed dataset, we additionally characterize the performance of multiple machine learning models for Hate speech identification in Arabic Jordanian dialect tweets. Specifically, the Word2Vec, TF-IDF, and AraBert text representation models have been applied to produce word vectors. With the help of these models, we can provide classification models with vectors representing text. After that, seven machine learning classifiers have been evaluated: Support Vector Machine (SVM), Logistic Regression (LR), Naive Bays (NB), Random Forest (RF), AdaBoost (Ada), XGBoost (XGB), and CatBoost (CatB). In light of this, the experimental evaluation revealed that, in this challenging and unstructured setting, our gathered and annotated datasets were rather efficient and generated encouraging assessment outcomes. This will enable academics to delve further into this crucial field of study.",2024,10.3389/frai.2024.1345445
Integrating AI tools in teacher professional learning: a conceptual model and illustrative case,"This conceptual paper aims to explore the complex nature of integrating AI technologies in teacher professional learning, highlighting the potential for AI to synergize teacher noticing and decision-making processes, support adaptive teaching, foster alignment with competence frameworks, and cultivate professional vision, thereby framing teacher practices within the framework of professional vision. We argue that rather than looking at the process of adopting AI solutions by teachers from a technology perspective or how teachers contribute to designing and developing such tools, we take the perspective of the teacher and ask how such tools are meaningfully integrated into teacher practices. In our conceptual paper, we illustrate the case of a novel approach to the teacher training model where the development of teacher' professional vision and professional learning is combined with the design of the AI solutions. We argue the importance of involving teachers into the design of AI solutions through professional learning models to support teachers to develop knowledge-based reasoning skills and at the same time to learn about pedagogical concepts and develop new mental models.",2023,10.3389/frai.2023.1255089
Explainable AI and Reinforcement Learning—A Systematic Review of Current Approaches and Trends,"Research into Explainable Artificial Intelligence (XAI) has been increasing in recent years as a response to the need for increased transparency and trust in AI. This is particularly important as AI is used in sensitive domains with societal, ethical, and safety implications. Work in XAI has primarily focused on Machine Learning (ML) for classification, decision, or action, with detailed systematic reviews already undertaken. This review looks to explore current approaches and limitations for XAI in the area of Reinforcement Learning (RL). From 520 search results, 25 studies (including 5 snowball sampled) are reviewed, highlighting visualization, query-based explanations, policy summarization, human-in-the-loop collaboration, and verification as trends in this area. Limitations in the studies are presented, particularly a lack of user studies, and the prevalence of toy-examples and difficulties providing understandable explanations. Areas for future study are identified, including immersive visualization, and symbolic representation.",2021,10.3389/frai.2021.550030
"Artificial intelligence and machine learning in the development of vaccines and immunotherapeutics—yesterday, today, and tomorrow","The development of vaccines and immunotherapies against infectious diseases and cancers has been one of the significant achievements of medical science in the last century. Subunit vaccines offer key advantages over whole-inactivated or attenuated-pathogen-based vaccines, as they elicit more specific B-and T-cell responses with improved safety, immunogenicity, and protective efficacy. However, developing subunit vaccines is often cost-and time-consuming. In the past, the development of vaccines and immunotherapeutics relied heavily on trial-and-error experimentation, as well as extensive and costly in vivo testing, which typically required years of pre-clinical and clinical trials. Today, artificial intelligence (AI) and deep learning (DL) are actively transforming vaccine and immunotherapeutic research by (i) offering predictive frameworks that support rapid, data-driven decision-making, (ii) integrating computational models, systems vaccinology, and multi-omics data (iii) helping to better phenotype, differentiate, and classify patients diseases and cancers; (iv), integrating host characteristics for tailored vaccines and immunotherapeutics; (v) refining the selection of B-and T-cell antigen/epitope targets to enhance efficacy and durability of immune protection; and (vi) enabling a deeper understanding of immune regulation, immune evasion, and regulatory pathways. Artificial intelligence and DL are pushing the boundaries toward (i) the potential replacement of animal preclinical testing of vaccines and immunotherapeutics with computational-based models, as recently proposed by the United States NIH and FDA, and (ii) improving clinical trials by enabling real-time modeling for immune-bridging, predicting patients’ immune responses, safety, and protective efficacy to vaccines and immunotherapeutics. In this review, we describe the past and current applications of AI and DL as time-and resource-efficient strategies and discuss future challenges in implementing AI and DL as new transformative fields that may facilitate the rapid development of precision and personalized vaccines and immunotherapeutics for infectious diseases and cancers.",2025,10.3389/frai.2025.1620572
Applications of contemporary artificial intelligence technology in forensic odontology as primary forensic identifier: A scoping review,"BackgroundForensic odontology may require a visual or clinical method during identification. Sometimes it may require forensic experts to refer to the existing technique to identify individuals, for example, by using the atlas to estimate the dental age. However, the existing technology can be a complicated procedure for a large-scale incident requiring a more significant number of forensic identifications, particularly during mass disasters. This has driven many experts to perform automation in their current practice to improve efficiency.ObjectiveThis article aims to evaluate current artificial intelligence applications and discuss their performance concerning the algorithm architecture used in forensic odontology.MethodsThis study summarizes the findings of 28 research papers published between 2010 and June 2022 using the Arksey and O'Malley framework, updated by the Joanna Briggs Institute Framework for Scoping Reviews methodology, highlighting the research trend of artificial intelligence technology in forensic odontology. In addition, a literature search was conducted on Web of Science (WoS), Scopus, Google Scholar, and PubMed, and the results were evaluated based on their content and significance.ResultsThe potential application of artificial intelligence technology in forensic odontology can be categorized into four: (1) human bite marks, (2) sex determination, (3) age estimation, and (4) dental comparison. This powerful tool can solve humanity's problems by giving an adequate number of datasets, the appropriate implementation of algorithm architecture, and the proper assignment of hyperparameters that enable the model to perform the prediction at a very high level of performance.ConclusionThe reviewed articles demonstrate that machine learning techniques are reliable for studies involving continuous features such as morphometric parameters. However, machine learning models do not strictly require large training datasets to produce promising results. In contrast, deep learning enables the processing of unstructured data, such as medical images, which require large volumes of data. Occasionally, transfer learning was used to overcome the limitation of data. In the meantime, this method's capacity to automatically learn task-specific feature representations has made it a significant success in forensic odontology.",2022,10.3389/frai.2022.1049584
Application of Seq2Seq Models on Code Correction,"We apply various seq2seq models on programming language correction tasks on Juliet Test Suite for C/C++ and Java of Software Assurance Reference Datasets and achieve 75% (for C/C++) and 56% (for Java) repair rates on these tasks. We introduce pyramid encoder in these seq2seq models, which significantly increases the computational efficiency and memory efficiency, while achieving similar repair rate to their nonpyramid counterparts. We successfully carry out error type classification task on ITC benchmark examples (with only 685 code instances) using transfer learning with models pretrained on Juliet Test Suite, pointing out a novel way of processing small programming language datasets.",2021,10.3389/frai.2021.590215
Machine learning-based analysis of Ebola virus' impact on gene expression in nonhuman primates,"IntroductionThis study introduces the Supervised Magnitude-Altitude Scoring (SMAS) methodology, a novel machine learning-based approach for analyzing gene expression data from non-human primates (NHPs) infected with Ebola virus (EBOV). By focusing on host-pathogen interactions, this research aims to enhance the understanding and identification of critical biomarkers for Ebola infection.MethodsWe utilized a comprehensive dataset of NanoString gene expression profiles from Ebola-infected NHPs. The SMAS system combines gene selection based on both statistical significance and expression changes. Employing linear classifiers such as logistic regression, the method facilitates precise differentiation between RT-qPCR positive and negative NHP samples.ResultsThe application of SMAS led to the identification of IFI6 and IFI27 as key biomarkers, which demonstrated perfect predictive performance with 100% accuracy and optimal Area Under the Curve (AUC) metrics in classifying various stages of Ebola infection. Additionally, genes including MX1, OAS1, and ISG15 were significantly upregulated, underscoring their vital roles in the immune response to EBOV.DiscussionGene Ontology (GO) analysis further elucidated the involvement of these genes in critical biological processes and immune response pathways, reinforcing their significance in Ebola pathogenesis. Our findings highlight the efficacy of the SMAS methodology in revealing complex genetic interactions and response mechanisms, which are essential for advancing the development of diagnostic tools and therapeutic strategies.ConclusionThis study provides valuable insights into EBOV pathogenesis, demonstrating the potential of SMAS to enhance the precision of diagnostics and interventions for Ebola and other viral infections.",2024,10.3389/frai.2024.1405332
Multi-scale dynamics by adjusting the leaking rate to enhance the performance of deep echo state networks,"IntroductionThe deep echo state network (Deep-ESN) architecture, which comprises a multi-layered reservoir layer, exhibits superior performance compared to conventional echo state networks (ESNs) owing to the divergent layer-specific time-scale responses in the Deep-ESN. Although researchers have attempted to use experimental trial-and-error grid searches and Bayesian optimization methods to adjust the hyperparameters, suitable guidelines for setting hyperparameters to adjust the time scale of the dynamics in each layer from the perspective of dynamical characteristics have not been established. In this context, we hypothesized that evaluating the dependence of the multi-time-scale dynamical response on the leaking rate as a typical hyperparameter of the time scale in each neuron would help to achieve a guideline for optimizing the hyperparameters of the Deep-ESN.MethodFirst, we set several leaking rates for each layer of the Deep-ESN and performed multi-scale entropy (MSCE) analysis to analyze the impact of the leaking rate on the dynamics in each layer. Second, we performed layer-by-layer cross-correlation analysis between adjacent layers to elucidate the structural mechanisms to enhance the performance.ResultsAs a result, an optimum task-specific leaking rate value for producing layer-specific multi-time-scale responses and a queue structure with layer-to-layer signal transmission delays for retaining past applied input enhance the Deep-ESN prediction performance.DiscussionThese findings can help to establish ideal design guidelines for setting the hyperparameters of Deep-ESNs.",2024,10.3389/frai.2024.1397915
"“Part Man, Part Machine, All Cop”: Automation in Policing","Digitisation, automation, and datafication permeate policing and justice more and more each year—from predictive policing methods through recidivism prediction to automated biometric identification at the border. The sociotechnical issues surrounding the use of such systems raise questions and reveal problems, both old and new. Our article reviews contemporary issues surrounding automation in policing and the legal system, finds common issues and themes in various different examples, introduces the distinction between human “retail bias” and algorithmic “wholesale bias”, and argues for shifting the viewpoint on the debate to focus on both workers' rights and organisational responsibility as well as fundamental rights and the right to an effective remedy.",2021,10.3389/frai.2021.655486
OLTW-TEC: online learning with sliding windows for text classifier ensembles,"In the digital age, rapid dissemination of information has elevated the challenge of distinguishing between authentic news and disinformation. This challenge is particularly acute in regions experiencing geopolitical tensions, where information plays a pivotal role in shaping public perception and policy. The prevalence of disinformation in the Ukrainian-language information space, intensified by the hybrid war with russia, necessitates the development of sophisticated tools for its detection and mitigation. Our study introduces the “Online Learning with Sliding Windows for Text Classifier Ensembles” (OLTW-TEC) method, designed to address this urgent need. This research aims to develop and validate an advanced machine learning method capable of dynamically adapting to evolving disinformation tactics. The focus is on creating a highly accurate, flexible, and efficient system for detecting disinformation in Ukrainian-language texts. The OLTW-TEC method leverages an ensemble of classifiers combined with a sliding window technique to continuously update the model with the most recent data, enhancing its adaptability and accuracy over time. A unique dataset comprising both authentic and fake news items was used to evaluate the method’s performance. Advanced metrics, including precision, recall, and F1-score, facilitated a comprehensive analysis of its effectiveness. The OLTW-TEC method demonstrated exceptional performance, achieving a classification accuracy of 93%. The integration of the sliding window technique with a classifier ensemble significantly contributed to the system’s ability to accurately identify disinformation, making it a robust tool in the ongoing battle against fake news in the Ukrainian context. The application of the OLTW-TEC method highlights its potential as a versatile and effective solution for disinformation detection. Its adaptability to the specifics of the Ukrainian language and the dynamic nature of information warfare offers valuable insights into the development of similar tools for other languages and regions. OLTW-TEC represents a significant advancement in the detection of disinformation within the Ukrainian-language information space. Its development and successful implementation underscore the importance of innovative machine learning techniques in combating fake news, paving the way for further research and application in the field of digital information integrity.",2024,10.3389/frai.2024.1401126
Comparing Deep Learning Approaches for Understanding Genotype × Phenotype Interactions in Biomass Sorghum,"We explore the use of deep convolutional neural networks (CNNs) trained on overhead imagery of biomass sorghum to ascertain the relationship between single nucleotide polymorphisms (SNPs), or groups of related SNPs, and the phenotypes they control. We consider both CNNs trained explicitly on the classification task of predicting whether an image shows a plant with a reference or alternate version of various SNPs as well as CNNs trained to create data-driven features based on learning features so that images from the same plot are more similar than images from different plots, and then using the features this network learns for genetic marker classification. We characterize how efficient both approaches are at predicting the presence or absence of a genetic markers, and visualize what parts of the images are most important for those predictions. We find that the data-driven approaches give somewhat higher prediction performance, but have visualizations that are harder to interpret; and we give suggestions of potential future machine learning research and discuss the possibilities of using this approach to uncover unknown genotype × phenotype relationships.",2022,10.3389/frai.2022.872858
From Lexicon to Flexicon: The Principles of Morphological Transcendence and Lexical Superstates in the Characterization of Words in the Mind,"The field of mental lexicon research has benefitted greatly from the founding metaphor of a dictionary in the mind. That metaphor, however, had its origins in a perspective in which the lexicon was seen as a static repository of representations with fixed structural properties. This paper presents a contrasting view. It is a view that highlights that words are activities that we perform, rather than simply representations that we have. It is proposed that lexical representations are best seen as hierarchies of action within a highly interconnected and dynamic system. The paper presents two principles of lexical organization:morphological transcendenceandlexical superstates. The former principle claims that through the activities of language comprehension and production, lexical forms can develop variant forms. Thus, the formkeymay develop into forms such askey- (e.g.,keyboard)and-key, (e.g.,turnkey). The paper also discusses how transcendence leads to lexical superstates, which do not have a fixed morphological structure. As part of a lexical superstate, alternative morphological structures exist as potential realizations. Which one is actually realized will depend on the specific circumstances of a lexical action. An account is presented in which the effects of semantic transparency are treated in terms of transcendence and superstate interactions. It is claimed that this approach, which highlights the dynamic and flexible nature of the mental lexicon, has implications for how we approach the modeling of language and cognition in general.",2022,10.3389/frai.2021.788430
DeepCarc: Deep Learning-Powered Carcinogenicity Prediction Using Model-Level Representation,"Carcinogenicity testing plays an essential role in identifying carcinogens in environmental chemistry and drug development. However, it is a time-consuming and label-intensive process to evaluate the carcinogenic potency with conventional 2-years rodent animal studies. Thus, there is an urgent need for alternative approaches to providing reliable and robust assessments on carcinogenicity. In this study, we proposed a DeepCarc model to predict carcinogenicity for small molecules using deep learning-based model-level representations. The DeepCarc Model was developed using a data set of 692 compounds and evaluated on a test set containing 171 compounds in the National Center for Toxicological Research liver cancer database (NCTRlcdb). As a result, the proposed DeepCarc model yielded a Matthews correlation coefficient (MCC) of 0.432 for the test set, outperforming four advanced deep learning (DL) powered quantitative structure-activity relationship (QSAR) models with an average improvement rate of 37%. Furthermore, the DeepCarc model was also employed to screen the carcinogenicity potential of the compounds from both DrugBank and Tox21. Altogether, the proposed DeepCarc model could serve as an early detection tool (https://github.com/TingLi2016/DeepCarc) for carcinogenicity assessment.",2021,10.3389/frai.2021.757780
"Insights Into Co-Morbidity and Other Risk Factors Related to COVID-19 Within Ontario, Canada","The worldwide rapid spread of the severe acute respiratory syndrome coronavirus 2 has affected millions of individuals and caused unprecedented medical challenges by putting healthcare services under high pressure. Given the global increase in number of cases and mortalities due to the current COVID-19 pandemic, it is critical to identify predictive features that assist identification of individuals most at-risk of COVID-19 mortality and thus, enable planning for effective usage of medical resources. The impact of individual variables in an XGBoost artificial intelligence model, applied to a dataset containing 57,390 individual COVID-19 cases and 2,822 patient deaths in Ontario, is explored with the use of SHapley Additive exPlanations values. The most important variables were found to be: age, date of the positive test, sex, income, dementia plus many more that were considered. The utility of SHapley Additive exPlanations dependency graphs is used to provide greater interpretation of the black-box XGBoost mortality prediction model, allowing focus on the non-linear relationships to improve insights. A “Test-date Dependency” plot indicates mortality risk dropped substantially over time, as likely a result of the improved treatment being developed within the medical system. As well, the findings indicate that people of lower income and people from more ethnically diverse communities, face an increased mortality risk due to COVID-19 within Ontario. These findings will help guide clinical decision-making for patients with COVID-19.",2021,10.3389/frai.2021.684609
Leveraging pre-trained embeddings in an ensemble machine learning approach for Arabic sentiment analysis,"IntroductionArabic sentiment analysis presents unique challenges due to the linguistic complexity of the language, including its wide range of dialects, orthographic ambiguity, and limited language resources. Addressing these issues is essential to develop robust sentiment classification systems.MethodsThis study investigates the application of ensemble machine learning methods for Arabic sentiment analysis. Several homogeneous ensemble techniques are implemented and evaluated on two datasets: the balanced ArTwitter dataset and the highly imbalanced Syria_Tweets dataset. To mitigate class imbalance, the Synthetic Minority Over-sampling Technique (SMOTE) is employed. The models incorporate pre-trained word embeddings and unigram features.ResultsExperimental results indicate that individual classifiers using pre-trained embeddings achieve strong performance; however, ensemble models consistently yield superior outcomes. On the ArTwitter dataset, the ensemble of Naive Bayes, Support Vector Machine, and Decision Tree classifiers achieved an accuracy of 90.22% and an F1-score of 92.0%. On the Syria_Tweets dataset, an ensemble combining Stochastic Gradient Descent, k-Nearest Neighbors, and Random Forest attained 83.82% accuracy and an 83.86% F1-score.DiscussionThe findings highlight the effectiveness of ensemble learning in enhancing the robustness and generalizability of Arabic sentiment analysis systems. Incorporating pre-trained embeddings further strengthens performance, demonstrating that ensemble-based approaches can overcome challenges posed by linguistic complexity and dataset imbalance in Arabic natural language processing tasks.",2025,10.3389/frai.2025.1653728
It's not just a phase: Investigating text simplification in a second language from a process and product perspective,"Text simplification involves making texts easier to understand, usually for lay readers. Simplifying texts is a complex task, especially when conducted in a second language. The readability of the produced texts and the way in which authors manage the different phases of the text simplification process are influenced by their writing expertise and by their language proficiency. Training on audience awareness can be beneficial for writers, but most research so far has devoted attention to first-language writers who simplify their own texts. Therefore, this study investigated the impact of text simplification training on second-language writers (university students) who simplify already existing texts. Specifically, after identifying a first and a second phase in the text simplification process (namely, two distinct series of writing dynamics), we analyzed the impact of our training on pausing and revision behavior across phases, as well as levels of readability achieved by the students. Additionally, we examined correlations between pausing behavior and readability by using keystroke logging data and automated text analysis. We found that phases of text simplification differ along multiple dimensions, even though our training did not seem to influence pausing and revision dynamics. Our training led to texts with fewer and shorter words, and with syntactically simpler sentences. The correlation analysis showed that longer and more frequent pauses at specific text locations were linked with increased readability in the same or adjacent text locations. We conclude the paper by discussing theoretical, methodological, and pedagogical implications, alongside limitations and areas for future research.",2022,10.3389/frai.2022.983008
Enhancing random forest predictive performance for foot and mouth disease outbreaks in Uganda: a calibrated uncertainty prediction approach for varying distributions,"Foot-and-mouth disease poses a significant threat to both domestic and wild cloven-hoofed animals, leading to severe economic losses and jeopardizing food security. While machine learning models have become essential for predicting foot-and-mouth disease outbreaks, their effectiveness is often compromised by distribution shifts between training and target datasets, especially in non-stationary environments. Despite the critical impact of these shifts, their implications in foot-and-mouth disease outbreak prediction have been largely overlooked. This study introduces the Calibrated Uncertainty Prediction approach, designed to enhance the performance of Random Forest models in predicting foot-and-mouth disease outbreaks across varying distributions. The Calibrated Uncertainty Prediction approach effectively addresses distribution shifts by calibrating uncertain instances for pseudo-label annotation, allowing the active learner to generalize more effectively to the target domain. By utilizing a probabilistic calibration model, Calibrated Uncertainty Prediction pseudo-annotates the most informative instances, refining the active learner iteratively and minimizing the need for human annotation and outperforming existing methods known to mitigate distribution shifts. This reduces costs, saves time, and lessens the dependence on domain experts while achieving outstanding predictive performance. The results demonstrate that Calibrated Uncertainty Prediction significantly enhances predictive performance in non-stationary environments, achieving an accuracy of 98.5%, Area Under the Curve of 0.842, recall of 0.743, precision of 0.855, and an F1 score of 0.791. These findings underscore Calibrated Uncertainty Prediction’s ability to overcome the vulnerabilities of existing ML models, offering a robust solution for foot-and-mouth disease outbreak prediction and contributing to the broader field of predictive modeling in infectious disease management.",2024,10.3389/frai.2024.1455331
A hype-adjusted probability measure for NLP stock return forecasting,"This article introduces a Hype-Adjusted Probability Measure in the context of a new Natural Language Processing (NLP) approach for stock return and volatility forecasting. A novel sentiment score equation is proposed to represent the impact of intraday news on forecasting next-period stock return and volatility for selected U.S. semiconductor tickers, a very vibrant industry sector. This work improves the forecast accuracy by addressing news bias, memory, and weight, and incorporating shifts in sentiment direction. More importantly, it extends the use of the remarkable tool of change of Probability Measure developed in the finance of Asset Pricing to NLP forecasting by constructing a Hype-Adjusted Probability Measure, obtained from a redistribution of the weights in the probability space, meant to correct for excessive or insufficient news.",2025,10.3389/frai.2025.1527180
"A framework for establishing shared, task-oriented understanding in hybrid open multi-agent systems","In Open Multi-Agent Systems (OMAS), the open nature of such systems precludes that all communication protocols are hardwired in advance. It is therefore essential that agents can incrementally learn to understand each other. Ideally, this is done with a minimal number of a priori assumptions, in order not to compromise the open nature of the system. This challenge becomes even harder for hybrid (human-artificial agent) populations. In such a hybrid setting, the challenge of learning to communicate is exacerbated by the requirement to do this in a minimal number of interactions with the humans involved. The difficulty arises from the conflict between making a minimal number of assumptions while also minimizing the number of interactions required. This study provides a fine-grained analysis of the process of establishing a shared task-oriented understanding for OMAS, with a particular focus on hybrid populations, i.e., containing both human and artificial agents. We present a framework that describes this process of reaching a shared task-oriented understanding. Our framework defines components that reflect decisions the agent designer needs to make, and we show how these components are affected when the agent population includes humans, i.e., when moving to a hybrid setting. The contribution of this paper is not to define yet another method for agents that learn to communicate. Instead, our goal is to provide a framework to assist researchers in designing agents that need to interact with humans in unforeseen scenarios. We validate our framework by showing that it provides a uniform way to analyze a diverse set of existing approaches from the literature for establishing shared understanding between agents. Our analysis reveals limitations of these existing approaches if they were to be applied in hybrid populations, and suggests how these can be resolved.",2025,10.3389/frai.2025.1440582
AI adoption among adolescents in education: extending the UTAUT2 with psychological and contextual factors,"IntroductionThis correlational study investigates the psychological and contextual factors associated with the adoption of artificial intelligence (AI) technologies among Italian high school students. Building on the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2), the study extends the model by incorporating Problematic Internet Use (PIU) and Attitudes Toward AI (ATAI) to better account for habitual AI use and behavioural intentions.MethodA sample of 933 students (Mage = 16.20, SDage = 1.29, 54.98% female) completed a survey assessing key UTAUT2 dimensions, psychological traits, and usage patterns of AI tools in educational contexts. Confirmatory factor analysis (CFA) was used to evaluate the functioning of the adapted UTAUT2. Multiple regression was used to investigate factors predicting habit formation and behavioural intention related to AI use.ResultsConfirmatory factor analysis supported the structural validity of the adapted UTAUT2 model. Multiple regression analyses revealed that Performance Expectancy, Social Influence, Hedonic Motivation, and Schoolwork-related AI use were significant predictors of both habit and behavioural intention. PIU showed a robust association with habitual use, suggesting a spillover effect from compulsive Internet behavior to AI engagement. ATAI was associated only with behavioural intention, indicating its role in initial adoption rather than sustained use. Demographic and contextual factors (e.g., school type, citizenship) showed additional effects.DiscussionThese findings contribute to a more comprehensive understanding of adolescent AI engagement by highlighting the role of compulsive tendencies and motivational beliefs. The study underscores the importance of designing inclusive, age-appropriate interventions to promote balanced and informed AI use in educational settings.",2025,10.3389/frai.2025.1614993
A comparison of the diagnostic ability of large language models in challenging clinical cases,"IntroductionThe rise of accessible, consumer facing large language models (LLM) provides an opportunity for immediate diagnostic support for clinicians.ObjectivesTo compare the different performance characteristics of common LLMS utility in solving complex clinical cases and assess the utility of a novel tool to grade LLM output.MethodsUsing a newly developed rubric to assess the models’ diagnostic utility, we measured to models’ ability to answer cases according to accuracy, readability, clinical interpretability, and an assessment of safety. Here we present a comparative analysis of three LLM models—Bing, Chat GPT, and Gemini—across a diverse set of clinical cases as presented in the New England Journal of Medicines case series.ResultsOur results suggest that models performed differently when presented with identical clinical information, with Gemini performing best. Our grading tool had low interobserver variability and proved a reliable tool to grade LLM clinical output.ConclusionThis research underscores the variation in model performance in clinical scenarios and highlights the importance of considering diagnostic model performance in diverse clinical scenarios prior to deployment. Furthermore, we provide a new tool to assess LLM output.",2024,10.3389/frai.2024.1379297
Machine learning-based classifiers to predict metastasis in colorectal cancer patients,"BackgroundThe increasing prevalence of colorectal cancer (CRC) in Iran over the past three decades has made it a key public health burden. This study aimed to predict metastasis in CRC patients using machine learning (ML) approaches in terms of demographic and clinical factors.MethodsThis study focuses on 1,127 CRC patients who underwent appropriate treatments at Taleghani Hospital, a tertiary care facility. The patients were divided into training and test datasets in an 80:20 ratio. Various ML methods, including Naive Bayes (NB), random rorest (RF), support vector machine (SVM), neural network (NN), decision tree (DT), and logistic regression (LR), were used for predicting metastasis in CRC patients. Model performance was evaluated using 5-fold cross-validation, reporting sensitivity, specificity, the area under the curve (AUC), and other indexes.ResultsAmong the 1,127 patients, 183 (16%) had experienced metastasis. In the predictionof metastasis, both the NN and RF algorithms had the highest AUC, while SVM ranked third in both the original and balanced datasets. The NN and RF algorithms achieved the highest AUC (100%), sensitivity (100% and 100%, respectively), and accuracy (99.2% and 99.3%, respectively) on the balanced dataset, followed by the SVM with an AUC of 98.8%, a sensitivity of 97.5%, and an accuracy of 97%. Moreover, lower false negative rate (FNR), false positive rate (FPR), and higher negative predictive value (NPV) can be confirmed by these two methods. The results also showed that all methods exhibited good performance in the test datasets, and the balanced dataset improved the performance of most ML methods. The most important variables for predicting metastasis were the tumor stage, the number of involved lymph nodes, and the treatment type. In a separate analysis of patients with tumor stages I–III, it was identified that tumor grade, tumor size, and tumor stage are the most important features.ConclusionThis study indicated that NN and RF were the best among ML-based approaches for predicting metastasis in CRC patients. Both the tumor stage and the number of involved lymph nodes were considered the most important features.",2024,10.3389/frai.2024.1285037
Applications of artificial intelligence in emergency and critical care diagnostics: a systematic review and meta-analysis,"IntroductionArtificial intelligence has come to be the highlight in almost all fields of science. It uses various models and algorithms to detect patterns and specific findings to diagnose a disease with utmost accuracy. With the increasing need for accurate and precise diagnosis of disease, employing artificial intelligence models and concepts in healthcare setup can be beneficial.MethodologyThe search engines and databases employed in this study are PubMed, ScienceDirect and Medline. Studies published between 1st January 2013 to 1st February 2023 were included in this analysis. The selected articles were screened preliminarily using the Rayyan web tool, after which investigators screened the selected articles individually. The risk of bias for the selected studies was assessed using QUADAS-2 tool specially designed to test bias among studies related to diagnostic test reviews.ResultsIn this review, 17 studies were included from a total of 12,173 studies. These studies were analysed for their sensitivity, accuracy, positive predictive value, specificity and negative predictive value in diagnosing barrette’s neoplasia, cardiac arrest, esophageal adenocarcinoma, sepsis and gastrointestinal stromal tumors. All the studies reported heterogeneity with p-value &lt;0.05 at confidence interval 95%.ConclusionThe existing evidential data suggests that artificial intelligence can be highly helpful in the field of diagnosis providing maximum precision and early detection. This helps to prevent disease progression and also helps to provide treatment at the earliest. Employing artificial intelligence in diagnosis will define the advancement of health care environment and also be beneficial in every aspect concerned with treatment to illnesses.",2024,10.3389/frai.2024.1422551
Convolutional Neural Network-Based Technique for Gaze Estimation on Mobile Devices,"Eye tracking is becoming a very popular, useful, and important technology. Many eye tracking technologies are currently expensive and only available to large corporations. Some of them necessitate explicit personal calibration, which makes them unsuitable for use in real-world or uncontrolled environments. Explicit personal calibration can also be cumbersome and degrades the user experience. To address these issues, this study proposes a Convolutional Neural Network (CNN) based calibration-free technique for improved gaze estimation in unconstrained environments. The proposed technique consists of two components, namely a face component and a 39-point facial landmark component. The face component is used to extract the gaze estimation features from the eyes, while the 39-point facial landmark component is used to encode the shape and location of the eyes (within the face) into the network. Adding this information can make the network learn free-head and eye movements. Another CNN model was designed in this study primarily for the sake of comparison. The CNN model accepts only the face images as input. Different experiments were performed, and the experimental result reveals that the proposed technique outperforms the second model. Fine-tuning was also performed using the VGG16 pre-trained model. Experimental results show that the fine-tuned results of the proposed technique perform better than the fine-tuned results of the second model. Overall, the results show that 39-point facial landmarks can be used to improve the performance of CNN-based gaze estimation models.",2022,10.3389/frai.2021.796825
Deep Learning Based Superconducting Radio-Frequency Cavity Fault Classification at Jefferson Laboratory,"This work investigates the efficacy of deep learning (DL) for classifying C100 superconducting radio-frequency (SRF) cavity faults in the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. CEBAF is a large, high-power continuous wave recirculating linac that utilizes 418 SRF cavities to accelerate electrons up to 12 GeV. Recent upgrades to CEBAF include installation of 11 new cryomodules (88 cavities) equipped with a low-level RF system that records RF time-series data from each cavity at the onset of an RF failure. Typically, subject matter experts (SME) analyze this data to determine the fault type and identify the cavity of origin. This information is subsequently utilized to identify failure trends and to implement corrective measures on the offending cavity. Manual inspection of large-scale, time-series data, generated by frequent system failures is tedious and time consuming, and thereby motivates the use of machine learning (ML) to automate the task. This study extends work on a previously developed system based on traditional ML methods (Tennant and Carpenter and Powers and Shabalina Solopova and Vidyaratne and Iftekharuddin, Phys. Rev. Accel. Beams, 2020, 23, 114601), and investigates the effectiveness of deep learning approaches. The transition to a DL model is driven by the goal of developing a system with sufficiently fast inference that it could be used to predict a fault event and take actionable information before the onset (on the order of a few hundred milliseconds). Because features are learned, rather than explicitly computed, DL offers a potential advantage over traditional ML. Specifically, two seminal DL architecture types are explored: deep recurrent neural networks (RNN) and deep convolutional neural networks (CNN). We provide a detailed analysis on the performance of individual models using an RF waveform dataset built from past operational runs of CEBAF. In particular, the performance of RNN models incorporating long short-term memory (LSTM) are analyzed along with the CNN performance. Furthermore, comparing these DL models with a state-of-the-art fault ML model shows that DL architectures obtain similar performance for cavity identification, do not perform quite as well for fault classification, but provide an advantage in inference speed.",2022,10.3389/frai.2021.718950
COVID-19 lateral flow test image classification using deep CNN and StyleGAN2,"IntroductionArtificial intelligence (AI) in healthcare can enhance clinical workflows and diagnoses, particularly in large-scale operations like COVID-19 mass testing. This study presents a deep Convolutional Neural Network (CNN) model for automated COVID-19 RATD image classification.MethodsTo address the absence of a RATD image dataset, we crowdsourced 900 real-world images focusing on positive and negative cases. Rigorous data augmentation and StyleGAN2-ADA generated simulated images to overcome dataset limitations and class imbalances.ResultsThe best CNN model achieved a 93% validation accuracy. Test accuracies were 88% for simulated datasets and 82% for real datasets. Augmenting simulated images during training did not significantly improve real-world test image performance but enhanced simulated test image performance.DiscussionThe findings of this study highlight the potential of the developed model in expediting COVID-19 testing processes and facilitating large-scale testing and tracking systems. The study also underscores the challenges in designing and developing such models, emphasizing the importance of addressing dataset limitations and class imbalances.ConclusionThis research contributes to the deployment of large-scale testing and tracking systems, offering insights into the potential applications of AI in mitigating outbreaks similar to COVID-19. Future work could focus on refining the model and exploring its adaptability to other healthcare scenarios.",2024,10.3389/frai.2023.1235204
Computer-vision based automatic rider helmet violation detection and vehicle identification in Indian smart city scenarios using NVIDIA TAO toolkit and YOLOv8,"Two-wheeler traffic offenses are a well-known fact about the Indian Road scenario. In addition to endangering the offenders, these offenses also endanger other commuters. Two-wheeler traffic violations can take many different forms, such as overloading, triple riding, and helmetless riding. Effective identification and enforcement strategies are necessary for these offenses since they pose a serious risk to public safety. Due to the inadequacy of traditional traffic monitoring and enforcement techniques, advanced technology-based solutions are now required. Deep learning-based systems have demonstrated significant promise in identifying and stopping such infractions in recent years. We propose a two-step deep learning approach that leverages the strengths of pre-trained object detection models to detect two-wheeler riders and specialized helmet classifiers to identify helmet wear status as well as detect number plates. In the first stage, we utilized a highly efficient, robust, and accurate object identification DetectNet (Model 1) framework developed by NVIDIA, and it uses the ResNet18 Convolutional Neural Network (CNN) architecture as part of the Transfer Learning Toolkit known as TAO (Train, Adapt, Optimize). The second stage demands accurate detection of a helmet on the identified rider and extracting numbers from the violator’s license plates using the OCR module in real time. We employed YOLOv8 (Model 2), a deep learning-based architecture that has proven effective in several applications involving object detection in real time. It predicts bounding boxes and class probabilities for objects within an image using a single neural network, making it a perfect choice for real-time applications like rider helmet violations detections and number plate processing. Due to a lack of publicly available traffic datasets, we created a custom dataset containing motorcycle rider images captured under complex scenarios for training and validating our models. Experimental analysis shows that our proposed two-step model achieved a promising helmet detection accuracy of 98.56% and a 97.6% number plate detection accuracy of persons not wearing helmets. The major objective of our proposed study is to enforce stringent traffic laws in real-time to decrease rider helmet violations.",2025,10.3389/frai.2025.1582257
Evaluating the impact of common clinical confounders on performance of deep-learning-based sepsis risk assessment,"IntroductionEarly identification of sepsis in the emergency department using machine learning remains a challenging problem, primarily due to the lack of a gold standard for sepsis diagnosis, the heterogeneity in clinical presentations, and the impact of confounding conditions.MethodsIn this work, we present a deep-learning-based predictive model designed to enable early detection of patients at risk of developing sepsis, using data from the first 24 h of admission. The model is based on routine blood test results commonly performed on patients, including CBC (Complete Blood Count), CMP (Comprehensive Metabolic Panel), lipid panels, vital signs, age, and sex. To address the challenge of label uncertainty as a part of the training process, we explore two different definitions, namely, Sepsis-3 and Adult Sepsis Event. We analyze the advantages and limitations of each in the context of patient clinical parameters and comorbidities. We specifically examine how the quality of the ground truth label influences the performance of the deep learning system and evaluate the effect of a consensus-based approach that incorporates both definitions. We also evaluated the model's performance across sub-cohorts, including patients with confounding comorbidities (such as chronic kidney, liver disease, and coagulation disorders) and those with infections confirmed by billing codes.ResultsOur results show that the consensus-based model identifies at-risk patients in the first 24 h with 83.7% sensitivity, 80% specificity, 36% PPV, 97% NPV, and an AUC of 0.9. Our cohort-wise analysis revealed a high PPV (77%) in infection-confirmed subgroups and a drop in specificity across cohorts with confounding comorbidities (47-70%).DiscussionThis work highlights the limitations of retrospective sepsis definitions and underscores the need for tailored approaches in automated sepsis detection, particularly when dealing with patients with confounding comorbidities.",2025,10.3389/frai.2025.1452471
AI and its consequences for the written word,"The latest developments of chatbots driven by Large Language Models (LLMs), more specifically ChatGPT, have shaken the foundations of how text is created, and may drastically reduce and change the need, ability, and valuation of human writing. Furthermore, our trust in the written word is likely to decrease, as an increasing proportion of all written text will be AI-generated – and potentially incorrect. In this essay, I discuss these implications and possible scenarios for us humans, and for AI itself.",2024,10.3389/frai.2023.1326166
Resource-efficient fine-tuning of large vision-language models for multimodal perception in autonomous excavators,"Recent advances in large vision-language models (LVLMs) have transformed visual recognition research by enabling multimodal integration of images, text, and videos. This fusion supports a deeper and more context-aware understanding of visual environments. However, the application of LVLMs to multitask visual recognition in real-world construction scenarios remains underexplored. In this study, we present a resource-efficient framework for fine-tuning LVLMs tailored to autonomous excavator operations, with a focus on robust detection of humans and obstacles, as well as classification of weather conditions on consumer-grade hardware. By leveraging Quantized Low-Rank Adaptation (QLoRA) in conjunction with the Unsloth framework, our method substantially reduces memory consumption and accelerates fine-tuning compared with conventional approaches. We comprehensively evaluate a domain-specific excavator-vision dataset using five open-source LVLMs. These include Llama-3.2-Vision, Qwen2-VL, Qwen2.5-VL, LLaVA-1.6, and Gemma 3. Each model is fine-tuned on 1,000 annotated frames and tested on 2000 images. Experimental results demonstrate significant improvements in both object detection and weather classification, with Qwen2-VL-7B achieving an mAP@50 of 88.03%, mAP@[0.50:0.95] of 74.20%, accuracy of 84.54%, and F1 score of 78.83%. Our fine-tuned Qwen2-VL-7B model not only detects humans and obstacles robustly but also classifies weather accurately. These results illustrate the feasibility of deploying LVLM-based multimodal AI agents for safety monitoring, pose estimation, activity tracking, and strategic planning in autonomous excavator operations.",2025,10.3389/frai.2025.1681277
The application progress of artificial intelligence in osteoporosis diagnosis,"Osteoporosis (OP) is a systemic bone metabolic disorder characterized by a decrease in bone mineral density (BMD) and damage to the trabecular bone microarchitecture. With the increasing global aging population, the incidence of OP has been rising annually, particularly among elderly women, making it a significant public health issue. Traditional diagnostic methods such as dual-energy X-ray absorptiometry (DXA), quantitative computed tomography (QCT), and magnetic resonance imaging (MRI) are effective, but they also have certain limitations. Artificial intelligence (AI) technology is playing an increasingly important role in the management of osteoporosis. Through machine learning (ML), image processing, and data analysis, AI can accurately assess bone density, fracture risk, and other factors, improving the early diagnosis rate of OP and providing strong decision support for clinicians to optimize treatment plans and enhance treatment outcomes. However, it also faces challenges such as AI model interpretability, insufficient diversity in training data, lack of clinical validation, and issues related to privacy protection and ethics. Addressing these problems is crucial for promoting the widespread application of AI technology in this field. As technology continues to advance, AI will become an indispensable part of OP research and clinical applications, driving the development of personalized treatment and precision medicine.",2025,10.3389/frai.2025.1699762
Safer not to know? Shaping liability law and policy to incentivize adoption of predictive AI technologies in the food system,"Governments, researchers, and developers emphasize creating “trustworthy AI,” defined as AI that prevents bias, ensures data privacy, and generates reliable results that perform as expected. However, in some cases problems arise not when AI is not trustworthy, technologically, but when it is. This article focuses on such problems in the food system. AI technologies facilitate the generation of masses of data that may illuminate existing food-safety and employee-safety risks. These systems may collect incidental data that could be used, or may be designed specifically, to assess and manage risks. The predictions and knowledge generated by these data and technologies may increase company liability and expense, and discourage adoption of these predictive technologies. Such problems may extend beyond the food system to other industries. Based on interviews and literature, this article discusses vulnerabilities to liability and obstacles to technology adoption that arise, arguing that “trustworthy AI” cannot be achieved through technology alone, but requires social, cultural, political, as well as technical cooperation. Implications for law and further research are also discussed.",2023,10.3389/frai.2023.1298604
Enhancing the design of voting advice applications with BERT language model,"The relevance and importance of voting advice applications (VAAs) are demonstrated by their popularity among potential voters. On average, around 30% of voters take into account the recommendations of these applications during elections. The comparison between potential voters' and parties' positions is made on the basis of VAA policy statements on which users are asked to express opinions. VAA designers devote substantial time and effort to analyzing domestic and international politics to formulate policy statements and select those to be included in the application. This procedure involves manually reading and evaluating a large volume of publicly available data, primarily party manifestos. A problematic part of the work is the limited time frame. This study proposes a system to assist VAA designers in formulating, revising, and selecting policy statements. Using pre-trained language models and machine learning methods to process politics-related textual data, the system produces a set of suggestions corresponding to relevant VAA statements. Experiments were conducted using party manifestos and YouTube comments from Japan, combined with VAA policy statements from six Japanese and two European VAAs. The technical approaches used in the system are based on the BERT language model, which is known for its capability to capture the context of words in the documents. Although the output of the system does not completely eliminate the need for manual human assessment, it provides valuable suggestions for updating VAA policy statements on an objective, i.e., bias-free, basis.",2024,10.3389/frai.2024.1343214
Language Models Explain Word Reading Times Better Than Empirical Predictability,"Though there is a strong consensus that word length and frequency are the most important single-word features determining visual-orthographic access to the mental lexicon, there is less agreement as how to best capture syntactic and semantic factors. The traditional approach in cognitive reading research assumes that word predictability from sentence context is best captured by cloze completion probability (CCP) derived from human performance data. We review recent research suggesting that probabilistic language models provide deeper explanations for syntactic and semantic effects than CCP. Then we compare CCP with three probabilistic language models for predicting word viewing times in an English and a German eye tracking sample: (1) Symbolic n-gram models consolidate syntactic and semantic short-range relations by computing the probability of a word to occur, given two preceding words. (2) Topic models rely on subsymbolic representations to capture long-range semantic similarity by word co-occurrence counts in documents. (3) In recurrent neural networks (RNNs), the subsymbolic units are trained to predict the next word, given all preceding words in the sentences. To examine lexical retrieval, these models were used to predict single fixation durations and gaze durations to capture rapidly successful and standard lexical access, and total viewing time to capture late semantic integration. The linear item-level analyses showed greater correlations of all language models with all eye-movement measures than CCP. Then we examined non-linear relations between the different types of predictability and the reading times using generalized additive models. N-gram and RNN probabilities of the present word more consistently predicted reading performance compared with topic models or CCP. For the effects of last-word probability on current-word viewing times, we obtained the best results with n-gram models. Such count-based models seem to best capture short-range access that is still underway when the eyes move on to the subsequent word. The prediction-trained RNN models, in contrast, better predicted early preprocessing of the next word. In sum, our results demonstrate that the different language models account for differential cognitive processes during reading. We discuss these algorithmically concrete blueprints of lexical consolidation as theoretically deep explanations for human reading.",2022,10.3389/frai.2021.730570
Pipeline monitoring data recovery using novel deep learning models: an engineering case study,"Pipeline monitoring frequently encounters missing data, leading to incomplete evaluation and hindering a comprehensive assessment of the pipeline’s structural health. To address this issue, this study proposes a novel PDO-BiGRU-GAN model for missing data recovery. The model integrates three components: the prairie dog optimization algorithm (PDO) for hyperparameter tuning, the bidirectional gated recurrent unit (BiGRU) for effective temporal feature extraction, and the generative adversarial network (GAN) for data generation and completion. A comprehensive monitoring database was established using field data from an open-source pipeline project. The contributions of individual modules to the overall performance were evaluated via hyperparameter sensitivity analysis and ablation studies. The impact of missing data ratio and the number of missing sensors on the model’s recovery performance was analyzed. In addition, the proposed model was compared with eight existing mainstream deep learning models. The results show that each component of the PDO-BiGRU-GAN significantly enhances overall performance. The model achieves strong recovery accuracy across various missing data scenarios, with the R2 consistently exceeding 0.93. Moreover, the model performs optimally when the missing data ratio is below 20/24. Compared to other models, PDO-BiGRU-GAN achieves the highest R2 and the lowest error metrics (MSE, RMSE, MAPE, MAE). In terms of computational efficiency, the model requires slightly more processing time than simpler models but is faster than more complex models. Overall, the proposed model provides a robust and scalable solution for pipeline monitoring data recovery, advancing intelligent pipeline health assessment and supporting the development of infrastructure safety management and smart monitoring technologies.",2025,10.3389/frai.2025.1684018
Federated learning for cognitive impairment detection using speech data,"IntroductionIn Alzheimer’s disease (AD) research, clinical, neuroimaging, genetic, and biomarker data are vital for advancing its understanding and treatment. However, privacy concerns and limited datasets complicate data sharing. Federated learning (FL) offers a solution by enabling collaborative research while preserving data privacy.MethodsThis study analyzed data from patients assessed at the Memory Unit of the Ace Alzheimer Center Barcelona who completed a standardized digital speech protocol. Acoustic features extracted from these recordings were used to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals. The aim was to evaluate how data heterogeneity impacted the FL model performance across three scenarios: (1) equal contributions and class ratios, (2) unequal contributions, and (3) imbalanced class ratios. In each scenario, the performance of local models trained using an MLP feed-forward neural network on institutional data was analyzed and compared to a global model created by aggregating these local models using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA).ResultsThe cohort included 2,239 participants: 221 CU individuals (mean age 66.8, 64.7% female) and 2,018 CI subjects, comprising 1,219 with mild cognitive impairment (mean age 74.3, 61.9% female) and 799 with mild AD dementia (mean age 80.8, 64.8% female). In scenarios 1 and 3, FL provided modest gains in accuracy and AUC. In scenario 2, FL markedly improved performance for the smaller dataset (balanced accuracy rising from 0.51 to 0.80) while preserving 0.86 accuracy in the larger dataset, highlighting scalability across heterogeneous conditions.ConclusionThese findings demonstrate the potential of FL to enable collaborative modeling of speech-based biomarkers for cognitive impairment detection, even under conditions of data imbalance and institutional disparity. This work highlights FL as a scalable and privacy-preserving approach for advancing digital health research in neurodegenerative diseases.",2025,10.3389/frai.2025.1662859
Search-optimized quantization in biomedical ontology alignment,"In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by 70%.",2025,10.3389/frai.2025.1662984
Enhancing Ishihara and educational images using machine learning: toward accessible learning for colorblind individuals,"Color Vision Deficiency (CVD) affects over 300 million individuals worldwide, with protanopia and deuteranopia being the most common subtypes, causing red–green confusion. This study leverages machine learning to (a) classify reference (considered as normal vision) and simulated protanopia and deuteranopia Ishihara plate images, (b) generate corresponding enhanced versions of these images, and (c) provide improved textbook diagrams (from NCERT books) and other pseudochromatic figures for CVD students, validated through feedback from diagnosed individuals. Tritanopia and milder forms of CVD were excluded in this study. A dataset of 1,400 Ishihara plates was processed to simulate protanopia and deuteranopia perception via standard Red Green Blue (sRGB) to long-, medium-, and short-wavelength cone (LMS) modeling. Enhanced images were generated using a daltonization function defined by the error between reference and simulated images, with enhancement strength (α) optimized to maximize contrast gain while minimizing distortion. Feature embeddings from ResNet-50, EfficientNet-B0, and DenseNet-201 were fused and reduced via PCA, followed by One-vs-All (OvA) (classifiers: linear support vector machine, logistic regression, and decision tree), random forest, gradient boosting, and neural network. Results showed optimal enhancement at α = 0.54 for deuteranopia and 0.64 for protanopia, achieving contrast gains of 69.6 and 64.3, respectively, with minimal color distortion (ΔE ≈ 4.9) and negligible clipping (&lt;0.002). The OvA strategy achieved 99.7% accuracy, while MLP reached 100% across metrics. Surveys with 15 diagnosed students confirmed substantial perceptual improvement: recognition of previously unreadable digits and symbols increased from &lt;20% to full visibility, with mean ratings above 4/5 for enhanced images. The OvA technique integrated with daltonization can assist in enhancing Ishihara and educational images in real time.",2025,10.3389/frai.2025.1676644
Adaptation of convolutional neural networks for real-time abdominal ultrasound interpretation,"Point of care ultrasound (POCUS) is commonly used for diagnostic triage of internal injuries in both civilian and military trauma. In resource constrained environments, such as mass-casualty situations on the battlefield, POCUS allows medical providers to rapidly and noninvasively assess for free fluid or hemorrhage induced by trauma. A major disadvantage of POCUS diagnostics is the skill threshold needed to acquire and interpret ultrasound scans. For this purpose, AI has been shown to be an effective tool to aid the caregiver when interpreting medical imaging. Here, we focus on sophisticated AI training methodologies to improve the blind, real-time diagnostic accuracy of AI models for detection of hemorrhage in two major abdominal scan sites. In this work, we used a retrospective dataset of over 60,000 swine ultrasound images to train binary classification models exploring frame-pooling methods using the backbone of a pre-existing model architecture to handle multi-channel inputs for detecting free fluid in the pelvic and right-upper-quadrant regions. Earlier classifications models had achieved 0.59 and 0.70 accuracy metrics in blind predictions, respectively. After implementing this novel training technique, performance accuracy improved to over 0.90 for both scan sites. These are promising results demonstrating a significant diagnostic improvement which encourages further optimization to achieve similar results using clinical data. Furthermore, these results show how AI-informed diagnostics can offload cognitive burden in situations where casualties may benefit from rapid triage decision making.",2025,10.3389/frai.2025.1718503
The AI trilemma: Saving the planet without ruining our jobs,"Digitalization and artificial intelligence increasingly affect the world of work. Rising risk of massive job losses have sparked technological fears. Limited income and productivity gains concentrated among a few tech companies are fueling inequalities. In addition, the increasing ecological footprint of digital technologies has become the focus of much discussion. This creates a trilemma of rising inequality, low productivity growth and high ecological costs brought by technological progress. How can this trilemma be resolved? Which digital applications should be promoted specifically? And what should policymakers do to address this trilemma? This contribution shows that policymakers should create suitable conditions to fully exploit the potential in the area of network applications (transport, information exchange, supply, provisioning) in order to reap maximum societal benefits that can be widely shared. This requires shifting incentives away from current uses toward those that can, at least partially, address the trilemma. The contribution analyses the scope and limits of current policy instruments in this regard and discusses alternative approaches that are more aligned with the properties of the emerging technological paradigm underlying the digital economy. In particular, it discusses the possibility of institutional innovations required to address the socio-economic challenges resulting from the technological innovations brought about by artificial intelligence.",2022,10.3389/frai.2022.886561
EmotionNet Nano: An Efficient Deep Convolutional Neural Network Design for Real-Time Facial Expression Recognition,"While recent advances in deep learning have led to significant improvements in facial expression classification (FEC), a major challenge that remains a bottleneck for the widespread deployment of such systems is their high architectural and computational complexities. This is especially challenging given the operational requirements of various FEC applications, such as safety, marketing, learning, and assistive living, where real-time requirements on low-cost embedded devices is desired. Motivated by this need for a compact, low latency, yet accurate system capable of performing FEC in real-time on low-cost embedded devices, this study proposes EmotionNet Nano, an efficient deep convolutional neural network created through a human-machine collaborative design strategy, where human experience is combined with machine meticulousness and speed in order to craft a deep neural network design catered toward real-time embedded usage. To the best of the author’s knowledge, this is the very first deep neural network architecture for facial expression recognition leveraging machine-driven design exploration in its design process, and exhibits unique architectural characteristics such as high architectural heterogeneity and selective long-range connectivity not seen in previous FEC network architectures. Two different variants of EmotionNet Nano are presented, each with a different trade-off between architectural and computational complexity and accuracy. Experimental results using the CK + facial expression benchmark dataset demonstrate that the proposed EmotionNet Nano networks achieved accuracy comparable to state-of-the-art FEC networks, while requiring significantly fewer parameters. Furthermore, we demonstrate that the proposed EmotionNet Nano networks achieved real-time inference speeds (e.g., &gt;25 FPS and &gt;70 FPS at 15 and 30 W, respectively) and high energy efficiency (e.g., &gt;1.7 images/sec/watt at 15 W) on an ARM embedded processor, thus further illustrating the efficacy of EmotionNet Nano for deployment on embedded devices.",2021,10.3389/frai.2020.609673
Emulation of Cosmological Mass Maps with Conditional Generative Adversarial Networks,"Weak gravitational lensing mass maps play a crucial role in understanding the evolution of structures in the Universe and our ability to constrain cosmological models. The prediction of these mass maps is based on expensive N-body simulations, which can create a computational bottleneck for cosmological analyses. Simulation-based emulators of map summary statistics, such as the matter power spectrum and its covariance, are starting to play increasingly important role, as the analytical predictions are expected to reach their precision limits for upcoming experiments. Creating an emulator of the cosmological mass maps themselves, rather than their summary statistics, is a more challenging task. Modern deep generative models, such as Generative Adversarial Networks (GAN), have demonstrated their potential to achieve this goal. Most existing GAN approaches produce simulations for a fixed value of the cosmological parameters, which limits their practical applicability. We propose a novel conditional GAN model that is able to generate mass maps for any pair of matter density Ωm and matter clustering strength σ8, parameters which have the largest impact on the evolution of structures in the Universe, for a given source galaxy redshift distribution n(z). Our results show that our conditional GAN can interpolate efficiently within the space of simulated cosmologies, and generate maps anywhere inside this space with good visual quality high statistical accuracy. We perform an extensive quantitative comparison of the N-body and GAN -generated maps using a range of metrics: the pixel histograms, peak counts, power spectra, bispectra, Minkowski functionals, correlation matrices of the power spectra, the Multi-Scale Structural Similarity Index (MS-SSIM) and our equivalent of the Fréchet Inception Distance. We find a very good agreement on these metrics, with typical differences are &lt;5% at the center of the simulation grid, and slightly worse for cosmologies at the grid edges. The agreement for the bispectrum is slightly worse, on the &lt;20% level. This contribution is a step toward building emulators of mass maps directly, capturing both the cosmological signal and its variability. We make the code1 and the data2 publicly available.",2021,10.3389/frai.2021.673062
Conditional autoencoder pre-training and optimization algorithms for personalized care of hemophiliac patients,"This paper presents the use of deep conditional autoencoder to predict the effect of treatments for patients suffering from hemophiliac disorders. Conditional autoencoder is a semi-supervised model that learns an abstract representation of the data and provides conditional reconstruction capabilities. Such models are suited to problems with limited and/or partially observable data, common situation for data in medicine. Deep conditional autoencoders allow the representation of highly non-linear functions which makes them promising candidates. However, the optimization of parameters and hyperparameters is particularly complex. For parameter optimization, the classical approach of random initialization of weight matrices works well in the case of simple architectures, but is not feasible for deep architectures. For hyperparameter optimization of deep architectures, the classical cross-validation method is costly. In this article, we propose solutions using a conditional pre-training algorithm and incremental optimization strategies. Such solutions reduce the variance of the estimation process and enhances convergence of the learning algorithm. Our proposal is applied for personalized care of hemophiliac patients. Results show better performances than generative adversarial networks (baseline) and highlight the benefits of your contribution to predict the effect of treatments for patients.",2023,10.3389/frai.2023.1048010
Is AI a functional equivalent to expertise in organizations and decision-making? Opportunities and pitfalls for AI in the context of just transitions,"The urgency of addressing climate change and achieving a just transition to sustainability has never been greater, as the world approaches critical environmental thresholds. While artificial intelligence (AI) presents both opportunities and challenges in this context, its role in organizational decision-making and expertise remains underexplored. This paper examines the interplay between AI and human expertise within organizations, focusing on how AI can complement or substitute traditional expertise across factual, temporal, and social dimensions. Drawing on Social Systems Theory, we argue that while AI excels in data processing and rapid decision-making, it falls short in contextual adaptation, long-term strategic thinking, and social legitimacy—areas where human expertise remains indispensable. And this is, we observe, particularly evident in problems connected with climate change and sustainability more broadly, where the tensions for organizational decision-making -and governance become even denser as much in the factual, temporal and social dimensions, making them into very complex, ‘super-wicked’, problem situations. Thus, there is a need to think more in detail about possible hybrid approaches, integrating AI’s computational strengths with human interpretive and adaptive capabilities, which may offer promising pathways for advancing organizational decision-making in the overly complex, wicked decision-making scenarios characteristic of just transitions. However, this requires careful consideration of power dynamics, trust-building, and the ethical implications of AI adoption. By moving beyond techno-optimism, this study highlights the need for a nuanced understanding of AI’s functional and social plausibility in organizational settings, offering insights for fostering equitable and sustainable transitions in an increasingly complex world.",2025,10.3389/frai.2025.1571698
Using Crowd-Sourced Speech Data to Study Socially Constrained Variation in Nonmodal Phonation,"This study examines the status of nonmodal phonation (e.g. breathy and creaky voice) in British English using smartphone recordings from over 2,500 speakers. With this novel data collection method, it uncovers effects that have not been reported in past work, such as a relationship between speakers’ education and their production of nonmodal phonation. The results also confirm that previous findings on nonmodal phonation, including the greater use of creaky voice by male speakers than female speakers, extend to a much larger and more diverse sample than has been considered previously. This confirmation supports the validity of using crowd-sourced data for phonetic analyses. The acoustic correlates that were examined include fundamental frequency, H1*-H2*, cepstral peak prominence, and harmonic-to-noise ratio.",2021,10.3389/frai.2020.565682
"Person-based design and evaluation of MIA, a digital medical interview assistant for radiology","Introduction
                    Radiologists frequently lack direct patient contact due to time constraints. Digital medical interview assistants aim to facilitate the collection of health information. In this paper, we propose leveraging conversational agents to realize a medical interview assistant to facilitate medical history taking, while at the same time offering patients the opportunity to ask questions on the examination.
                  
                  
                    Methods
                    MIA, the digital medical interview assistant, was developed using a person-based design approach, involving patient opinions and expert knowledge during the design and development with a specific use case in collecting information before a mammography examination. MIA consists of two modules: the interview module and the question answering module (Q&amp;A). To ensure interoperability with clinical information systems, we use HL7 FHIR to store and exchange the results collected by MIA during the patient interaction. The system was evaluated according to an existing evaluation framework that covers a broad range of aspects related to the technical quality of a conversational agent including usability, but also accessibility and security.
                  
                  
                    Results
                    Thirty-six patients recruited from two Swiss hospitals (Lindenhof group and Inselspital, Bern) and two patient organizations conducted the usability test. MIA was favorably received by the participants, who particularly noted the clarity of communication. However, there is room for improvement in the perceived quality of the conversation, the information provided, and the protection of privacy. The Q&amp;A module achieved a precision of 0.51, a recall of 0.87 and an F-Score of 0.64 based on 114 questions asked by the participants. Security and accessibility also require improvements.
                  
                  
                    Conclusion
                    The applied person-based process described in this paper can provide best practices for future development of medical interview assistants. The application of a standardized evaluation framework helped in saving time and ensures comparability of results.",2024,10.3389/frai.2024.1431156
Protecting digital assets using an ontology based cyber situational awareness system,"IntroductionCyber situational awareness is critical for detecting and mitigating cybersecurity threats in real-time. This study introduces a comprehensive methodology that integrates the Isolation Forest and autoencoder algorithms, Structured Threat Information Expression (STIX) implementation, and ontology development to enhance cybersecurity threat detection and intelligence. The Isolation Forest algorithm excels in anomaly detection in high-dimensional datasets, while autoencoders provide nonlinear detection capabilities and adaptive feature learning. Together, they form a robust framework for proactive anomaly detection.MethodsThe proposed methodology leverages the Isolation Forest for efficient anomaly identification and autoencoders for feature learning and nonlinear anomaly detection. Threat information was standardized using the STIX framework, facilitating structured and dynamic assessment of threat intelligence. Ontology development was employed to represent knowledge systematically and enable semantic correlation of threats. Feature mapping enriched datasets with contextual threat information.ResultsThe proposed dual-algorithm framework demonstrated superior performance, achieving 95% accuracy, a 99% F1 score, and a 94.60% recall rate. These results outperformed the benchmarks, highlighting the model’s effectiveness in proactive anomaly detection and cyber situational awareness enhancement.DiscussionThe integration of STIX and ontology development within the proposed methodology significantly enhanced threat information standardization and semantic analysis. The dual-algorithm approach provided improved detection capabilities compared to traditional methods, underscoring its potential for scalable and effective cybersecurity applications. Future research could explore further optimization and real-world deployments to refine and validate the approach.",2025,10.3389/frai.2024.1394363
One or two things we know about concept drift—a survey on monitoring in evolving environments. Part B: locating and explaining concept drift,"In an increasing number of industrial and technical processes, machine learning-based systems are being entrusted with supervision tasks. While they have been successfully utilized in many application areas, they frequently are not able to generalize to changes in the observed data, which environmental changes or degrading sensors might cause. These changes, commonly referred to as concept drift can trigger malfunctions in the used solutions which are safety-critical in many cases. Thus, detecting and analyzing concept drift is a crucial step when building reliable and robust machine learning-driven solutions. In this work, we consider the setting of unsupervised data streams which is highly relevant for different monitoring and anomaly detection scenarios. In particular, we focus on the tasks of localizing and explaining concept drift which are crucial to enable human operators to take appropriate action. Next to providing precise mathematical definitions of the problem of concept drift localization, we survey the body of literature on this topic. By performing standardized experiments on parametric artificial datasets we provide a direct comparison of different strategies. Thereby, we can systematically analyze the properties of different schemes and suggest first guidelines for practical applications. Finally, we explore the emerging topic of explaining concept drift.",2024,10.3389/frai.2024.1330258
Exploring Behavioral Patterns for Data-Driven Modeling of Learners' Individual Differences,"Educational data mining research has demonstrated that the large volume of learning data collected by modern e-learning systems could be used to recognize student behavior patterns and group students into cohorts with similar behavior. However, few attempts have been done to connect and compare behavioral patterns with known dimensions of individual differences. To what extent learner behavior is defined by known individual differences? Which of them could be a better predictor of learner engagement and performance? Could we use behavior patterns to build a data-driven model of individual differences that could be more useful for predicting critical outcomes of the learning process than traditional models? Our paper attempts to answer these questions using a large volume of learner data collected in an online practice system. We apply a sequential pattern mining approach to build individual models of learner practice behavior and reveal latent student subgroups that exhibit considerably different practice behavior. Using these models we explored the connections between learner behavior and both, the incoming and outgoing parameters of the learning process. Among incoming parameters we examined traditionally collected individual differences such as self-esteem, gender, and knowledge monitoring skills. We also attempted to bridge the gap between cluster-based behavior pattern models and traditional scale-based models of individual differences by quantifying learner behavior on a latent data-driven scale. Our research shows that this data-driven model of individual differences performs significantly better than traditional models of individual differences in predicting important parameters of the learning process, such as performance and engagement.",2022,10.3389/frai.2022.807320
NeuroSim Simulator for Compute-in-Memory Hardware Accelerator: Validation and Benchmark,"Compute-in-memory (CIM) is an attractive solution to process the extensive workloads of multiply-and-accumulate (MAC) operations in deep neural network (DNN) hardware accelerators. A simulator with options of various mainstream and emerging memory technologies, architectures, and networks can be a great convenience for fast early-stage design space exploration of CIM hardware accelerators. DNN+NeuroSim is an integrated benchmark framework supporting flexible and hierarchical CIM array design options from a device level, to a circuit level and up to an algorithm level. In this study, we validate and calibrate the prediction of NeuroSim against a 40-nm RRAM-based CIM macro post-layout simulations. First, the parameters of a memory device and CMOS transistor are extracted from the foundry’s process design kit (PDK) and employed in the NeuroSim settings; the peripheral modules and operating dataflow are also configured to be the same as the actual chip implementation. Next, the area, critical path, and energy consumption values from the SPICE simulations at the module level are compared with those from NeuroSim. Some adjustment factors are introduced to account for transistor sizing and wiring area in the layout, gate switching activity, post-layout performance drop, etc. We show that the prediction from NeuroSim is precise with chip-level error under 1% after the calibration. Finally, the system-level performance benchmark is conducted with various device technologies and compared with the results before the validation. The general conclusions stay the same after the validation, but the performance degrades slightly due to the post-layout calibration.",2021,10.3389/frai.2021.659060
Three levels at which the user's cognition can be represented in artificial intelligence,"Artificial intelligence (AI) plays an important role in modern society. AI applications are omnipresent and assist many decisions we make in daily life. A common and important feature of such AI applications are user models. These models allow an AI application to adapt to a specific user. Here, we argue that user models in AI can be optimized by modeling these user models more closely to models of human cognition. We identify three levels at which insights from human cognition can be—and have been—integrated in user models. Such integration can be very loose with user models only being inspired by general knowledge of human cognition or very tight with user models implementing specific cognitive processes. Using AI-based applications in the context of education as a case study, we demonstrate that user models that are more deeply rooted in models of cognition offer more valid and more fine-grained adaptations to an individual user. We propose that such user models can also advance the development of explainable AI.",2023,10.3389/frai.2022.1092053
Dimensions of artificial intelligence on family communication,"IntroductionArtificial intelligence (AI) has created a plethora of prospects for communication. The study aims to examine the impacts of AI dimensions on family communication. By investigating the multifaceted effects of AI on family communication, this research aims to provide valuable insights, uncover potential concerns, and offer recommendations for both families and society at large in this digital era.MethodA convenience sampling technique was adopted to recruit 300 participants.ResultsA linear regression model was measured to examine the impact of AI dimensions which showed a statistically significant effect on accessibility (p = 0.001), personalization (p = 0.001), and language translation (p = 0.016).DiscussionThe findings showed that in terms of accessibility (p = 0.006), and language translation (p = 0.010), except personalization (p = 0.126), there were differences between males and females. However, using multiple AI tools was statistically associated with raising concerns about bias and privacy (p = 0.015), safety, and dependence (p = 0.049) of parents.ConclusionThe results showed a lack of knowledge and transparency about the data storage and privacy policy of AI-enabled communication systems. Overall, there was a positive impact of AI dimensions on family communication.",2024,10.3389/frai.2024.1398960
Navigating the AI revolution: challenges and opportunities for integrating emerging technologies into knowledge management systems. Systematic literature review,"IntroductionArtificial intelligence (AI) is transforming organizational knowledge management (KM) by leveraging techniques such as machine learning, neural networks, and fuzzy logic to enhance knowledge discovery, capture, storage, and sharing. While this shift promises improved efficiency and personalization, it also poses challenges related to data quality, employee resistance, and alignment with existing workflows.MethodsThis study presents a systematic literature review (SLR) of 40 peer-reviewed publications focused on the integration of AI in KM. The review follows PRISMA guidelines and includes thematic coding to identify patterns, critical success factors, and knowledge gaps.ResultsFindings indicate that successful AI-enabled KM depends on strong leadership commitment, adaptable governance structures, and context-sensitive technology selection. AI’s role is evolving from supporting routine tasks to enabling dynamic, real-time knowledge flows. The review also highlights a critical need to balance automation with human oversight.DiscussionKey gaps were identified in understanding cost–benefit trade-offs, ethical implications, and governance mechanisms. These insights suggest directions for future research focused on practical, accountable, and empirically validated KM strategies. As part of an ongoing research project, the synthesized findings will inform the design of future empirical studies. The evidence suggests that, when strategically implemented, AI can serve as a competitive enabler in knowledge-driven organizations.",2025,10.3389/frai.2025.1595930
Application of artificial intelligence in mine ventilation: a brief review,"In recent years, there has been a notable integration of artificial intelligence (AI) technologies into mine ventilation systems. A mine ventilation network presents a complex system with numerous interconnected processes, some of which pose challenges for deterministic simulation methods. The utilization of machine learning techniques and evolutionary algorithms offers a promising avenue to address these complexities, resulting in enhanced monitoring and control of air parameter distribution within the ventilation network. These methods facilitate the timely identification of resistance faults and enable prompt calculation of ventilation parameters during emergency scenarios, such as underground explosions and fires. Furthermore, evolutionary algorithms play a crucial role in the advancement of methods for visual analysis of ventilation systems. However, it is essential to acknowledge that the current utilization of AI technologies in mine ventilation is limited and does not encompass the full spectrum of challenging-to-formalize problems. Promising areas for AI application include analyzing changes in air distribution caused by unaccounted thermal draft and gas pressure, as well as developing novel approaches for calculating shock losses. Moreover, the application of AI technologies in optimizing large-scale mine ventilation networks remains an unresolved issue. Addressing these challenges holds significant potential for enhancing safety and efficiency in mine ventilation systems.",2024,10.3389/frai.2024.1402555
An Ontology-Based Chatbot to Enhance Experiential Learning in a Cultural Heritage Scenario,"Italy is rich in cultural attractions, many known worldwide, others more hidden and unrecognized. Cultural attractions include tangible cultural assets (works of art, archaeological excavations, and churches) and intangible ones (music, poetry, and art). Today, given the pervasive diffusion of “smart” devices, the intelligent use of modern technologies could play a crucial role in changing the habit of consulting and visiting cultural heritage mainly with traditional methodologies, making little or no use of the advantages coming from the more and more availability of digitalized resources. A realm of particular interest is “experiential learning” when applied to cultural heritage, where tourists more and more ask to be helped in discovering the richness of sites they explore. In this article, we will present an innovative chatbot-based system, called HeriBot, that supports experiential tourism. Our system has been developed and experimented with a research effort for applying ICT technologies to enhance the knowledge, valorization, and sustainable fruition of the Cultural Heritage related to the Archaeological Urban Park of Naples (PAUN—Parco Archeologico Urbano di Napoli). Our article starts exploiting the ontological approach based on a purpose ontology describing the Park Heritage. Using such an ontology, we designed a chatbot that can identify the specific characteristics and motivations of the tourist, defining language, tone, and visitable scenarios and, through the ontology, allows the visit to be transformed into a personalized educational opportunity. The system has been validated in terms of dialogue effectiveness and training efficiency by a panel of experts, and we present and discuss obtained results.",2022,10.3389/frai.2022.808281
The Turing Teacher: Identifying core attributes for AI learning in K-12,"IntroductionArtificial intelligence in the educational domain has many uses; however, using AI specifically to enhance education and teaching in a K-12 environment poses the most significant challenges to its use. Beyond usage and application, the quality of the education is made even more arduous due to the dynamics of teaching primary and secondary school children, whose needs far exceed mere fact recollection. Utilizing prior research using AI in education and online education in the K-12 space, we explore some of the hurdles that AI applications face in K-12 teaching and provide core attributes for a “Turing Teacher,” i.e., an AI powered technology for learning, specifically targeting the K-12 space.MethodsUsing a survey, which included qualitative responses during the implementation of online learning during the Covid Pandemic, we analyze the results using univariate and multivariate tests and analyzed the qualitative responses to create core attributes needed for AI powered teaching technology.ResultsThe results present the challenges faced by any technology in an education setting and show that AI technology must help overcome negative feelings about technology in education. Further, the core attributes identified in the research must be addressed from the three stakeholder perspectives of teachers, parents and students.DiscussionWe present our findings and lay the groundwork for future research in the area of AI powered education. The Turing Teacher must be able to adapt and collaborate with real teachers and address the varying needs of students. In addition, we explore the use of AI technology as a means to close the digital divide in traditionally disadvantaged communities.",2022,10.3389/frai.2022.1031450
The technology acceptance model and adopter type analysis in the context of artificial intelligence,"IntroductionArtificial Intelligence (AI) is a transformative technology impacting various sectors of society and the economy. Understanding the factors influencing AI adoption is critical for both research and practice. This study focuses on two key objectives: (1) validating an extended version of the Technology Acceptance Model (TAM) in the context of AI by integrating the Big Five personality traits and AI mindset, and (2) conducting an exploratory k-prototype analysis to classify AI adopters based on demographics, AI-related attitudes, and usage patterns.MethodsA sample of N = 1,007 individuals individuals (60% female; M = 30.92; SD = 8.63 years) was collected. Psychometric data were obtained using validated scales for TAM constructs, Big Five personality traits, and AI mindset. Regression analysis was used to validate TAM, and a k-prototype clustering algorithm was applied to classify participants into adopter categories.ResultsThe psychometric analysis confirmed the validity of the extended TAM. Perceived usefulness was the strongest predictor of attitudes towards AI usage (β = 0.34, p &lt; 0.001), followed by AI mindset scale growth (β = 0.28, p &lt; 0.001). Additionally, openness was positively associated with perceived ease of use (β = 0.15, p &lt; 0.001). The k-prototype analysis revealed four distinct adopter clusters, consistent with the diffusion of innovations model: early adopters (n = 218), early majority (n = 331), late majority (n = 293), and laggards (n = 165).DiscussionThe findings highlight the importance of perceived usefulness and AI mindset in shaping attitudes toward AI adoption. The clustering results provide a nuanced understanding of AI adopter types, aligning with established innovation diffusion theories. Implications for AI deployment strategies, policy-making, and future research directions are discussed.",2025,10.3389/frai.2024.1496518
Machine learning approaches to identify Parkinson's disease using voice signal features,"Parkinson's Disease (PD) is the second most common age-related neurological disorder that leads to a range of motor and cognitive symptoms. A PD diagnosis is difficult since its symptoms are quite similar to those of other disorders, such as normal aging and essential tremor. When people reach 50, visible symptoms such as difficulties walking and communicating begin to emerge. Even though there is no cure for PD, certain medications can relieve some of the symptoms. Patients can maintain their lifestyles by controlling the complications caused by the disease. At this point, it is essential to detect this disease and prevent it from progressing. The diagnosis of the disease has been the subject of much research. In our project, we aim to detect PD using different types of Machine Learning (ML), and Deep Learning (DL) models such as Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), K-Nearest Neighbor (KNN), and Multi-Layer Perceptron (MLP) to differentiate between healthy and PD patients by voice signal features. The dataset taken from the University of California at Irvine (UCI) machine learning repository consisted of 195 voice recordings of examinations carried out on 31 patients. Moreover, our models were trained using different techniques such as Synthetic Minority Over-sampling Technique (SMOTE), Feature Selection, and hyperparameter tuning (GridSearchCV) to enhance their performance. At the end, we found that MLP and SVM with a ratio of 70:30 train/test split using GridSearchCV with SMOTE gave the best results for our project. MLP performed with an overall accuracy of 98.31%, an overall recall of 98%, an overall precision of 100%, and f1-score of 99%. In addition, SVM performed with an overall accuracy of 95%, an overall recall of 96%, an overall precision of 98%, and f1-score of 97%. The experimental results of this research imply that the proposed method can be used to reliably predict PD and can be easily incorporated into healthcare for diagnosis purposes.",2023,10.3389/frai.2023.1084001
A Survey of Topological Machine Learning Methods,"The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as “topological machine learning,” i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges.",2021,10.3389/frai.2021.681108
Predicting Tissue-Specific mRNA and Protein Abundance in Maize: A Machine Learning Approach,"Machine learning and modeling approaches have been used to classify protein sequences for a broad set of tasks including predicting protein function, structure, expression, and localization. Some recent studies have successfully predicted whether a given gene is expressed as mRNA or even translated to proteins potentially, but given that not all genes are expressed in every condition and tissue, the challenge remains to predict condition-specific expression. To address this gap, we developed a machine learning approach to predict tissue-specific gene expression across 23 different tissues in maize, solely based on DNA promoter and protein sequences. For class labels, we defined high and low expression levels for mRNA and protein abundance and optimized classifiers by systematically exploring various methods and combinations of k-mer sequences in a two-phase approach. In the first phase, we developed Markov model classifiers for each tissue and built a feature vector based on the predictions. In the second phase, the feature vector was used as an input to a Bayesian network for final classification. Our results show that these methods can achieve high classification accuracy of up to 95% for predicting gene expression for individual tissues. By relying on sequence alone, our method works in settings where costly experimental data are unavailable and reveals useful insights into the functional, evolutionary, and regulatory characteristics of genes.",2022,10.3389/frai.2022.830170
Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.",2024,10.3389/frai.2024.1408843
Artificial intelligence in healthcare text processing: a review applied to named entity recognition,"ContextTraditional methods such as rule-based systems, word embeddings (e.g. Word2Vec, GloVe) and sequence tagging models such as CRFs and HMMs have difficulty capturing the complex and nuanced context of medical texts, leading to low precision and inflexibility. These methods also struggle with the inherent variability of medical language and often require large and difficult-to-obtain labeled datasets.ObjectiveWe examine the growing importance of Named Entity Recognition (NER) in the analysis of healthcare texts. NER, a fundamental technique in Natural Language Processing (NLP), automatically identifies and categorizes named entities in the text, such as names of people and organizations, in medical texts, medical conditions and drug names. This facilitates better information retrieval, personalized medicine approaches and clinical decision support systems.MethodsA systematic mapping was carried out that focused on advanced language models, specifically transformation-based models such as BERT. These models are known for capturing complex semantic dependencies and linguistic nuances, which are crucial for accurate processing of medical texts. Transformation architectures, unlike traditional techniques such as CNNs and RNNs, are better suited to dealing with the contextual and semantic nature of medical texts due to their ability to manage long sequences and the need for high precision.ResultsThe results indicate that transformation-based models, in particular BERT and its specialized variants (e.g. ClinicalBERT), consistently demonstrate high performance on NER tasks, with F1 scores often exceeding 97%, outperforming traditional and hybrid methods. When examining the geographical distribution of contributions, the research identifies a significant contribution from China, followed by the United States. These findings have crucial implications for the integration of NER technologies into the Brazilian National Health System (SUS).ConclusionThis systematic review contributes to the advancement of NER in health texts by evaluating methods, showing results and highlighting the wider implications for the field. The article is systematically structured into the following sections: Methodology, Bibliometric analysis, Results and discussion, Threats to validity, Future work and Conclusion. This systematic organization provides a comprehensive review of the research, its impact and future directions, highlighting the importance of keeping up to date with advances in the field to increase the relevance of NER applications in healthcare.",2025,10.3389/frai.2025.1584203
Utilizing XGBoosts to correct arcjet contamination in magnetic field measurements from GOES missions,"The magnetometers onboard the Geostationary Operational Environmental Satellites (GOES) provide crucial measurements for space weather monitoring and scientific research. However, periodic arcjet thruster firings introduce contamination in the measured magnetic field, affecting data accuracy. The currently used correction matrix approach mitigates these effects but struggles with transient variations and residual errors. In this study, we present an alternative correction method using XGBoost, a machine learning algorithm, to correct arcjet-induced contamination in the GOES-17 magnetometer data using GOES-18 as ground truth. Using cross-satellite comparisons and supervised learning techniques, our model is effective in reducing artificial disturbances, especially non-linear variations. We found that the XGBoost method works better than the existing correction matrix approach for E and P components, while the correction matrix performs better for the N component. Although some limitations remain due to training data constraints, our results highlight the importance of machine learning to improve magnetometer data quality by recognizing and correcting complex satellite-driven artifacts. The collocation of GOES-17 and GOES-18 provided a unique opportunity for cross-satellite calibration and validation, and with a longer collocation period, the XGBoost method shows significant promise for better correction of operational data, emphasizing the need for such configurations in future satellite missions.",2025,10.3389/frai.2025.1628029
Machine learning corroborates subjective ratings of walking and balance difficulty in multiple sclerosis,"Machine learning can discern meaningful information from large datasets. Applying machine learning techniques to raw sensor data from instrumented walkways could automatically detect subtle changes in walking and balance. Multiple sclerosis (MS) is a neurological disorder in which patients report varying degrees of walking and balance disruption. This study aimed to determine whether machine learning applied to walkway sensor data could classify severity of self-reported symptoms in MS patients. Ambulatory people with MS (n = 107) were asked to rate the severity of their walking and balance difficulties, from 1-No problems to 5-Extreme problems, using the MS-Impact Scale-29. Those who scored less than 3 (moderately) were assigned to the “mild” group (n = 35), and those scoring higher were in the “moderate” group (n = 72). Three machine learning algorithms were applied to classify the “mild” group from the “moderate” group. The classification achieved 78% accuracy, a precision of 85%, a recall of 90%, and an F1 score of 87% for distinguishing those people reporting mild from moderate walking and balance difficulty. This study demonstrates that machine learning models can reliably be applied to instrumented walkway data and distinguish severity of self-reported impairment in people with MS.",2022,10.3389/frai.2022.952312
AI-driven routing pipeline in software-defined networks using DQL: a mini review,"State-of-the-art data center networks are experiencing an increase in dynamic traffic. Even minor inefficiencies cause latency, congestion, and high costs. Software-defined networking (SDN) provides centralized programmability, but classical algorithms such as Dijkstra and Equal-Cost Multi-Path (ECMP) fall short because they cannot adapt in real time. To overcome this limitation, Reinforcement Learning (RL), particularly Q-learning, adds adaptability; however, scalability remains a challenge. DQL addresses this by using neural networks to approximate the Q-function, enabling SDN controllers to learn routing strategies directly from live network states. This Mini Review brings together recent DQL approaches for SDN. We examine architectures, algorithmic variants, and emulation environments (such as Mininet with Ryu). In addition, we introduce a structured taxonomy, with a practice-oriented synthesis of empirical trade-offs and deployment issues. The focus is on trade-offs, throughput, latency, and convergence. Reported studies show that DQL typically improves throughput by about 15–22 percent and reduces delays by roughly 10–12 percent compared with ECMP. These gains, however, come at the cost of longer training, inference delays, and scalability hurdles. Unlike prior surveys, this review makes three distinct contributions: a structured taxonomy, with a practice-oriented synthesis of empirical trade-offs and deployment issues. We also highlight emerging directions: federated learning, graph-based neural models, and explainable AI, which may help transition DQL from promising simulations to production-ready SDN solutions.",2025,10.3389/frai.2025.1685155
Leveraging explanations in interactive machine learning: An overview,"Explanations have gained an increasing level of interest in the AI and Machine Learning (ML) communities in order to improve model transparency and allow users to form a mental model of a trained ML model. However, explanations can go beyond this one way communication as a mechanism to elicit user control, because once users understand, they can then provide feedback. The goal of this paper is to present an overview of research where explanations are combined with interactive capabilities as a mean to learn new models from scratch and to edit and debug existing ones. To this end, we draw a conceptual map of the state-of-the-art, grouping relevant approaches based on their intended purpose and on how they structure the interaction, highlighting similarities and differences between them. We also discuss open research issues and outline possible directions forward, with the hope of spurring further research on this blooming research topic.",2023,10.3389/frai.2023.1066049
Precision enhancement in wireless capsule endoscopy: a novel transformer-based approach for real-time video object detection,"BackgroundWireless Capsule Endoscopy (WCE) enables non-invasive imaging of the gastrointestinal tract but generates vast video data, making real-time and accurate abnormality detection challenging. Traditional detection methods struggle with uncontrolled illumination, complex textures, and high-speed processing demands.MethodsThis study presents a novel approach using Real-Time Detection Transformer (RT-DETR), a transformer-based object detection model, specifically optimized for WCE video analysis. The model captures contextual information between frames and handles variable image conditions. It was evaluated using the Kvasir-Capsule dataset, with performance assessed across three RT-DETR variants: Small (S), Medium (M), and X-Large (X).ResultsRT-DETR-X achieved the highest detection precision. RT-DETR-M offered a practical trade-off between accuracy and speed, while RT-DETR-S processed frames at 270 FPS, enabling real-time performance. All three models demonstrated improved detection accuracy and computational efficiency compared to baseline methods.DiscussionThe RT-DETR framework significantly enhances precision and real-time performance in gastrointestinal abnormality detection using WCE. Its clinical potential lies in supporting faster and more accurate diagnosis. Future work will focus on further optimization and deployment in endoscopic video analysis systems.",2025,10.3389/frai.2025.1529814
Clinical Enhancement in AI-Based Post-processed Fast-Scan Low-Dose CBCT for Head and Neck Adaptive Radiotherapy,"Purpose: To assess image quality and uncertainty in organ-at-risk segmentation on cone beam computed tomography (CBCT) enhanced by deep-learning convolutional neural network (DCNN) for head and neck cancer.Methods: An in-house DCNN was trained using forty post-operative head and neck cancer patients with their planning CT and first-fraction CBCT images. Additional fifteen patients with repeat simulation CT (rCT) and CBCT scan taken on the same day (oCBCT) were used for validation and clinical utility assessment. Enhanced CBCT (eCBCT) images were generated from the oCBCT using the in-house DCNN. Quantitative imaging quality improvement was evaluated using HU accuracy, signal-to-noise-ratio (SNR), and structural similarity index measure (SSIM). Organs-at-risk (OARs) were delineated on o/eCBCT and compared with manual structures on the same day rCT. Contour accuracy was assessed using dice similarity coefficient (DSC), Hausdorff distance (HD), and center of mass (COM) displacement. Qualitative assessment of users’ confidence in manual segmenting OARs was performed on both eCBCT and oCBCT by visual scoring.Results: eCBCT organs-at-risk had significant improvement on mean pixel values, SNR (p &lt; 0.05), and SSIM (p &lt; 0.05) compared to oCBCT images. Mean DSC of eCBCT-to-rCT (0.83 ± 0.06) was higher than oCBCT-to-rCT (0.70 ± 0.13). Improvement was observed for mean HD of eCBCT-to-rCT (0.42 ± 0.13 cm) vs. oCBCT-to-rCT (0.72 ± 0.25 cm). Mean COM was less for eCBCT-to-rCT (0.28 ± 0.19 cm) comparing to oCBCT-to-rCT (0.44 ± 0.22 cm). Visual scores showed OAR segmentation was more accessible on eCBCT than oCBCT images.Conclusion: DCNN improved fast-scan low-dose CBCT in terms of the HU accuracy, image contrast, and OAR delineation accuracy, presenting potential of eCBCT for adaptive radiotherapy.",2021,10.3389/frai.2020.614384
Sequence labeling via reinforcement learning with aggregate labels,"Sequence labeling is pervasive in natural language processing, encompassing tasks such as Named Entity Recognition, Question Answering, and Information Extraction. Traditionally, these tasks are addressed via supervised machine learning approaches. However, despite their success, these approaches are constrained by two key limitations: a common mismatch between the training and evaluation objective, and the resource-intensive acquisition of ground-truth token-level annotations. In this work, we introduce a novel reinforcement learning approach to sequence labeling that leverages aggregate annotations by counting entity mentions to generate feedback for training, thereby addressing the aforementioned limitations. We conduct experiments using various combinations of aggregate feedback and reward functions for comparison, focusing on Named Entity Recognition to validate our approach. The results suggest that sequence labeling can be learned from purely count-based labels, even at the sequence-level. Overall, this count-based method has the potential to significantly reduce annotation costs and variances, as counting entity mentions is more straightforward than determining exact boundaries.",2024,10.3389/frai.2024.1463164
Construction of medical scientific data repositories in China: analysis of survey and recommendations,"BackgroundIn the context of global open science trends, medical open-access repositories (OARs) promote transparency in research and facilitate the sharing of scientific data. The increase in scientific output necessitates a robust infrastructure to enhance OARs in China.ObjectivesThis study aimed to evaluate medical open-access repositories (OARs) in China that are indexed in re3data.org and OpenDOAR.org. The study analyzed data classification, descriptions, retrieval, and the utilization of selected repositories.MethodsThis study ascertained the current status of the Chinese medical OARs by visiting their respective websites and attempted to identify the disciplinary orientation of each OAR. A content analysis approach was utilized to achieve this study’s objective. Twelve Chinese medical open-access repositories were selected from re3data.org and OpenDOAR.org to examine how their information is organized. The data were collected manually from May 1 to 30, 2023, and analyzed using various quantitative techniques to understand the current status of medical scientific repositories in China.ResultsBased on the results, this study proposed the following recommendations: (1) implement multi-dimensional data classification, (2) use persistent data identifiers, (3) formalize the description metadata, (4) enhance advanced retrieval and result set filtering functions, and (5) optimize the preview and interaction features of data repositories.ConclusionThe scope of this study is restricted to the medical open-access repositories in China as listed on re3data.org and OpenDOAR.org. Therefore, the results of this study are only generalizable within China. The primary focus of research output in China is on medical open-access repositories. This study is essential for assessing China’s current status in research data management within the medical field and its distribution infrastructure in global open science trends.",2025,10.3389/frai.2025.1544200
Causal contextual bandits with one-shot data integration,"We study a contextual bandit setting where the agent has access to causal side information, in addition to the ability to perform multiple targeted experiments corresponding to potentially different context-action pairs—simultaneously in one-shot within a budget. This new formalism provides a natural model for several real-world scenarios where parallel targeted experiments can be conducted and where some domain knowledge of causal relationships is available. We propose a new algorithm that utilizes a novel entropy-like measure that we introduce. We perform several experiments, both using purely synthetic data and using a real-world dataset. In addition, we study sensitivity of our algorithm's performance to various aspects of the problem setting. The results show that our algorithm performs better than baselines in all of the experiments. We also show that the algorithm is sound; that is, as budget increases, the learned policy eventually converges to an optimal policy. Further, we theoretically bound our algorithm's regret under additional assumptions. Finally, we provide ways to achieve two popular notions of fairness, namely counterfactual fairness and demographic parity, with our algorithm.",2024,10.3389/frai.2024.1346700
Accuracy of AI chatbots in answering frequently asked questions on cervical cancer,"ObjectiveTo compare the accuracy of Deepseek and ChatGPT in answering frequently asked questions (FAQs) about cervical cancer.MethodsTo compile a list of FAQs concerning cervical cancer, a comprehensive search was conducted on social media and community platforms. The answer keys for all the selected questions were created on the basis of the guidelines of the National Comprehensive Cancer Network (NCCN), the International Federation of Gynecology and Obstetrics (FIGO), and the World Health Organization (WHO) for cervical cancer. The answers given by Deepseek-R1 and ChatGPT O1 were scored according to the Global Quality Score (GQS).ResultsA total of 74 FAQs covered a diverse range of topics related to cervical cancer, including diagnosis (n = 16), risk factors and epidemiology (n = 19), treatment (n = 20), and prevention (n = 19). When all the answers provided by DeepSeek to the FAQs about cervical cancer according to the GQS were evaluated, 68 answers were rated as score five, 4 answers were rated as score four, and 2 answers were rated as score three. For ChatGPT’s responses to the same set of FAQs, 67 answers were classified as score five, 6 answers were classified as score four, and 1 answer was classified as score three. There was no statistically significant difference between the two groups (p &gt; 0.05).ConclusionBoth DeepSeek and ChatGPT demonstrated accurate and satisfactory responses to FAQs about cervical cancer when evaluated according to the GQS. However, in regard to treatment issues, a cautious attitude should be maintained. Compared to ChatGPT, DeepSeek stands out for its free availability, which makes it more accessible in resource-limited scenarios to the public.",2025,10.3389/frai.2025.1655303
"Culture intelligent workflow, structure, and steps","IntroductionTechnologies abstract intelligence and provide predictor and precision insight in workflows that manage disorders, similar to cardiology and hematological disease. Positive perceptions of Artificial Intelligence (AI) that support Machine Learning (ML) and Deep Learning (DL) manage transformations with a safe system that improves wellbeing. In sections, workflow introduces an eXamination (X = AI) as an end-to-end structure to culture workstreams in a step-by-step design to manage populace health in a governed system.MethodTo better healthcare outcomes, communities and personnel benefit from an explanation and an interpretive that elucidates workflow for citizens or practitioners to comprehend personalized platforms. Therefore, the author undertook structure and practice reviews and appraised perspectives that impact the management of AI in public health and medicine.ResultsFigures for the management of AI workflow illustrate and inform on the model, structure, culture, assurance, process steps, values, and governance required for abstract insights in public health and medicine. The papers' end-to-end structure with explanans in a work culture interprets the step-by-step designs that manage the success of AI. Personalized care graphics offer an explanandum in the management of biological analytic value.DiscussionHealthcare leadership collaboratives plan population health with an upstream, workplace and workstream format. Secure workflow and safety wellbeing system requirements prove that genomics and AI improve medicine. Therefore, the paper discusses group understanding of current practice, ethics, policy, and legality.Conclusion“Culture, intelligent workflow, structure, and steps” improve wellbeing with personalized care and align a percept for national opportunities, regional control, and local needs. Personalized practice cultures support analytic systems to describe, predict, precision, and prescript medicine in population health management eXaminations.",2023,10.3389/frai.2023.985469
Real-Time Inference With 2D Convolutional Neural Networks on Field Programmable Gate Arrays for High-Rate Particle Imaging Detectors,"We present a custom implementation of a 2D Convolutional Neural Network (CNN) as a viable application for real-time data selection in high-resolution and high-rate particle imaging detectors, making use of hardware acceleration in high-end Field Programmable Gate Arrays (FPGAs). To meet FPGA resource constraints, a two-layer CNN is optimized for accuracy and latency with KerasTuner, and networkquantizationis further used to minimize the computing resource utilization of the network. We use “High Level Synthesis for Machine Learning” (hls4ml) tools to test CNN deployment on a Xilinx UltraScale+ FPGA, which is an FPGA technology proposed for use in the front-end readout system of the future Deep Underground Neutrino Experiment (DUNE) particle detector. We evaluate network accuracy and estimate latency and hardware resource usage, and comment on the feasibility of applying CNNs for real-time data selection within the currently planned DUNE data acquisition system. This represents the first-ever exploration of employing 2D CNNs on FPGAs for DUNE.",2022,10.3389/frai.2022.855184
Constructing and evaluating ArabicStanceX: a social media dataset for Arabic stance detection,"Arabic stance detection has attracted significant interest due to the growing importance of social media in shaping public opinion. However, the lack of comprehensive datasets has limited research progress in Arabic Natural Language Processing (NLP). To address this, we introduce ArabicStanceX, a novel and extensive Arabic stance detection dataset sourced from social media, comprising 14,477 tweets across 17 diverse topics. Utilizing the transformer-based MARBERTv2 model, we explore stance detection through Multi-Topic Single Model (MTSM) strategies, achieving a promising F1 score of 0.74 for detecting ‘favor' and ‘against' stances, and 0.67 overall. Our experiments highlight the model's capabilities and challenges, particularly in accurately classifying neutral stances and generalizing to unseen topics. Further investigations using zero-shot and few-shot learning demonstrate the model's adaptability to new contexts. This study significantly advances Arabic NLP, providing crucial resources and insights into stance detection methodologies and future research directions. The dataset is publicly available1.",2025,10.3389/frai.2025.1615800
XGSleeve: detecting sleeve incidents in well completion by using XGBoost classifier,"The sliding sleeve holds a pivotal role in regulating fluid flow during hydraulic fracturing within shale oil extraction processes. However, concerns persist surrounding its reliability due to repeated attempts at opening the sleeve, resulting in process inefficiencies. While downhole cameras can verify sleeve states, their high cost poses a limitation. This study proposes an alternative approach, leveraging downhole data analysis for sleeve incident detection in lieu of cameras. This study introduces “XGSleeve,” a novel machine-learning methodology. XGSleeve amalgamates hidden Markov model-based clustering with the XGBoost model, offering robust identification of sleeve incidents. This method serves as an operator-centric tool, addressing the domains of oil and gas, well completion, sliding sleeves, time series classification, signal processing, XGBoost, and hidden Markov models. The XGSleeve model exhibits a commendable 86% precision in detecting sleeve incidents. This outcome significantly curtails the need for multiple sleeve open-close attempts, thereby enhancing operational efficiency and safety. The successful implementation of the XGSleeve model rectifies existing limitations in sleeve incident detection, consequently fostering optimization, safety, and resilience within the oil and gas sector. This innovation further underscores the potential for data-driven decision-making in the industry. The XGSleeve model represents a groundbreaking advancement in sleeve incident detection, demonstrating the potential for broader integration of AI and machine learning in oil and gas operations. As technology advances, such methodologies are poised to optimize processes, minimize environmental impact, and promote sustainable practices. Ultimately, the adoption of XGSleeve contributes to the enduring growth and responsible management of global oil and gas resources.",2023,10.3389/frai.2023.1243584
The use of automation in the rendition of certain articles of the Saudi Commercial Law into English: a post-editing-based comparison of five machine translation systems,"Efforts to automate translation were made in the 1950s and 1960s, albeit with limited resources compared to current advanced standards. Machine translation is categorised under computational linguistics that examines employing computer software in the rendition of text from one language into another. The present paper seeks to compare five different machine translation systems for the sake of assessing the quality of their outputs in rendering certain articles of the Saudi Commercial Law into English through post-editing based on Human Translation Edit Rate. Each machine translation output is assessed against the same post-edited version, and the closest output to the post-edited version with regard to the use of the same lexicon and word order will achieve the lowest score. The lower the score of the machine translation output is, the higher quality it has. The paper then analyses the results of the Human Translation Edit Rate metric evaluation to ascertain as to whether or not high-quality machine translation outputs always produce acceptable Arabic–English legal translation. The present paper argues that the use of Human Translation Edit Rate metric is a useful tool for the sake of undertaking post-editing procedures as it is a combination of both human evaluation as well as automatic evaluation. It is also advantageous as it takes account of both the use of lexicon and word order. However, such metric cannot be sufficiently depended on as one term substitution, which will be counted according to this metric as a single error, may render the whole sentence invalid, particularly in legal translation. This paper offers a baseline for the quality assessment of machine translation output through post-editing based on Human Translation Edit Rate metric and how its results should be analysed within Arabic–English legal translation context, which may have implications for similar machine translation output quality assessment contexts.",2024,10.3389/frai.2023.1282020
Evaluating ChatGPT-4’s historical accuracy: a case study on the origins of SWOT analysis,"In this study we test ChatGPT-4’s ability to provide accurate information about the origins and evolution of SWOT analysis, perhaps the most widely used strategy tool in practice worldwide. ChatGPT-4 is tested for historical accuracy and hallucinations. The API is prompted using a Python script with a series of structured questions from an Excel file and the results are recorded in another Excel file and rated on a binary scale. Our findings present a nuanced view of ChatGPT-4’s capabilities. We observe that while ChatGPT-4 demonstrates a high level of proficiency in describing and outlining the general concept of SWOT analysis, there are notable discrepancies when it comes to detailing its origins and evolution. These inaccuracies range from minor factual errors to more serious hallucinations that deviate from evidence in scholarly publications. However, we also find that ChatGPT-4 comes up with spontaneous historically accurate facts. Our interpretation of the result is that ChatGPT is largely trained on easily available websites and to a very limited extent has been trained on scholarly publications on SWOT analysis, especially when these are behind a paywall. We conclude with four propositions for future research.",2024,10.3389/frai.2024.1402047
A review on AI Safety in highly automated driving,"Remarkable progress in the fields of machine learning (ML) and artificial intelligence (AI) has led to an increased number of applications of (data-driven) AI systems for the partial or complete control of safety-critical systems. Recently, ML solutions have been particularly popular. Such approaches are often met with concerns regarding their correct and safe execution, which is often caused by missing knowledge or intransparency of their exact functionality. The investigation and derivation of methods for the safety assessment of AI systems are thus of great importance. Among others, these issues are addressed in the field of AI Safety. The aim of this work is to provide an overview of this field by means of a systematic literature review with special focus on the area of highly automated driving, as well as to present a selection of approaches and methods for the safety assessment of AI systems. Particularly, validation, verification, and testing are considered in light of this context. In the review process, two distinguished classes of approaches have been identified: On the one hand established methods, either referring to already published standards or well-established concepts from multiple research areas outside ML and AI. On the other hand newly developed approaches, including methods tailored to the scope of ML and AI which gained importance only in recent years.",2022,10.3389/frai.2022.952773
AI competence and sentiment: a mixed-methods study of attitudes and open-ended reflections,"As artificial intelligence (AI) technologies become increasingly integrated into everyday life, understanding how the public perceives and interacts with AI is essential for fostering responsible and secure adoption. This study investigates the relationship between self-assessed AI competence, trust in AI-generated content, and sentiment toward AI among public and private sector employees in Latvia. Using a mixed-methods approach, the research combines quantitative survey data with open-ended qualitative responses to explore how demographic factors influence AI-related perceptions. Results reveal that although participants rate their AI competence and trust relatively highly, a significant portion of respondents either do not use AI or use it only for simple tasks. Sentiment toward AI is generally positive but often neutral, indicating that public attitudes are still forming. Statistically significant differences in AI competence were found across gender, age, and work sector, while trust in AI varied by education and age. Sentiment remained consistent across groups. Importantly, AI competence was positively correlated with trust, which in turn correlated with sentiment. Thematic analysis identified concerns about risk assessment, ethical implications, and the uncertain role of AI in daily life. The study underscores the need to enhance AI literacy and critical evaluation skills to ensure informed trust and societal resilience. These findings inform future strategies for public education, workforce training, and digital security policy in the context of accelerating AI adoption.",2025,10.3389/frai.2025.1658791
Physics-Informed Tensor-Train ConvLSTM for Volumetric Velocity Forecasting of the Loop Current,"According to the National Academies, a week long forecast of velocity, vertical structure, and duration of the Loop Current (LC) and its eddies at a given location is a critical step toward understanding their effects on the gulf ecosystems as well as toward anticipating and mitigating the outcomes of anthropogenic and natural disasters in the Gulf of Mexico (GoM). However, creating such a forecast has remained a challenging problem since LC behavior is dominated by dynamic processes across multiple time and spatial scales not resolved at once by conventional numerical models. In this paper, building on the foundation of spatiotemporal predictive learning in video prediction, we develop a physics informed deep learning based prediction model called—Physics-informed Tensor-train ConvLSTM (PITT-ConvLSTM)—for forecasting 3D geo-spatiotemporal sequences. Specifically, we propose (1) a novel 4D higher-order recurrent neural network with empirical orthogonal function analysis to capture the hidden uncorrelated patterns of each hierarchy, (2) a convolutional tensor-train decomposition to capture higher-order space-time correlations, and (3) a mechanism that incorporates prior physics from domain experts by informing the learning in latent space. The advantage of our proposed approach is clear: constrained by the law of physics, the prediction model simultaneously learns good representations for frame dependencies (both short-term and long-term high-level dependency) and inter-hierarchical relations within each time frame. Experiments on geo-spatiotemporal data collected from the GoM demonstrate that the PITT-ConvLSTM model can successfully forecast the volumetric velocity of the LC and its eddies for a period greater than 1 week.",2021,10.3389/frai.2021.780271
"Cosmetogenomics unveiled: a systematic review of AI, genomics, and the future of personalized skincare","Introduction
                    The integration of genomics, proteomics, and artificial intelligence (AI) is shaping the approach to personalized skincare and aesthetic dermatology, moving from generalized protocols toward precision-based interventions.
                  
                  
                    Objective
                    To systematically review the emerging field of cosmetogenomics, focusing on how AI and multi-omics technologies are enabling personalized dermatologic treatments, and to critically evaluate the strength, scope, and limitations of current evidence.
                  
                  
                    Methods
                    We conducted a systematic review in accordance with PRISMA 2020 guidelines. PubMed, Scopus, and Embase databases were searched for articles from January 2012 to April 2025 using Boolean combinations of terms including [“cosmetogenomics” OR “AI in dermatology” OR “personalized skincare” OR “multi-omics dermatology”] AND [“SNP” OR “genomics” OR “proteomics”]. Eligible studies included peer-reviewed clinical or ex vivo research involving human subjects and reporting measurable dermatologic outcomes related to genomics, single nucleotide polymorphisms (SNPs), AI tools, or proteomics. Study quality was assessed using the JAMA Users’ Guides to the Medical Literature quality scheme.
                  
                  
                    Results
                    From 403 screened articles, 74 met inclusion criteria. Of these, 22 were randomized controlled trials (RCTs, Level I evidence), 35 observational studies (Level II), and 17 conceptual or expert opinion papers (Level III). AI and genomics were found to enhance skincare personalization by identifying SNPs associated with collagen degradation, oxidative stress, and inflammation. AI-powered platforms integrate these insights with imaging, lifestyle data, and digital twins to optimize interventions ranging from topical regimens to laser and injectable treatments. However, a significant proportion of studies were exploratory, with limited geographic diversity and underrepresentation of darker skin phototypes. No quantitative synthesis (meta-analysis) was performed due to heterogeneity in outcome measures, though hydration, elasticity, and pigmentation outcomes may permit such analysis in future work.
                  
                  
                    Conclusion
                    AI-driven cosmetogenomics is advancing dermatology into a predictive, personalized era. While the evidence base is expanding, clinical translation requires stronger validation, ethical safeguards, and regulatory oversight. This field holds significant promise for enhancing treatment efficacy, patient satisfaction, and long-term skin health. Broader validation, greater diversity in study populations, more transparent methodologies, and expanded ethical safeguards, including genetic discrimination risks, data ownership, and cross-border data transfer, are necessary before widespread clinical integration.",2025,10.3389/frai.2025.1660356
PACKETCLIP: multi-modal embedding of network traffic and language for cybersecurity reasoning,"Traffic classification is vital for cybersecurity, yet encrypted traffic poses significant challenges. We introduce PACKETCLIP which is a multi-modal framework combining packet data with natural language semantics through contrastive pre-training and hierarchical Graph Neural Network (GNN) reasoning. PACKETCLIP integrates semantic reasoning with efficient classification, enabling robust detection of anomalies in encrypted network flows. By aligning textual descriptions with packet behaviors, PACKETCLIP offers enhanced interpretability, scalability, and practical applicability across diverse security scenarios. With a 95% mean AUC, an 11.6% improvement over baselines, and a 92% reduction in intrusion detection training parameters, it is ideally suited for real-time anomaly detection. By bridging advanced machine-learning techniques and practical cybersecurity needs, PACKETCLIP provides a foundation for scalable, efficient, and interpretable solutions to tackle encrypted traffic classification and network intrusion detection challenges in resource-constrained environments.",2025,10.3389/frai.2025.1593944
Recursive Metropolis-Hastings naming game: symbol emergence in a multi-agent system based on probabilistic generative models,"In the studies on symbol emergence and emergent communication in a population of agents, a computational model was employed in which agents participate in various language games. Among these, the Metropolis-Hastings naming game (MHNG) possesses a notable mathematical property: symbol emergence through MHNG is proven to be a decentralized Bayesian inference of representations shared by the agents. However, the previously proposed MHNG is limited to a two-agent scenario. This paper extends MHNG to an N-agent scenario. The main contributions of this paper are twofold: (1) we propose the recursive Metropolis-Hastings naming game (RMHNG) as an N-agent version of MHNG and demonstrate that RMHNG is an approximate Bayesian inference method for the posterior distribution over a latent variable shared by agents, similar to MHNG; and (2) we empirically evaluate the performance of RMHNG on synthetic and real image data, i.e., YCB object dataset, enabling multiple agents to develop and share a symbol system. Furthermore, we introduce two types of approximations—one-sample and limited-length—to reduce computational complexity while maintaining the ability to explain communication in a population of agents. The experimental findings showcased the efficacy of RMHNG as a decentralized Bayesian inference for approximating the posterior distribution concerning latent variables, which are jointly shared among agents, akin to MHNG, although the improvement in ARI and κ coefficient is smaller in the real image dataset condition. Moreover, the utilization of RMHNG elucidated the agents' capacity to exchange symbols. Furthermore, the study discovered that even the computationally simplified version of RMHNG could enable symbols to emerge among the agents.",2023,10.3389/frai.2023.1229127
"Assessing longitudinal housing status using Electronic Health Record data: a comparison of natural language processing, structured data, and patient-reported history","IntroductionMeasuring long-term housing outcomes is important for evaluating the impacts of services for individuals with homeless experience. However, assessing long-term housing status using traditional methods is challenging. The Veterans Affairs (VA) Electronic Health Record (EHR) provides detailed data for a large population of patients with homeless experiences and contains several indicators of housing instability, including structured data elements (e.g., diagnosis codes) and free-text clinical narratives. However, the validity of each of these data elements for measuring housing stability over time is not well-studied.MethodsWe compared VA EHR indicators of housing instability, including information extracted from clinical notes using natural language processing (NLP), with patient-reported housing outcomes in a cohort of homeless-experienced Veterans.ResultsNLP achieved higher sensitivity and specificity than standard diagnosis codes for detecting episodes of unstable housing. Other structured data elements in the VA EHR showed promising performance, particularly when combined with NLP.DiscussionEvaluation efforts and research studies assessing longitudinal housing outcomes should incorporate multiple data sources of documentation to achieve optimal performance.",2023,10.3389/frai.2023.1187501
Multi-perspective hotel operation process anomaly prediction method based on graph transformer and autoencoder,"Due to the complexity of hotel operation processes, abnormal situations are inevitable, making proactive anomaly prediction essential for ensuring operational stability. Although current deep learning methods can encode control and data flows to predict anomalies in attributes like activity and time, they often fail to adequately represent the behavioral relationships between activities and lack specific mechanisms to model the interaction between control and data flows. To address these challenges, this paper proposes a business process anomaly prediction method based on a Multi-perspective Graph Transformer and Auto Encoder (MLGTAE). The proposed method first constructs multi-perspective trace graphs by combining Petri nets—which capture process behaviors—with data attributes such as time and resources. It then leverages an attention mechanism to achieve deep semantic interaction between process behavior and data, followed by a decoder that performs reconstruction to detect anomalies. Validated on multiple real-world datasets, the results demonstrate that MLGTAE outperforms existing state-of-the-art methods, showing superior accuracy in predicting anomalies at both the activity and data attribute levels.",2025,10.3389/frai.2025.1682701
Socially interactive agents for robotic neurorehabilitation training: conceptualization and proof-of-concept study,"IntroductionIndividuals with diverse motor abilities often benefit from intensive and specialized rehabilitation therapies aimed at enhancing their functional recovery. Nevertheless, the challenge lies in the restricted availability of neurorehabilitation professionals, hindering the effective delivery of the necessary level of care. Robotic devices hold great potential in reducing the dependence on medical personnel during therapy but, at the same time, they generally lack the crucial human interaction and motivation that traditional in-person sessions provide.MethodsTo bridge this gap, we introduce an AI-based system aimed at delivering personalized, out-of-hospital assistance during neurorehabilitation training. This system includes a rehabilitation training device, affective signal classification models, training exercises, and a socially interactive agent as the user interface. With the assistance of a professional, the envisioned system is designed to be tailored to accommodate the unique rehabilitation requirements of an individual patient. Conceptually, after a preliminary setup and instruction phase, the patient is equipped to continue their rehabilitation regimen autonomously in the comfort of their home, facilitated by a socially interactive agent functioning as a virtual coaching assistant. Our approach involves the integration of an interactive socially-aware virtual agent into a neurorehabilitation robotic framework, with the primary objective of recreating the social aspects inherent to in-person rehabilitation sessions. We also conducted a feasibility study to test the framework with healthy patients.Results and discussionThe results of our preliminary investigation indicate that participants demonstrated a propensity to adapt to the system. Notably, the presence of the interactive agent during the proposed exercises did not act as a source of distraction; instead, it positively impacted users' engagement.",2024,10.3389/frai.2024.1441955
"Machine vs. human, who makes a better judgment on innovation? Take GPT-4 for example","IntroductionHuman decision-making is a complex process that is often influenced by various external and internal factors. One such factor is noise, random, and irrelevant influences that can skew outcomes.MethodsThis essay uses the CAT test and computer simulations to measure creativity.ResultsEvidence indicates that humans are intrinsically prone to noise, leading to inconsistent and, at times, inaccurate decisions. In contrast, simple rules demonstrate a higher level of accuracy and consistency, while artificial intelligence demonstrates an even higher capability to process vast data and employ logical algorithms.DiscussionThe potential of AI, particularly its intuitive capabilities, might be surpassing human intuition in specific decision-making scenarios. This raises crucial questions about the future roles of humans and machines in decision-making spheres, especially in domains where precision is paramount.",2023,10.3389/frai.2023.1206516
Use of big data from health insurance for assessment of cardiovascular outcomes,"Outcome research that supports guideline recommendations for primary and secondary preventions largely depends on the data obtained from clinical trials or selected hospital populations. The exponentially growing amount of real-world medical data could enable fundamental improvements in cardiovascular disease (CVD) prediction, prevention, and care. In this review we summarize how data from health insurance claims (HIC) may improve our understanding of current health provision and identify challenges of patient care by implementing the perspective of patients (providing data and contributing to society), physicians (identifying at-risk patients, optimizing diagnosis and therapy), health insurers (preventive education and economic aspects), and policy makers (data-driven legislation). HIC data has the potential to inform relevant aspects of the healthcare systems. Although HIC data inherit limitations, large sample sizes and long-term follow-up provides enormous predictive power. Herein, we highlight the benefits and limitations of HIC data and provide examples from the cardiovascular field, i.e. how HIC data is supporting healthcare, focusing on the demographical and epidemiological differences, pharmacotherapy, healthcare utilization, cost-effectiveness and outcomes of different treatments. As an outlook we discuss the potential of using HIC-based big data and modern artificial intelligence (AI) algorithms to guide patient education and care, which could lead to the development of a learning healthcare system and support a medically relevant legislation in the future.",2023,10.3389/frai.2023.1155404
XAI-BT-EdgeNet: explainable edge-aware deep learning with squeeze-and-excitation for brain tumor detection and prediction,"Introduction
                    Accurate and early detection of brain tumors is critical for effective treatment and improved patient outcomes, yet manual radiological analysis remains time-consuming, subjective, and error-prone. To address these challenges and improve clinical trust in AI systems, this study presents XAI-BT-EdgeNet, an explainable, edge-aware deep learning framework integrated with squeeze-and-excitation (SE) modules for brain tumor detection using MRI scans.
                  
                  
                    Methods
                    The proposed architecture employs a dual-branch design that fuses high-level semantic features from InceptionV3 with low-level edge representations via an Edge Feature Block, while SE modules adaptively recalibrate feature importance to enhance diagnostic accuracy. To ensure transparency, the model incorporates four XAI techniques—LIME, Grad-CAM, Grad-CAM++, and Vanilla Saliency—which provide interpretable visual justifications for predictions. The framework was trained and evaluated on the Brain Tumor Dataset by Preet Viradiya, comprising 4,589 labeled MRI images divided into Brain Tumor (2,513) and Healthy (2,076) classes.
                  
                  
                    Results
                    The model achieved 99.58% training accuracy, 99.71% validation accuracy, and 100.00% testing accuracy, alongside minimal loss values of 0.0103, 0.0051, and 0.0026, respectively. These results demonstrate the robustness and precision of the proposed framework in brain tumor classification.
                  
                  
                    Discussion
                    This work includes the development of a dual-branch CNN architecture that combines semantic and edge features for enhanced classification, the integration of SE modules to highlight clinically significant regions, and the application of multi-method XAI to offer transparent, interpretable outputs for clinical applicability. Overall, XAI-BT-EdgeNet delivers a high-performing, interpretable solution that bridges the gap between deep learning and trustworthy clinical decision-making in brain tumor diagnosis.",2025,10.3389/frai.2025.1676524
Locally linear attributes of ReLU neural networks,"A ReLU neural network functions as a continuous piecewise linear map from an input space to an output space. The weights in the neural network determine a partitioning of the input space into convex polytopes, where each polytope is associated with a distinct affine mapping. The structure of this partitioning, together with the affine map attached to each polytope, can be analyzed to investigate the behavior of the associated neural network. We investigate simple problems to build intuition on how these regions act and both how they can potentially be reduced in number and how similar structures occur across different networks. To validate these intuitions, we apply them to networks trained on MNIST to demonstrate similarity between those networks and the potential for them to be reduced in complexity.",2023,10.3389/frai.2023.1255192
Decision tree-based approach to robust Parkinson's disease subtyping using clinical data of the Michael J. Fox Foundation LRRK2 cross-sectional study,"Parkinson's Disease (PD) is a neurodegenerative disorder with high heterogeneity in clinical symptoms, progression course, treatment response, and genetic factors. Thus, PD subtyping aims to enhance understanding of disease mechanisms and helps to facilitate targeted interventions or treatment regimens. Data-driven PD subtyping is typically done using cluster analysis. Still, such studies face difficulty from widespread adoption in clinical practice due to the following issues: (i) results are quite sensitive to study design, and actual subtype rules are not reasonably interpretable; (ii) results are not robustly replicable across multiple datasets, and most studies focus on a single dataset. This paper aims to identify novel PD subtypes using an interpretable decision-tree-based method that is robustly reproducible in an independent PD cohort. We first train a decision tree classifier on an LRRK2 dataset to determine whether a patient has early onset or late onset PD. By tracing back from the leaves of the learned decision tree subtyping rules are established. The independent MDS dataset is used for external validation, after mapping features between the two datasets. We finally obtained six novel subtypes that are clinically consistent and sufficiently large across both training and external validation datasets. Finally, a clinical characterization study showed that the following clinical features may be the most important diagnostic markers for our six detected subtypes: (i) persistent asymmetry affecting the side of onset most, (ii) clinical course of 10 years or more, and (iii) postural instability not caused by other dysfunction. The subtypes identified in our study may provide relevant guidance for prognosis and therapeutic strategies. An early onset subtype (E4) can be linked to a comparatively favorable prognosis. In contrast, the mixed onset subtypes (M3 and M7) may predict faster functional decline, suggesting that patients in these groups could benefit from intensified supportive measures. One late onset subtype (L1) seems to have a more benign course, while the other two (L2 and L4) are connected with predictors of reduced quality of life and increased care dependency.",2025,10.3389/frai.2025.1668206
Ocular Biometry OCR: a machine learning algorithm leveraging optical character recognition to extract intra ocular lens biometry measurements,"Given close relationships between ocular structure and ophthalmic disease, ocular biometry measurements (including axial length, lens thickness, anterior chamber depth, and keratometry values) may be leveraged as features in the prediction of eye diseases. However, ocular biometry measurements are often stored as PDFs rather than as structured data in electronic health records. Thus, time-consuming and laborious manual data entry is required for using biometry data as a disease predictor. Herein, we used two separate models, PaddleOCR and Gemini, to extract eye specific biometric measurements from 2,965 Lenstar, 104 IOL Master 500, and 3,616 IOL Master 700 optical biometry reports. For each patient eye, our text extraction pipeline, referred to as Ocular Biometry OCR, involves 1) cropping the report to the biometric data, 2) extracting the text via the optical character recognition model, 3) post-processing the metrics and values into key value pairs, 4) correcting erroneous angles within the pairs, 5) computing the number of errors or missing values, and 6) selecting the window specific results with fewest errors or missing values. To ensure the models’ predictions could be put into a machine learning-ready format, artifacts were removed from categorical text data through manual modification where necessary. Performance was evaluated by scoring PaddleOCR and Gemini results. In the absence of ground truth, higher scoring indicated greater inter-model reliability, assuming an equal value between models indicated an accurate result. The detection scores, measuring the number of valid values (i.e., not missing or erroneous), were Lenstar: 0.990, IOLM 500: 1.000, and IOLM 700: 0.998. The similarity scores, measuring the number of equal values, were Lenstar: 0.995, IOLM 500: 0.999, and IOLM 700: 0.999. The agreement scores, combining detection and similarity scores, were Lenstar: 0.985, IOLM 500: 0.999, and IOLM 700: 0.998. IOLM 500 was annotated for ground truths; in this case, higher scoring indicated greater model-to-annotator accuracy. PaddleOCR-to-Annotator achieved scores of detection: 1.000, similarity: 0.999, and agreement: 0.999. Gemini-to-Annotator achieved scores of detection: 1.000, similarity: 1.000, and agreement: 1.000. Scores range from 0 to 1. While PaddleOCR and Gemini demonstrated high agreement, PaddleOCR offered slightly better performance upon reviewing quantitative and qualitative results.",2025,10.3389/frai.2024.1428716
Risk prediction of stroke-associated pneumonia in acute ischemic stroke with atrial fibrillation using machine learning models,"Stroke-associated pneumonia (SAP) is a serious complication of acute ischemic stroke (AIS), significantly affecting patient prognosis and increasing healthcare burden. AIS patients are often accompanied by basic diseases, and atrial fibrillation (AF) is one of the common basic diseases. Despite the high prevalence of AF in AIS patients, few studies have specifically addressed SAP prediction in this comorbid population. We aimed to analyze the factors influencing the occurrence of SAP in patients with AIS and AF and to assess the risk of SAP development through an optimal predictive model. We performed a case-control study. This study included 4,496 hospitalized patients with AIS and AF in China between January 2020 and September 2023. The primary outcome was SAP during hospitalization. Univariate analysis and LASSO regression analysis methods were used to screen predictors. The patients with AIS and AF were randomly divided into a training set, validation set, and test set. Then, we established logistic regression (LR), random forest (RF), support vector machine (SVM), and extreme gradient boosting (XGBoost) models. The accuracy, sensitivity, specificity, area under the curve, Youden index and F1 score were adopted to evaluate the predictive value of each model. The optimal prediction model was visualized using a nomogram. In this study, SAP was identified in 10.16% of cases. The variables screened by univariate analysis and LASSO regression, variables such as coronary artery disease, hypertension, and dysphagia, identified by univariate and LASSO regression analyses (p &lt; 0.05), were included in the LR, RF, and SVM. The LR model outperformed other models, achieving an AUC of 0.866, accuracy of 90.13%, sensitivity of 79.49%, specificity of 86.11%, F1 score of 0.80. A nomogram based on the LR model was developed to predict SAP risk, providing a practical tool for early identification of high-risk patients, and enabling targeted interventions to reduce SAP incidence and improve outcomes.",2025,10.3389/frai.2025.1595101
"Legal regulation of AI-assisted academic writing: challenges, frameworks, and pathways","IntroductionThe widespread application of artificial intelligence in academic writing has triggered a series of pressing legal challenges.MethodsThis study systematically examines critical issues, including copyright protection, academic integrity, and comparative research methods. We establishes a risk assessment matrix to quantitatively analyze various risks in AI-assisted academic writing from three dimensions: impact, probability, and mitigation cost, thereby identifying high-risk factors.ResultsThe findings reveal that AI-assisted writing challenges fundamental principles of traditional copyright law, with judicial practice tending to position AI as a creative tool while emphasizing human agency. Regarding academic integrity, new risks, such as “credibility illusion” and “implicit plagiarism,” have become prominent in AI-generated content, necessitating adaptive regulatory mechanisms. Research data protection and personal information security face dual challenges in data security that require technological and institutional innovations.DiscussionBased on these findings, we propose a three-dimensional regulatory framework of “transparency, accountability, technical support” and present systematic policy recommendations from institutional design, organizational structure, and international cooperation perspectives. The research results deepen understanding of legal attributes of AI creation, promote theoretical innovation in digital era copyright and academic ethics, and provide practical guidance for academic institutions in formulating AI usage policies.",2025,10.3389/frai.2025.1546064
Large language models generating synthetic clinical datasets: a feasibility and comparative analysis with real-world perioperative data,"BackgroundClinical data is instrumental to medical research, machine learning (ML) model development, and advancing surgical care, but access is often constrained by privacy regulations and missing data. Synthetic data offers a promising solution to preserve privacy while enabling broader data access. Recent advances in large language models (LLMs) provide an opportunity to generate synthetic data with reduced reliance on domain expertise, computational resources, and pre-training.ObjectiveThis study aims to assess the feasibility of generating realistic tabular clinical data with OpenAI’s GPT-4o using zero-shot prompting, and evaluate the fidelity of LLM-generated data by comparing its statistical properties to the Vital Signs DataBase (VitalDB), a real-world open-source perioperative dataset.MethodsIn Phase 1, GPT-4o was prompted to generate a dataset with qualitative descriptions of 13 clinical parameters. The resultant data was assessed for general errors, plausibility of outputs, and cross-verification of related parameters. In Phase 2, GPT-4o was prompted to generate a dataset using descriptive statistics of the VitalDB dataset. Fidelity was assessed using two-sample t-tests, two-sample proportion tests, and 95% confidence interval (CI) overlap.ResultsIn Phase 1, GPT-4o generated a complete and structured dataset comprising 6,166 case files. The dataset was plausible in range and correctly calculated body mass index for all case files based on respective heights and weights. Statistical comparison between the LLM-generated datasets and VitalDB revealed that Phase 2 data achieved significant fidelity. Phase 2 data demonstrated statistical similarity in 12/13 (92.31%) parameters, whereby no statistically significant differences were observed in 6/6 (100.0%) categorical/binary and 6/7 (85.71%) continuous parameters. Overlap of 95% CIs were observed in 6/7 (85.71%) continuous parameters.ConclusionZero-shot prompting with GPT-4o can generate realistic tabular synthetic datasets, which can replicate key statistical properties of real-world perioperative data. This study highlights the potential of LLMs as a novel and accessible modality for synthetic data generation, which may address critical barriers in clinical data access and eliminate the need for technical expertise, extensive computational resources, and pre-training. Further research is warranted to enhance fidelity and investigate the use of LLMs to amplify and augment datasets, preserve multivariate relationships, and train robust ML models.",2025,10.3389/frai.2025.1533508
AI can empower agriculture for global food security: challenges and prospects in developing nations,"Food and nutrition are a steadfast essential to all living organisms. With specific reference to humans, the sufficient and efficient supply of food is a challenge as the world population continues to grow. Artificial Intelligence (AI) could be identified as a plausible technology in this 5th industrial revolution in bringing us closer to achieving zero hunger by 2030—Goal 2 of the United Nations Sustainable Development Goals (UNSDG). This goal cannot be achieved unless the digital divide among developed and underdeveloped countries is addressed. Nevertheless, developing and underdeveloped regions fall behind in economic resources; however, they harbor untapped potential to effectively address the impending demands posed by the soaring world population. Therefore, this study explores the in-depth potential of AI in the agriculture sector for developing and under-developed countries. Similarly, it aims to emphasize the proven efficiency and spin-off applications of AI in the advancement of agriculture. Currently, AI is being utilized in various spheres of agriculture, including but not limited to crop surveillance, irrigation management, disease identification, fertilization practices, task automation, image manipulation, data processing, yield forecasting, supply chain optimization, implementation of decision support system (DSS), weed control, and the enhancement of resource utilization. Whereas AI supports food safety and security by ensuring higher crop yields that are acquired by harnessing the potential of multi-temporal remote sensing (RS) techniques to accurately discern diverse crop phenotypes, monitor land cover dynamics, assess variations in soil organic matter, predict soil moisture levels, conduct plant biomass modeling, and enable comprehensive crop monitoring. The present study identifies various challenges, including financial, infrastructure, experts, data availability, customization, regulatory framework, cultural norms and attitudes, access to market, and interdisciplinary collaboration, in the adoption of AI for developing nations with their subsequent remedies. The identification of challenges and opportunities in the implementation of AI could ignite further research and actions in these regions; thereby supporting sustainable development.",2024,10.3389/frai.2024.1328530
Uncertainty quantification in multi-class image classification using chest X-ray images of COVID-19 and pneumonia,"This paper investigates uncertainty quantification (UQ) techniques in multi-class classification of chest X-ray images (COVID-19, Pneumonia, and Normal). We evaluate Bayesian Neural Networks (BNN) and the Deep Neural Network with UQ (DNN with UQ) techniques, including Monte Carlo dropout, Ensemble Bayesian Neural Network (EBNN), Ensemble Monte Carlo (EMC) dropout, across different evaluation metrics. Our analysis reveals that DNN with UQ, especially EBNN and EMC dropout, consistently outperform BNNs. For example, in Class 0 vs. All, EBNN achieved a UAcc of 92.6%, UAUC-ROC of 95.0%, and a Brier Score of 0.157, significantly surpassing BNN's performance. Similarly, EMC Dropout excelled in Class 1 vs. All with a UAcc of 83.5%, UAUC-ROC of 95.8%, and a Brier Score of 0.165. These advanced models demonstrated higher accuracy, better discriaminative capability, and more accurate probabilistic predictions. Our findings highlight the efficacy of DNN with UQ in enhancing model reliability and interpretability, making them highly suitable for critical healthcare applications like chest X-ray imageQ6 classification.",2024,10.3389/frai.2024.1410841
AI-driven epidemic intelligence: the future of outbreak detection and response,"Epidemic intelligence, the process of detecting, verifying, and analyzing public health threats to enable timely responses, traditionally relies heavily on manual reporting and structured data, often causing delays and coverage gaps. The growing frequency of emerging infectious diseases highlights the urgency for more rapid and accurate surveillance methods. This perspective proposes a forward-looking conceptual framework for AI-driven epidemic intelligence, emphasizing the transformative potential of integrating large language models (LLMs), natural language processing (NLP), and optimization-based resource allocation strategies. While existing AI-driven systems have shown significant capabilities during the COVID-19 pandemic, several challenges remain, including real-time adaptability, multilingual data handling, misinformation, and public health policy alignment. To address these gaps, we propose an integrated, real-time adaptable LLM-based epidemic intelligence system, capable of correlating cross-source data, optimizing healthcare resource allocation, and supporting informed outbreak response. This approach aims to significantly improve early warning capabilities, enhancing forecasting accuracy, and strengthen pandemic preparedness.",2025,10.3389/frai.2025.1645467
Specific challenges posed by artificial intelligence in research ethics,"BackgroundThe twenty first century is often defined as the era of Artificial Intelligence (AI), which raises many questions regarding its impact on society. It is already significantly changing many practices in different fields. Research ethics (RE) is no exception. Many challenges, including responsibility, privacy, and transparency, are encountered. Research ethics boards (REB) have been established to ensure that ethical practices are adequately followed during research projects. This scoping review aims to bring out the challenges of AI in research ethics and to investigate if REBs are equipped to evaluate them.MethodsThree electronic databases were selected to collect peer-reviewed articles that fit the inclusion criteria (English or French, published between 2016 and 2021, containing AI, RE, and REB). Two instigators independently reviewed each piece by screening with Covidence and then coding with NVivo.ResultsFrom having a total of 657 articles to review, we were left with a final sample of 28 relevant papers for our scoping review. The selected literature described AI in research ethics (i.e., views on current guidelines, key ethical concept and approaches, key issues of the current state of AI-specific RE guidelines) and REBs regarding AI (i.e., their roles, scope and approaches, key practices and processes, limitations and challenges, stakeholder perceptions). However, the literature often described REBs ethical assessment practices of projects in AI research as lacking knowledge and tools.ConclusionEthical reflections are taking a step forward while normative guidelines adaptation to AI's reality is still dawdling. This impacts REBs and most stakeholders involved with AI. Indeed, REBs are not equipped enough to adequately evaluate AI research ethics and require standard guidelines to help them do so.",2023,10.3389/frai.2023.1149082
AI generations: from AI 1.0 to AI 4.0,"This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and a speculative AI 4.0 (Conscious AI). Each AI generation is driven by shifting priorities among algorithms, computing power, and data. AI 1.0 accompanied breakthroughs in pattern recognition and information processing, fueling advances in computer vision, natural language processing, and recommendation systems. AI 2.0 is built on these foundations through real-time decision-making in digital environments, leveraging reinforcement learning and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world settings. Building on these developments, the proposed AI 4.0 puts forward the bold vision of self-directed AI capable of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of machine consciousness. This paper traces the historical foundations of AI across roughly 70 years, mapping how changes in technological bottlenecks from algorithmic innovation to high-performance computing to specialized data have stimulated each generational leap. It further highlights the ongoing synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the ethical, regulatory, and philosophical challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting responsible governance, and ensuring that AI’s transformative potential benefits society.",2025,10.3389/frai.2025.1585629
Robust predictive framework for diabetes classification using optimized machine learning on imbalanced datasets,"IntroductionDiabetes prediction using clinical datasets is crucial for medical data analysis. However, class imbalances, where non-diabetic cases dominate, can significantly affect machine learning model performance, leading to biased predictions and reduced generalization.MethodsA novel predictive framework employing cutting-edge machine learning algorithms and advanced imbalance handling techniques was developed. The framework integrates feature engineering and resampling strategies to enhance predictive accuracy.ResultsRigorous testing was conducted on three datasets—PIMA, Diabetes Dataset 2019, and BIT_2019—demonstrating the robustness and adaptability of the methodology across varying data environments.DiscussionThe experimental results highlight the critical role of model selection and imbalance mitigation in achieving reliable and generalizable diabetes predictions. This study offers significant contributions to medical informatics by proposing a robust data-driven framework that addresses class imbalance challenges, thereby advancing diabetes prediction accuracy.",2025,10.3389/frai.2024.1499530
Named entity recognition for Chinese electronic medical records by integrating knowledge graph and ClinicalBERT,"IntroductionGeneral purpose language models often struggle with accurately identifying domain specific terminology in the medical field, resulting in suboptimal performance in named entity recognition (NER) tasks. This challenge is particularly pronounced in Chinese electronic medical records (EMRs), which lack clear word boundaries and contain complex medical expressions.MethodsThis study proposes a novel NER method for Chinese EMRs that integrates ClinicalBERT, a language model pre trained on clinical corpora, with structured knowledge from a medical knowledge graph. Entity representations derived via Translating Embeddings (TransE) are incorporated to inject external semantic knowledge. Furthermore, the model fuses multiple character level features, including positional labels, contextual category clues, and semantic embeddings, to enhance boundary detection. The input text is annotated using the BIOES (Begin, Inside, Outside, End, Single) tagging scheme and subsequently encoded by ClinicalBERT. The encoded features are then passed through a bidirectional long short term memory (BiLSTM) network and a conditional random field (CRF) layer for final label prediction.ResultsExperiments conducted on publicly available datasets demonstrate that the proposed approach achieves an F1 score of 89.44 percent, surpassing multiple existing baseline models in performance.DiscussionThese findings confirm that the integration of domain specific language modeling, structured medical knowledge, and enriched character level features significantly enhances NER accuracy in Chinese EMRs. The proposed method shows strong potential for practical deployment in clinical information extraction systems.",2025,10.3389/frai.2025.1634774
Spherical model for Minimalist Machine Learning paradigm in handling complex databases,"This paper presents the development of the N-Spherical Minimalist Machine Learning (MML) classifier, an innovative model within the Minimalist Machine Learning paradigm. Using N-spherical coordinates and concepts from metaheuristics and associative models, this classifier effectively addresses challenges such as data dimensionality and class imbalance in complex datasets. Performance evaluations using the F1 measure and balanced accuracy demonstrate its superior efficiency and robustness compared to state-of-the-art classifiers. Statistical validation is conducted using the Friedman and Holm tests. Although currently limited to binary classification, this work highlights the potential of minimalist approaches in machine learning for classification of highly dimensional and imbalanced data. Future extensions aim to include multi-class problems and mechanisms for handling categorical data.",2025,10.3389/frai.2025.1521063
Similarities and Differences in Gene Expression Networks Between the Breast Cancer Cell Line Michigan Cancer Foundation-7 and Invasive Human Breast Cancer Tissues,"Failure to adequately characterize cell lines, and understand the differences between in vitro and in vivo biology, can have serious consequences on the translatability of in vitro scientific studies to human clinical trials. This project focuses on the Michigan Cancer Foundation-7 (MCF-7) cells, a human breast adenocarcinoma cell line that is commonly used for in vitro cancer research, with over 42,000 publications in PubMed. In this study, we explore the key similarities and differences in gene expression networks of MCF-7 cell lines compared to human breast cancer tissues. We used two MCF-7 data sets, one data set collected by ARCHS4 including 1032 samples and one data set from Gene Expression Omnibus GSE50705 with 88 estradiol-treated MCF-7 samples. The human breast invasive ductal carcinoma (BRCA) data set came from The Cancer Genome Atlas, including 1212 breast tissue samples. Weighted Gene Correlation Network Analysis (WGCNA) and functional annotations of the data showed that MCF-7 cells and human breast tissues have only minimal similarity in biological processes, although some fundamental functions, such as cell cycle, are conserved. Scaled connectivity—a network topology metric—also showed drastic differences in the behavior of genes between MCF-7 and BRCA data sets. Finally, we used canSAR to compute ligand-based druggability scores of genes in the data sets, and our results suggested that using MCF-7 to study breast cancer may lead to missing important gene targets. Our comparison of the networks of MCF-7 and human breast cancer highlights the nuances of using MCF-7 to study human breast cancer and can contribute to better experimental design and result interpretation of study involving this cell line.",2021,10.3389/frai.2021.674370
Traditional vs. AI-generated meteorological risks for emergency predictions,"This study aims to analyze and examine in-depth the feature selection process using Large Language Models (LLMs) to optimize firefighter prediction performance. Although features from reliable sources are known to significantly aid predictions, their accuracy may be limited in critical situations requiring rigorous prioritization. Therefore, the focus was placed on meteorological risks for a comparative diagnosis between their extraction from Météo France and those generated by LLMs across various dimensions. Given the crucial role of meteorological risks as key informational sources for decision-making, this study explores the impact of feature extraction methods related to these risks on predicting firefighter interventions over nine years, from 2015 to 2024. Annual reports on firefighter activities in France highlight the growing influence of weather-related risks, underscoring the urgent need for precise and actionable meteorological information to support rapid and effective emergency response strategies. The methodology implemented involved comprehensive data preparation, an in-depth analysis of feature extraction through different approaches, and their evaluation from multiple perspectives. This required leveraging machine learning models such as XGBoost, Random Forest, and Support Vector Machines (SVM) to assess and analyze prediction results based on two feature spaces: F1 (including general features and meteorological risks extracted from Météo France) and F2 (including general features and meteorological risks generated by LLMs). The results revealed that models trained with the F2 feature space consistently demonstrated superior performance. Notably, annual improvements were observed, particularly for high and very high intervention activities. However, the use of the F2 space proved less effective for low intervention activities and underperformed compared to F1 during the summer season. In conclusion, this work presents a concrete methodology for forecasting and enhancing resource management, accelerating firefighter response times, and ultimately contributing to life preservation by reducing the risk of failure during critical incidents.",2025,10.3389/frai.2025.1545851
SE(3) group convolutional neural networks and a study on group convolutions and equivariance for DWI segmentation,"We present an SE(3) Group Convolutional Neural Network along with a series of networks with different group actions for segmentation of Diffusion Weighted Imaging data. These networks gradually incorporate group actions that are natural for this type of data, in the form of convolutions that provide equivariant transformations of the data. This knowledge provides a potentially important inductive bias and may alleviate the need for data augmentation strategies. We study the effects of these actions on the performances of the networks by training and validating them using the diffusion data from the Human Connectome project. Unlike previous works that use Fourier-based convolutions, we implement direct convolutions, which are more lightweight. We show how incorporating more actions - using the SE(3) group actions - generally improves the performances of our segmentation while limiting the number of parameters that must be learned.",2025,10.3389/frai.2025.1369717
Noise-induced modality-specific pretext learning for pediatric chest X-ray image classification,"IntroductionDeep learning (DL) has significantly advanced medical image classification. However, it often relies on transfer learning (TL) from models pretrained on large, generic non-medical image datasets like ImageNet. Conversely, medical images possess unique visual characteristics that such general models may not adequately capture.MethodsThis study examines the effectiveness of modality-specific pretext learning strengthened by image denoising and deblurring in enhancing the classification of pediatric chest X-ray (CXR) images into those exhibiting no findings, i.e., normal lungs, or with cardiopulmonary disease manifestations. Specifically, we use a VGG-16-Sharp-U-Net architecture and leverage its encoder in conjunction with a classification head to distinguish normal from abnormal pediatric CXR findings. We benchmark this performance against the traditional TL approach, viz., the VGG-16 model pretrained only on ImageNet. Measures used for performance evaluation are balanced accuracy, sensitivity, specificity, F-score, Matthew’s Correlation Coefficient (MCC), Kappa statistic, and Youden’s index.ResultsOur findings reveal that models developed from CXR modality-specific pretext encoders substantially outperform the ImageNet-only pretrained model, viz., Baseline, and achieve significantly higher sensitivity (p &lt; 0.05) with marked improvements in balanced accuracy, F-score, MCC, Kappa statistic, and Youden’s index. A novel attention-based fuzzy ensemble of the pretext-learned models further improves performance across these metrics (Balanced accuracy: 0.6376; Sensitivity: 0.4991; F-score: 0.5102; MCC: 0.2783; Kappa: 0.2782, and Youden’s index:0.2751), compared to Baseline (Balanced accuracy: 0.5654; Sensitivity: 0.1983; F-score: 0.2977; MCC: 0.1998; Kappa: 0.1599, and Youden’s index:0.1327).DiscussionThe superior results of CXR modality-specific pretext learning and their ensemble underscore its potential as a viable alternative to conventional ImageNet pretraining for medical image classification. Results from this study promote further exploration of medical modality-specific TL techniques in the development of DL models for various medical imaging applications.",2024,10.3389/frai.2024.1419638
Applications for open access normalized synthesis in metastatic prostate cancer trials,"Recent metastatic castration-resistant prostate cancer (mCRPC) clinical trials have integrated homologous recombination and DNA repair deficiency (HRD/DRD) biomarkers into eligibility criteria and secondary objectives. These trials led to the approval of some PARP inhibitors for mCRPC with HRD/DRD indications. Unfortunately, biomarker-trial outcome data is only discovered by reviewing publications, a process that is error-prone, time-consuming, and laborious. While prostate cancer researchers have written systematic evidence reviews (SERs) on this topic, given the time involved from the last search to publication, an SER is often outdated even before publication. The difficulty in reusing previous review data has resulted in multiple reviews of the same trials. Thus, it will be useful to create a normalized evidence base from recently published/presented biomarker-trial outcome data that one can quickly update. We present a new approach to semi-automating normalized, open-access data tables from published clinical trials of metastatic prostate cancer using a data curation and SER platform. Clinicaltrials.gov and Pubmed.gov were used to collect mCRPC clinical trial publications with HRD/DRD biomarkers. We extracted data from 13 publications covering ten trials that started before 22nd Apr 2021. We extracted 585 hazard ratios, response rates, duration metrics, and 543 adverse events. Across 334 patients, we also extracted 8,180 patient-level survival and biomarker values. Data tables were populated with survival metrics, raw patient data, eligibility criteria, adverse events, and timelines. A repeated strong association between HRD and improved PARP inhibitor response was observed. Several use cases for the extracted data are demonstrated via analyses of trial methods, comparison of treatment hazard ratios, and association of treatments with adverse events. Machine learning models are also built on combined and normalized patient data to demonstrate automated discovery of therapy/biomarker relationships. Overall, we demonstrate the value of systematically extracted and normalized data. We have also made our code open-source with simple instructions on updating the analyses as new data becomes available, which anyone can use even with limited programming knowledge. Finally, while we present a novel method of SER for mCRPC trials, one can also implement such semi-automated methods in other clinical trial domains to advance precision medicine.",2022,10.3389/frai.2022.984836
A hybrid computational approach to anticipate individuals in sequential problem solving,"Human-awareness is an ever more important requirement for AI systems that are designed to assist humans with daily physical interactions and problem solving. This is especially true for patients that need support to stay as independent as possible. To be human-aware, an AI should be able to anticipate the intentions of the individual humans it interacts with, in order to understand the difficulties and limitations they are facing and to adapt accordingly. While data-driven AI approaches have recently gained a lot of attention, more research is needed on assistive AI systems that can develop models of their partners' goals to offer proactive support without needing a lot of training trials for new problems. We propose an integrated AI system that can anticipate actions of individual humans to contribute to the foundations of trustworthy human-robot interaction. We test this in Tangram, which is an exemplary sequential problem solving task that requires dynamic decision making. In this task the sequences of steps to the goal might be variable and not known by the system. These are aspects that are also recognized as real world challenges for robotic systems. A hybrid approach based on the cognitive architecture ACT-R is presented that is not purely data-driven but includes cognitive principles, meaning heuristics that guide human decisions. Core of this Cognitive Tangram Solver (CTS) framework is an ACT-R cognitive model that simulates human problem solving behavior in action, recognizes possible dead ends and identifies ways forward. Based on this model, the CTS anticipates and adapts its predictions about the next action to take in any given situation. We executed an empirical study and collected data from 40 participants. The predictions made by CTS were evaluated with the participants' behavior, including comparative statistics as well as prediction accuracy. The model's anticipations compared to the human test data provide support for justifying further steps built upon our conceptual approach.",2023,10.3389/frai.2023.1223251
A Straightforward HPV16 Lineage Classification Based on Machine Learning,"Human Papillomavirus (HPV) is the causal agent of 5% of cancers worldwide and the main cause of cervical cancer and it is also associated with a significant percentage of oropharyngeal and anogenital cancers. More than 60% of cervical cancers are caused by HPV16 genotype, which has been classified into lineages (A, B, C, and D). Lineages are related to the progression of cervical cancer and the current method to assess lineages is by building a Maximum Likelihood Tree (MLT); which is slow, it cannot assess poor sequenced samples, and annotation is done manually. In this study, we have developed a new model to assess HPV16 lineage using machine learning tools. A total of 645 HPV16 genomes were analyzed using Genome-Wide Association Study (GWAS), which identified 56 lineage-specific Single Nucleotide Polymorphisms (SNPs). From the SNPs found, training-test models were constructed using different algorithms such as Random Forest (RF), Support Vector Machine (SVM), and K-nearest neighbor (KNN). A distinct set of HPV16 sequences (n = 1,028), whose lineage was previously determined by MLT, was used for validation. The RF-based model allowed a precise assignment of HPV16 lineage, showing an accuracy of 99.5% in the known lineage samples. Moreover, the RF model could assess lineage to 273 samples that MLT could not determine. In terms of computer consuming time, the RF-based model was almost 40 times faster than MLT. Having a fast and efficient method for assigning HPV16 lineages, could facilitate the implementation of lineage classification as a triage or prognostic marker in the clinical setting.",2022,10.3389/frai.2022.851841
Enhanced deep Convolutional Neural Network for SARS-CoV-2 variants classification,"IntroductionRapid and scalable classification of SARS-CoV-2 genomes from spike-gene sequences can support real-time genomic surveillance in contexts where whole-genome data or high-end computing resources are limited.MethodsWe curated approximately 35,800 quality-filtered spike sequences spanning multiple clades and lineages and trained a hybrid CNN–BiLSTM model with standard regularization and class-imbalance handling. Model performance was benchmarked against Nextclade assignments and compared with classical machine-learning baselines.ResultsAcross 10 experimental runs, the model achieved a mean training accuracy of 99.74% ± 0.11, a validation accuracy of 99.00% ± 0.00, and a test accuracy of 99.91% ± 0.03. In benchmarking against the molecular epidemiology tool Nextclade, our model demonstrated superior performance, correctly identifying 100% of Omicron sequences, compared to 34.95% achieved by Nextclade. Saliency and feature attribution analyses highlighted recurrent spike substitutions consistent with known variant-defining mutations, as well as additional uncharacterized motifs with potential biological relevance.DiscussionThese findings demonstrate that spike-only deep models can provide rapid and accurate clade or variant classification, while also yielding interpretable feature importance. Such models complement phylogenetic approaches in settings with constrained resources and enable efficient triage of samples for confirmatory whole-genome analysis, supporting more timely genomic surveillance.",2025,10.3389/frai.2025.1512003
On the Impact of Digitalization and Artificial Intelligence on Employers' Flexibility Requirements in Occupations—Empirical Evidence for Germany,"Artificial intelligence (AI) has a high application potential in many areas of the economy, and its use is expected to accelerate strongly in the coming years. This is linked with changes in working conditions that may be substantial and entail serious health risks for employees. With our paper we are the first to conduct an empirical analysis of employers' increasing flexibility requirements in the course of advancing digitalization, based on a representative business survey, the IAB Job Vacancy Survey. We combine establishment-level data from the survey and occupation-specific characteristics from other sources and apply non-linear random effects estimations. According to employers' assessments, office and secretarial occupations are undergoing the largest changes in terms of flexibility requirements, followed by other occupations that are highly relevant in the context of AI: occupations in company organization and strategy, vehicle/aerospace/shipbuilding technicians and occupations in insurance and financial services. The increasing requirements we observe most frequently are those concerning demands on employees' self-organization, although short-term working-time flexibility and workplace flexibility also play an important role. The estimation results show that the occupational characteristics, independently of the individual employer, play a major role for increasing flexibility requirements. For example, occupations with a larger share of routine cognitive activities (which in the literature are usually more closely associated with artificial intelligence than others) reveal a significantly higher probability of increasing flexibility demands, specifically with regard to the employees' self-organization. This supports the argument that AI changes above all work content and work processes. For the average age of the workforce and the unemployment rate in an occupation we find significantly negative effects. At the establishment level the share of female employees plays a significant negative role. Our findings provide clear indications for targeted action in labor market and education policy in order to minimize the risks and to strengthen the chances of an increasing application of AI technologies.",2022,10.3389/frai.2022.868789
Self-evolving cognitive substrates through metabolic data processing and recursive self-representation with autonomous memory prioritization mechanisms,"Introduction
                    Conventional artificial intelligence (AI) systems are limited by static architectures that require periodic retraining and fail to adapt efficiently to continuously changing data environments. To address this limitation, this research introduces a novel biologically inspired computing paradigm that supports perpetual learning through continuous data assimilation and autonomous structural evolution. The proposed system aims to emulate biological cognition, enabling lifelong learning, self-repair, and adaptive evolution without human intervention.
                  
                  
                    Methods
                    The system is built upon dynamic cognitive substrates that continuously absorb and map real-time information streams. These substrates eliminate the traditional distinction between training and inference phases, supporting uninterrupted learning. Quantum-inspired uncertainty management ensures computational robustness, while biomimetic self-healing protocols maintain structural integrity during adaptive changes. Additionally, micro-optimization via fractal propagation enhances mathematical specialization across hierarchical computational levels. Recursive learning mechanisms allow the architecture to refine its functionality based on its own outputs.
                  
                  
                    Results
                    Experimental validation demonstrates that the proposed architecture sustains effective learning across diverse, heterogeneous data domains. The system autonomously restructures itself, maintaining stability while improving performance in dynamic environments. Specialized cognitive processing units, analogous to biological organs, perform distinct functions and collectively enhance adaptive intelligence. Notably, the system prioritizes and retains valuable information through evolution, reflecting biological memory consolidation patterns.
                  
                  
                    Discussion
                    The findings reveal that continuous, self-modifying AI architectures can outperform traditional models in non-stationary conditions. By integrating quantum uncertainty control, biomimetic repair mechanisms, and fractal-based optimization, the system achieves resilient, autonomous learning over time. This approach has far-reaching implications for developing lifelong-learning machines capable of dynamic adaptation, self-maintenance, and evolution paving the way toward fully autonomous, continuously learning artificial organisms.",2025,10.3389/frai.2025.1689727
A novel deep learning technique for multi classify Alzheimer disease: hyperparameter optimization technique,"A progressive brain disease that affects memory and cognitive function is Alzheimer’s disease (AD). To put therapies in place that potentially slow the progression of AD, early diagnosis and detection are essential. Early detection of these phases enables early activities, which are essential for controlling the disease. To address issues with limited data and computing resources, this work presents a novel deep-learning method based on using a newly proposed hyperparameter optimization method to identify the hyperparameters of ResNet152V2 model for classifying the phases of AD more accurately. The proposed model is compared to state-of-the-art models divided into two categories: transfer learning models and classical models to showcase its effectiveness and efficiency. This comparison is based on four performance metrics: recall, precision, F1 score, and accuracy. According to the experimental results, the proposed method is more efficient and effective in classifying various AD phases.",2025,10.3389/frai.2025.1558725
Heuristic machine learning approaches for identifying phishing threats across web and email platforms,"Life has become more comfortable in the era of advanced technology in this cutthroat competitive world. However, there are also emerging harmful technologies that pose a threat. Without a doubt, phishing is one of the rising concerns that leads to stealing vital information such as passwords, security codes, and personal data from any target node through communication hijacking techniques. In addition, phishing attacks include delivering false messages that originate from a trusted source. Moreover, a phishing attack aims to get the victim to run malicious programs and reveal confidential data, such as bank credentials, one-time passwords, and user login credentials. The sole intention is to collect personal information through malicious program-based attempts embedded in URLs, emails, and website-based attempts. Notably, this proposed technique detects URL, email, and website-based phishing attacks, which will be beneficial and secure us from scam attempts. Subsequently, the data are pre-processed to identify phishing attacks using data cleaning, attribute selection, and attacks detected using machine learning techniques. Furthermore, the proposed techniques use heuristic-based machine learning to identify phishing attacks. Admittedly, 56 features are used to analyze URL phishing findings, and experimental results show that the proposed technique has a better accuracy of 97.2%. Above all, the proposed techniques for email phishing detection obtain a higher accuracy of 97.4%. In addition, the proposed technique for website phishing detection has a better accuracy of 98.1%, and 48 features are used for analysis.",2024,10.3389/frai.2024.1414122
Social Networks of Lexical Innovation. Investigating the Social Dynamics of Diffusion of Neologisms on Twitter,"Societies continually evolve and speakers use new words to talk about innovative products and practices. While most lexical innovations soon fall into disuse, others spread successfully and become part of the lexicon. In this paper, I conduct a longitudinal study of the spread of 99 English neologisms on Twitter to study their degrees and pathways of diffusion. Previous work on lexical innovation has almost exclusively relied on usage frequency for investigating the spread of new words. To get a more differentiated picture of diffusion, I use frequency-based measures to study temporal aspects of diffusion and I use network analyses for a more detailed and accurate investigation of the sociolinguistic dynamics of diffusion. The results show that frequency measures manage to capture diffusion with varying success. Frequency counts can serve as an approximate indicator for overall degrees of diffusion, yet they miss important information about the temporal usage profiles of lexical innovations. The results indicate that neologisms with similar total frequency can exhibit significantly different degrees of diffusion. Analysing differences in their temporal dynamics of use with regard to their age, trends in usage intensity, and volatility contributes to a more accurate account of their diffusion. The results obtained from the social network analysis reveal substantial differences in the social pathways of diffusion. Social diffusion significantly correlates with the frequency and temporal usage profiles of neologisms. However, the network visualisations and metrics identify neologisms whose degrees of social diffusion are more limited than suggested by their overall frequency of use. These include, among others, highly volatile neologisms (e.g.,poppygate) and political terms (e.g.,alt-left), whose use almost exclusively goes back to single communities of closely-connected, like-minded individuals. I argue that the inclusion of temporal and social information is of particular importance for the study of lexical innovation since neologisms exhibit high degrees of temporal volatility and social indexicality. More generally, the present approach demonstrates the potential of social network analysis for sociolinguistic research on linguistic innovation, variation, and change.",2021,10.3389/frai.2021.648583
ExDoRA: enhancing the transferability of large language models for depression detection using free-text explanations,"Few-shot prompting in large language models (LLMs) significantly improves performance across various tasks, including both in-domain and previously unseen natural language tasks, by learning from limited in-context examples. How these examples enhance transferability and contribute to achieving state-of-the-art (SOTA) performance in downstream tasks remains unclear. To address this, we propose ExDoRA, a novel LLM transferability framework designed to clarify the selection of the most relevant examples using synthetic free-text explanations. Our novel hybrid method ranks LLM-generated explanations by selecting the most semantically relevant examples closest to the input query while balancing diversity. The top-ranked explanations, along with few-shot examples, are then used to enhance LLMs’ knowledge transfer in multi-party conversational modeling for previously unseen depression detection tasks. Evaluations using the IMHI corpus demonstrate that ExDoRA consistently produces high-quality free-text explanations. Extensive experiments on depression detection tasks, including depressed utterance classification (DUC) and depressed speaker identification (DSI), show that ExDoRA achieves SOTA performance. The evaluation results indicate significant improvements, with up to 20.59% in recall for DUC and 21.58% in F1 scores for DSI, using 5-shot examples with top-ranked explanations in the RSDD and eRisk 18 T2 corpora. These findings underscore ExDoRA’s potential as an effective screening tool for digital mental health applications.",2025,10.3389/frai.2025.1564828
Toward the Impact of Non-pharmaceutical Interventions and Vaccination on the COVID-19 Pandemic With Time-Dependent SEIR Model,"The outbreak of COVID-19, caused by the SARS-CoV-2 coronavirus, has been declared a pandemic by the World Health Organization (WHO) in March, 2020 and rapidly spread to over 210 countries and territories around the world. By December 24, there are over 77M cumulative confirmed cases with more than 1.72M deaths worldwide. To mathematically describe the dynamic of the COVID-19 pandemic, we propose a time-dependent SEIR model considering the incubation period. Furthermore, we take immunity, reinfection, and vaccination into account and propose the SEVIS model. Unlike the classic SIR based models with constant parameters, our dynamic models not only predicts the number of cases, but also monitors the trajectories of changing parameters, such as transmission rate, recovery rate, and the basic reproduction number. Tracking these parameters, we observe the significant decrease in the transmission rate in the U.S. after the authority announced a series of orders aiming to prevent the spread of the virus, such as closing non-essential businesses and lockdown restrictions. Months later, as restrictions being gradually lifted, we notice a new surge of infection emerges as the transmission rates show increasing trends in some states. Using our epidemiology models, people can track, timely monitor, and predict the COVID-19 pandemic with precision. To illustrate and validate our model, we use the national level data (the U.S.) and the state level data (New York and North Dakota), and the resulting relative prediction errors for the infected group and recovered group are mostly lower than 0.5%. We also simulate the long-term development of the pandemic based on our proposed models to explore when the crisis will end under certain conditions.",2021,10.3389/frai.2021.648579
Fake review identification and utility evaluation model using machine learning,"Due to the structural growth of e-commerce platforms, the frequency of exchange of opinions and the number of online reviews of platform participants related to products are increasing. However, given the growth of fake reviews, the corresponding growth in the quality of online reviews seems to be slow, at best. The number of cases of harm to retailers and customers caused by malicious false reviews is steadily increasing every year. In this context, it is becoming difficult for users to determine useful reviews amid a flood of information. As a result, the intrinsic value of online reviews that reduce uncertainty in pre-purchase decisions is blurred, and e-commerce platforms are on the verge of losing credibility and traffic. Through this study, we intend to present solutions related to review filtering and classification by constructing a model for judging the authenticity and usefulness of online reviews using machine learning.",2023,10.3389/frai.2022.1064371
A panoramic view of personalization based on individual differences in persuasive and behavior change interventions,"Persuasive technologies are designed to change human behavior or attitude using various persuasive strategies. Recent years have witnessed increasing evidence of the need to personalize and adapt persuasive interventions to various users and contextual factors because a persuasive strategy that works for one individual may rather demotivate others. As a result, several research studies have been conducted to investigate how to effectively personalize persuasive technologies. As research in this direction is gaining increasing attention, it becomes essential to conduct a systematic review to provide an overview of the current trends, challenges, approaches used for developing personalized persuasive technologies, and opportunities for future research in the area. To fill this need, we investigate approaches to personalize persuasive interventions by understanding user-related factors considered when personalizing persuasive technologies. Particularly, we conducted a systematic review of 72 research published in the last ten years in personalized and adaptive persuasive systems. The reviewed papers were evaluated based on different aspects, including metadata (e.g., year of publication and venue), technology, personalization dimension, personalization approaches, target outcome, individual differences, theories and scales, and evaluation approaches. Our results show (1) increased attention toward personalizing persuasive interventions, (2) personality trait is the most popular dimension of individual differences considered by existing research when tailoring their persuasive and behavior change systems, (3) students are among the most commonly targeted audience, and (4) education, health, and physical activity are the most considered domains in the surveyed papers. Based on our results, the paper provides insights and prospective future research directions.",2023,10.3389/frai.2023.1125191
Fostering effective hybrid human-LLM reasoning and decision making,"The impressive performance of modern Large Language Models (LLMs) across a wide range of tasks, along with their often non-trivial errors, has garnered unprecedented attention regarding the potential of AI and its impact on everyday life. While considerable effort has been and continues to be dedicated to overcoming the limitations of current models, the potentials and risks of human-LLM collaboration remain largely underexplored. In this perspective, we argue that enhancing the focus on human-LLM interaction should be a primary target for future LLM research. Specifically, we will briefly examine some of the biases that may hinder effective collaboration between humans and machines, explore potential solutions, and discuss two broader goals—mutual understanding and complementary team performance—that, in our view, future research should address to enhance effective human-LLM reasoning and decision-making.",2025,10.3389/frai.2024.1464690
Using Facial Landmark Detection on Thermal Images as a Novel Prognostic Tool for Emergency Departments,"IntroductionEmergency departments (ED) at hospitals sometimes experience unexpected deterioration in patients that were assessed to be in a stable condition upon arrival. Odense University Hospital (OUH) has conducted a retrospective study to investigate the possibilities of prognostic tools that can detect these unexpected deterioration cases at an earlier stage. The study suggests that the temperature difference (gradient) between the core and the peripheral body parts can be used to detect these cases. The temperature between the patient's inner canthus (core temperature) and the tip of the nose (peripheral temperature) can be measured with a thermal camera. Based on the temperature measurement from a thermal image, a gradient value can be calculated, which can be used as an early indicator of potential deterioration.ProblemThe lack of a tool to automatically calculate the gradient has prevented the ED at OUH in conducting a comprehensive prospective study on early indicators of patients at risk of deterioration. The current manual way of doing facial landmark detection on thermal images is too time consuming and not feasible as part of the daily workflow at the ED, where nurses have to triage patients within a few minutes.ObjectiveThe objective of this study was to automate the process of calculating the gradient by developing a handheld prognostic tool that can be used by nurses for automatically performing facial landmark detection on thermal images of patients as they arrive at the ED.MethodsA systematic literature review has been conducted to investigate previous studies that have been done for applying computer vision methods on thermal images. Several meetings, interviews and field studies have been conducted with the ED at OUH in order to understand their workflow, formulate and prioritize requirements and co-design the prognostic tool.ResultsThe study resulted in a novel Android app that can capture a thermal image of a patient's face with a thermal camera attached to a smartphone. Within a few seconds, the app then automatically calculates the gradient to be used in the triage process. The developed tool is the first of its kind using facial landmark detection on thermal images for calculating a gradient that can serve as a novel prognostic indicator for ED patients.",2022,10.3389/frai.2022.815333
Real-time temperature anomaly detection in vaccine refrigeration systems using deep learning on a resource-constrained microcontroller,"Maintaining consistent and accurate temperature is critical for the safe and effective storage of vaccines. Traditional monitoring methods often lack real-time capabilities and may not be sensitive enough to detect subtle anomalies. This paper presents a novel deep learning-based system for real-time temperature fault detection in refrigeration systems used for vaccine storage. Our system utilizes a semi-supervised Convolutional Autoencoder (CAE) model deployed on a resource-constrained ESP32 microcontroller. The CAE is trained on real-world temperature sensor data to capture temporal patterns and reconstruct normal temperature profiles. Deviations from the reconstructed profiles are flagged as potential anomalies, enabling real-time fault detection. Evaluation using real-time data demonstrates an impressive 92% accuracy in identifying temperature faults. The system’s low energy consumption (0.05 watts) and memory usage (1.2 MB) make it suitable for deployment in resource-constrained environments. This work paves the way for improved monitoring and fault detection in refrigeration systems, ultimately contributing to the reliable storage of life-saving vaccines.",2024,10.3389/frai.2024.1429602
Balancing Performance and Human Autonomy With Implicit Guidance Agent,"The human-agent team, which is a problem in which humans and autonomous agents collaborate to achieve one task, is typical in human-AI collaboration. For effective collaboration, humans want to have an effective plan, but in realistic situations, they might have difficulty calculating the best plan due to cognitive limitations. In this case, guidance from an agent that has many computational resources may be useful. However, if an agent guides the human behavior explicitly, the human may feel that they have lost autonomy and are being controlled by the agent. We therefore investigated implicit guidance offered by means of an agent’s behavior. With this type of guidance, the agent acts in a way that makes it easy for the human to find an effective plan for a collaborative task, and the human can then improve the plan. Since the human improves their plan voluntarily, he or she maintains autonomy. We modeled a collaborative agent with implicit guidance by integrating the Bayesian Theory of Mind into existing collaborative-planning algorithms and demonstrated through a behavioral experiment that implicit guidance is effective for enabling humans to maintain a balance between improving their plans and retaining autonomy.",2021,10.3389/frai.2021.736321
Artificial intelligence in healthcare: combining deep learning and Bayesian optimization to forecast COVID-19 confirmed cases,"Healthcare is a topic of significant concern within the academic and business sectors. The COVID-19 pandemic has had a considerable effect on the health of people worldwide. The rapid increase in cases adversely affects a nation's economy, public health, and residents' social and personal well-being. Improving the precision of COVID-19 infection forecasts can aid in making informed decisions regarding interventions, given the pandemic's harmful impact on numerous aspects of human life, such as health and the economy. This study aims to predict the number of confirmed COVID-19 cases in Saudi Arabia using Bayesian optimization (BOA) and deep learning (DL) methods. Two methods were assessed for their efficacy in predicting the occurrence of positive cases of COVID-19. The research employed data from confirmed COVID-19 cases in Saudi Arabia (SA), the United Kingdom (UK), and Tunisia (TU) from 2020 to 2021. The findings from the BOA model indicate that accurately predicting the number of COVID-19 positive cases is difficult due to the BOA projections needing to align with the assumptions. Thus, a DL approach was utilized to enhance the precision of COVID-19 positive case prediction in South Africa. The DQN model performed better than the BOA model when assessing RMSE and MAPE values. The model operates on a local server infrastructure, where the trained policy is transmitted solely to DQN. DQN formulated a reward function to amplify the efficiency of the DQN algorithm. By examining the rate of change and duration of sleep in the test data, this function can enhance the DQN model's training. Based on simulation findings, it can decrease the DQN work cycle by roughly 28% and diminish data overhead by more than 50% on average.",2024,10.3389/frai.2023.1327355
A geometric semantic model and Parts-of-Sense Inference annotation framework,"We introduce a geometric semantic model designed to capture fine-grained semantic representations in a multidimensional space. Building on this model, we develop a novel annotation framework that facilitates detailed semantic analysis across languages. Central to our approach is a set of Parts-of-Sense Inference (POSI) tags: 135 interpretable four-letter codes that annotate subtle semantic attributes often overlooked by traditional models. To evaluate the cross-linguistic and cross-structural applicability of this framework, we annotate expressions in four typologically diverse languages. Our results demonstrate that the proposed model provides an interpretable, cognitively plausible approach to semantic representation and can serve as a robust tool for investigating language processing and meaning inference across linguistic contexts.",2025,10.3389/frai.2025.1666074
An Explainable Multimodal Neural Network Architecture for Predicting Epilepsy Comorbidities Based on Administrative Claims Data,"Epilepsy is a complex brain disorder characterized by repetitive seizure events. Epilepsy patients often suffer from various and severe physical and psychological comorbidities (e.g., anxiety, migraine, and stroke). While general comorbidity prevalences and incidences can be estimated from epidemiological data, such an approach does not take into account that actual patient-specific risks can depend on various individual factors, including medication. This motivates to develop a machine learning approach for predicting risks of future comorbidities for individual epilepsy patients. In this work, we use inpatient and outpatient administrative health claims data of around 19,500 U.S. epilepsy patients. We suggest a dedicated multimodal neural network architecture (Deep personalized LOngitudinal convolutional RIsk model—DeepLORI) to predict the time-dependent risk of six common comorbidities of epilepsy patients. We demonstrate superior performance of DeepLORI in a comparison with several existing methods. Moreover, we show that DeepLORI-based predictions can be interpreted on the level of individual patients. Using a game theoretic approach, we identify relevant features in DeepLORI models and demonstrate that model predictions are explainable in light of existing knowledge about the disease. Finally, we validate the model on independent data from around 97,000 patients, showing good generalization and stable prediction performance over time.",2021,10.3389/frai.2021.610197
Human Autonomy in Future Drone Traffic: Joint Human–AI Control in Temporal Cognitive Work,"The roles of human operators are changing due to increased intelligence and autonomy of computer systems. Humans will interact with systems at a more overarching level or only in specific situations. This involves learning new practices and changing habitual ways of thinking and acting, including reconsidering human autonomy in relation to autonomous systems. This paper describes a design case of a future autonomous management system for drone traffic in cities in a key scenario we call The Computer in Brussels. Our approach to designing for human collaboration with autonomous systems builds on scenario-based design and cognitive work analysis facilitated by computer simulations. We use a temporal method, called the Joint Control Framework to describe human and automated work in an abstraction hierarchy labeled Levels of Autonomy in Cognitive Control. We use the Score notation to analyze patterns of temporal developments that span levels of the abstraction hierarchy and discuss implications for human-automation communication in traffic management. We discuss how autonomy at a lower level can prevent autonomy on higher levels, and vice versa. We also discuss the temporal nature of autonomy in minute-to-minute operative work. Our conclusion is that human autonomy in relation to autonomous systems is based on fundamental trade-offs between technological opportunities to automate and values of what human actors find meaningful.",2021,10.3389/frai.2021.704082
Developing a Cancer Digital Twin: Supervised Metastases Detection From Consecutive Structured Radiology Reports,"The development of digital cancer twins relies on the capture of high-resolution representations of individual cancer patients throughout the course of their treatment. Our research aims to improve the detection of metastatic disease over time from structured radiology reports by exposing prediction models to historical information. We demonstrate that Natural language processing (NLP) can generate better weak labels for semi-supervised classification of computed tomography (CT) reports when it is exposed to consecutive reports through a patient's treatment history. Around 714,454 structured radiology reports from Memorial Sloan Kettering Cancer Center adhering to a standardized departmental structured template were used for model development with a subset of the reports included for validation. To develop the models, a subset of the reports was curated for ground-truth: 7,732 total reports in the lung metastases dataset from 867 individual patients; 2,777 reports in the liver metastases dataset from 315 patients; and 4,107 reports in the adrenal metastases dataset from 404 patients. We use NLP to extract and encode important features from the structured text reports, which are then used to develop, train, and validate models. Three models—a simple convolutional neural network (CNN), a CNN augmented with an attention layer, and a recurrent neural network (RNN)—were developed to classify the type of metastatic disease and validated against the ground truth labels. The models use features from consecutive structured text radiology reports of a patient to predict the presence of metastatic disease in the reports. A single-report model, previously developed to analyze one report instead of multiple past reports, is included and the results from all four models are compared based on accuracy, precision, recall, and F1-score. The best model is used to label all 714,454 reports to generate metastases maps. Our results suggest that NLP models can extract cancer progression patterns from multiple consecutive reports and predict the presence of metastatic disease in multiple organs with higher performance when compared with a single-report-based prediction. It demonstrates a promising automated approach to label large numbers of radiology reports without involving human experts in a time- and cost-effective manner and enables tracking of cancer progression over time.",2022,10.3389/frai.2022.826402
Training humans for synthetic face image detection,"Fake identities created using highly realistic synthetic face images have become increasingly prevalent in recent years, driven by advancements in generative neural networks that are readily accessible online and easy to use. These fake identities can be exploited for malicious purposes, such as spreading misinformation or committing fraud. Given the widespread availability of online content and the ease of generating fake online identities, it is desirable that users are able to distinguish real face images from synthetic ones. Additionally, it is important to explore whether specialized training can enhance the ability of individuals to detect synthetically generated face images. In this work, we address these challenges by designing an online experiment to evaluate human detection capabilities and the impact of training on detecting synthetic face images. As part of the experiments, we recruited 184 participants divided into an experimental group and a control group, where the experimental group underwent a tailored training session halfway through the experiment. The study shows that training may moderately enhance human capabilities to detect synthetic face images. Specifically, it was found that the experimental group generally outperformed the control group after training, primarily due to improved abilities in detecting synthetic face images. However, after training, the experimental group showed increased sensitivity and misclassified also more authentic face images, as compared to the control group.",2025,10.3389/frai.2025.1568267
Comparison of 3D and 2D area measurement of acute burn wounds with LiDAR technique and deep learning model,"It is generally understood that wound areas appear smaller when calculated using 2D images, but the factors contributing to this discrepancy are not well-defined. With the rise of 3D photography, 3D segmentation, and 3D measurement, more accurate assessments have become possible. We developed an application called the Burn Evaluation Network (B.E.N.), which combines a deep learning model with LiDAR technology to perform both 2D and 3D measurements. In the first part of our study, we used burn wound templates to verify that the results of 3D segmentation closely matched the actual size of the burn wound and to examine the effect of limb curvature on the 3D/2D area ratio. Our findings revealed that smaller curvatures, indicative of flatter surfaces, were associated with lower 3D/2D area ratios, and larger curvatures corresponded to higher ratios. For instance, the back had the lowest average curvature (0.027 ± 0.004) and the smallest 3D/2D area ratio (1.005 ± 0.055). In the second part of our study, we applied our app to real patients, measuring burn areas in both 3D and 2D. Regions such as the head and neck (ratio: 1.641) and dorsal foot (ratio: 1.908) exhibited significantly higher 3D/2D area ratios. Additionally, images containing multiple burn wounds also showed a larger ratio (1.656) and greater variability in distribution. These findings suggest that 2D segmentation tends to significantly underestimate surface areas in highly curved regions or when measurements require summing multiple wound areas. We recommend using 3D measurements for wounds located on areas like the head, neck, and dorsal foot, as well as for cases involving multiple wounds or large areas, to improve measurement accuracy.",2025,10.3389/frai.2025.1510905
Integration of AI and ML in regenerative braking for electric vehicles: a review,"Electric vehicle technology has grown rapidly in recent years due to battery advancements, environmental concerns and supportive policies. Regenerative braking systems play a critical role in improving energy efficiency by converting kinetic energy into electrical energy, thereby extending battery life and vehicle range. However, conventional regenerative braking faces challenges in energy recovery, comfort, and adaptability. Optimizing energy recovery ensures prolonged battery life by preventing overcharging or undercharging, making EVs more sustainable and cost-effective. This review paper explores the integration of Artificial Intelligence and machine learning techniques in regenerative braking systems to overcome these challenges. This study examines AI techniques such as regression models, neural networks, deep reinforcement learning, fuzzy logic, genetic algorithm and swarm intelligence based techniques for regenerative braking. The study also compares AI-based strategies with traditional braking methods. Unlike previous studies, which focus on individual AI techniques, this paper provides a comparative analysis of multiple AI approaches, assessing their impact on braking performance and energy recovery, and propose a hybrid AI framework. This paper covers challenges in real-time implementation, road adaptability, and vehicle control integration. This paper also discusses future research that optimize braking performance like V2X communication, edge computing, and explainable AI etc.",2025,10.3389/frai.2025.1626804
Revisiting the political biases of ChatGPT,"Although ChatGPT promises wide-ranging applications, there is a concern that it is politically biased; in particular, that it has a left-libertarian orientation. Nevertheless, following recent trends in attempts to reduce such biases, this study re-evaluated the political biases of ChatGPT using political orientation tests and the application programming interface. The effects of the languages used in the system as well as gender and race settings were evaluated. The results indicate that ChatGPT manifests less political bias than previously assumed; however, they did not entirely dismiss the political bias. The languages used in the system, and the gender and race settings may induce political biases. These findings enhance our understanding of the political biases of ChatGPT and may be useful for bias evaluation and designing the operational strategy of ChatGPT.",2023,10.3389/frai.2023.1232003
"Explainable person–job recommendations: challenges, approaches, and comparative analysis","IntroductionAs person–job recommendation systems (PJRS) increasingly mediate hiring decisions, concerns over their “black box” opacity have sparked demand for explainable AI (XAI) solutions.MethodsThis systematic review examines 85 studies on explainable PJRS methods published between 2019 and August 2025, selected from 150 screened articles across Google Scholar, Web of Science, and CNKI, following PRISMA 2020 guidelines.ResultsGuided by a PICOS-formulated review question, we categorize explainability techniques into three layers—data (e.g., feature attribution, causal diagrams), model (e.g., attention mechanisms, knowledge graphs), and output (e.g., SHAP, counterfactuals)—and summarize their objectives, trade-offs, and practical applications. We further synthesize these into an integrated end-to-end framework that addresses opacity across layers and supports traceable recommendations. Quantitative benchmarking of six representative methods (e.g., LIME, attention-based, KG-GNN) reveals performance–explainability trade-offs, with counterfactual approaches achieving the highest Explainability-Performance (E‑P) score (0.95).DiscussionThis review provides a taxonomy, cross-layer framework, and comparative evidence to inform the design of transparent and trustworthy PJRS systems. Future directions include multimodal causal inference, feedback-driven adaptation, and efficient explainability tools.",2025,10.3389/frai.2025.1660548
DICE: A Drug Indication Classification and Encyclopedia for AI-Based Indication Extraction,"Drug labeling contains an ‘INDICATIONS AND USAGE’ that provides vital information to support clinical decision making and regulatory management. Effective extraction of drug indication information from free-text based resources could facilitate drug repositioning projects and help collect real-world evidence in support of secondary use of approved medicines. To enable AI-powered language models for the extraction of drug indication information, we used manual reading and curation to develop aDrugIndicationClassification andEncyclopedia (DICE) based on FDA approved human prescription drug labeling. A DICE scheme with 7,231 sentences categorized into five classes (indications, contradictions, side effects, usage instructions, and clinical observations) was developed. To further elucidate the utility of the DICE, we developed nine different AI-based classifiers for the prediction of indications based on the developed DICE to comprehensively assess their performance. We found that the transformer-based language models yielded an average MCC of 0.887, outperforming the word embedding-based Bidirectional long short-term memory (BiLSTM) models (0.862) with a 2.82% improvement on the test set. The best classifiers were also used to extract drug indication information in DrugBank and achieved a high enrichment rate (&gt;0.930) for this task. We found that domain-specific training could provide more explainable models without performance sacrifices and better generalization for external validation datasets. Altogether, the proposed DICE could be a standard resource for the development and evaluation of task-specific AI-powered, natural language processing (NLP) models.",2021,10.3389/frai.2021.711467
"A comprehensive review of machine learning for heart disease prediction: challenges, trends, ethical considerations, and future directions","This review provides a thorough and organized overview of machine learning (ML) applications in predicting heart disease, covering technological advancements, challenges, and future prospects. As cardiovascular diseases (CVDs) are the leading cause of global mortality, there is an urgent demand for early and precise diagnostic tools. ML models hold considerable potential by utilizing large-scale healthcare data to enhance predictive diagnostics. To systematically investigate this field, the literature is organized into five thematic categories such as “Heart Disease Detection and Diagnostics,” “Machine Learning Models and Algorithms for Healthcare,” “Feature Engineering and Optimization Techniques,” “Emerging Technologies in Healthcare,” and “Applications of AI Across Diseases and Conditions.” The review incorporates performance benchmarking of various ML models, highlighting that hybrid deep learning (DL) frameworks, e.g., convolutional neural network-long short-term memory (CNN-LSTM) consistently outperform traditional models in terms of sensitivity, specificity, and area under the curve (AUC). Several real-world case studies are presented to demonstrate the successful deployment of ML models in clinical and wearable settings. This review showcases the progression of ML approaches from traditional classifiers to hybrid DL structures and federated learning (FL) frameworks. It also discusses ethical issues, dataset limitations, and model transparency. The conclusions provide important insights for the development of artificial intelligence (AI) powered, clinically applicable heart disease prediction systems.",2025,10.3389/frai.2025.1583459
Fetal Organ Anomaly Classification Network for Identifying Organ Anomalies in Fetal MRI,"Rapid development in Magnetic Resonance Imaging (MRI) has played a key role in prenatal diagnosis over the last few years. Deep learning (DL) architectures can facilitate the process of anomaly detection and affected-organ classification, making diagnosis more accurate and observer-independent. We propose a novel DL image classification architecture, Fetal Organ Anomaly Classification Network (FOAC-Net), which uses squeeze-and-excitation (SE) and naïve inception (NI) modules to automatically identify anomalies in fetal organs. This architecture can identify normal fetal anatomy, as well as detect anomalies present in the (1) brain, (2) spinal cord, and (3) heart. In this retrospective study, we included fetal 3-dimensional (3D) SSFP sequences of 36 participants. We classified the images on a slice-by-slice basis. FOAC-Net achieved a classification accuracy of 85.06, 85.27, 89.29, and 82.20% when predicting brain anomalies, no anomalies (normal), spinal cord anomalies, and heart anomalies, respectively. In a comparison study, FOAC-Net outperformed other state-of-the-art classification architectures in terms of class-average F1 and accuracy. This work aims to develop a novel classification architecture identifying the affected organs in fetal MRI.",2022,10.3389/frai.2022.832485
Let Me Take Over: Variable Autonomy for Meaningful Human Control,"As Artificial Intelligence (AI) continues to expand its reach, the demand for human control and the development of AI systems that adhere to our legal, ethical, and social values also grows. Many (international and national) institutions have taken steps in this direction and published guidelines for the development and deployment of responsible AI systems. These guidelines, however, rely heavily on high-level statements that provide no clear criteria for system assessment, making the effective control over systems a challenge. “Human oversight” is one of the requirements being put forward as a means to support human autonomy and agency. In this paper, we argue that human presence alone does not meet this requirement and that such a misconception may limit the use of automation where it can otherwise provide so much benefit across industries. We therefore propose the development of systems with variable autonomy—dynamically adjustable levels of autonomy—as a means of ensuring meaningful human control over an artefact by satisfying all three core values commonly advocated in ethical guidelines: accountability, responsibility, and transparency.",2021,10.3389/frai.2021.737072
Using the DiCoT framework for integrated multimodal analysis in mixed-reality training environments,"Simulation-based training (SBT) programs are commonly employed by organizations to train individuals and teams for effective workplace cognitive and psychomotor skills in a broad range of applications. Distributed cognition has become a popular cognitive framework for the design and evaluation of these SBT environments, with structured methodologies such asDistributed Cognition for Teamwork (DiCoT)used for analysis. However, the analysis and evaluations generated by such distributed cognition frameworks require extensive domain-knowledge and manual coding and interpretation, and the analysis is primarily qualitative. In this work, we propose and develop the application of multimodal learning analysis techniques to SBT scenarios. Using these analysis methods, we can use the rich multimodal data collected in SBT environments to generate more automated interpretations of trainee performance that supplement and extend traditional DiCoT analysis. To demonstrate the use of these methods, we present a case study of nurses training in a mixed-reality manikin-based (MRMB) training environment. We show how the combined analysis of the video, speech, and eye-tracking data collected as the nurses train in the MRMB environment supports and enhances traditional qualitative DiCoT analysis. By applying such quantitative data-driven analysis methods, we can better analyze trainee activities online in SBT and MRMB environments. With continued development, these analysis methods could be used to provide targeted feedback to learners, a detailed review of training performance to the instructors, and data-driven evidence for improving the environment to simulation designers.",2022,10.3389/frai.2022.941825
Neural Network Training With Asymmetric Crosspoint Elements,"Analog crossbar arrays comprising programmable non-volatile resistors are under intense investigation for acceleration of deep neural network training. However, the ubiquitous asymmetric conductance modulation of practical resistive devices critically degrades the classification performance of networks trained with conventional algorithms. Here we first describe the fundamental reasons behind this incompatibility. Then, we explain the theoretical underpinnings of a novel fully-parallel training algorithm that is compatible with asymmetric crosspoint elements. By establishing a powerful analogy with classical mechanics, we explain how device asymmetry can be exploited as a useful feature for analog deep learning processors. Instead of conventionally tuning weights in the direction of the error function gradient, network parameters can be programmed to successfully minimize the total energy (Hamiltonian) of the system that incorporates the effects of device asymmetry. Our technique enables immediate realization of analog deep learning accelerators based on readily available device technologies.",2022,10.3389/frai.2022.891624
Profiling investor behavior in the Malaysian derivatives market using K-means clustering,"This study investigates the trading behaviors of Malaysian derivatives traders using a comprehensive dataset from Bursa Malaysia with K-means clustering, representing one of the first AI applications to derivatives market segmentation. The analysis encompassed over 11 million trade records for FCPO and FKLI derivatives from January to December 2022. Six key features were engineered to segment derivative traders: Total Number of Trades, Total Traded Amount, Overall Realized Profit, Average ROI, Maximum Account Vintage (trader experience in years), and Median Holding Days (typical position duration). Inverse Hyperbolic Sine transformation was applied to address extreme outliers, ensuring robust feature scaling. K-means clustering identified five distinct profiles: “High-Frequency, High-Risk Derivative Traders with Consistent Losses,” “Conservative, Steady-Growth Derivative Trader,” “High-Frequency, High-Yield Derivative Traders,” “Conservative, Low-Yield Derivative Traders,” and “Cautious, Low-Activity Novice Derivative Traders.” Decision tree classifiers validated these clusters through interpretable splitting conditions. These profiles enable targeted risk management strategies, personalized trading services, and evidence-based regulatory policies for derivatives markets and future research.",2025,10.3389/frai.2025.1640776
A bird’s-eye view of the biological mechanism and machine learning prediction approaches for cell-penetrating peptides,"Cell-penetrating peptides (CPPs) are highly effective at passing through eukaryotic membranes with various cargo molecules, like drugs, proteins, nucleic acids, and nanoparticles, without causing significant harm. Creating drug delivery systems with CPP is associated with cancer, genetic disorders, and diabetes due to their unique chemical properties. Wet lab experiments in drug discovery methodologies are time-consuming and expensive. Machine learning (ML) techniques can enhance and accelerate the drug discovery process with accurate and intricate data quality. ML classifiers, such as support vector machine (SVM), random forest (RF), gradient-boosted decision trees (GBDT), and different types of artificial neural networks (ANN), are commonly used for CPP prediction with cross-validation performance evaluation. Functional CPP prediction is improved by using these ML strategies by using CPP datasets produced by high-throughput sequencing and computational methods. This review focuses on several ML-based CPP prediction tools. We discussed the CPP mechanism to understand the basic functioning of CPPs through cells. A comparative analysis of diverse CPP prediction methods was conducted based on their algorithms, dataset size, feature encoding, software utilities, assessment metrics, and prediction scores. The performance of the CPP prediction was evaluated based on accuracy, sensitivity, specificity, and Matthews correlation coefficient (MCC) on independent datasets. In conclusion, this review will encourage the use of ML algorithms for finding effective CPPs, which will have a positive impact on future research on drug delivery and therapeutics.",2025,10.3389/frai.2024.1497307
EXP-Crowd: A Gamified Crowdsourcing Framework for Explainability,"The spread of AI and black-box machine learning models made it necessary to explain their behavior. Consequently, the research field of Explainable AI was born. The main objective of an Explainable AI system is to be understood by a human as the final beneficiary of the model. In our research, we frame the explainability problem from the crowds point of view and engage both users and AI researchers through a gamified crowdsourcing framework. We research whether it's possible to improve the crowds understanding of black-box models and the quality of the crowdsourced content by engaging users in a set of gamified activities through a gamified crowdsourcing framework named EXP-Crowd. While users engage in such activities, AI researchers organize and share AI- and explainability-related knowledge to educate users. We present the preliminary design of a game with a purpose (G.W.A.P.) to collect features describing real-world entities which can be used for explainability purposes. Future works will concretise and improve the current design of the framework to cover specific explainability-related needs.",2022,10.3389/frai.2022.826499
Improving Adversarial Robustness via Attention and Adversarial Logit Pairing,"Though deep neural networks have achieved the state of the art performance in visual classification, recent studies have shown that they are all vulnerable to the attack of adversarial examples. In this paper, we develop improved techniques for defending against adversarial examples. First, we propose an enhanced defense technique denoted Attention and Adversarial Logit Pairing (AT + ALP), which encourages both attention map and logit for the pairs of examples to be similar. When being applied to clean examples and their adversarial counterparts, AT + ALP improves accuracy on adversarial examples over adversarial training. We show that AT + ALP can effectively increase the average activations of adversarial examples in the key area and demonstrate that it focuses on discriminate features to improve the robustness of the model. Finally, we conduct extensive experiments using a wide range of datasets and the experiment results show that our AT + ALP achieves the state of the art defense performance. For example, on 17 Flower Category Database, under strong 200-iteration Projected Gradient Descent (PGD) gray-box and black-box attacks where prior art has 34 and 39% accuracy, our method achieves 50 and 51%. Compared with previous work, our work is evaluated under highly challenging PGD attack: the maximum perturbation ϵ ∈ {0.25, 0.5} i.e. L∞ ∈ {0.25, 0.5} with 10–200 attack iterations. To the best of our knowledge, such a strong attack has not been previously explored on a wide range of datasets.",2022,10.3389/frai.2021.752831
Learning and reasoning with graph data,"Reasoning about graphs, and learning from graph data is a field of artificial intelligence that has recently received much attention in the machine learning areas of graph representation learning and graph neural networks. Graphs are also the underlying structures of interest in a wide range of more traditional fields ranging from logic-oriented knowledge representation and reasoning to graph kernels and statistical relational learning. In this review we outline a broad map and inventory of the field of learning and reasoning with graphs that spans the spectrum from reasoning in the form of logical deduction to learning node embeddings. To obtain a unified perspective on such a diverse landscape we introduce a simple and general semantic concept of a model that covers logic knowledge bases, graph neural networks, kernel support vector machines, and many other types of frameworks. Still at a high semantic level, we survey common strategies for model specification using probabilistic factorization and standard feature construction techniques. Based on this semantic foundation we introduce a taxonomy of reasoning tasks that casts problems ranging from transductive link prediction to asymptotic analysis of random graph models as queries of different complexities for a given model. Similarly, we express learning in different frameworks and settings in terms of a common statistical maximum likelihood principle. Overall, this review aims to provide a coherent conceptual framework that provides a basis for further theoretical analyses of respective strengths and limitations of different approaches to handling graph data, and that facilitates combination and integration of different modeling paradigms.",2023,10.3389/frai.2023.1124718
"Next generation immuno-oncology tumor profiling using a rapid, non-invasive, computational biophysics biomarker in early-stage breast cancer","BackgroundImmuno-oncology (IO) therapies targeting the PD-1/PD-L1 axis, such as immune checkpoint inhibitor (ICI) antibodies, have emerged as promising treatments for early-stage breast cancer (ESBC). Despite immunotherapy's clinical significance, the number of benefiting patients remains small, and the therapy can prompt severe immune-related events. Current pathologic and transcriptomic predictions of IO response are limited in terms of accuracy and rely on single-site biopsies, which cannot fully account for tumor heterogeneity. In addition, transcriptomic analyses are costly and time-consuming. We therefore constructed a computational biomarker coupling biophysical simulations and artificial intelligence-based tissue segmentation of dynamic contrast-enhanced magnetic resonance imaging (DCE-MRIs), enabling IO response prediction across the entire tumor.MethodsBy analyzing both single-cell and whole-tissue RNA-seq data from non-IO-treated ESBC patients, we associated gene expression levels of the PD-1/PD-L1 axis with local tumor biology. PD-L1 expression was then linked to biophysical features derived from DCE-MRIs to generate spatially- and temporally-resolved atlases (virtual tumors) of tumor biology, as well as the TumorIO biomarker of IO response. We quantified TumorIO within patient virtual tumors (n = 63) using integrative modeling to train and develop a corresponding TumorIO Score.ResultsWe validated the TumorIO biomarker and TumorIO Score in a small, independent cohort of IO-treated patients (n = 17) and correctly predicted pathologic complete response (pCR) in 15/17 individuals (88.2% accuracy), comprising 10/12 in triple negative breast cancer (TNBC) and 5/5 in HR+/HER2- tumors. We applied the TumorIO Score in a virtual clinical trial (n = 292) simulating ICI administration in an IO-naïve cohort that underwent standard chemotherapy. Using this approach, we predicted pCR rates of 67.1% for TNBC and 17.9% for HR+/HER2- tumors with addition of IO therapy; comparing favorably to empiric pCR rates derived from published trials utilizing ICI in both cancer subtypes.ConclusionThe TumorIO biomarker and TumorIO Score represent a next generation approach using integrative biophysical analysis to assess cancer responsiveness to immunotherapy. This computational biomarker performs as well as PD-L1 transcript levels in identifying a patient's likelihood of pCR following anti-PD-1 IO therapy. The TumorIO biomarker allows for rapid IO profiling of tumors and may confer high clinical decision impact to further enable personalized oncologic care.",2023,10.3389/frai.2023.1153083
"Large language models for closed-library multi-document query, test generation, and evaluation","IntroductionLearning complex, detailed, and evolving knowledge is a challenge in multiple technical professions. Relevant source knowledge is contained within many large documents and information sources with frequent updates to these documents. Knowledge tests need to be generated on new material and existing tests revised, tracking knowledge base updates. Large Language Models (LLMs) provide a framework for artificial intelligence-assisted knowledge acquisition and continued learning. Retrieval-Augmented Generation (RAG) provides a framework to leverage available, trained LLMs combined with technical area-specific knowledge bases.MethodsHerein, two methods are introduced (DaaDy: document as a dictionary and SQAD: structured question answer dictionary), which together enable effective implementation of LLM-RAG question-answering on large documents. Additionally, the AI for knowledge intensive tasks (AIKIT) solution is presented for working with numerous documents for training and continuing education. AIKIT is provided as a containerized open source solution that deploys on standalone, high performance, and cloud systems. AIKIT includes LLM, RAG, vector stores, relational database, and a Ruby on Rails web interface.ResultsCoverage of source documents by LLM-RAG generated questions decreases as the length of documents increase. Segmenting source documents improve coverage of generated questions. The AIKIT solution enabled easy use of multiple LLM models with multimodal RAG source documents; AIKIT retains LLM-RAG responses for queries against one or multiple LLM models.DiscussionAIKIT provides an easy-to-use set of tools to enable users to work with complex information using LLM-RAG capabilities. AIKIT enables easy use of multiple LLM models with retention of LLM-RAG responses.",2025,10.3389/frai.2025.1592013
Cosmic Ray Background Removal With Deep Neural Networks in SBND,"In liquid argon time projection chambers exposed to neutrino beams and running on or near surface levels, cosmic muons, and other cosmic particles are incident on the detectors while a single neutrino-induced event is being recorded. In practice, this means that data from surface liquid argon time projection chambers will be dominated by cosmic particles, both as a source of event triggers and as the majority of the particle count in true neutrino-triggered events. In this work, we demonstrate a novel application of deep learning techniques to remove these background particles by applying deep learning on full detector images from the SBND detector, the near detector in the Fermilab Short-Baseline Neutrino Program. We use this technique to identify, on a pixel-by-pixel level, whether recorded activity originated from cosmic particles or neutrino interactions.",2021,10.3389/frai.2021.649917
Research on the structure function recognition of PLOS,"PurposeThe present study explores and investigates the efficiency of deep learning models in identifying discourse structure and functional features and explores the potential application of natural language processing (NLP) techniques in text mining, information measurement, and scientific communication.MethodThe PLOS literature series has been utilized to obtain full-text data, and four deep learning models, including BERT, RoBERTa, SciBERT, and SsciBERT, have been employed for structure-function recognition.ResultThe experimental findings reveal that the SciBERT model performs outstandingly, surpassing the other models, with an F1 score. Additionally, the performance of different paragraph structures has been analyzed, and it has been found that the model performs well in paragraphs such as method and result.ConclusionThe study's outcomes suggest that deep learning models can recognize the structure and functional elements at the discourse level, particularly for scientific literature, where the SciBERT model performs remarkably. Moreover, the NLP techniques have extensive prospects in various fields, including text mining, information measurement, and scientific communication. By automatically parsing and identifying structural and functional information in text, the efficiency of literature management and retrieval can be improved, thereby expediting scientific research progress. Therefore, deep learning and NLP technologies hold significant value in scientific research.",2024,10.3389/frai.2024.1254671
Backchannel Behavior Influences the Perceived Personality of Human and Artificial Communication Partners,"Different applications or contexts may require different settings for a conversational AI system, as it is clear that e.g., a child-oriented system would need a different interaction style than a warning system used in emergency situations. The current article focuses on the extent to which a system's usability may benefit from variation in the personality it displays. To this end, we investigate whether variation in personality is signaled by differences in specific audiovisual feedback behavior, with a specific focus on embodied conversational agents. This article reports about two rating experiments in which participants judged the personalities (i) of human beings and (ii) of embodied conversational agents, where we were specifically interested in the role of variability in audiovisual cues. Our results show that personality perceptions of both humans and artificial communication partners are indeed influenced by the type of feedback behavior used. This knowledge could inform developers of conversational AI on how to also include personality in their feedback behavior generation algorithms, which could enhance the perceived personality and in turn generate a stronger sense of presence for the human interlocutor.",2022,10.3389/frai.2022.835298
LLMCARE: early detection of cognitive impairment via transformer models enhanced by LLM-generated synthetic data,"Background
                    Alzheimer’s disease and related dementias (ADRD) affect nearly five million older adults in the United States, yet more than half remain undiagnosed. Speech-based natural language processing (NLP) provides a scalable approach to identify early cognitive decline by detecting subtle linguistic markers that may precede clinical diagnosis.
                  
                  
                    Objective
                    This study aims to develop and evaluate a speech-based screening pipeline that integrates transformer-based embeddings with handcrafted linguistic features, incorporates synthetic augmentation using large language models (LLMs), and benchmarks unimodal and multimodal LLM classifiers. External validation was performed to assess generalizability to an MCI-only cohort.
                  
                  
                    Methods
                    
                      Transcripts were obtained from the ADReSSo 2021 benchmark dataset (
                      n
                       = 237; derived from the Pitt Corpus, DementiaBank) and the DementiaBank Delaware corpus (
                      n
                       = 205; clinically diagnosed mild cognitive impairment [MCI] vs. controls). Audio was automatically transcribed using Amazon Web Services Transcribe (general model). Ten transformer models were evaluated under three fine-tuning strategies. A late-fusion model combined embeddings from the best-performing transformer with 110 linguistically derived features. Five LLMs (LLaMA-8B/70B, MedAlpaca-7B, Ministral-8B, GPT-4o) were fine-tuned to generate label-conditioned synthetic speech for data augmentation. Three multimodal LLMs (GPT-4o, Qwen-Omni, Phi-4) were tested in zero-shot and fine-tuned settings.
                    
                  
                  
                    Results
                    On the ADReSSo dataset, the fusion model achieved an F1-score of 83.32 (AUC = 89.48), outperforming both transformer-only and linguistic-only baselines. Augmentation with MedAlpaca-7B synthetic speech improved performance to F1 = 85.65 at 2 × scale, whereas higher augmentation volumes reduced gains. Fine-tuning improved unimodal LLM classifiers (e.g., MedAlpaca-7B, F1 = 47.73 → 78.69), while multimodal models demonstrated lower performance (Phi-4 = 71.59; GPT-4o omni = 67.57). On the Delaware corpus, the pipeline generalized to an MCI-only cohort, with the fusion model plus 1 × MedAlpaca-7B augmentation achieving F1 = 72.82 (AUC = 69.57).
                  
                  
                    Conclusion
                    
                      Integrating transformer embeddings with handcrafted linguistic features enhances ADRD detection from speech. Distributionally aligned LLM-generated narratives provide effective but bounded augmentation, while current multimodal models remain limited. Crucially, validation on the Delaware corpus demonstrates that the proposed pipeline generalizes to early-stage impairment, supporting its potential as a scalable approach for clinically relevant early screening. All codes for LLMCARE are publicly available at:
                      GitHub
                      .",2025,10.3389/frai.2025.1669896
Meta-learner-based frameworks for interpretable email spam detection,"IntroductionWith the increasing reliance on digital communication, email has become an essential tool for personal and professional correspondence. However, despite its numerous benefits, digital communication faces significant challenges, particularly the prevalence of spam emails. Effective spam email classification systems are crucial to mitigate these issues by automatically identifying and filtering out unwanted messages, enhancing the efficiency of email communication.MethodsWe compare five traditional machine-learning and five deep-learning spam classifiers against a novel meta-learner, evaluating how different word embeddings, vectorization schemes, and model architectures affect performance on the Enron-Spam and TREC 2007 datasets. The primary aim is to show how the meta-learner's combined predictions stack up against individual ML and DL approaches.ResultsOur meta-learner outperforms all state-of-the-art models, achieving an accuracy of 0.9905 and an AUC score of 0.9991 on a hybrid dataset that combines Enron-Spam and TREC 2007. To the best of our knowledge, our model also surpasses the only other meta-learning-based spam detection model reported in recent literature, with higher accuracy, better generalization from a significantly larger dataset, and lower computational complexity. We also evaluated our meta-learner in a zero-shot setting on an unseen real-world dataset, achieving a spam sensitivity rate of 0.8970 and an AUC score of 0.7605.DiscussionThese results demonstrate that meta-learning can yield more robust, bias-resistant spam filters suited for real-world deployment. By combining complementary model strengths, the meta-learner also offers improved resilience against evolving spam tactics.",2025,10.3389/frai.2025.1569804
Segmenting female students' perceptions about Fintech using Explainable AI,"The use of Financial Technology (Fintech) has been proposed as a promising way to bridge the gender gap, both financially and socially. However, there is evidence that Fintech is far from achieving this objective, and that women's perceptions of Fintech usages are not clear. Therefore, the main objective of the this study is to segment women's perceptions toward Fintech tools and interpret these segments using machine learning methods. Two primary segments of women were produced, namely a “Fintech-friendly” group and a “Fintech-sceptical” group. The importance and reasonings behind the aforementioned segmentation are then examined. The most prominent factors affecting a woman being in the “Fintech-friendly” group are the perceived benefits of Fintech tools compared to the traditional ones, such as ease of usage, time-space convenience, and its advantageous nature. Finally, for Fintech stakeholders, implications for usability, ease, Fintech education, and tailored experiences may be advantageous approaches.",2024,10.3389/frai.2024.1504963
Compact Neural Architecture Designs by Tensor Representations,"We propose a framework of tensorial neural networks (TNNs) extending existing linear layers on low-order tensors to multilinear operations on higher-order tensors. TNNs have three advantages over existing networks: First, TNNs naturally apply to higher-order data without flattening, which preserves their multi-dimensional structures. Second, compressing a pre-trained network into a TNN results in a model with similar expressive power but fewer parameters. Finally, TNNs interpret advanced compact designs of network architectures, such as bottleneck modules and interleaved group convolutions. To learn TNNs, we derive their backpropagation rules using a novel suite of generalized tensor algebra. With backpropagation, we can either learn TNNs from scratch or pre-trained models using knowledge distillation. Experiments on VGG, ResNet, and Wide-ResNet demonstrate that TNNs outperform the state-of-the-art low-rank methods on a wide range of backbone networks and datasets.",2022,10.3389/frai.2022.728761
ML-based validation of experimental randomization in learning games,"Randomization is a standard method in experimental research, yet its validity is not always guaranteed. This study introduces machine learning (ML) models as supplementary tools for validating participant randomization. A learning direction game with dichotomized scenarios was introduced, and both supervised and unsupervised ML models were evaluated on a binary classification task. Supervised models (logistic regression, decision tree, and support vector machine) achieved the highest accuracy of 87% after adding synthetic data to enlarge the sample size, while unsupervised models (k-means, k-nearest neighbors, and ANN—artificial neural networks) performed less effectively. The ANN model, in particular, showed overfitting, even with synthetic data. Feature importance analysis further revealed predictors of assignment bias. These findings support the proposed methodology for detecting randomization patterns; however, its effectiveness is influenced by sample size and experimental design complexity. Future studies should apply this approach with caution and further examine its applicability across diverse experimental designs.",2025,10.3389/frai.2025.1541087
Who speaks next? Multi-party AI discussion leveraging the systematics of turn-taking in Murder Mystery games,"IntroductionMulti-agent systems utilizing large language models (LLMs) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenging.MethodsIn this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called “Murder Mystery Agents” that applies these norms to AI agents' dialogue control. As an evaluation target, we employed the “Murder Mystery” game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue.ResultsTo verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using LLMs, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning.DiscussionThe results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among AI agents, and provide design guidelines for more advanced multi-agent dialogue systems.",2025,10.3389/frai.2025.1582287
Long-short term memory networks for modeling track geometry in laser metal deposition,"Modeling metal additive manufacturing processes is of great importance because it allows for the production of objects that are closer to the desired geometry and mechanical properties. Over-deposition often takes place during laser metal deposition, especially when the deposition head changes its direction and results in more material being melted onto the substrate. Modeling over-deposition is one of the necessary steps toward online process control, as a good model can be used in a closed-loop system to adjust the deposition parameters in real-time to reduce this phenomenon. In this study, we present a long-short memory neural network to model over-deposition. The model has been trained on simple geometries such as straight tracks, spiral and V-tracks made of Inconel 718. The model shows good generalization capabilities and can predict the height of more complex and previously unseen random tracks with limited performance loss. After the addition to the training dataset of a small amount of data coming from the random tracks, the performance of the model for such additional shapes improves significantly, making this approach feasible for more general applications as well.",2023,10.3389/frai.2023.1156630
Swedish Medical LLM Benchmark: development and evaluation of a framework for assessing large language models in the Swedish medical domain,"IntroductionWe present the Swedish Medical LLM Benchmark (SMLB), an evaluation framework for assessing large language models (LLMs) in the Swedish medical domain.MethodThe SMLB addresses the lack of language-specific, clinically relevant benchmarks by incorporating four datasets: translated PubMedQA questions, Swedish Medical Exams, Emergency Medicine scenarios, and General Medicine cases.ResultOur evaluation of 18 state-of-the-art LLMs reveals GPT-4-turbo, Claude- 3.5 (October 2023), and the o3model as top performers, demonstrating a strong alignment between medical reasoning and general language understanding capabilities. Hybrid systems incorporating retrieval-augmented generation (RAG) improved accuracy for clinical knowledge questions, highlighting promising directions for safe implementation.DiscussionThe SMLB provides not only an evaluation tool but also reveals fundamental insights about LLM capabilities and limitations in Swedish healthcare applications, including significant performance variations between models. By open-sourcing the benchmark, we enable transparent assessment of medical LLMs while promoting responsible development through community-driven refinement. This study emphasizes the critical need for rigorous evaluation frameworks as LLMs become increasingly integrated into clinical workflows, particularly in non-English medical contexts where linguistic and cultural specificity are paramount.",2025,10.3389/frai.2025.1557920
NatureKG: an ontology and knowledge graph for nature finance with a Text2Cypher application,"Introduction
                    Nature finance involves complex, multi-dimensional challenges that require analytical frameworks to assess risks, impacts, dependencies, and systemic resilience. Existing financial systems lack structured tools to map dependencies between natural capital and financial assets. To address this, we introduce NatureKG, the first ontology and instantiated knowledge graph (KG) specifically tailored to nature finance, aiming to support financial institutions in assessing environmental risks, impacts, and dependencies systematically.
                  
                  
                    Methods
                    We designed a domain ontology grounded in ENCORE, the Science-Based Targets Network (SBTN), and peer-reviewed literature. This ontology defines entities such as Actions, Drivers of Nature Loss, Value Chains, Evidence, and Sources. The ontology was instantiated into NatureKG within Neo4j, consisting of 320 nodes and 540 relationships curated by domain experts. As a proof of concept, we constructed a Text2Cypher dataset and fine-tuned three open-source large language models (Phi-3, LLaMA-3.1-8B, and Mistral-7B) to translate natural language queries into Cypher graph queries. The models were trained and evaluated under different dataset split strategies (paraphrase, cypher-level, and generalization) using metrics such as BLEU, exact match, execution accuracy, and Macro F1 scores.
                  
                  
                    Results
                    Phi-3 achieved the highest execution accuracy (0.21) and Macro F1 score (0.56), demonstrating better structural and reasoning capability under paraphrase and schema generalization splits. LLaMA-3.1-8B exhibited balanced performance, while Mistral-7B lagged across most metrics. The results indicate that smaller, fine-tuned models can generalize effectively in low-resource, domain-specific settings, validating the feasibility of LLM-assisted querying for nature finance.
                  
                  
                    Discussion
                    Despite modest initial accuracy, this feasibility study establishes a baseline for integrating domain-specific ontologies with AI systems. NatureKG offers a reusable foundation for representing environmental risks, dependencies, and interventions, with potential to enhance transparency and scalability in sustainable finance decision support. Future work should expand dataset diversity, sectoral coverage beyond the built environment, and refine model reasoning through larger, domain-aligned data catalogues.",2025,10.3389/frai.2025.1693843
Deep Q-Managed: a new framework for multi-objective deep reinforcement learning,"This paper introduces Deep Q-Managed, a novel multi-objective reinforcement leaning (MORL) algorithm designed to discover all policies within the Pareto Front. This approach enhances multi-objective optimization by integrating deep leaning techniques, including Double and Dueling Networks, to effectively mitigate the curve of dimensionality and overestimation bias. Deep Q-Managed demonstrates high proficiency in attaining non-dominated multi-objective policies across deterministic episodic environments, adapting to convex, concave, or mixed Pareto Front complexities. Experiments on traditional MORL benchmarks (Deep Sea Treasure, Bountiful Sea Treasure, and Modified Bountiful Sea Treasure) show it consistently achieves maximum hypervolume values (e.g., 1,155 for DST, 3,352 for BST, and 2,632 for MBST) and locates all Pareto Front points. While robust and versatile for practical applications in robotics, finance, and healthcare, this study's validation is currently confined to deterministic episodic settings, with stochastic environments reserved for future work.",2025,10.3389/frai.2025.1683323
Exploring the use and perceived impact of artificial intelligence in medical internship: a cross-sectional study of Palestinian doctors,"Background
                    Artificial intelligence (AI) is increasingly used in medical education to support academic learning, clinical competence, and efficiency. However, the extent and impact of AI usage among medical interns, particularly in Palestine, remain underexplored.
                  
                  
                    Objective
                    This study aimed to assess the prevalence of AI usage among internship doctors in Palestine and evaluate its perceived impact on their academic performance, clinical competence, time management, and research skills.
                  
                  
                    Methods
                    A cross-sectional survey was conducted with 307 internship doctors in Palestine. The survey collected data on the frequency and types of AI tools used, including ChatGPT, and interns’ perceptions of AI’s impact on their training. Demographic information, such as age, gender, and university affiliation, was also gathered to explore potential associations with AI usage patterns.
                  
                  
                    Results
                    The study found that 76.9% of interns used AI regularly, with ChatGPT being the most popular tool (76.2%). Despite frequent use, only 3.3% reported formal AI training. The majority of interns perceived AI as beneficial in improving academic performance (61%), clinical competence (67%), and time management (74%). Notably, time management showed the highest perceived improvement. However, 75.9% expressed concerns about becoming overly reliant on AI, fearing it could diminish critical thinking and clinical judgment. Age and university affiliation were associated with differences in AI usage patterns and perceived benefits, with older interns and those from international universities reporting greater perceived improvements.
                  
                  
                    Conclusion
                    This cross-sectional study highlights the widespread use of AI among internship doctors in Palestine and generally positive perceptions of its educational value, particularly for academic performance and clinical competence. However, it also reveals a substantial gap in formal AI training, suggesting a need for structured, ethically grounded AI education in medical curricula. Because the study is exploratory and cross-sectional, these findings should be interpreted as perceived associations rather than evidence that AI use or training causes improved outcomes; future longitudinal and interventional studies are needed to clarify long term effects.",2025,10.3389/frai.2025.1738782
Sequence-to-sequence pretraining for a less-resourced Slovenian language,"IntroductionLarge pretrained language models have recently conquered the area of natural language processing. As an alternative to predominant masked language modeling introduced in BERT, the T5 model has introduced a more general training objective, namely sequence to sequence transformation, which more naturally fits text generation tasks. The monolingual variants of T5 models have been limited to well-resourced languages, while the massively multilingual T5 model supports 101 languages.MethodsWe trained two different-sized T5-type sequence-to-sequence models for morphologically rich Slovene language with much fewer resources. We analyzed the behavior of new models on 11 tasks, eight classification ones (named entity recognition, sentiment classification, lemmatization, two question answering tasks, two natural language inference tasks, and a coreference resolution task), and three text generation tasks (text simplification and two summarization tasks on different datasets). We compared the new SloT5 models with the multilingual mT5 model, multilingual mBART-50 model, and with four encoder BERT-like models: multilingual BERT, multilingual XLM-RoBERTa, trilingual Croatian-Slovene-English BERT, and monolingual Slovene RoBERTa model.ResultsConcerning the classification tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa model. However, these models are helpful for generative tasks and provide several useful results. In general, the size of models matters, and currently, there is not enough training data for Slovene for successful pretraining of large models.DiscussionWhile the results are obtained on Slovene, we believe that they may generalize to other less-resourced languages, where such models will be built. We make the training and evaluation code, as well as the trained models, publicly available.",2023,10.3389/frai.2023.932519
Deep learning-based feature selection for detection of autism spectrum disorder,"IntroductionAutism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by challenges in communication, social interactions, and repetitive behaviors. The heterogeneity of symptoms across individuals complicates diagnosis. Neuroimaging techniques, particularly resting-state functional MRI (rs-fMRI), have shown potential for identifying neural signatures of ASD, though challenges such as high dimensionality, noise, and small sample sizes hinder their clinical application.MethodsThis study proposes a novel approach for ASD detection utilizing deep learning and advanced feature selection techniques. A hybrid model combining Stacked Sparse Denoising Autoencoder (SSDAE) and Multi-Layer Perceptron (MLP) is employed to extract relevant features from rs-fMRI data in the ABIDE I dataset, which was preprocessed using the CPAC pipeline. Feature selection is enhanced through an optimized Hiking Optimization Algorithm (HOA) that integrates DynamicOpposites Learning (DOL) and Double Attractors to improve convergence toward the optimal subset of features.ResultsThe proposed model is evaluated using multiple ASD datasets. The performance metrics include an average accuracy of 0.735, sensitivity of 0.765, and specificity of 0.752, surpassing the results of existing state-of-the-art methods.DiscussionThe findings demonstrate the effectiveness of the hybrid deep learning approach for ASD detection. The enhanced feature selection process, coupled with the hybrid model, addresses limitations in current neuroimaging analyses and offers a promising direction for more accurate and clinically applicable ASD detection models.",2025,10.3389/frai.2025.1594372
"Exploring the role of AI in classifying, analyzing, and generating case reports on assisted suicide cases: feasibility and ethical implications","This paper presents a study on the use of AI models for the classification of case reports on assisted suicide procedures. The database of the five Dutch regional bioethics committees was scraped to collect the 72 case reports available in English. We trained several AI models for classification according to the categories defined by the Dutch Termination of Life on Request and Assisted Suicide (Review Procedures) Act. We also conducted a related project to fine-tune an OpenAI GPT-3.5-turbo large language model for generating new fictional but plausible cases. As AI is increasingly being used for judgement, it is possible to imagine an application in decision-making regarding assisted suicide. Here we explore two arising questions: feasibility and ethics, with the aim of contributing to a critical assessment of the potential role of AI in decision-making in highly sensitive areas.",2023,10.3389/frai.2023.1328865
Artificial intelligence in clinical medicine: catalyzing a sustainable global healthcare paradigm,"As the demand for quality healthcare increases, healthcare systems worldwide are grappling with time constraints and excessive workloads, which can compromise the quality of patient care. Artificial intelligence (AI) has emerged as a powerful tool in clinical medicine, revolutionizing various aspects of patient care and medical research. The integration of AI in clinical medicine has not only improved diagnostic accuracy and treatment outcomes, but also contributed to more efficient healthcare delivery, reduced costs, and facilitated better patient experiences. This review article provides an extensive overview of AI applications in history taking, clinical examination, imaging, therapeutics, prognosis and research. Furthermore, it highlights the critical role AI has played in transforming healthcare in developing nations.",2023,10.3389/frai.2023.1227091
Improving plant disease classification by adaptive minimal ensembling,"A novel method for improving plant disease classification, a challenging and time-consuming process, is proposed. First, using as baseline EfficientNet, a recent and advanced family of architectures having an excellent accuracy/complexity trade-off, we have introduced, devised, and applied refined techniques based on transfer learning, regularization, stratification, weighted metrics, and advanced optimizers in order to achieve improved performance. Then, we go further by introducing adaptive minimal ensembling, which is a unique input to the knowledge base of the proposed solution. This represents a leap forward since it allows improving the accuracy with limited complexity using only two EfficientNet-b0 weak models, performing ensembling on feature vectors by a trainable layer instead of classic aggregation on outputs. To the best of our knowledge, such an approach to ensembling has never been used before in literature. Our method was tested on PlantVillage, a public reference dataset used for benchmarking models' performances for crop disease diagnostic, considering both its original and augmented versions. We noticeably improved the state of the art by achieving 100% accuracy in both the original and augmented datasets. Results were obtained using PyTorch to train, test, and validate the models; reproducibility is granted by providing exhaustive details, including hyperparameters used in the experimentation. A Web interface is also made publicly available to test the proposed methods.",2022,10.3389/frai.2022.868926
"Argument-based inductive logics, with coverage of compromised perception","Formal deductive logic, used to express and reason over declarative, axiomatizable content, captures, we now know, essentially all of what is known in mathematics and physics, and captures as well the details of the proofs by which such knowledge has been secured. This is certainly impressive, but deductive logic alone cannot enable rational adjudication of arguments that are at variance (however much additional information is added). After affirming a fundamental directive, according to which argumentation should be the basis for human-centric AI, we introduce and employ both a deductive and—crucially—an inductive cognitive calculus. The former cognitive calculus, DCEC, is the deductive one and is used with our automated deductive reasoner ShadowProver; the latter, IDCEC, is inductive, is used with the automated inductive reasoner ShadowAdjudicator, and is based on human-used concepts of likelihood (and in some dialects of IDCEC, probability). We explain that ShadowAdjudicator centers around the concept of competing and nuanced arguments adjudicated non-monotonically through time. We make things clearer and more concrete by way of three case studies, in which our two automated reasoners are employed. Case Study 1 involves the famous Monty Hall Problem. Case Study 2 makes vivid the efficacy of our calculi and automated reasoners in simulations that involve a cognitive robot (PERI.2). In Case Study 3, as we explain, the simulation employs the cognitive architecture ARCADIA, which is designed to computationally model human-level cognition in ways that take perception and attention seriously. We also discuss a type of argument rarely analyzed in logic-based AI; arguments intended to persuade by leveraging human deficiencies. We end by sharing thoughts about the future of research and associated engineering of the type that we have displayed.",2024,10.3389/frai.2023.1144569
Human-like problem-solving abilities in large language models using ChatGPT,"BackgroundsThe field of Artificial Intelligence (AI) has seen a major shift in recent years due to the development of new Machine Learning (ML) models such as Generative Pre-trained Transformer (GPT). GPT has achieved previously unheard-of levels of accuracy in most computerized language processing tasks and their chat-based variations.AimThe aim of this study was to investigate the problem-solving abilities of ChatGPT using two sets of verbal insight problems, with a known performance level established by a sample of human participants.Materials and methodsA total of 30 problems labeled as “practice problems” and “transfer problems” were administered to ChatGPT. ChatGPT's answers received a score of “0” for each incorrectly answered problem and a score of “1” for each correct response. The highest possible score for both the practice and transfer problems was 15 out of 15. The solution rate for each problem (based on a sample of 20 subjects) was used to assess and compare the performance of ChatGPT with that of human subjects.ResultsThe study highlighted that ChatGPT can be trained in out-of-the-box thinking and demonstrated potential in solving verbal insight problems. The global performance of ChatGPT equalled the most probable outcome for the human sample in both practice problems and transfer problems as well as upon their combination. Additionally, ChatGPT answer combinations were among the 5% of most probable outcomes for the human sample both when considering practice problems and pooled problem sets. These findings demonstrate that ChatGPT performance on both set of problems was in line with the mean rate of success of human subjects, indicating that it performed reasonably well.ConclusionsThe use of transformer architecture and self-attention in ChatGPT may have helped to prioritize inputs while predicting, contributing to its potential in verbal insight problem-solving. ChatGPT has shown potential in solving insight problems, thus highlighting the importance of incorporating AI into psychological research. However, it is acknowledged that there are still open challenges. Indeed, further research is required to fully understand AI's capabilities and limitations in verbal problem-solving.",2023,10.3389/frai.2023.1199350
Transfer Learning Approaches for Neuroimaging Analysis: A Scoping Review,"Deep learning algorithms have been moderately successful in diagnoses of diseases by analyzing medical images especially through neuroimaging that is rich in annotated data. Transfer learning methods have demonstrated strong performance in tackling annotated data. It utilizes and transfers knowledge learned from a source domain to target domain even when the dataset is small. There are multiple approaches to transfer learning that result in a range of performance estimates in diagnosis, detection, and classification of clinical problems. Therefore, in this paper, we reviewed transfer learning approaches, their design attributes, and their applications to neuroimaging problems. We reviewed two main literature databases and included the most relevant studies using predefined inclusion criteria. Among 50 reviewed studies, more than half of them are on transfer learning for Alzheimer's disease. Brain mapping and brain tumor detection were second and third most discussed research problems, respectively. The most common source dataset for transfer learning was ImageNet, which is not a neuroimaging dataset. This suggests that the majority of studies preferred pre-trained models instead of training their own model on a neuroimaging dataset. Although, about one third of studies designed their own architecture, most studies used existing Convolutional Neural Network architectures. Magnetic Resonance Imaging was the most common imaging modality. In almost all studies, transfer learning contributed to better performance in diagnosis, classification, segmentation of different neuroimaging diseases and problems, than methods without transfer learning. Among different transfer learning approaches, fine-tuning all convolutional and fully-connected layers approach and freezing convolutional layers and fine-tuning fully-connected layers approach demonstrated superior performance in terms of accuracy. These recent transfer learning approaches not only show great performance but also require less computational resources and time.",2022,10.3389/frai.2022.780405
Technostress and generative AI in the workplace: a qualitative analysis of young professionals,"Generative artificial intelligence (GenAI) is rapidly diffusing into the workplace and is expected to substantially reshape roles, workflows, and skill requirements, particularly for young professionals as early adopters who are highly exposed to these tools. While GenAI is widely regarded as a means to increase productivity, its adoption may simultaneously introduce new challenges, including various forms of technostress. Drawing on 15 semi-structured interviews with young professionals in research and development (R&amp;D), IT, finance, and marketing in organizations piloting or using GenAI, we conducted a structured qualitative content analysis guided by established technostress dimensions. Our findings indicate that classic technostress dimensions remain relevant but manifest differently across sectors and contexts. Moreover, additional GenAI-specific stressors emerged, such as regulatory and compliance ambiguity, data protection and copyright concerns, perceived dependency, potential skill degradation, doubts about the reliability and controllability of AI outputs, and a shift towards more monitoring and conceptual work. At the same time, participants reported techno-eustress in the form of efficiency gains, learning opportunities, and enhanced intrinsic motivation. Overall, the study extends existing technostress frameworks and underscores the importance of AI literacy, clear organizational governance, and supportive work design to mitigate negative technostress while enabling the productive use of GenAI.",2025,10.3389/frai.2025.1728881
Research agenda for algorithmic fairness studies: Access to justice lessons for interdisciplinary research,"Access to justice is one of the fundamental legitimating principles underlying all modern Western legal systems, yet its role in critical algorithm studies remains underdeveloped. In historical and methodological terms, the access to justice movement showcased multi- and interdisciplinary research on legal phenomena. We argue that interdisciplinary research on AI ethics and regulation, datafication of society, and algorithmic governance could benefit from adopting access to justice as a vantage point for bridging the different approaches in the context of administering justice. To this end, we explore technological, legal, and societal intersections to demonstrate how law, social sciences, and algorithm studies could benefit from a historically more informed and holistic approach facilitating more “cost-effective” interdisciplinary research collaboration. Such approach could assist the substantive study of algorithmic fairness to contribute actionable systemic solutions on what we perceive as systemic challenges. We propose utilizing access to justice as a boundary object for interdisciplinary dialogue over algorithmic fairness while respecting the epistemic diversity of disciplines.",2022,10.3389/frai.2022.882134
The Impact of Pedagogical Agents' Gender on Academic Learning: A Systematic Review,"Virtual learning environments often use virtual characters to facilitate and improve the learning process. These characters, known as pedagogical agents, can take on different roles, such as tutors or companions. Research has highlighted the importance of various characteristics of virtual agents, including their voice or non-verbal behaviors. Little attention has been paid to the gender-specific design of pedagogical agents, although gender has an important influence on the educational process. In this article, we perform an extensive review of the literature regarding the impact of the gender of pedagogical agents on academic outcomes. Based on a detailed review of 59 articles, we analyze the influence of pedagogical agents' gender on students' academic self-evaluations and achievements to answer the following questions: (1) Do students perceive virtual agents differently depending on their own gender and the gender of the agent? (2) Does the gender of pedagogical agents influence students' academic performance and self-evaluations? (3) Are there tasks or academic situations to which a male virtual agent is better suited than a female virtual agent, and vice versa, according to empirical evidence? (4) How do a virtual agent's pedagogical roles impact these results? (5) How do a virtual agent's appearance and interactive capacities impact these results? (6) Are androgynous virtual agents a potential solution to combatting gender stereotypes? This review provides important insight to researchers on how to approach gender when designing pedagogical agents in virtual learning environments.",2022,10.3389/frai.2022.862997
DeepCausality: A general AI-powered causal inference framework for free text: A case study of LiverTox,"Causality plays an essential role in multiple scientific disciplines, including the social, behavioral, and biological sciences and portions of statistics and artificial intelligence. Manual-based causality assessment from a large number of free text-based documents is very time-consuming, labor-intensive, and sometimes even impractical. Herein, we proposed a general causal inference framework named DeepCausality to empirically estimate the causal factors for suspected endpoints embedded in the free text. The proposed DeepCausality seamlessly incorporates AI-powered language models, named entity recognition and Judea Pearl's Do-calculus, into a general framework for causal inference to fulfill different domain-specific applications. We exemplified the utility of the proposed DeepCausality framework by employing the LiverTox database to estimate idiosyncratic drug-induced liver injury (DILI)-related causal terms and generate a knowledge-based causal tree for idiosyncratic DILI patient stratification. Consequently, the DeepCausality yielded a prediction performance with an accuracy of 0.92 and an F-score of 0.84 for the DILI prediction. Notably, 90% of causal terms enriched by the DeepCausality were consistent with the clinical causal terms defined by the American College of Gastroenterology (ACG) clinical guideline for evaluating suspected idiosyncratic DILI (iDILI). Furthermore, we observed a high concordance of 0.91 between the iDILI severity scores generated by DeepCausality and domain experts. Altogether, the proposed DeepCausality framework could be a promising solution for causality assessment from free text and is publicly available throughhttps://github.com/XingqiaoWang/https-github.com-XingqiaoWang-DeepCausality-LiverTox.",2022,10.3389/frai.2022.999289
Predicting disease onset from electronic health records for population health management: a scalable and explainable Deep Learning approach,"IntroductionThe move from a reactive model of care which treats conditions when they arise to a proactive model which intervenes early to prevent adverse healthcare events will benefit from advances in the predictive capabilities of Artificial Intelligence and Machine Learning. This paper investigates the ability of a Deep Learning (DL) approach to predict future disease diagnosis from Electronic Health Records (EHR) for the purposes of Population Health Management.MethodsIn this study, embeddings were created using a Word2Vec algorithm from structured vocabulary commonly used in EHRs e.g., Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT) codes. This study is based on longitudinal medical data from ~50 m patients in the USA. We introduced a novel method of including binned observation values into an embeddings model. We also included novel features associated with wider determinants of health. Patient records comprising these embeddings were then fed to a Bidirectional Gated Recurrent Unit (GRU) model to predict the likelihood of patients developing Type 2 Diabetes Mellitus, Chronic Obstructive Pulmonary Disorder (COPD), Hypertension or experiencing an Acute Myocardial Infarction (MI) in the next 3 years. SHapley Additive exPlanations (SHAP) values were calculated to achieve model explainability.ResultsIncreasing the data scope to include binned observations and wider determinants of health was found to improve predictive performance. We achieved an area under the Receiver Operating Characteristic curve value of 0.92 for Diabetes prediction, 0.94 for COPD, 0.92 for Hypertension and 0.94 for MI. The SHAP values showed that the models had learned features known to be associated with these outcomes.DiscussionThe DL approach outlined in this study can identify clinically-relevant features from large-scale EHR data and use these to predict future disease outcomes. This study highlights the promise of DL solutions for identifying patients at future risk of disease and providing clinicians with the means to understand and evaluate the drivers of those predictions.",2024,10.3389/frai.2023.1287541
General SIR model for visible and hidden epidemic dynamics,"To simulate hidden epidemic dynamics connected with asymptomatic and unregistered patients, a new general SIR model was proposed. For some cases, the analytical solutions of the set of 5 differential equations were found, which allow simplifying the parameter identification procedure. Two waves of the pertussis epidemic in England in 2023 and 2024 were simulated with the assumption of zero hidden cases. The accumulated and daily numbers of cases and the duration of the second wave were predicted with rather high accuracy. If the trend will not change, the monthly figure of 9 new pertussis cases (as it was in January–February 2023) can be achieved only in May 2025. The proposed approach can be recommended for both simulations and predictions of different epidemics.",2025,10.3389/frai.2025.1559880
MagNet: Detecting Digital Presentation Attacks on Face Recognition,"Presentation attacks on face recognition systems are classified into two categories: physical and digital. While much research has focused on physical attacks such as photo, replay, and mask attacks, digital attacks such as morphing have received limited attention. With the advancements in deep learning and computer vision algorithms, several easy-to-use applications are available where with few taps/clicks, an image can be easily and seamlessly altered. Moreover, generation of synthetic images or modifying images/videos (e.g. creating deepfakes) is relatively easy and highly effective due to the tremendous improvement in generative machine learning models. Many of these techniques can be used to attack the face recognition systems. To address this potential security risk, in this research, we present a novel algorithm for digital presentation attack detection, termed as MagNet, using a “Weighted Local Magnitude Pattern” (WLMP) feature descriptor. We also present a database, termed as IDAgender, which consists of three different subsets of swapping/morphing and neural face transformation. In contrast to existing research, which utilizes sophisticated machine learning networks for attack generation, the databases in this research are prepared using social media platforms that are readily available to everyone with and without any malicious intent. Experiments on the proposed database, FaceForensic database, GAN generated images, and real-world images/videos show the stimulating performance of the proposed algorithm. Through the extensive experiments, it is observed that the proposed algorithm not only yields lower error rates, but also provides computational efficiency.",2021,10.3389/frai.2021.643424
A Novel Bayesian General Medical Diagnostic Assistant Achieves Superior Accuracy With Sparse History,"Online AI symptom checkers and diagnostic assistants (DAs) have tremendous potential to reduce misdiagnosis and cost, while increasing the quality, convenience, and availability of healthcare, but only if they can perform with high accuracy. We introduce a novel Bayesian DA designed to improve diagnostic accuracy by addressing key weaknesses of Bayesian Network implementations for clinical diagnosis. We compare the performance of our prototype DA (MidasMed) to that of physicians and six other publicly accessible DAs (Ada, Babylon, Buoy, Isabel, Symptomate, and WebMD) using a set of 30 publicly available case vignettes, and using only sparse history (no exam findings or tests). Our results demonstrate superior performance of the MidasMed DA, with the correct diagnosis being the top ranked disorder in 93% of cases, and in the top 3 in 96% of cases.",2022,10.3389/frai.2022.727486
Mind the semantic gap: semantic efficiency in human computer interfaces,"As we become increasingly dependent on technology in our daily lives, the usability of HCIs is a key driver of individual empowerment for us all. A primary focus of AI systems has been to make HCIs easier to use by identifying what users need and agentively taking over some of the cognitive work users would have otherwise performed, as such, they are becoming our delegates. To become effective and reliable delegates, AI agents need to understand all relevant situational semantic context surrounding a user’s need and how the tools of the HCI can be leveraged. Current ML systems have fundamental semantic gaps in bespoke human context, real-time world knowledge, and how those relate to HCI tooling. These challenges are difficult to close due factors such as privacy, continual learning, access to real-time context, and how deeply integrated the semantics are with in-context learning. As such, we need to research and explore new ways to safely capture, compactly model, and incrementally evolve semantics in ways that can efficiently integrate into how AI systems act on our behalf. This article presents a thought experiment called the Game of Delegation as a lens to view the effectiveness of delegation and the semantic efficiency with which the delegation was achieved.",2025,10.3389/frai.2025.1451865
Models of Language and Multiword Expressions,"Traditional accounts of language postulate two basic components: words stored in a lexicon, and rules that govern how they can be combined into meaningful sentences, a grammar. But, although this words-and-rules framework has proven itself to be useful in natural language processing and cognitive science, it has also shown important shortcomings when faced with actual language use. In this article, we review evidence from language acquisition, sentence processing, and computational modeling that shows how multiword expressions such as idioms, collocations, and other meaningful and common units that comprise more than one word play a key role in the organization of our linguistic knowledge. Importantly, multiword expressions straddle the line between lexicon and grammar, calling into question how useful this distinction is as a foundation for our understanding of language. Nonetheless, finding a replacement for the foundational role the words-and-rules approach has played in our theories is not straightforward. Thus, the second part of our article reviews and synthesizes the diverse approaches that have attempted to account for the central role of multiword expressions in language representation, acquisition, and processing.",2022,10.3389/frai.2022.781962
Recommendations for ethical and responsible use of artificial intelligence in digital agriculture,"Artificial intelligence (AI) applications are an integral and emerging component of digital agriculture. AI can help ensure sustainable production in agriculture by enhancing agricultural operations and decision-making. Recommendations about soil condition and pesticides or automatic devices for milking and apple picking are examples of AI applications in digital agriculture. Although AI offers many benefits in farming, AI systems may raise ethical issues and risks that should be assessed and proactively managed. Poor design and configuration of intelligent systems may impose harm and unintended consequences on digital agriculture. Invasion of farmers' privacy, damaging animal welfare due to robotic technologies, and lack of accountability for issues resulting from the use of AI tools are only some examples of ethical challenges in digital agriculture. This paper examines the ethical challenges of the use of AI in agriculture in six categories including fairness, transparency, accountability, sustainability, privacy, and robustness. This study further provides recommendations for agriculture technology providers (ATPs) and policymakers on how to proactively mitigate ethical issues that may arise from the use of AI in farming. These recommendations cover a wide range of ethical considerations, such as addressing farmers' privacy concerns, ensuring reliable AI performance, enhancing sustainability in AI systems, and reducing AI bias.",2022,10.3389/frai.2022.884192
Image based deep learning in 12-lead ECG diagnosis,"Background
                    The electrocardiogram is an integral tool in the diagnosis of cardiovascular disease. Most studies on machine learning classification of electrocardiogram (ECG) diagnoses focus on processing raw signal data rather than ECG images. This presents a challenge for models in many areas of clinical practice where ECGs are printed on paper or only digital images are accessible, especially in remote and regional settings. This study aims to evaluate the accuracy of image based deep learning algorithms on 12-lead ECG diagnosis.
                  
                  
                    Methods
                    Deep learning models using VGG architecture were trained on various 12-lead ECG datasets and evaluated for accuracy by testing on holdout test data as well as data from datasets not seen in training. Grad-CAM was utilized to depict heatmaps of diagnosis.
                  
                  
                    Results
                    The results demonstrated excellent AUROC, AUPRC, sensitivity and specificity on holdout test data from datasets used in training comparable to the best signal and image-based models. Detection of hidden characteristics such as gender were achieved at a high rate while Grad-CAM successfully highlight pertinent features on ECGs traditionally used by human interpreters.
                  
                  
                    Discussion
                    This study demonstrates feasibility of image based deep learning algorithms in ECG diagnosis and identifies directions for future research in order to develop clinically applicable image based deep-learning models in ECG diagnosis.",2023,10.3389/frai.2022.1087370
DeepSeek vs. ChatGPT: prospects and challenges,"DeepSeek has introduced its recent model DeepSeek-R1, showing divergence from OpenAI’s ChatGPT, suggesting an open-source alternative to users. This paper analyzes the architecture of DeepSeek-R1, mainly adopting rule-based reinforcement learning (RL) without preliminary supervised fine-tuning (SFT), which has shown better efficiency. By integrating multi-stage training along with cold-start data usage before RL, the model can achieve meaningful performance in reasoning tasks along with reward modeling optimizing training process. DeepSeek shows its strength in technical, reasoning tasks, able to show its decision-making process through open source whereas ChatGPT shows its strength on general tasks and areas requiring creativeness. Despite the groundbreaking developments of both models, there is room for improvement in AI landscape and matters to be handled such as quality of data, black box problems, privacy management, and job displacement. This paper suggests the future of AI, expecting better performance in multi-modal tasks, enhancing its effectiveness in handling larger data sets, enabling users with improved AI landscapes and utility.",2025,10.3389/frai.2025.1576992
"Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health","In Low- and Middle- Income Countries (LMICs), machine learning (ML) and artificial intelligence (AI) offer attractive solutions to address the shortage of health care resources and improve the capacity of the local health care infrastructure. However, AI and ML should also be used cautiously, due to potential issues of fairness and algorithmic bias that may arise if not applied properly. Furthermore, populations in LMICs can be particularly vulnerable to bias and fairness in AI algorithms, due to a lack of technical capacity, existing social bias against minority groups, and a lack of legal protections. In order to address the need for better guidance within the context of global health, we describe three basic criteria (Appropriateness, Fairness, and Bias) that can be used to help evaluate the use of machine learning and AI systems: 1) APPROPRIATENESS is the process of deciding how the algorithm should be used in the local context, and properly matching the machine learning model to the target population; 2) BIAS is a systematic tendency in a model to favor one demographic group vs another, which can be mitigated but can lead to unfairness; and 3) FAIRNESS involves examining the impact on various demographic groups and choosing one of several mathematical definitions of group fairness that will adequately satisfy the desired set of legal, cultural, and ethical requirements. Finally, we illustrate how these principles can be applied using a case study of machine learning applied to the diagnosis and screening of pulmonary disease in Pune, India. We hope that these methods and principles can help guide researchers and organizations working in global health who are considering the use of machine learning and artificial intelligence.",2021,10.3389/frai.2020.561802
Weight-aware semi-supervised self-ensembling framework for interior decoration style classification,"Automatic classification of interior decoration styles has great potential to guide and streamline the design process. Despite recent advancements, it remains challenging to construct an accurate interior decoration style recognition model due to the scarcity of expert annotations. In this article, we develop a new weight-aware semi-supervised self-ensembling framework for interior decoration style recognition, which selectively leverages the abundant unlabeled data to address the aforementioned challenge. Specifically, we devise a weight module that utilizes a truncated Gaussian function to automatically assess the reliability of unlabeled data. This enables more reliable unlabeled samples to be adaptively assigned higher weights during the training process. By incorporating adaptive weights, we devise a weighted consistency regularization to enforce consistent predictions for reliable unlabeled data under different perturbations. Furthermore, we devise a weighted relation consistency regularization to preserve the semantic relationships of reliable unlabeled data across various perturbations. Additionally, we introduce a weighted class-aware contrastive learning regularization to improve the model's discriminative feature learning capability using reliable unlabeled data. The synergistic learning of weighted consistency regularization, weighted relation consistency, and weighted class-aware contrastive learning significantly enhances the model's generalizability. Extensive experiments conducted on interior decoration style image datasets demonstrate the superior performance of our framework compared to existing semi-supervised learning methods.",2025,10.3389/frai.2025.1645877
Using ChatGPT as an assessment tool for medical residents in Mexico: a descriptive experience,"IntroductionArtificial intelligence (AI) in medical education has progressed gradually, with numerous authors debating whether to prohibit, restrict, or adopt its use in academic contexts. Growing evidence exists regarding the capabilities and applications of AI in this field, particularly in supporting educational tasks such as student assessment. In this article we described our experience using ChatGPT to evaluate medical residents.Materials and methodsA descriptive cross-sectional study was conducted involving 35 medical residents from different specialty’s at a secondary-level hospital. Two different exams were generated using ChatGPT in topics of Rocky Mountain Spotted Fever (RMSF) and Pertussis. Additionally, an opinion survey—previously validated was administered to assess participants’ perceptions of ChatGPT ability to generate multiple-choice questions.ResultsOverall average score for the Pertussis examination was 8.46, while the average for the RMSF examination was 8.29. All participants reported that the examination was well written and that the language used was coherent; 34 residents (97.14%) stated that the language was clear, concise, and easy to understand; 9 residents (25.71%) agreed that the language used was confusing; 33 residents (94.28%) rated the exams questions as difficult; 32 residents (91.42%) felt that they had adequately prepared for both examinations.DiscussionChatGPT exhibits a promising faculty as a tool to support teaching activities in the training of medical specialists, mainly in reducing the human workload of healthcare personnel, and becoming integral to the next phase of medical education through AI-assisted content creation supervised by educators.",2025,10.3389/frai.2025.1662203
On Distributed Cognition While Designing an AI System for Adapted Learning,"When analyzing learning, focus has traditionally been on the teacher, but has in the recent decades slightly moved toward the learner. This is also reflected when supporting systems, both computer-based and more practical equipment, has been introduced. Seeing learning as an integration of both an internal psychological process of acquisition and elaboration, and an external interaction process between the learner and the rest of the learning environment though, we see the necessity of expanding the vision and taking on a more holistic view to include the whole learning environment. Specially, when introducing an AI (artificial intelligence) system for adapting the learning process to an individual learner through machine learning, this AI system should take into account both the learner and the other agents and artifacts being part of this extended learning system. This paper outlines some lessons learned in a process of developing an electronic textbook adapting to a single learner through machine learning, to the process of extracting input from and providing feedback both to the learner, the teacher, the learning institution, and the learning resources provider based on a XAI (explainable artificial intelligence) system while also taking into account characteristics with respect to the learner's peers.",2022,10.3389/frai.2022.910630
Freedom under algorithms: how unpredictable and asocial management erodes free choice,"This article examines the impact of algorithmic management on individual freedom. To orient this exploration, I draw on the (feminist) conception of liberty as the choosing subject. The central suggestion is that algorithmic management poses a serious threat to an indispensable part of the freely choosing subject: namely, it degrades the ability of subordinates to reasonably foresee the consequences of their choices and consequently, fully realise their personality. I call this phenomenon the ‘foresight endangerment problem’ and argue that it has both a technical and a social face. The technical face highlights the inherent unpredictability of advanced algorithms, including those that execute managerial functions. This issue is further complicated by the fact that as algorithms become more resilient and useful, their outputs grow increasingly opaque and unpredictable—what some refer to as the resilience-predictability paradox. The technical face is made manifest in the reported experiences of workers in the gig economy who describe experiencing unpredictable managerial decisions that they cannot anticipate nor easily contest. Subjection to such managerial randomness erodes their ability to make informed choices in service of their personal goals. The social face emphasises the consequences of disembedding managerial power from social relationships between humans to asocial relationships between humans and software. Subordinates of human managers enjoy a vast number of tools to predict managerial thinking that arise from the intricate and complex processes of social interaction. The disembedding process forecloses the use of these tools and fundamentally undermines the capacity of subordinates to promote their ends through free choice.",2025,10.3389/frai.2025.1582085
Artificial liver classifier: a new alternative to conventional machine learning models,"IntroductionSupervised machine learning classifiers sometimes face challenges related to the performance, accuracy, or overfitting.MethodsThis paper introduces the Artificial Liver Classifier (ALC), a novel supervised learning model inspired by the human liver's detoxification function. The ALC is characterized by its simplicity, speed, capability to reduce overfitting, and effectiveness in addressing multi-class classification problems through straightforward mathematical operations. To optimize the ALC's parameters, an improved FOX optimization algorithm (IFOX) is employed during training.ResultsWe evaluate the proposed ALC on five benchmark datasets: Iris Flower, Breast Cancer Wisconsin, Wine, Voice Gender, and MNIST. The results demonstrate competitive performance, with ALC achieving up to 100% accuracy on the Iris dataset–surpassing logistic regression, multilayer perceptron, and support vector machine–and 99.12% accuracy on the Breast Cancer dataset, outperforming XGBoost and logistic regression. Across all datasets, ALC consistently shows smaller generalization gaps and lower loss values compared to conventional classifiers.DiscussionThese findings highlight the potential of biologically inspired models to develop efficient machine learning classifiers and open new avenues for innovation in the field.",2025,10.3389/frai.2025.1639720
DiaGuide-LLM—Using large language models for patient-specific education and health guidance in diabetes,"Effective diabetes care relies on communication, patient empowerment, and lifestyle management. However, rising prevalence and workforce shortages challenge current care models. Large language models (LLMs) have the potential to support healthcare delivery by providing personalized health information. While prior studies show promising results, few have compared LLM-generated responses with those from healthcare professionals in chronic disease contexts, particularly from end-users' perspectives. This study compared GPT-4o and healthcare professional responses to diabetes-related questions, evaluating them on knowledge, helpfulness, and empathy. It also explored correlations between these qualities and differences based on participants' educational background. Using a cross-sectional experimental design, 1,810 evaluations were collected through an online questionnaire (November 2024–January 2025). Participants rated responses on 5-point Likert scales for knowledge, helpfulness, and empathy. For all metrics combined, GPT-4o received higher ratings in 46.7% of evaluations (95% CI: 28.8%–64.5%), while healthcare professionals were preferred in 23.3% (95% CI: 8.2%–38.5%). Participants with lower education levels rated GPT-4o significantly higher across all dimensions, while those with ≥4 years of higher education rated it higher for empathy and helpfulness. Quality measures were strongly correlated. Although differences were statistically significant, the observed effect sizes were small and should be interpreted as modest in practical terms. These findings assess perceived quality and accessibility of healthcare communication from end-user perspectives and suggest that LLMs may enhance the perceived quality and accessibility of healthcare communication, particularly among individuals with lower educational attainment. Further research is needed to determine their appropriate role in clinical practice, including objective assessment of clinical accuracy.",2025,10.3389/frai.2025.1652556
ADP-Net: a hierarchical attention-diffusion-prediction framework for human trajectory prediction,"Accurate prediction of human crowd behavior presents a significant challenge with critical implications for autonomous systems. The core difficulty lies in developing a comprehensive computational framework capable of effectively modeling the spatial-temporal dynamics through three essential components: feature extraction, attention propagation, and predictive modeling. Current spatial-temporal graph convolutional networks (STGCNs), which typically employ single-hop neighborhood message passing with optional self-attention mechanisms, exhibit three fundamental limitations: restricted receptive fields due to being confined to limited propagation steps, poor topological extensibility, and structural inconsistencies between network components that collectively lead to suboptimal performance. To address these challenges, we establish the theoretical connection between graph convolutional networks and personalized propagation neural architectures, thereby proposing attention diffusion-prediction network (ADP-Net). This novel framework integrates three key innovations: (1) Consistent graph convolution layers with immediate attention mechanisms; (2) Multi-scale attention diffusion layers implementing graph diffusion convolution (GDC); and (3) Adaptive temporal convolution modules handling multi-timescale variations. The architecture employs polynomial approximation for GCN operations and implements an approximate personalized propagation scheme for GDC, enabling efficient multi-hop interaction modeling while maintaining structural consistency across spatial and temporal domains. Comprehensive experiments on standardized benchmarks (ETH/UCY and Stanford Drone Dataset) show cutting-edge results, with enhancements of 4% for the average displacement error (ADE) and 26% for the final displacement error (FDE) metrics when contrasted with prior approaches. This advancement provides a robust theoretical framework and practical implementation for crowd behavior modeling in autonomous systems.",2025,10.3389/frai.2025.1690704
Data stream-pairwise bottleneck transformer for engagement estimation from video conversation,"This study aims to assess participant engagement in multiparty conversations using video and audio data. For this task, the interaction among numerous data streams, such as video and audio from multiple participants, should be modeled effectively, considering the redundancy of video and audio across frames. To efficiently model participant interactions while accounting for such redundancy, a previous study proposed inputting participant feature sequences into global token-based transformers, which constrain attention across feature sequences to pass through only a small set of internal units, allowing the model to focus on key information. However, this approach still faces the challenge of redundancy in participant-feature estimation based on standard cross-attention transformers, which can connect all frames across different modalities. To address this, we propose a joint model for interactions among all data streams using global token-based transformers, without distinguishing between cross-modal and cross-participant interactions. Experiments on the RoomReader corpus confirm that the proposed model outperforms previous models, achieving accuracy ranging from 0.720 to 0.763, weighted F1 scores from 0.733 to 0.771, and macro F1 scores from 0.236 to 0.277.",2025,10.3389/frai.2025.1516295
QF-TraderNet: Intraday Trading via Deep Reinforcement With Quantum Price Levels Based Profit-And-Loss Control,"Reinforcement Learning (RL) based machine trading attracts a rich profusion of interest. However, in the existing research, RL in the day-trade task suffers from the noisy financial movement in the short time scale, difficulty in order settlement, and expensive action search in a continuous-value space. This paper introduced an end-to-end RL intraday trading agent, namely QF-TraderNet, based on the quantum finance theory (QFT) and deep reinforcement learning. We proposed a novel design for the intraday RL trader’s action space, inspired by the Quantum Price Levels (QPLs). Our action space design also brings the model a learnable profit-and-loss control strategy. QF-TraderNet composes two neural networks: 1) A long short term memory networks for the feature learning of financial time series; 2) a policy generator network (PGN) for generating the distribution of actions. The profitability and robustness of QF-TraderNet have been verified in multi-type financial datasets, including FOREX, metals, crude oil, and financial indices. The experimental results demonstrate that QF-TraderNet outperforms other baselines in terms of cumulative price returns and Sharpe Ratio, and the robustness in the acceidential market shift.",2021,10.3389/frai.2021.749878
AMDCnet: attention-gate-based multi-scale decomposition and collaboration network for long-term time series forecasting,"IntroductionTime series analysis plays a critical role in various applications, including sensor data monitoring, weather forecasting, economic predictions, and network traffic management. While traditional methods primarily focus on modeling time series data at a single temporal scale and achieve notable results, they often overlook dependencies across multiple scales. Furthermore, the intricate structure of multi-scale time series complicates the effective extraction of features at different temporal resolutions.MethodTo address these limitations, we propose AMDCnet, a multi-scale-based time series decomposition and collaboration network designed to enhance the model's capacity for decomposing and integrating data across varying time scales. Specifically, AMDCnet transforms the original time series into multiple temporal resolutions and conducts multi-scale feature decomposition while preserving the overall temporal dynamics. By extracting features from downsampled sequences and integrating multi-resolution features through attention-gated co-training mechanisms, AMDCnet enables efficient modeling of complex time series data.ResultsAMDCnet achieving 44 best results and 10 second-best results out of 64 cases. Experimental results on 8 benchmark datasets demonstrate that AMDCnet achieves state-of-the-art performance in time series forecasting.DiscussionOur research provides a robust baseline for the application of artificial intelligence in multivariate time series forecasting. This work leverages multi-scale time series decomposition and gated units for feature fusion, effectively capturing dependencies across different temporal scales. Future studies may further optimize the scale decomposition and fusion modules. Such efforts could enhance the representation of multi-scale information and help address key challenges in multivariate time series prediction.",2025,10.3389/frai.2025.1607232
Online platform vs. doctors: a comparative exploration of congenital cataract patient education from virtual to reality,"ObjectiveThis study aimed to assess the quality and readability of patient education on congenital cataracts provided by Google, ChatGPT, and clinical doctors. Given the rarity of congenital cataracts and the need for accessible, accurate information for parents, we sought to evaluate the platforms’ effectiveness in delivering relevant health information.Methods and analysisWe developed two question banks related to congenital cataracts from different sources. Responses from Google, ChatGPT, and two doctors were evaluated across five criteria: correctness, completeness, readability, helpfulness, and safety. An ophthalmologist panel used a five-point Likert scale to score these responses. The readability of responses was also assessed using passage and readability statistics, with additional readability enhancements applied to ChatGPT responses.ResultsThe ChatGPT responses demonstrated similar quality to those from experienced doctors, particularly excelling in readability, which was enhanced further with simplification techniques. Resident doctors provided the most readable doctor responses, while Google results scored the lowest across all five evaluative criteria. Post-enhancement, ChatGPT responses showed significant improvements in readability and maintained response quality.ConclusionChatGPT is a promising tool for delivering accessible, accurate information on congenital cataracts, especially for populations with lower health literacy. This study underscores the value of AI in healthcare education for rare conditions and highlights the need for consulting multiple information sources for comprehensive health guidance. ChatGPT, with readability enhancements, stands out as a particularly effective resource for public health information on congenital cataracts.",2025,10.3389/frai.2025.1548385
Online Brand Community User Segments: A Text Mining Approach,"There is a trend that customers increasingly join the online brand community. However, evidence shows that there are nuances between different user segments, and only a small group of users are active. Thus, one key concern marketers face is identifying and targeting specific segments and decreasing user churn rates in an online environment. To this end, this study aims to propose a UGC-based segmentation of online brand community users, identify the characteristics of each segment, and consequently reduce online brand community users' churn rate. We used python to obtain users' post data from a well-known online brand community in China between July 2012 and December 2019, resulting in 912,452 posts and 20,493 users. We then use text mining and clustering methods to segment the users and compare the differences between the segments. Three groups—information-oriented users, entertainment-oriented users, and multi-motivation users—were emerged. Our results imply that entertainment-oriented users were the most active, yet, multi-directional users have the lowest probability of churn, with a churn rate of only 0.607 times than that of users who focus either on information or entertainment. Implications for marketing and future research opportunities are discussed.",2022,10.3389/frai.2022.900775
Modeling needs user modeling,"Modeling has actively tried to take the human out of the loop, originally for objectivity and recently also for automation. We argue that an unnecessary side effect has been that modeling workflows and machine learning pipelines have become restricted to only well-specified problems. Putting the humans back into the models would enable modeling a broader set of problems, through iterative modeling processes in which AI can offer collaborative assistance. However, this requires advances in how we scope our modeling problems, and in the user models. In this perspective article, we characterize the required user models and the challenges ahead for realizing this vision, which would enable new interactive modeling workflows, and human-centric or human-compatible machine learning pipelines.",2023,10.3389/frai.2023.1097891
DCM2Net: an improved face recognition model for panoramic stereoscopic videos,"The panoramic stereo video has brought a new visual experience for the audience with its immersion and stereo effect. In panoramic stereo video, the face is an important element. However, the face image in panoramic stereo video has varying degrees of deformation. This brings new challenges to face recognition. Therefore, this paper proposes a face recognition model DCM2Net (Deformable Convolution MobileFaceNet) for panoramic stereo video. The model mainly integrates the feature information between channels during feature fusion, redistributes the information between channels in the deeper part of the network, and fully uses the information between different channels for feature extraction. This paper also built a panoramic stereo video live system, using the DCM2Net model to recognize the face in panoramic stereo video, and the recognition results are displayed in the video. After experiments on different datasets, the results show that our model has better results on popular datasets and panoramic datasets.",2024,10.3389/frai.2024.1295554
Advancing smart city factories: enhancing industrial mechanical operations via deep learning techniques,"In the contemporary realm of industry, the imperative for influential and steadfast systems to detect anomalies is critically recognized. Our study introduces a cutting-edge approach utilizing a deep learning model of the Long-Short Term Memory variety, meticulously crafted for real-time surveillance and mitigation of irregularities within industrial settings. Through the careful amalgamation of data acquisition and analytic processing informed by our model, we have forged a system adept at pinpointing anomalies with high precision, capable of autonomously proposing or implementing remedial measures. The findings demonstrate a marked enhancement in the efficacy of operations, with the model’s accuracy surging to 95%, recall at 90%, and an F1 score reaching 92.5%. Moreover, the system has favorably impacted the environment, evidenced by a 25% decline in CO2 emissions and a 20% reduction in water usage. Our model surpasses preceding systems, showcasing significant gains in speed and precision. This research corroborates the capabilities of deep learning within the industrial sector. It underscores the role of automated systems in fostering more sustainable and efficient operations in the contemporary industrial landscape.",2024,10.3389/frai.2024.1398126
MixTrain: accelerating DNN training via input mixing,"Training Deep Neural Networks (DNNs) places immense compute requirements on the underlying hardware platforms, expending large amounts of time and energy. An important factor contributing to the long training times is the increasing dataset complexity required to reach state-of-the-art performance in real-world applications. To address this challenge, we explore the use of input mixing, where multiple inputs are combined into a single composite input with an associated composite label for training. The goal is for training on the mixed input to achieve a similar effect as training separately on each the constituent inputs that it represents. This results in a lower number of inputs (or mini-batches) to be processed in each epoch, proportionally reducing training time. We find that naive input mixing leads to a considerable drop in learning performance and model accuracy due to interference between the forward/backward propagation of the mixed inputs. We propose two strategies to address this challenge and realize training speedups from input mixing with minimal impact on accuracy. First, we reduce the impact of inter-input interference by exploiting the spatial separation between the features of the constituent inputs in the network's intermediate representations. We also adaptively vary the mixing ratio of constituent inputs based on their loss in previous epochs. Second, we propose heuristics to automatically identify the subset of the training dataset that is subject to mixing in each epoch. Across ResNets of varying depth, MobileNetV2 and two Vision Transformer networks, we obtain upto 1.6 × and 1.8 × speedups in training for the ImageNet and Cifar10 datasets, respectively, on an Nvidia RTX 2080Ti GPU, with negligible loss in classification accuracy.",2024,10.3389/frai.2024.1387936
"A brief reference to AI-driven audible reality (AuRa) in open world: potential, applications, and evaluation","Recent developments on artificial intelligence (AI) and machine learning (ML) techniques are expected to have significant impact on public health in several ways. Indeed, modern AI/ML methods have been applied on multiple occasions on topics ranging from drug discovery and disease diagnostics to personalized medicine, medical imaging, and healthcare operations. While such developments may improve several quality-of-life aspects (such as access to health services and education), it is important considering that some individuals may face more challenges, particularly in extreme or emergency situations. In this work, we focus on utilizing AI/ML components to support scenarios when visual impairment or other limitations hinder the ability to interpret the world in this way. Specifically, we discuss the potential and the feasibility of automatically transferring key visual information into audio communication, in different languages and in real-time—a setting which we name ‘audible reality’ (AuRa). We provide a short guide to practical options currently available for implementing similar solutions and summarize key aspects for evaluating their scope. Finally, we discuss diverse settings and functionalities that AuRA applications could have in terms of broader impact, from a social and public health context, and invite the community to further such digital solutions and perspectives soon.",2024,10.3389/frai.2024.1424371
Using ChatGPT to navigate ambivalent and contradictory research findings on artificial intelligence,"With the rapid development and integration of AI in various domains, understanding the nuances of AI research has become critical for policymakers, researchers, and practitioners. However, the results are vast and diverse and even can be contradictory or ambivalent, presenting a significant challenge for individuals seeking to grasp and synthesize the findings. This perspective paper discusses the ambivalent and contradictory research findings in the literature on artificial intelligence (AI) and explores whether ChatGPT can be used to navigate and make sense of the AI literature.",2023,10.3389/frai.2023.1195797
The Issue of Proxies and Choice Architectures. Why EU Law Matters for Recommender Systems,"Recommendations are meant to increase sales or ad revenue, as these are the first priority of those who pay for them. As recommender systems match their recommendations with inferred preferences, we should not be surprised if the algorithm optimizes for lucrative preferences and thus co-produces the preferences they mine. This relates to the well-known problems of feedback loops, filter bubbles, and echo chambers. In this article, I discuss the implications of the fact that computing systems necessarily work with proxies when inferring recommendations and raise a number of questions about whether recommender systems actually do what they are claimed to do, while also analysing the often-perverse economic incentive structures that have a major impact on relevant design decisions. Finally, I will explain how the choice architectures for data controllers and providers of AI systems as foreseen in the EU's General Data Protection Regulation (GDPR), the proposed EU Digital Services Act (DSA) and the proposed EU AI Act will help to break through various vicious circles, by constraining how people may be targeted (GDPR, DSA) and by requiring documented evidence of the robustness, resilience, reliability, and the responsible design and deployment of high-risk recommender systems (AI Act).",2022,10.3389/frai.2022.789076
On the Adaptability of Recurrent Neural Networks for Real-Time Jazz Improvisation Accompaniment,"Jazz improvisation on a given lead sheet with chords is an interesting scenario for studying the behaviour of artificial agents when they collaborate with humans. Specifically in jazz improvisation, the role of the accompanist is crucial for reflecting the harmonic and metric characteristics of a jazz standard, while identifying in real-time the intentions of the soloist and adapt the accompanying performance parameters accordingly. This paper presents a study on a basic implementation of an artificial jazz accompanist, which provides accompanying chord voicings to a human soloist that is conditioned by the soloing input and the harmonic and metric information provided in a lead sheet chart. The model of the artificial agent includes a separate model for predicting the intentions of the human soloist, towards providing proper accompaniment to the human performer in real-time. Simple implementations of Recurrent Neural Networks are employed both for modeling the predictions of the artificial agent and for modeling the expectations of human intention. A publicly available dataset is modified with a probabilistic refinement process for including all the necessary information for the task at hand and test-case compositions on two jazz standards show the ability of the system to comply with the harmonic constraints within the chart. Furthermore, the system is indicated to be able to provide varying output with different soloing conditions, while there is no significant sacrifice of “musicality” in generated music, as shown in subjective evaluations. Some important limitations that need to be addressed for obtaining more informative results on the potential of the examined approach are also discussed.",2021,10.3389/frai.2020.508727
The innovation paradox in human-AI symbiosis: ambidextrous effects of AI technology adoption on innovative behavior,"IntroductionAI is radically changing workplace ecosystems in the midst of the Fourth Industrial Revolution, making human-machine collaboration a need for organizations. The ambidextrous processes by which AI simultaneously encourages and constrains inventive behaviors need systematic examination, even though employee innovation is still essential for maintaining competitive advantage. In order to understand the paradoxical consequences of AI, this study builds a dual-path moderated mediation model based on the Job Demands-Resources (JD-R) paradigm.MethodsUsing a two-wave longitudinal design with a 3-month interval and multi-source data from 250 experts in China, we combined survey measurements with quasi-experimental manipulations. The following findings were obtained using structural equation modeling (SEM) and bootstrapping.Results(1) AI technology adoption is a job resource that increases Felt Obligation for Constructive Change (FOCC), but it also acts as a job demand that inhibits innovation by creating a sense of job insecurity; (2) task crafting is a crucial boundary condition that amplifies the positive mediation path while attenuating the negative pathway.DiscussionBased on the aforementioned findings, this study highlights the importance of considering employees' psychological states and behavioral changes while fostering technological innovation, exposing the intricacy of artificial intelligence technology in HRM from both a subjective and objective standpoint. Job insecurity is a possible drawback of technology use, hence businesses should take appropriate steps to lessen employee uneasiness while using new technologies. Felt Obligation for Constructive Change, on the other hand, is a crucial strategy for encouraging creative behavior. To do this, managers must investigate and enhance employees' intrinsic motivation for their everyday tasks and foster a culture of creativity. Task crafting, as an effective self-management and driving factor, is also very important to reduce the negative effects of technology adoption and increase its positive effects. For this reason, businesses should support and encourage employees to improve their autonomy and flexibility, iterate on their work methods, and stimulate their ability to innovate. This will not only help employees develop their own skills but also give businesses a competitive edge and continuous innovation motivation.",2025,10.3389/frai.2025.1635246
Toward Sharing Brain Images: Differentially Private TOF-MRA Images With Segmentation Labels Using Generative Adversarial Networks,"Sharing labeled data is crucial to acquire large datasets for various Deep Learning applications. In medical imaging, this is often not feasible due to privacy regulations. Whereas anonymization would be a solution, standard techniques have been shown to be partially reversible. Here, synthetic data using a Generative Adversarial Network (GAN) with differential privacy guarantees could be a solution to ensure the patient's privacy while maintaining the predictive properties of the data. In this study, we implemented a Wasserstein GAN (WGAN) with and without differential privacy guarantees to generate privacy-preserving labeled Time-of-Flight Magnetic Resonance Angiography (TOF-MRA) image patches for brain vessel segmentation. The synthesized image-label pairs were used to train a U-net which was evaluated in terms of the segmentation performance on real patient images from two different datasets. Additionally, the Fréchet Inception Distance (FID) was calculated between the generated images and the real images to assess their similarity. During the evaluation using the U-Net and the FID, we explored the effect of different levels of privacy which was represented by the parameter ϵ. With stricter privacy guarantees, the segmentation performance and the similarity to the real patient images in terms of FID decreased. Our best segmentation model, trained on synthetic and private data, achieved a Dice Similarity Coefficient (DSC) of 0.75 for ϵ = 7.4 compared to 0.84 for ϵ = ∞ in a brain vessel segmentation paradigm (DSC of 0.69 and 0.88 on the second test set, respectively). We identified a threshold of ϵ &lt;5 for which the performance (DSC &lt;0.61) became unstable and not usable. Our synthesized labeled TOF-MRA images with strict privacy guarantees retained predictive properties necessary for segmenting the brain vessels. Although further research is warranted regarding generalizability to other imaging modalities and performance improvement, our results mark an encouraging first step for privacy-preserving data sharing in medical imaging.",2022,10.3389/frai.2022.813842
Combining different points of view on plant descriptions: mapping agricultural plant roles and biological taxa,"This article describes our study on the alignment of two complementary knowledge graphs useful in agriculture: the thesaurus of cultivated plants in France named French Crop Usage (FCU) and the French national taxonomic repository TAXREF for fauna, flora, and fungi. FCU describes the usages of plants in agriculture: “tomatoes” are crops used for human food, and “grapevines” are crops used for human beverage. TAXREF describes biological taxa and associated scientific names: for example, a tomato species may be “Solanum lycopersicum” or a grapevine species may be “Vitis vinifera”. Both knowledge graphs contain vernacular names of plants but those names are ambiguous. Thus, a group of agricultural experts produced some mappings from FCU crops to TAXREF taxa. Moreover, new RDF properties have been defined to declare those new types of mapping relations between plant descriptions. The metadata for the mappings and the mapping set are encoded with the Simple Standard for Sharing Ontological Mappings (SSSOM), a new model which, among other qualities, offers means to report on provenance of particular interest for this study. The produced mappings are available for download in Recherche Data Gouv, the federated national platform for research data in France.",2023,10.3389/frai.2023.1188036
Applied machine learning in intelligent systems: knowledge graph-enhanced ophthalmic contrastive learning with “clinical profile” prompts,"IntroductionThe integration of artificial intelligence (AI) into ophthalmic diagnostics has the potential to significantly enhance diagnostic accuracy and interpretability, thereby supporting clinical decision-making. However, a major challenge in AI-driven medical applications is the lack of transparency, which limits clinicians’ trust in automated recommendations. This study investigates the application of machine learning techniques by integrating knowledge graphs with contrastive learning and utilizing “clinical profile” prompts to refine the performance of the ophthalmology-specific large language model, MeEYE, which is built on the CHATGLM3-6B architecture. This approach aims to improve the model’s ability to capture clinically relevant features while enhancing both the accuracy and explainability of diagnostic predictions.MethodsThis study employs a novel methodological framework that incorporates domain-specific knowledge through knowledge graphs and enhances feature representation using contrastive learning. The MeEYE model is fine-tuned with structured clinical knowledge, enabling it to better distinguish subtle yet significant ophthalmic features. Additionally, “clinical profile” prompts are incorporated to further improve contextual understanding and diagnostic precision. The proposed method is evaluated through comprehensive performance benchmarking, including quantitative assessments and clinical case studies, to ensure its efficacy in real-world ophthalmic diagnosis.ResultsThe experimental findings demonstrate that integrating knowledge graphs and contrastive learning into the MeEYE model significantly improves both diagnostic accuracy and model interpretability. Comparative analyses against baseline models reveal that the proposed approach enhances the identification of ophthalmic conditions with higher precision and clarity. Furthermore, the model’s ability to generate transparent and clinically relevant AI recommendations is substantiated through rigorous evaluation, highlighting its potential for real-world clinical implementation.DiscussionThe results underscore the importance of explainable AI in medical diagnostics, particularly in ophthalmology, where model transparency is critical for clinical acceptance and utility. By incorporating domain-specific knowledge with advanced machine learning techniques, the proposed approach not only enhances model performance but also ensures that AI-generated insights are interpretable and reliable for clinical decision-making. These findings suggest that integrating structured medical knowledge with machine learning frameworks can address key challenges in AI-driven diagnostics, ultimately contributing to improved patient outcomes. Future research should explore the adaptability of this approach across various medical domains to further advance AI-assisted diagnostic systems.",2025,10.3389/frai.2025.1527010
"GDP Forecasting: Machine Learning, Linear or Autoregression?","This paper compares the predictive power of different models to forecast the real U.S. GDP. Using quarterly data from 1976 to 2020, we find that the machine learning K-Nearest Neighbour (KNN) model captures the self-predictive ability of the U.S. GDP and performs better than traditional time series analysis. We explore the inclusion of predictors such as the yield curve, its latent factors, and a set of macroeconomic variables in order to increase the level of forecasting accuracy. The predictions result to be improved only when considering long forecast horizons. The use of machine learning algorithm provides additional guidance for data-driven decision making.",2021,10.3389/frai.2021.757864
Configural relations in humans and deep convolutional neural networks,"Deep convolutional neural networks (DCNNs) have attracted considerable interest as useful devices and as possible windows into understanding perception and cognition in biological systems. In earlier work, we showed that DCNNs differ dramatically from human perceivers in that they have no sensitivity to global object shape. Here, we investigated whether those findings are symptomatic of broader limitations of DCNNs regarding the use of relations. We tested learning and generalization of DCNNs (AlexNet and ResNet-50) for several relations involving objects. One involved classifying two shapes in an otherwise empty field as same or different. Another involved enclosure. Every display contained a closed figure among contour noise fragments and one dot; correct responding depended on whether the dot was inside or outside the figure. The third relation we tested involved a classification that depended on which of two polygons had more sides. One polygon always contained a dot, and correct classification of each display depended on whether the polygon with the dot had a greater number of sides. We used DCNNs that had been trained on the ImageNet database, and we used both restricted and unrestricted transfer learning (connection weights at all layers could change with training). For the same-different experiment, there was little restricted transfer learning (82.2%). Generalization tests showed near chance performance for new shapes. Results for enclosure were at chance for restricted transfer learning and somewhat better for unrestricted (74%). Generalization with two new kinds of shapes showed reduced but above-chance performance (≈66%). Follow-up studies indicated that the networks did not access the enclosure relation in their responses. For the relation of more or fewer sides of polygons, DCNNs showed successful learning with polygons having 3–5 sides under unrestricted transfer learning, but showed chance performance in generalization tests with polygons having 6–10 sides. Experiments with human observers showed learning from relatively few examples of all of the relations tested and complete generalization of relational learning to new stimuli. These results using several different relations suggest that DCNNs have crucial limitations that derive from their lack of computations involving abstraction and relational processing of the sort that are fundamental in human perception.",2023,10.3389/frai.2022.961595
Robust deep-learning based refrigerator food recognition,"Automatic food identification utilizing artificial intelligence (AI) technology in smart refrigerators presents an innovative solution. However, existing studies exhibit significant limitations. Achieving consistent high performance in recognition across varying camera distances and diverse real-world conditions remain a formidable challenge. Current approaches often struggle to accurately recognize items in scenarios involving occlusions, variable distortions, and complex backgrounds, thereby limiting their practical applicability in household environments. This study addresses these deficiencies by enhancing the Feature Pyramid Network (FPN) of YOLACT with an additional layer designed to capture nuanced information. Furthermore, we propose a two-stage data augmentation method that simulates diverse conditions including distortion and occlusion, to generate images that reflect various backgrounds and handheld scenarios. Comparative analyses with previous research and evaluations on our original dataset demonstrate that our approach significantly improves recognition rates for both typical and challenging real-world images. These enhancements contribute to more effective food waste management in households and indicate broader applications for automatic identification systems.",2024,10.3389/frai.2024.1442948
Deep Learning–Based COVID-19 Pneumonia Classification Using Chest CT Images: Model Generalizability,"Since the outbreak of the COVID-19 pandemic, worldwide research efforts have focused on using artificial intelligence (AI) technologies on various medical data of COVID-19–positive patients in order to identify or classify various aspects of the disease, with promising reported results. However, concerns have been raised over their generalizability, given the heterogeneous factors in training datasets. This study aims to examine the severity of this problem by evaluating deep learning (DL) classification models trained to identify COVID-19–positive patients on 3D computed tomography (CT) datasets from different countries. We collected one dataset at UT Southwestern (UTSW) and three external datasets from different countries: CC-CCII Dataset (China), COVID-CTset (Iran), and MosMedData (Russia). We divided the data into two classes: COVID-19–positive and COVID-19–negative patients. We trained nine identical DL-based classification models by using combinations of datasets with a 72% train, 8% validation, and 20% test data split. The models trained on a single dataset achieved accuracy/area under the receiver operating characteristic curve (AUC) values of 0.87/0.826 (UTSW), 0.97/0.988 (CC-CCCI), and 0.86/0.873 (COVID-CTset) when evaluated on their own dataset. The models trained on multiple datasets and evaluated on a test set from one of the datasets used for training performed better. However, the performance dropped close to an AUC of 0.5 (random guess) for all models when evaluated on a different dataset outside of its training datasets. Including MosMedData, which only contained positive labels, into the training datasets did not necessarily help the performance of other datasets. Multiple factors likely contributed to these results, such as patient demographics and differences in image acquisition or reconstruction, causing a data shift among different study cohorts.",2021,10.3389/frai.2021.694875
Algorithmic fairness: challenges to building an effective regulatory regime,"Unfair treatment by artificial intelligence toward protected groups has become an important topic of discussion. Its potential for causing harm has spurred many to think that legislation aimed at regulating AI systems is essential. In the US, laws have already been proposed both by Congress as well as by several key states. However, a number of challenges stand in the way of effective legislation. Proposed laws mandating testing for fairness must articulate clear positions on how fairness is defined. But the task of selecting a suitable definition (or definitions) of fairness is not a simple one. Experts in AI continue to disagree as to what constitutes algorithmic fairness, which has led to an ever-expanding list of definitions that are highly technical in nature and require expertise that most legislators simply do not possess. Complicating things further, several of the proposed definitions are incommensurable with one another, making a cross-jurisdictional regulatory regime incorporating different standards of fairness susceptible to inconsistent determinations. On top of all this, legislators must also contend with existing laws prohibiting group-based discrimination that codify conceptions of fairness that may not be suitable for evaluating certain algorithms. In this article, I examine these challenges in detail, and suggest ways to deal with them such that the regulatory regime that emerges is one that is more effective in carrying out its intended purpose.",2025,10.3389/frai.2025.1637134
Revolutionizing the construction industry by cutting edge artificial intelligence approaches: a review,"The construction industry is rapidly adopting Industry 4.0 technologies, creating new opportunities to address persistent environmental and operational challenges. This review focuses on how Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) are being leveraged to tackle these issues. It specifically explores AI’s role in predicting air pollution, improving material quality, monitoring worker health and safety, and enhancing Cyber-Physical Systems (CPS) for construction. This study evaluates various AI and ML models, including Artificial Neural Networks (ANNs) and Support Vector Machines SVMs, as well as optimization techniques like whale and moth flame optimization. These tools are assessed for their ability to predict air pollutant levels, improve concrete quality, and monitor worker safety in real time. Research papers were also reviewed to understand AI’s application in predicting the compressive strength of materials like cement mortar, fly ash, and stabilized clay soil. The performance of these models is measured using metrics such as coefficient of determination (R2), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, AI has shown promise in predicting and reducing emissions of air pollutants such as PM2.5, PM10, NO2, CO, SO2, and O3. In addition, it improves construction material quality and ensures worker safety by monitoring health indicators like standing postures, electrocardiogram, and galvanic skin response. It is also concluded that AI technologies, including Explainable AI and Petri Nets, are also making advancements in CPS for the construction industry. The models’ performance metrics indicate they are well-suited for real-time construction operations. The study highlights the adaptability and effectiveness of these technologies in meeting current and future construction needs. However, gaps remain in certain areas of research, such as broader AI integration across diverse construction environments and the need for further validation of models in real-world applications. Finally, this research underscores the potential of AI and ML to revolutionize the construction industry by promoting sustainable practices, improving operational efficiency, and addressing safety concerns. It also provides a roadmap for future research, offering valuable insights for industry stakeholders interested in adopting AI technologies.",2024,10.3389/frai.2024.1474932
Applications of Learning Analytics in High Schools: A Systematic Literature Review,"Learning analytics aims to analyze data from students and learning environments to support learning at different levels. Although learning analytics is a recent field, it reached a high level of maturity, especially in its applications for higher education. However, little of the research in learning analytics targets other educational levels, such as high school. This paper reports the results of a systematic literature review (SLR) focused on the adoption of learning analytics in high schools. More specifically, the SLR followed four steps: the search, selection of relevant studies, critical assessment, and the extraction of the relevant field, which included the main goals, approaches, techniques, and challenges of adopting learning analytics in high school. The results show that, in this context, learning analytics applications are focused on small-scale initiatives rather than institutional adoption. Based on the findings of this study, in combination with the literature, this paper proposes future directions of research and development in order to scale up learning analytics applications in high schools.",2021,10.3389/frai.2021.737891
Persuasive Technology and computational manipulation: hypernudging out of mental self-determination,"Artificial Intelligence, unperceived, can acquire the user's data, find connections not visible by a human being, profile the users, and aim at persuading them, resulting in Persuasive Technology (PT). During the persuasive process, PT can use manipulation, finding and using routes to affect System 1, the primordial brain of individuals, in the absence of their awareness, undermining their decision-making processes. Multiple international and European bodies recognized that AI systems could use manipulation at an unprecedented degree via second-generation dark patterns such as the hypernudge and that computational manipulation constitutes a risk for autonomy and different, overlapping, fundamental rights such as privacy, informational self-determination and freedom of thought. However, there is a lack of shared ideas regarding which fundamental rights are violated by computational manipulation and which fundamental rights can protect individuals against it. The right to be let alone and the right to hold and express a thought differ from the right to create a thought, being in control of the decision-making process and free from cognitive interferences operated by computational manipulation. Therefore, this paper argues in favor of recognizing a newly emerged fundamental right, the right to mental self-determination, tailored to the unprecedented abilities of AI-driven manipulative technologies.",2023,10.3389/frai.2023.1216340
A multi-model longitudinal assessment of ChatGPT performance on medical residency examinations,"IntroductionChatGPT, a generative artificial intelligence, has potential applications in numerous fields, including medical education. This potential can be assessed through its performance on medical exams. Medical residency exams, critical for entering medical specialties, serve as a valuable benchmark.Materials and methodsThis study aimed to assess the accuracy of ChatGPT-4 and GPT-4o in responding to 1,041 medical residency questions from Brazil, examining overall accuracy and performance across different medical areas, based on evaluations conducted in 2023 and 2024. The questions were classified into higher and lower cognitive levels according to Bloom’s taxonomy. Additionally, questions answered incorrectly by both models were tested using the recent GPT models that use chain-of-thought reasoning (e.g., o1-preview, o3, o4-mini-high) with evaluations carried out in both 2024 and 2025.ResultsGPT-4 achieved 81.27% accuracy (95% CI: 78.89–83.64%), while GPT-4o reached 85.88% (95% CI: 83.76–88.00%), significantly outperforming GPT-4 (p &lt; 0.05). Both models showed reduced accuracy on higher-order thinking questions. On questions that both models failed, GPT o1-preview achieved 53.26% accuracy (95% CI: 42.87–63.65%), GPT o3 47.83% (95% CI: 37.42–58.23%) and o4-mini-high 35.87% (95% CI: 25.88–45.86%), with all three models performing better on higher-order questions.ConclusionArtificial intelligence could be a beneficial tool in medical education, enhancing residency exam preparation, helping to understand complex topics, and improving teaching strategies. However, careful use of artificial intelligence is essential due to ethical concerns and potential limitations in both educational and clinical practice.",2025,10.3389/frai.2025.1614874
A deep learning/machine learning approach for anomaly based network intrusion detection,"IntroductionThe increasing complexity and frequency of cybersecurity threats necessitate the development of advanced detection systems capable of identifying both known and emerging attacks. In this study, we present a hybrid anomaly-based Network Intrusion Detection System (NIDS) that integrates multiple machine learning and deep learning algorithms, including XGBoost, Random Forest, Graph Neural Networks (GNN), Long Short-Term Memory (LSTM) networks, and Autoencoders.MethodsThe proposed system was trained on a large-scale dataset comprising over 5.6 million network traffic records. Comprehensive data preprocessing and feature engineering were applied, and the Synthetic Minority Over-sampling Technique (SMOTE) was employed to address class imbalance. To enhance robustness and generalization, a weighted soft-voting ensemble strategy was used to combine predictions from the individual models.ResultsThe experimental evaluation demonstrated near-perfect performance, with accuracy, precision, recall, and F1-score values approaching 100% on the primary dataset. These results were validated through rigorous 5-fold cross-validation.DiscussionEvaluation on an independent benchmark dataset confirmed the strong generalizability and robustness of the proposed model across diverse intrusion scenarios. These findings highlight the effectiveness of the hybrid ensemble framework in significantly improving intrusion detection capabilities within complex and dynamic network environments.",2025,10.3389/frai.2025.1625891
Conformational Changes of the Receptor Binding Domain of SARS-CoV-2 Spike Protein and Prediction of a B-Cell Antigenic Epitope Using Structural Data,"COVID-19, the illness caused by the SARS-CoV-2 virus, is now a worldwide pandemic with mortality in hundreds of thousands as infections continue to increase. Containing the spread of this viral infection and decreasing the mortality rate is a major challenge. Identifying appropriate antigenic epitopes from the viral proteins is a very important task for vaccine production and the development of diagnostic kits and antibody therapy. A novel antigenic epitope would be specific to the SARS-CoV-2 virus and can distinguish infections caused by common cold viruses. In this study two approaches are employed to identify both continuous and conformational B-cell antigenic epitopes. To achieve this goal, we modeled a complete structure of the receptor binding domain (RBD) of the spike protein using recently deposited coordinates (6vxx, 6vsb, and 6w41) in the protein data bank. In addition, we also modeled the RBD-ACE2 receptor complex for SARS-CoV-2 using the SARS-CoV RBD-ACE2 complex (3D0J) as a reference model. Finally, structure based predicted antigenic epitopes were compared to the ACE2 binding region of RBD of SARS-CoV-2. The identified conformational epitopes show overlaps with the ACE2-receptor binding region of the RBD of SARS-CoV-2. Strategies defined in the current study identified novel antigenic epitope that is specific to the SARS-CoV-2 virus. Integrating such approach in the diagnosis can distinguish infections caused by common cold viruses from SARS-CoV-2 virus.",2021,10.3389/frai.2021.630955
Advancements in cache management: a review of machine learning innovations for enhanced performance and security,"Machine learning techniques have emerged as a promising tool for efficient cache management, helping optimize cache performance and fortify against security threats. The range of machine learning is vast, from reinforcement learning-based cache replacement policies to Long Short-Term Memory (LSTM) models predicting content characteristics for caching decisions. Diverse techniques such as imitation learning, reinforcement learning, and neural networks are extensively useful in cache-based attack detection, dynamic cache management, and content caching in edge networks. The versatility of machine learning techniques enables them to tackle various cache management challenges, from adapting to workload characteristics to improving cache hit rates in content delivery networks. A comprehensive review of various machine learning approaches for cache management is presented, which helps the community learn how machine learning is used to solve practical challenges in cache management. It includes reinforcement learning, deep learning, and imitation learning-driven cache replacement in hardware caches. Information on content caching strategies and dynamic cache management using various machine learning techniques in cloud and edge computing environments is also presented. Machine learning-driven methods to mitigate security threats in cache management have also been discussed.",2025,10.3389/frai.2025.1441250
Early diagnosis of autism across developmental stages through scalable and interpretable ensemble model,"Autism Spectrum Disorder (ASD) is a multifaceted neurodevelopmental condition that challenges early diagnosis due to its diverse manifestations across different developmental stages. Timely and accurate detection is essential to enable interventions that significantly enhance developmental outcomes. This study introduces a robust and interpretable machine learning framework to diagnose ASD using questionnaire data. The proposed framework leverages a stacked ensemble model, combining Random Forest (RF), Extra Tree (ET), and CatBoost (CB) as base classifiers, with an Artificial Neural Network (ANN) serving as the meta-classifier. The methodology addresses class imbalance using Safe-Level SMOTE, dimensionality reduction via Principal Component Analysis (PCA), and feature selection using Mutual Information and Pearson correlation. Evaluation on publicly available datasets representing toddlers, children, adolescents, adults, and a merged dataset (Combining children, adolescents, and adults dataset) demonstrates high diagnostic accuracy, achieving 99.86%, 99.68%, 98.17%, 99.89%, and 96.96%, respectively. Comparative analysis with standard machine learning models underscores the superior performance of the proposed framework. SHapley Additive exPlanations (SHAP) were used to interpret feature importance, while Monte Carlo Dropout (MCD) quantified uncertainty in predictions. This framework provides a scalable, interpretable, and reliable solution for ASD screening across diverse populations and developmental stages.",2025,10.3389/frai.2025.1507922
Artificial intelligence approaches for tinnitus diagnosis: leveraging high-frequency audiometry data for enhanced clinical predictions,"This research investigates the application of machine learning to improve the diagnosis of tinnitus using high-frequency audiometry data. A Logistic Regression (LR) model was developed alongside an Artificial Neural Network (ANN) and various baseline classifiers to identify the most effective approach for classifying tinnitus presence. The methodology encompassed data preprocessing, feature extraction focused on point detection, and rigorous model evaluation through performance metrics including accuracy, Area Under the ROC Curve (AUC), precision, recall, and F1 scores. The main findings reveal that the LR model, supported by the ANN, significantly outperformed other machine learning models, achieving an accuracy of 94.06%, an AUC of 97.06%, and high precision and recall scores. These results demonstrate the efficacy of the LR model and ANN in accurately diagnosing tinnitus, surpassing traditional diagnostic methods that rely on subjective assessments. The implications of this research are substantial for clinical audiology, suggesting that machine learning, particularly advanced models like ANNs, can provide a more objective and quantifiable tool for tinnitus diagnosis, especially when utilizing high-frequency audiometry data not typically assessed in standard hearing tests. The study underscores the potential for machine learning to facilitate earlier and more accurate tinnitus detection, which could lead to improved patient outcomes. Future work should aim to expand the dataset diversity, explore a broader range of algorithms, and conduct clinical trials to validate the models' practical utility. The research highlights the transformative potential of machine learning, including the LR model and ANN, in audiology, paving the way for advancements in the diagnosis and treatment of tinnitus.",2024,10.3389/frai.2024.1381455
"Assuring assistance to healthcare and medicine: Internet of Things, Artificial Intelligence, and Artificial Intelligence of Things","IntroductionThe convergence of healthcare with the Internet of Things (IoT) and Artificial Intelligence (AI) is reshaping medical practice with promising enhanced data-driven insights, automated decision-making, and remote patient monitoring. It has the transformative potential of these technologies to revolutionize diagnosis, treatment, and patient care.PurposeThis study aims to explore the integration of IoT and AI in healthcare, outlining their applications, benefits, challenges, and potential risks. By synthesizing existing literature, this study aims to provide insights into the current landscape of AI, IoT, and AIoT in healthcare, identify areas for future research and development, and establish a framework for the effective use of AI in health.MethodA comprehensive literature review included indexed databases such as PubMed/Medline, Scopus, and Google Scholar. Key search terms related to IoT, AI, healthcare, and medicine were employed to identify relevant studies. Papers were screened based on their relevance to the specified themes, and eventually, a selected number of papers were methodically chosen for this review.ResultsThe integration of IoT and AI in healthcare offers significant advancements, including remote patient monitoring, personalized medicine, and operational efficiency. Wearable sensors, cloud-based data storage, and AI-driven algorithms enable real-time data collection, disease diagnosis, and treatment planning. However, challenges such as data privacy, algorithmic bias, and regulatory compliance must be addressed to ensure responsible deployment of these technologies.ConclusionIntegrating IoT and AI in healthcare holds immense promise for improving patient outcomes and optimizing healthcare delivery. Despite challenges such as data privacy concerns and algorithmic biases, the transformative potential of these technologies cannot be overstated. Clear governance frameworks, transparent AI decision-making processes, and ethical considerations are essential to mitigate risks and harness the full benefits of IoT and AI in healthcare.",2024,10.3389/frai.2024.1442254
Assessing Banks' Distress Using News and Regular Financial Data,"In this paper, we focus our attention on leveraging the information contained in financial news to enhance the performance of a bank distress classifier. The news information should be analyzed and inserted into the predictive model in the most efficient way and this task deals with the issues related to Natural Language interpretation and to the analysis of news media. Among the different models proposed for such purpose, we investigate a deep learning approach. The methodology is based on a distributed representation of textual data obtained from a model (Doc2Vec) that maps the documents and the words contained within a text onto a reduced latent semantic space. Afterwards, a second supervised feed forward fully connected neural network is trained combining news data distributed representations with standard financial figures in input. The goal of the model is to classify the corresponding banks in distressed or tranquil state. The final aim is to comprehend both the improvement of the predictive performance of the classifier and to assess the importance of news data in the classification process. This to understand if news data really bring useful information not contained in standard financial variables.",2022,10.3389/frai.2022.871863
COVLIAS 3.0: cloud-based quantized hybrid UNet3+ deep learning for COVID-19 lesion detection in lung computed tomography,"Background and noveltyWhen RT-PCR is ineffective in early diagnosis and understanding of COVID-19 severity, Computed Tomography (CT) scans are needed for COVID diagnosis, especially in patients having high ground-glass opacities, consolidations, and crazy paving. Radiologists find the manual method for lesion detection in CT very challenging and tedious. Previously solo deep learning (SDL) was tried but they had low to moderate-level performance. This study presents two new cloud-based quantized deep learning UNet3+ hybrid (HDL) models, which incorporated full-scale skip connections to enhance and improve the detections.MethodologyAnnotations from expert radiologists were used to train one SDL (UNet3+), and two HDL models, namely, VGG-UNet3+ and ResNet-UNet3+. For accuracy, 5-fold cross-validation protocols, training on 3,500 CT scans, and testing on unseen 500 CT scans were adopted in the cloud framework. Two kinds of loss functions were used: Dice Similarity (DS) and binary cross-entropy (BCE). Performance was evaluated using (i) Area error, (ii) DS, (iii) Jaccard Index, (iii) Bland–Altman, and (iv) Correlation plots.ResultsAmong the two HDL models, ResNet-UNet3+ was superior to UNet3+ by 17 and 10% for Dice and BCE loss. The models were further compressed using quantization showing a percentage size reduction of 66.76, 36.64, and 46.23%, respectively, for UNet3+, VGG-UNet3+, and ResNet-UNet3+. Its stability and reliability were proved by statistical tests such as the Mann–Whitney, Paired t-Test, Wilcoxon test, and Friedman test all of which had a p &lt; 0.001.ConclusionFull-scale skip connections of UNet3+ with VGG and ResNet in HDL framework proved the hypothesis showing powerful results improving the detection accuracy of COVID-19.",2024,10.3389/frai.2024.1304483
The potential of learning with (and not from) artificial intelligence in education,"AI-powered technologies are increasingly being developed for educational purposes to contribute to students' academic performance and overall better learning outcomes. This exploratory review uses the PRISMA approach to describe how the effectiveness of AI-driven technologies is being measured, as well as the roles attributed to teachers, and the theoretical and practical contributions derived from the interventions. Findings from 48 articles highlighted that learning outcomes were more aligned with the optimization of AI systems, mostly nested in a computer science perspective, and did not consider teachers in an active role in the research. Most studies proved to be atheoretical and practical contributions were limited to enhancing the design of the AI system. We discuss the importance of developing complementary research designs for AI-powered tools to be integrated optimally into education.",2022,10.3389/frai.2022.903051
Reader’s digest version of scientific writing: comparative evaluation of summarization capacity between large language models and medical students in analyzing scientific writing in sleep medicine,"IntroductionAs artificial intelligence systems like large language models (LLM) and natural language processing advance, the need to evaluate their utility within medicine and medical education grows. As medical research publications continue to grow exponentially, AI systems offer valuable opportunities to condense and synthesize information, especially in underrepresented areas such as Sleep Medicine. The present study aims to compare summarization capacity between LLM generated summaries of sleep medicine research article abstracts, to summaries generated by Medical Student (humans) and to evaluate if the research content, and literary readability summarized is retained comparably.MethodsA collection of three AI-generated and human-generated summaries of sleep medicine research article abstracts were shared with 19 study participants (medical students) attending a sleep medicine conference. Participants were blind as to which summary was human or LLM generated. After reading both human and AI-generated research summaries participants completed a 1–5 Likert scale survey on the readability of the extracted writings. Participants also answered article-specific multiple-choice questions evaluating their comprehension of the summaries, as a representation of the quality of content retained by the AI-generated summaries.ResultsAn independent sample t-test between the AI-generated and human-generated summaries comprehension by study participants revealed no significant difference between the Likert readability ratings (p = 0.702). A chi-squared test of proportions revealed no significant association (χ2 = 1.485, p = 0.223), and a McNemar test revealed no significant association between summary type and the proportion of correct responses to the comprehension multiple choice questions (p = 0.289).DiscussionSome limitations in this study were a small number of participants and user bias. Participants attended at a sleep conference and study summaries were all from sleep medicine journals. Lastly the summaries did not include graphs, numbers, and pictures, and thus were limited in material extraction. While the present analysis did not demonstrate a significant difference among the readability and content quality between the AI and human-generated summaries, limitations in the present study indicate that more research is needed to objectively measure, and further define strengths and weaknesses of AI models in condensing medical literature into efficient and accurate summaries.",2024,10.3389/frai.2024.1477535
Evolving intellectual property landscape for AI-driven innovations in the biomedical sector: opportunities in stable IP regime for shared success,"Artificial Intelligence (AI) has revolutionized the biomedical sector in advanced diagnosis, treatment, and personalized medicine. While these AI-driven innovations promise vast benefits for patients and service providers, they also raise complex intellectual property (IP) challenges due to the inherent nature of AI technology. In this review, we discussed the multifaceted impact of AI on IP within the biomedical sector, exploring implications in areas like drug research and discovery, personalized medicine, and medical diagnostics. We dissect critical issues surrounding AI inventorship, patent and copyright protection for AI-generated works, data ownership, and licensing. To provide context, we analyzed the current IP legislative landscape in the United States, EU, China, and India, highlighting convergences, divergences, and precedent-setting cases relevant to the biomedical sector. Recognizing the need for harmonization, we reviewed current developments and discussed a way forward. We advocate for a collaborative approach, convening policymakers, clinicians, researchers, industry players, legal professionals, and patient advocates to navigate this dynamic landscape. It will create a stable IP regime and unlock the full potential of AI for enhanced healthcare delivery and improved patient outcomes.",2024,10.3389/frai.2024.1372161
Electronic Brainstorming With a Chatbot Partner: A Good Idea Due to Increased Productivity and Idea Diversity,"Brainstorming is a creative technique that fosters collaboration to enhance idea generation. The occurrence of evaluation apprehension, a fear of being evaluated negatively by others, however, can stymy brainstorming. How the advantages of collaboration can be leveraged while evaluation apprehension is prevented is an open scientific and practical problem. In this brief research report, it is proposed that chatbots could provide a solution. Chatbots can be designed to share ideas with their users, facilitating inspiration. Compared to human beings, chatbots are also perceived as possessing limited agency and evaluative capacity. This could reduce evaluation apprehension. Given that chatbots are often embedded in a textual chat interface, social cues (picture, name, and description) can reinforce the perceived chatbot identity, enhancing its alleged effects on evaluation apprehension and subsequently on brainstorming performance. These conjectures were tested in an online 2 × 2 between-subjects experiment (n = 120) where people were instructed to brainstorm with a partner that was framed as either a chatbot or human being (but followed the same automated script), with or without the presence of social cues. The results showed that brainstorming with a chatbot led participants to produce more ideas, with more diversity than brainstorming with an alleged human being. Social cues enhanced the effect on idea diversity, but only with the chatbot. No significant effects on evaluation apprehension were found. The contribution of this study is therefore that chatbots can be used for effective human–machine teaming during brainstorming, but this enhancement is not explained by its effects on evaluation apprehension.",2022,10.3389/frai.2022.880673
Examining the integration of artificial intelligence in supply chain management from Industry 4.0 to 6.0: a systematic literature review,"BackgroundThis study examines the integration of Artificial Intelligence (AI) in supply chain management (SCM) during the transition from Industry 4.0 to Industry 6.0. The focus is on improving operational efficiency, promoting human-centric collaboration, and advancing sustainability within supply chains. As industries progress, the need to incorporate AI technologies that improve decision-making and operational resilience while ensuring sustainable practices becomes increasingly critical. This systematic review aims to explore how AI is transforming SCM through these industrial transitions.MethodsUtilising the PRISMA framework, a systematic review was conducted to gather and analyse relevant literature published between 2010 and 2023. A comprehensive search of databases including Web of Science, Scopus, IEEE Xplore, Google Scholar, and ScienceDirect was performed. The review involved rigorous screening for eligibility and thematic analysis using Atlas-ti software to identify key themes and patterns related to AI integration in SCM.ResultsThe findings indicate that AI integration significantly improves SCM by improving demand forecasting, inventory management, and overall decision-making capabilities. Industry 5.0 focuses on human-AI collaboration, improving customisation and problem-solving. AI technologies also contribute to sustainability by optimising resource utilisation and reducing environmental impacts. However, challenges such as cybersecurity risks and workforce skill gaps need to be addressed to fully leverage AI’s potential.ConclusionIntegrating AI in SCM not only improves operational efficiency and sustainability but also promotes resilience against disruptions. The insights from this review offer valuable guidance for both academics and practitioners aiming to optimise supply chain operations through AI technologies from Industry 4.0 to Industry 6.0. The study underlines the importance of a balanced approach that integrates technological developments with human-centric and sustainable practices.",2025,10.3389/frai.2024.1477044
Measuring the effects of pedagogical agent cognitive and affective feedback on students’ academic performance,"There is still a debate on the influence and effectiveness of pedagogical agents in a learning environment, especially on the means these agents employ for enhancing students’ academic performance. The current study aims at measuring the effectiveness of cognitive and affective feedback (CaAF) types that a human teacher and a virtual Affective Pedagogical Tutor (APT) used in their groups of students (control and experimental groups respectively) in an authentic long-term learning situation. Participants were a sample of 115 students carrying out collaborative activities in a “web design” course. Our findings showed that APT cognitive feedback (CF) significantly increased students’ learning outcomes compared to the human teacher’s feedback, whereas APT affective feedback (AF) only achieved partial success. Nevertheless, the study has some limitations: it is based on a single course and a specific academic context, limiting the generalizability of its findings. Additionally, while cognitive feedback demonstrated a clear impact, the analysis of affective feedback was less conclusive, and its design requires further refinement. Finally, the cross-sectional design of the study restricts the ability to assess whether improvements in learning outcomes persist over time. Future research directions include exploring the generalizability of results across diverse disciplines, deepening the analysis of affective feedback, and incorporating longitudinal studies to evaluate the durability of the observed effects.",2024,10.3389/frai.2024.1495342
Comparison of Structural Parsers and Neural Language Models as Surprisal Estimators,"Expectation-based theories of sentence processing posit that processing difficulty is determined by predictability in context. While predictability quantified via surprisal has gained empirical support, this representation-agnostic measure leaves open the question of how to best approximate the human comprehender's latent probability model. This article first describes an incremental left-corner parser that incorporates information about common linguistic abstractions such as syntactic categories, predicate-argument structure, and morphological rules as a computational-level model of sentence processing. The article then evaluates a variety of structural parsers and deep neural language models as cognitive models of sentence processing by comparing the predictive power of their surprisal estimates on self-paced reading, eye-tracking, and fMRI data collected during real-time language processing. The results show that surprisal estimates from the proposed left-corner processing model deliver comparable and often superior fits to self-paced reading and eye-tracking data when compared to those from neural language models trained on much more data. This may suggest that the strong linguistic generalizations made by the proposed processing model may help predict humanlike processing costs that manifest in latency-based measures, even when the amount of training data is limited. Additionally, experiments using Transformer-based language models sharing the same primary architecture and training data show a surprising negative correlation between parameter count and fit to self-paced reading and eye-tracking data. These findings suggest that large-scale neural language models are making weaker generalizations based on patterns of lexical items rather than stronger, more humanlike generalizations based on linguistic structure.",2022,10.3389/frai.2022.777963
Infant food users' perceptions of safety: A web-based analysis approach,"This paper aims to explore consumer beliefs about health hazards in infant foods by analyzing data gathered from the web, focusing on forums for parents in the UK. After selecting a subset of posts and classifying them by topic, according to the food product discussed and the health hazard discussed, two types of analyses were performed. Pearson correlation of term-occurrences highlighted what hazard-product pairs are most prevalent. Ordinary Least Squares (OLS) regression performed on sentiment measures generated from the texts provided significant results indicating positive or negative sentiment, objective or subjective language, and confident or unconfident modality associated with different food products and health hazards. The results allow comparison between perceptions obtained in different countries in Europe and may lead to recommendations concerning information and communication priorities.",2023,10.3389/frai.2023.1080950
An algorithm for computing Schubert varieties of best fit with applications,"We propose the geometric framework of the Schubert variety as a tool for representing a collection of subspaces of a fixed vector space. Specifically, given a collection of l-dimensional subspaces V1, …, Vr of ℝn, represented as the column spaces of matrices X1, …, Xr, we seek to determine a representative matrix K∈ℝn×k such that each subspace Vi intersects (or comes close to intersecting) the span of the columns of K in at least c dimensions. We formulate a non-convex optimization problem to determine such a K along with associated sets of vectors {ai} and {bi} used to express linear combinations of the columns of the Xi that are close to linear combinations of the columns of K. Further, we present a mechanism for integrating this representation into an artificial neural network architecture as a computational unit (which we refer to as an abstract node). The representative matrix K can be learned in situ, or sequentially, as part of a learning problem. Additionally, the matrix K can be employed as a change of coordinates in the learning problem. The set of all l-dimensional subspaces of ℝn that intersects the span of the columns of K in at least c dimensions is an example of a Schubert subvariety of the Grassmannian GR(l, n). When it is not possible to find a Schubert variety passing through a collection of points on GR(l, n), the goal of the non-convex optimization problem is to find the Schubert variety of best fit, i.e., the Schubert variety that comes as close as possible to the points. This may be viewed as an analog of finding a subspace of best fit to data in a vector space. The approach we take is well-suited to the modeling of collections of sets of data either as a stand-alone Schubert variety of best fit (SVBF), or in the processing workflow of a deep neural network. We present applications to some classification problems on sets of data to illustrate the behavior of the method.",2023,10.3389/frai.2023.1274830
Learning to play against any mixture of opponents,"Intuitively, experience playing against one mixture of opponents in a given domain should be relevant for a different mixture in the same domain. If the mixture changes, ideally we would not have to train from scratch, but rather could transfer what we have learned to construct a policy to play against the new mixture. We propose a transfer learning method, Q-Mixing, that starts by learning Q-values against each pure-strategy opponent. Then a Q-value for any distribution of opponent strategies is approximated by appropriately averaging the separately learned Q-values. From these components, we construct policies against all opponent mixtures without any further training. We empirically validate Q-Mixing in two environments: a simple grid-world soccer environment, and a social dilemma game. Our experiments find that Q-Mixing can successfully transfer knowledge across any mixture of opponents. Next, we consider the use of observations during play to update the believed distribution of opponents. We introduce an opponent policy classifier—trained reusing Q-learning data—and use the classifier results to refine the mixing of Q-values. Q-Mixing augmented with the opponent policy classifier performs better, with higher variance, than training directly against a mixed-strategy opponent.",2023,10.3389/frai.2023.804682
AI-assisted human clinical reasoning in the ICU: beyond “to err is human”,"Diagnostic errors pose a significant public health challenge, affecting nearly 800,000 Americans annually, with even higher rates globally. In the ICU, these errors are particularly prevalent, leading to substantial morbidity and mortality. The clinical reasoning process aims to reduce diagnostic uncertainty and establish a plausible differential diagnosis but is often hindered by cognitive load, patient complexity, and clinician burnout. These factors contribute to cognitive biases that compromise diagnostic accuracy. Emerging technologies like large language models (LLMs) offer potential solutions to enhance clinical reasoning and improve diagnostic precision. In this perspective article, we explore the roles of LLMs, such as GPT-4, in addressing diagnostic challenges in critical care settings through a case study of a critically ill patient managed with LLM assistance.",2024,10.3389/frai.2024.1506676
Decentralizing video copyright protection: a novel blockchain-enabled framework with performance evaluation,"IntroductionDigital content, including images and videos, is increasingly ruling the online world, and so multimedia services form a part of this modern life. However, the digital resources face significant problems, especially regarding copyright infringement. In such an instance, any modification without authority infringes intellectual property rights.MethodsBased on Inter Planetary File System (IPFS) and blockchain technology, a decentralized and distributed framework has been proposed in this study for dealing with insecurity over digital assets and openness of multimedia resources. In this respect, secure, transparent, and immutable transactions in regard to the transfer and ownership of creative works have been facilitated by the use of such a framework.ResultsThis paper proposes novel decentralized and Blockchain enabled framework to address the problem of video copyright protection by employing solidity based smart contract in a Ethereum network, that allows the content creators to register their videos. The designed smart contract performs copyright checks and release copyright disputes by generating and comparing perceptual hash’s (Phash) for original video and modified video.DiscussionPhash techniques play a crucial role in multimedia content analysis, particularly in verifying the integrity and similarity of the video data under various transformations. Additionally, the framework generates Inter Planetary File System (IPFS) main values that signifies the ownership of the video content. Then it compars the phash values, IPFS and similarly score in public Blockchain environment i.e. Ethereum. The framework performance was measured by simulating the contracts of the Application Binary Interface (ABI), JSON file in the Hyperledger Caliper environment. This result shows the performance in the form of video registration, the measured latency was 5.02 seconds with a throughput of 409.87 seconds. For video verification the latency was 4.57 seconds with a throughput of 484.23 seconds.",2025,10.3389/frai.2025.1655709
Does personality matter: examining the value of personality insights for personalized nudges that encourage the selection of learning resources,"Nudging is a mechanism aimed at influencing people's behavior while maintaining the individual's freedom of choice. Nudges have been adopted in learning contexts where individuals are responsible for shaping their learning and, at the same time, receive guidance from the system. Not everyone responds to nudges in the same way. While social science research indicates that individual differences play a crucial role in peoples' nudgeability, there has been little research examining computational approaches that explore how individual differences affect user responses to nudges (especially in a learning context). Two studies were conducted to explore how individual differences, specifically focusing on personality, can affect nudge response in the context of healthcare education, where individuals use resources as a part of their informal learning and professional development. Different nudges, designed based on personality characteristics, were provided to draw individual users' attention to educational resources to encourage user engagement. The findings indicate that personality insights can be a predictor for nudge selection, suggesting that different nudges may be more effective when recommending learning resources to people with different personality characteristics.",2024,10.3389/frai.2024.1211142
A dynamic multitask evolutionary algorithm for high-dimensional feature selection based on multi-indicator task construction and elite competition learning,"High-dimensional data often contain noisy and redundant features, posing challenges for accurate and efficient feature selection. To address this, a dynamic multitask learning framework is proposed, which integrates competitive learning and knowledge transfer within an evolutionary optimization setting. The framework begins by generating two complementary tasks through a multi-criteria strategy that combines multiple feature relevance indicators, ensuring both global comprehensiveness and local focus. These tasks are optimized in parallel using a competitive particle swarm optimization algorithm enhanced with hierarchical elite learning, where each particle learns from both winners and elite individuals to avoid premature convergence. To further improve optimization efficiency and diversity, a probabilistic elite-based knowledge transfer mechanism is introduced, allowing particles to selectively learn from elite solutions across tasks. Experimental results on 13 high-dimensional benchmark datasets demonstrate that the proposed algorithm achieves superior classification accuracy with fewer selected features compared to several state-of-the-art methods. Across 13 benchmarks, the proposed method achieves the highest accuracy on 11 out of 13 datasets and the fewest features on eight out of 13, with an average accuracy of 87.24% and an average dimensionality reduction of 96.2% (median 200 selected features), clearly validating its effectiveness in balancing exploration, exploitation, and knowledge sharing for robust feature selection.",2025,10.3389/frai.2025.1667167
Shape modeling of longitudinal medical images: from diffeomorphic metric mapping to deep learning,"Living biological tissue is a complex system, constantly growing and changing in response to external and internal stimuli. These processes lead to remarkable and intricate changes in shape. Modeling and understanding both natural and pathological (or abnormal) changes in the shape of anatomical structures is highly relevant, with applications in diagnostic, prognostic, and therapeutic healthcare. Nevertheless, modeling the longitudinal shape change of biological tissue is a non-trivial task due to its inherent nonlinear nature. In this review, we highlight several existing methodologies and tools for modeling longitudinal shape change (i.e., spatiotemporal shape modeling). These methods range from diffeomorphic metric mapping to deep-learning based approaches (e.g., autoencoders, generative networks, recurrent neural networks, etc.). We discuss the synergistic combinations of existing technologies and potential directions for future research, underscoring key deficiencies in the current research landscape.",2025,10.3389/frai.2025.1671099
AI in phishing detection: a bibliometric review,"Background
                    Phishing represents a category of cyber-attacks based on social engineering, with a significant impact on individuals and organizations, and a high capacity for reinvention by adapting its modus operandi according to technological advancements. With a relatively simple scenario and without using sophisticated technologies, phishing attacks exploit user vulnerabilities, convincing them to disclose sensitive personal or organizational data. Within anti-phishing solutions, the detection of spoofed URLs, counterfeit websites, and email or other types of messages that lure the user into entering their data in a form, plays an important role. Against this backdrop, artificial intelligence (AI) technologies, particularly Machine Learning (ML), have been successfully employed in phishing detection, with a rich body of literature in this field.
                  
                  
                    Objective
                    A review of the existing literature on phishing detection using AI was conducted. This study aims to fill this gap by providing comprehensive bibliometric analysis, complementing existing surveys in the field, focusing on the role of AI in phishing detection.
                  
                  
                    Methods
                    A total of 1096 documents focusing on AI, ML, Deep Learning (DL), or Natural Language Processing (NLP) in phishing detection were extracted from the Web of Science (WoS) scientific database. The information from these documents was subsequently loaded into the Biblioshiny (Bibliometrix package) and VOSviewer software.
                  
                  
                    Results
                    The dataset allowed for the identification of publication trends, influential documents and publications, patterns of author collaboration, and key topics of interest within the main author clusters. A thematic analysis of the field highlighted driving themes, niche themes, emerging and declining themes, and basic themes. Furthermore, thematic evolution over time was examined based on authors’ keywords. A thorough review of the most relevant articles identified through bibliometric analysis was conducted to discuss the primary methods of phishing detection using AI.
                  
                  
                    Conclusion
                    The research field of AI in phishing detection has evolved significantly starting with 2016, with a focus on using ML algorithms to identify phishing websites by extracting discriminative features, and experienced a consistent growth in 2024. Recent work emphasizes a shift from classical ML to DL, the importance of feature selection and engineering, and the use of hybrid models and classifier stacking.",2025,10.3389/frai.2025.1496580
Testing network clustering algorithms with natural language processing,"Introduction
                    We propose a hybrid methodology to evaluate the alignment between structural communities inferred from interaction networks and the linguistic coherence of users' textual production in online social networks. Understanding whether community structure reflects language use allows for a more nuanced validation of Community Detection Algorithms (CDAs) beyond assuming their outputs as ground truth.
                  
                  
                    Methods
                    Using Twitter data on climate change discussions, we compare several CDAs by training Natural Language Processing Classification Algorithms (NLPCA), such as BERTweet-based models, on the communities they generate. Classification accuracy serves as a proxy for the semantic coherence of CDA-induced groups. This comparative scoring approach offers a self-consistent framework for evaluating CDA performance without requiring manually annotated labels. We also introduce a coverage–precision trade-off metric to assess community-level performance.
                  
                  
                    Results
                    Our results show that the best CDA/NLPCA combinations predict a user's community with over 85% accuracy using only three short sentences. This demonstrates a strong alignment between structural and linguistic patterns in online discourse.
                  
                  
                    Discussion
                    Our framework enables scoring CDAs based on semantic predictability and allows prediction of community membership from minimal textual input. It offers practical benefits, such as providing proxy labels for low-supervision NLP tasks, and is adaptable to other social platforms. Limitations include potential noise in CDA-generated labels but the approach offers a generalizable method for evaluating CDA performance and the coherence of online social groups.",2025,10.3389/frai.2025.1635436
Learning private equity recommitment strategies for institutional investors,"Keeping strategic allocations at target level to maintain high exposure to private equity is a complex but essential task for investors who need to balance against the risk of default. Illiquidity and cashflow uncertainty are critical challenges especially when commitments are irrevocable. In this work, we propose to use a trustworthy and explainable A.I. approach to design recommitment strategies. Using intensive portfolios simulations and evolutionary computing, we show that efficient and dynamic recommitment strategies can be brought forth automatically.",2023,10.3389/frai.2023.1014317
Case Report: Utilizing AI and NLP to Assist with Healthcare and Rehabilitation During the COVID-19 Pandemic,"The COVID-19 pandemic has profoundly affected healthcare systems and healthcare delivery worldwide. Policy makers are utilizing social distancing and isolation policies to reduce the risk of transmission and spread of COVID-19, while the research, development, and testing of antiviral treatments and vaccines are ongoing. As part of these isolation policies, in-person healthcare delivery has been reduced, or eliminated, to avoid the risk of COVID-19 infection in high-risk and vulnerable populations, particularly those with comorbidities. Clinicians, occupational therapists, and physiotherapists have traditionally relied on in-person diagnosis and treatment of acute and chronic musculoskeletal (MSK) and neurological conditions and illnesses. The assessment and rehabilitation of persons with acute and chronic conditions has, therefore, been particularly impacted during the pandemic. This article presents a perspective on how Artificial Intelligence and Machine Learning (AI/ML) technologies, such as Natural Language Processing (NLP), can be used to assist with assessment and rehabilitation for acute and chronic conditions.",2021,10.3389/frai.2021.613637
Modelling societal preferences for automated vehicle behaviour with ethical goal functions,"Introduction
                    As automated vehicles (AVs) assume increasing decision-making responsibilities, ensuring their alignment with societal values becomes essential. Existing ethical frameworks for AVs have primarily remained conceptual, lacking empirical operationalization. To address this gap, this study develops an Ethical Goal Function (EGF)—a quantitative model that encodes societal moral preferences for AV decision-making—within the theoretical framework of Augmented Utilitarianism (AU). AU integrates consequentialist, deontological, and virtue-ethical principles while remaining adaptable to evolving societal values. This work also proposes embedding the EGF into a Socio-Technological Feedback (SOTEF) Loop, enabling continuous refinement of AV decision systems through stakeholder input.
                  
                  
                    Methods
                    The EGF was constructed using discrete choice experiments (DCEs) conducted with Dutch university students (N = 89). Participants evaluated AV-relevant moral scenarios characterized by six ethically salient attributes: physical harm, psychological harm, moral responsibility, fair innings, legality, and environmental harm. These attributes were derived from biomedical ethics and moral psychology and validated in prior AV ethics research. Using participants’ choices, a multinomial logit (MNL) model was estimated to derive attribute weights representing aggregate societal moral preferences. Model performance was evaluated using 5-fold cross-validation.
                  
                  
                    Results
                    The MNL model produced stable attribute weights across folds, achieving an average predictive accuracy of 63.8% (SD = 3.3%). These results demonstrate that the selected attributes and underlying AU-based framework can meaningfully predict participants’ ethical preferences in AV decision scenarios. The EGF thus represents a data-driven, empirically grounded method for translating societal moral judgments into computationally usable parameters for AV decision-making systems.
                  
                  
                    Discussion
                    This study contributes the first empirical operationalization of ethical frameworks for AVs through the development of an Ethical Goal Function and demonstrates how it can be embedded in a Socio-Technological Feedback (SOTEF) Loop for continuous societal alignment. The dual contribution advances both the theoretical grounding and practical implementation of human-centered ethics in automated decision-making. However, several limitations remain. The reliance on a Dutch university sample restricts cultural generalizability, and textual presentation may limit ecological validity. Future work should expand the cultural diversity of participants and compare alternative presentation modalities (e.g., visual, immersive) to better capture real-world decision contexts.",2025,10.3389/frai.2025.1676225
Remarks on Multimodality: Grammatical Interactions in the Parallel Architecture,"Language is typically embedded in multimodal communication, yet models of linguistic competence do not often incorporate this complexity. Meanwhile, speech, gesture, and/or pictures are each considered as indivisible components of multimodal messages. Here, we argue that multimodality should not be characterized by whole interacting behaviors, but by interactions of similar substructures which permeate across expressive behaviors. These structures comprise a unified architecture and align within Jackendoff's Parallel Architecture: a modality, meaning, and grammar. Because this tripartite architecture persists across modalities, interactions can manifest within each of these substructures. Interactions between modalities alone create correspondences in time (ex. speech with gesture) or space (ex. writing with pictures) of the sensory signals, while multimodal meaning-making balances how modalities carry “semantic weight” for the gist of the whole expression. Here we focus primarily on interactions between grammars, which contrast across two variables: symmetry, related to the complexity of the grammars, and allocation, related to the relative independence of interacting grammars. While independent allocations keep grammars separate, substitutive allocation inserts expressions from one grammar into those of another. We show that substitution operates in interactions between all three natural modalities (vocal, bodily, graphic), and also in unimodal contexts within and between languages, as in codeswitching. Altogether, we argue that unimodal and multimodal expressions arise as emergent interactive states from a unified cognitive architecture, heralding a reconsideration of the “language faculty” itself.",2022,10.3389/frai.2021.778060
Association of Shanghai air pollution with postoperative infection in adolescent orthopedic patients: a study using a deep learning-based evolutionary model,"Background
                    Surgical site infections (SSI) represent severe complications in adolescent orthopedic surgery. Shanghai’s complex air pollution profile creates a critical context to investigate multi-pollutant impacts on SSI risk in this vulnerable population.
                  
                  
                    Methods
                    We analyzed 32,261 adolescent SSI cases from Shanghai (2019–2024) alongside high-resolution pollution/meteorological data. An evolutionary deep learning model (CNN-BiGRU-Attention optimized by Improved StarFish Algorithm) and generalized additive models (GAMs) assessed lagged effects, age/gender stratification, and concentration-response relationships.
                  
                  
                    Results
                    
                      NO
                      2
                      and SO
                      2
                      showed significantly positive associations with SSI risk at lag0 (concurrent day); O
                      3
                      exhibited protective effects (strongest at lag05: −2.396% [95% CI: −3.349% to −1.443%] per 10 μg/m
                      3
                      increase); Age stratification: 7–14 ages groups demonstrated heightened sensitivity to NO
                      2
                      /SO
                      2
                      . O
                      3
                      effects varied across age groups; Gender differences: O
                      3
                      ’s negative association was stronger in males; Dose–response: NO
                      2
                      /SO
                      2
                      showed monotonic increases with no safety thresholds; O
                      3
                      displayed a straight line curve.
                    
                  
                  
                    Conclusion
                    
                      Multi-pollutant exposure modulates SSI risk in adolescents, with NO
                      2
                      /SO
                      2
                      as risk factors and O
                      3
                      showing context-dependent protection. Deep learning identified SO
                      2
                      /NO
                      2
                      /O
                      3
                      as dominant predictors, supporting perioperative air-quality interventions.",2025,10.3389/frai.2025.1692207
A hybrid deep learning-based approach for optimal genotype by environment selection,"The ability to accurately predict the yields of different crop genotypes in response to weather variability is crucial for developing climate resilient crop cultivars. Genotype-environment interactions introduce large variations in crop-climate responses, and are hard to factor in to breeding programs. Data-driven approaches, particularly those based on machine learning, can help guide breeding efforts by factoring in genotype-environment interactions when making yield predictions. Using a new yield dataset containing 93,028 records of soybean hybrids across 159 locations, 28 states, and 13 years, with 5,838 distinct genotypes and daily weather data over a 214-day growing season, we developed two convolutional neural network (CNN) models: one that integrates CNN and fully-connected neural networks (CNN model), and another that incorporates a long short-term memory (LSTM) layer after the CNN component (CNN-LSTM model). By applying the Generalized Ensemble Method (GEM), we combined the CNN-based models and optimized their weights to improve overall predictive performance. The dataset provided unique genotype information on seeds, enabling an investigation into the potential of planting different genotypes based on weather variables. We employed the proposed GEM model to identify the best-performing genotypes across various locations and weather conditions, making yield predictions for all potential genotypes in each specific setting. To assess the performance of the GEM model, we evaluated it on unseen genotype-location combinations, simulating real-world scenarios where new genotypes are introduced. By combining the base models, the GEM ensemble approach provided much better prediction accuracy compared to using the CNN-LSTM model alone and slightly better accuracy than the CNN model, as measured by both RMSE and MAE on the validation and test sets. The proposed data-driven approach can be valuable for genotype selection in scenarios with limited testing years. In addition, we explored the impact of incorporating state-level soil data alongside the weather, location, genotype and year variables. Due to data constraints, including the absence of latitude and longitude details, we used uniform soil variables for all locations within the same state. This limitation restricted our spatial information to state-level knowledge. Our findings suggested that integrating state-level soil variables did not substantially enhance the predictive capabilities of the models. We also performed a feature importance analysis using RMSE change to identify crucial predictors. Location showed the highest RMSE change, followed by genotype and year. Among weather variables, maximum direct normal irradiance (MDNI) and average precipitation (AP) displayed higher RMSE changes, indicating their importance.",2024,10.3389/frai.2024.1312115
Evaluating the accuracy of ChatGPT in delivering patient instructions for medications: an exploratory case study,"BackgroundThe use of ChatGPT in healthcare is still in its early stages; however, it has the potential to become a cornerstone in modern healthcare systems. This study aims to assess the accuracy of output of ChatGPT compared with those of CareNotes® in providing patient instructions for three medications: tirzepatide, citalopram, and apixaban.MethodsAn exploratory case study was conducted using a published questionnaire to evaluate ChatGPT-generated reports against patient instructions from CareNotes®. The evaluation focused on the completeness and correctness of the reports, as well as their potential to cause harm or lead to poor medication adherence. The evaluation was conducted by four pharmacy experts and 33 PharmD interns.ResultsThe evaluators indicated that the ChatGPT reports of tirzepatide, citalopram, and apixaban were correct but lacked completeness. Additionally, ChatGPT reports have the potential to cause harm and may negatively affect medication adherence.ConclusionAlthough ChatGPT demonstrated promising results, particularly in terms of correctness, it cannot yet be considered a reliable standalone source of patient drug information.",2025,10.3389/frai.2025.1550591
Deep Learning and its Application for Healthcare Delivery in Low and Middle Income Countries,"As anyone who has witnessed firsthand knows, healthcare delivery in low-resource settings is fundamentally different from more affluent settings. Artificial Intelligence, including Machine Learning and more specifically Deep Learning, has made amazing advances over the past decade. Significant resources are now dedicated to problems in the field of medicine, but with the potential to further the digital divide by neglecting underserved areas and their specific context. In the general case, Deep Learning remains a complex technology requiring deep technical expertise. This paper explores advances within the narrower field of deep learning image analysis that reduces barriers to adoption and allows individuals with less specialized software skills to effectively employ these techniques. This enables a next wave of innovation, driven largely by problem domain expertise and the creative application of this technology to unaddressed concerns in LMIC settings. The paper also explores the central role of NGOs in problem identification, data acquisition and curation, and integration of new technologies into healthcare systems.",2021,10.3389/frai.2021.553987
Exploring ChatGPT’s potential in the clinical stream of neurorehabilitation,"In several medical fields, generative AI tools such as ChatGPT have achieved optimal performance in identifying correct diagnoses only by evaluating narrative clinical descriptions of cases. The most active fields of application include oncology and COVID-19-related symptoms, with preliminary relevant results also in psychiatric and neurological domains. This scoping review aims to introduce the arrival of ChatGPT applications in neurorehabilitation practice, where such AI-driven solutions have the potential to revolutionize patient care and assistance. First, a comprehensive overview of ChatGPT, including its design, and potential applications in medicine is provided. Second, the remarkable natural language processing skills and limitations of these models are examined with a focus on their use in neurorehabilitation. In this context, we present two case scenarios to evaluate ChatGPT ability to resolve higher-order clinical reasoning. Overall, we provide support to the first evidence that generative AI can meaningfully integrate as a facilitator into neurorehabilitation practice, aiding physicians in defining increasingly efficacious diagnostic and personalized prognostic plans.",2024,10.3389/frai.2024.1407905
Contextual emotion detection in images using deep learning,"Introduction
                    Computerized sentiment detection, based on artificial intelligence and computer vision, has become essential in recent years. Thanks to developments in deep neural networks, this technology can now account for environmental, social, and cultural factors, as well as facial expressions. We aim to create more empathetic systems for various purposes, from medicine to interpreting emotional interactions on social media.
                  
                  
                    Methods
                    To develop this technology, we combined authentic images from various databases, including EMOTIC (ADE20K, MSCOCO), EMODB_SMALL, and FRAMESDB, to train our models. We developed two sophisticated algorithms based on deep learning techniques, DCNN and VGG19. By optimizing the hyperparameters of our models, we analyze context and body language to improve our understanding of human emotions in images. We merge the 26 discrete emotional categories with the three continuous emotional dimensions to identify emotions in context. The proposed pipeline is completed by fusing our models.
                  
                  
                    Results
                    We adjusted the parameters to outperform previous methods in capturing various emotions in different contexts. Our study showed that the Sentiment_recognition_model and VGG19_contexte increased mAP by 42.81% and 44.12%, respectively, surpassing the results of previous studies.
                  
                  
                    Discussion
                    This groundbreaking research could significantly improve contextual emotion recognition in images. The implications of these promising results are far-reaching, extending to diverse fields such as social robotics, affective computing, human-machine interaction, and human-robot communication.",2024,10.3389/frai.2024.1386753
Research on the robustness of the open-world test-time training model,"Introduction
                    Generalizing deep learning models to unseen target domains with low latency has motivated research into test-time training/adaptation (TTT/TTA). However, deploying TTT/TTA in open-world environments is challenging due to the difficulty in distinguishing between strong out-of-distribution (OOD) samples and regular weak OOD samples. While emerging Open-World TTT (OWTTT) approaches address this challenge, they introduce a new vulnerability: test-time poisoning attacks. These attacks differ fundamentally from traditional poisoning attacks that occur during model training, as adversaries cannot intervene in the training process itself.
                  
                  
                    Methods
                    In response to this threat, we design a novel test-time poisoning attack method specifically targeting OWTTT models. Capitalizing on the fact that model gradients dynamically change during testing, our method employs a single-step query-based approach to dynamically generate and update adversarial perturbations. These perturbations are then input into the OWTTT model during its adaptation phase.
                  
                  
                    Results
                    We extensively test our attack method on an OWTTT model. The experimental results demonstrate a significant vulnerability, showing that the OWTTT model's performance can be effectively compromised by our test-time poisoning attack.
                  
                  
                    Discussion
                    Our findings reveal that OWTTT algorithms lacking rigorous security assessment against such attacks are unsuitable for real-world deployment. Consequently, we strongly advocate for the integration of defenses against test-time poisoning attacks into the fundamental design of future open-world test-time training methodologies.",2025,10.3389/frai.2025.1621025
An analysis of artificial intelligence automation in digital music streaming platforms for improving consumer subscription responses: a review,"The rapid adoption and evolving nature of artificial intelligence (AI) is playing a significant role in shaping the music streaming industry. AI has become a key player in transforming the digital music streaming industry, particularly in enhancing user experiences and driving subscription growth. Through AI automation, platforms personalize music recommendations, optimize subscription offerings, and improve customer support services. This article reviews the role of AI in driving consumer subscription behaviors on digital music streaming platforms (DMSP), with a focus on recommendation algorithms, dynamic pricing models, marketing automation, and the future of AI in the music industry. Potential challenges related to privacy, ethics, and algorithmic biases are also discussed, showcasing how AI is revolutionizing the music streaming industry.",2025,10.3389/frai.2024.1515716
An Overcomplete Approach to Fitting Drift-Diffusion Decision Models to Trial-By-Trial Data,"Drift-diffusion models or DDMs are becoming a standard in the field of computational neuroscience. They extend models from signal detection theory by proposing a simple mechanistic explanation for the observed relationship between decision outcomes and reaction times (RT). In brief, they assume that decisions are triggered once the accumulated evidence in favor of a particular alternative option has reached a predefined threshold. Fitting a DDM to empirical data then allows one to interpret observed group or condition differences in terms of a change in the underlying model parameters. However, current approaches only yield reliable parameter estimates in specific situations (c.f. fixed drift rates vs drift rates varying over trials). In addition, they become computationally unfeasible when more general DDM variants are considered (e.g., with collapsing bounds). In this note, we propose a fast and efficient approach to parameter estimation that relies on fitting a “self-consistency” equation that RT fulfill under the DDM. This effectively bypasses the computational bottleneck of standard DDM parameter estimation approaches, at the cost of estimating the trial-specific neural noise variables that perturb the underlying evidence accumulation process. For the purpose of behavioral data analysis, these act as nuisance variables and render the model “overcomplete,” which is finessed using a variational Bayesian system identification scheme. However, for the purpose of neural data analysis, estimates of neural noise perturbation terms are a desirable (and unique) feature of the approach. Using numerical simulations, we show that this “overcomplete” approach matches the performance of current parameter estimation approaches for simple DDM variants, and outperforms them for more complex DDM variants. Finally, we demonstrate the added-value of the approach, when applied to a recent value-based decision making experiment.",2021,10.3389/frai.2021.531316
Non-linearity of Metabolic Pathways Critically Influences the Choice of Machine Learning Model,"The use of machine learning (ML) in life sciences has gained wide interest over the past years, as it speeds up the development of high performing models. Important modeling tools in biology have proven their worth for pathway design, such as mechanistic models and metabolic networks, as they allow better understanding of mechanisms involved in the functioning of organisms. However, little has been done on the use of ML to model metabolic pathways, and the degree of non-linearity associated with them is not clear. Here, we report the construction of different metabolic pathways with several linear and non-linear ML models. Different types of data are used; they lead to the prediction of important biological data, such as pathway flux and final product concentration. A comparison reveals that the data features impact model performance and highlight the effectiveness of non-linear models (e.g., QRF: RMSE = 0.021 nmol·min−1 and R2 = 1 vs. Bayesian GLM: RMSE = 1.379 nmol·min−1 R2 = 0.823). It turns out that the greater the degree of non-linearity of the pathway, the better suited a non-linear model will be. Therefore, a decision-making support for pathway modeling is established. These findings generally support the hypothesis that non-linear aspects predominate within the metabolic pathways. This must be taken into account when devising possible applications of these pathways for the identification of biomarkers of diseases (e.g., infections, cancer, neurodegenerative diseases) or the optimization of industrial production processes.",2022,10.3389/frai.2022.744755
The privacy-explainability trade-off: unraveling the impacts of differential privacy and federated learning on attribution methods,"Since the advent of deep learning (DL), the field has witnessed a continuous stream of innovations. However, the translation of these advancements into practical applications has not kept pace, particularly in safety-critical domains where artificial intelligence (AI) must meet stringent regulatory and ethical standards. This is underscored by the ongoing research in eXplainable AI (XAI) and privacy-preserving machine learning (PPML), which seek to address some limitations associated with these opaque and data-intensive models. Despite brisk research activity in both fields, little attention has been paid to their interaction. This work is the first to thoroughly investigate the effects of privacy-preserving techniques on explanations generated by common XAI methods for DL models. A detailed experimental analysis is conducted to quantify the impact of private training on the explanations provided by DL models, applied to six image datasets and five time series datasets across various domains. The analysis comprises three privacy techniques, nine XAI methods, and seven model architectures. The findings suggest non-negligible changes in explanations through the implementation of privacy measures. Apart from reporting individual effects of PPML on XAI, the paper gives clear recommendations for the choice of techniques in real applications. By unveiling the interdependencies of these pivotal technologies, this research marks an initial step toward resolving the challenges that hinder the deployment of AI in safety-critical settings.",2024,10.3389/frai.2024.1236947
Hyperdimensional computing with holographic and adaptive encoder,"IntroductionBrain-inspired computing has become an emerging field, where a growing number of works focus on developing algorithms that bring machine learning closer to human brains at the functional level. As one of the promising directions, Hyperdimensional Computing (HDC) is centered around the idea of having holographic and high-dimensional representation as the neural activities in our brains. Such representation is the fundamental enabler for the efficiency and robustness of HDC. However, existing HDC-based algorithms suffer from limitations within the encoder. To some extent, they all rely on manually selected encoders, meaning that the resulting representation is never adapted to the tasks at hand.MethodsIn this paper, we propose FLASH, a novel hyperdimensional learning method that incorporates an adaptive and learnable encoder design, aiming at better overall learning performance while maintaining good properties of HDC representation. Current HDC encoders leverage Random Fourier Features (RFF) for kernel correspondence and enable locality-preserving encoding. We propose to learn the encoder matrix distribution via gradient descent and effectively adapt the kernel for a more suitable HDC encoding.ResultsOur experiments on various regression datasets show that tuning the HDC encoder can significantly boost the accuracy, surpassing the current HDC-based algorithm and providing faster inference than other baselines, including RFF-based kernel ridge regression.DiscussionThe results indicate the importance of an adaptive encoder and customized high-dimensional representation in HDC.",2024,10.3389/frai.2024.1371988
Sentiment Analysis of Students’ Feedback in MOOCs: A Systematic Literature Review,"In recent years, sentiment analysis (SA) has gained popularity among researchers in various domains, including the education domain. Particularly, sentiment analysis can be applied to review the course comments in massive open online courses (MOOCs), which could enable instructors to easily evaluate their courses. This article is a systematic literature review on the use of sentiment analysis for evaluating students’ feedback in MOOCs, exploring works published between January 1, 2015, and March 4, 2021. To the best of our knowledge, this systematic review is the first of its kind. We have applied a stepwise PRISMA framework to guide our search process, by searching for studies in six electronic research databases (ACM, IEEE, ScienceDirect, Springer, Scopus, and Web of Science). Our review identified 40 relevant articles out of 440 that were initially found at the first stage. From the reviewed literature, we found that the research has revolved around six areas: MOOC content evaluation, feedback contradiction detection, SA effectiveness, SA through social network posts, understanding course performance and dropouts, and MOOC design model evaluation. In the end, some recommendations are provided and areas for future research directions are identified.",2021,10.3389/frai.2021.728708
Transforming glaucoma diagnosis: transformers at the forefront,"Although the Vision Transformer architecture has become widely accepted as the standard for image classification tasks, using it for object detection in computer vision poses significant challenges. This research aims to explore the potential of extending the Vision Transformer for object detection in medical imaging, specifically for glaucoma detection, and also includes an examination of the Detection Transformer for comparative analysis. The analysis involves assessing the cup-to-disc ratio and identifying signs of vertical thinning of the neuroretinal rim. A diagnostic threshold is proposed, flagging a cup-to-disc ratio exceeding 0.6 as a potential indicator of glaucoma. The experimental results demonstrate a remarkable 90.48% accuracy achieved by the pre-trained Detection Transformer, while the Vision Transformer exhibits competitive accuracy at 87.87%. Comparative evaluations leverage a previously untapped dataset from the Standardized Fundus Glaucoma Dataset available on Kaggle, providing valuable insights into automated glaucoma detection. The evaluation criteria and results are comprehensively validated by medical experts specializing in the field of glaucoma.",2024,10.3389/frai.2024.1324109
Ethical Questions Raised by AI-Supported Mentoring in Higher Education,"Mentoring is a highly personal and individual process, in which mentees take advantage of expertise and experience to expand their knowledge and to achieve individual goals. The emerging use of AI in mentoring processes in higher education not only necessitates the adherence to applicable laws and regulations (e.g., relating to data protection and non-discrimination) but further requires a thorough understanding of ethical norms, guidelines, and unresolved issues (e.g., integrity of data, safety, and security of systems, and confidentiality, avoiding bias, insuring trust in and transparency of algorithms). Mentoring in Higher Education requires one of the highest degrees of trust, openness, and social–emotional support, as much is at the stake for mentees, especially their academic attainment, career options, and future life choices. However, ethical compromises seem to be common when digital systems are introduced, and the underlying ethical questions in AI-supported mentoring are still insufficiently addressed in research, development, and application. One of the challenges is to strive for privacy and data economy on the one hand, while Big Data is the prerequisite of AI-supported environments on the other hand. How can ethical norms and general guidelines of AIED be respected in complex digital mentoring processes? This article strives to start a discourse on the relevant ethical questions and in this way raise awareness for the ethical development and use of future data-driven, AI-supported mentoring environments in higher education.",2021,10.3389/frai.2021.624050
A Survey on Human Cancer Categorization Based on Deep Learning,"In recent years, we have witnessed the fast growth of deep learning, which involves deep neural networks, and the development of the computing capability of computer devices following the advance of graphics processing units (GPUs). Deep learning can prototypically and successfully categorize histopathological images, which involves imaging classification. Various research teams apply deep learning to medical diagnoses, especially cancer diseases. Convolutional neural networks (CNNs) detect the conventional visual features of disease diagnoses, e.g., lung, skin, brain, prostate, and breast cancer. A CNN has a procedure for perfectly investigating medicinal science images. This study assesses the main deep learning concepts relevant to medicinal image investigation and surveys several charities in the field. In addition, it covers the main categories of imaging procedures in medication. The survey comprises the usage of deep learning for object detection, classification, and human cancer categorization. In addition, the most popular cancer types have also been introduced. This article discusses the Vision-Based Deep Learning System among the dissimilar sorts of data mining techniques and networks. It then introduces the most extensively used DL network category, which is convolutional neural networks (CNNs) and investigates how CNN architectures have evolved. Starting with Alex Net and progressing with the Google and VGG networks, finally, a discussion of the revealed challenges and trends for upcoming research is held.",2022,10.3389/frai.2022.884749
Topology Applied to Machine Learning: From Global to Local,"Through the use of examples, we explain one way in which applied topology has evolved since the birth of persistent homology in the early 2000s. The first applications of topology to data emphasized the global shape of a dataset, such as the three-circle model for 3 × 3 pixel patches from natural images, or the configuration space of the cyclo-octane molecule, which is a sphere with a Klein bottle attached via two circles of singularity. In these studies of global shape, short persistent homology bars are disregarded as sampling noise. More recently, however, persistent homology has been used to address questions about the local geometry of data. For instance, how can local geometry be vectorized for use in machine learning problems? Persistent homology and its vectorization methods, including persistence landscapes and persistence images, provide popular techniques for incorporating both local geometry and global topology into machine learning. Our meta-hypothesis is that the short bars are as important as the long bars for many machine learning tasks. In defense of this claim, we survey applications of persistent homology to shape recognition, agent-based modeling, materials science, archaeology, and biology. Additionally, we survey work connecting persistent homology to geometric features of spaces, including curvature and fractal dimension, and various methods that have been used to incorporate persistent homology into machine learning.",2021,10.3389/frai.2021.668302
XAI-MRI: an ensemble dual-modality approach for 3D brain tumor segmentation using magnetic resonance imaging,"Brain tumor segmentation from Magnetic Resonance Images (MRI) presents significant challenges due to the complex nature of brain tumor tissues. This complexity poses a significant challenge in distinguishing tumor tissues from healthy tissues, particularly when radiologists rely on manual segmentation. Reliable and accurate segmentation is crucial for effective tumor grading and treatment planning. In this paper, we proposed a novel ensemble dual-modality approach for 3D brain tumor segmentation using MRI. Initially, individual U-Net models are trained and evaluated on single MRI modalities (T1, T2, T1ce, and FLAIR) to establish each modality's performance. Subsequently, we trained U-net models using combinations of the best-performing modalities to exploit the complementary information and improve segmentation accuracy. Finally, we introduced the ensemble dual-modality by combining the two best-performing pre-trained dual-modalities models to enhance segmentation performance. Experimental results show that the proposed model enhanced the segmentation result and achieved a Dice Coefficient of 97.73% and a Mean IoU of 60.08%. The results illustrate that the ensemble dual-modality approach outperforms single-modality and dual-modality models. Grad-CAM visualizations are implemented, generating heat maps that highlight tumor regions and provide useful information to clinicians about how the model made the decision, increasing their confidence in using deep learning-based systems. Our code publicly available at:
                    https://github.com/Ahmeed-Suliman-Farhan/Ensemble-Dual-Modality-Approach
                    .",2025,10.3389/frai.2025.1525240
Evaluation of vision transformers for the detection of fullness of garbage bins for efficient waste management,"Efficient waste management is crucial for urban environments to maintain cleanliness, reduce environmental impact, and optimize resource allocation. Traditional waste collection systems often rely on scheduled pickups or manual inspections, leading to inefficient resource utilization and potential overflow issues. This paper presents a novel approach to automate the detection of garbage container fullness from images using machine learning techniques. More specifically, we explore three transformer-based architectures, namely, vision transformer, Swin transformer, and pyramid vision transformer to classify input images of garbage bins as clean or dirty. Our experimental results on the publicly available Clean dirty containers in Montevideo dataset suggest that transformer-based architectures are effective in garbage fullness detection. Moreover, a comparison with existing methods reveals that the proposed approach using the vision transformer surpasses the state-of-the-art, achieving a 96.74% accuracy in detecting garbage container fullness. In addition, the generalizability of the proposed approach is evaluated by testing the transformer-based classification frameworks on a synthetic image dataset generated using various generative AI models. The proposed approach achieved a highest test accuracy of 80% on this synthetic dataset, thereby highlighting its ability to generalize across different datasets. Synthetic dataset used in this work can be found at: https://www.kaggle.com/datasets/6df0652d2c4eb3b9f00043c40fba0afa0778b46d7c0685e212807c2f6967fe6f.",2025,10.3389/frai.2025.1612080
AI-enabled workforce integration: blended human resource contribution rate in Chinese companies,"IntroductionWith the development of AI technology, the employment mode of companies is undergoing unprecedented changes.MethodsThe paper defines the composition of blended human resources of a company as three types of formal employees, flexible workers and intelligent machine workers, constructs a blended human resource contribution rate calculation method based on BP-MIV, and analyzes the data of automobile manufacturing companies in 2022.ResultsThe results show that the contribution rate of blended human resources to company performance is 73.81%. Among them, the contribution rate of formal employees is 19.55%, while flexible workers and intelligent machine workers, despite their significantly smaller proportion in number compared to formal employees, have contribution rates of 20.26% and 34.00%, respectively. In further discussions, the calculation results of the blended human resource contribution rate based on the production function method were compared with those based on the BP-MIV method.DiscussionThe findings indicate that the BP-MIV-based calculation method exhibits certain advantages in capturing nonlinear relationships, such as the synergistic effects of various types of blended human resources on company performance. This study attempts to propose a preliminary theoretical framework and methodological approach for blended human resource management research in the AI era.",2025,10.3389/frai.2025.1645172
Assessing Open-Ended Human-Computer Collaboration Systems: Applying a Hallmarks Approach,"There is a growing desire to create computer systems that can collaborate with humans on complex, open-ended activities. These activities typically have no set completion criteria and frequently involve multimodal communication, extensive world knowledge, creativity, and building structures or compositions through multiple steps. Because these systems differ from question and answer (Q&amp;A) systems, chatbots, and simple task-oriented assistants, new methods for evaluating such collaborative computer systems are needed. Here, we present a set of criteria for evaluating these systems, calledHallmarks of Human-Machine Collaboration. The Hallmarks build on the success of heuristic evaluation used by the user interface community and past evaluation techniques used in the spoken language and chatbot communities. They consist of observable characteristics indicative of successful collaborative communication, grouped into eight high-level properties: robustness; habitability; mutual contribution of meaningful content; context-awareness; consistent human engagement; provision of rationale; use of elementary concepts to teach and learn new concepts; and successful collaboration. We present examples of how we used these Hallmarks in the DARPA Communicating with Computers (CwC) program to evaluate diverse activities, including story and music generation, interactive building with blocks, and exploration of molecular mechanisms in cancer. We used the Hallmarks as guides for developers and as diagnostics, assessing systems with the Hallmarks to identify strengths and opportunities for improvement using logs from user studies, surveying the human partner, third-party review of creative products, and direct tests. Informal feedback from CwC technology developers indicates that the use of the Hallmarks for program evaluation helped guide development. The Hallmarks also made it possible to identify areas of progress and major gaps in developing systems where the machine is an equal, creative partner.",2021,10.3389/frai.2021.670009
Machine learning techniques for improved prediction of cardiovascular diseases using integrated healthcare data,"Cardiovascular disease continues to cause an important global health challenge, highlighting the critical importance of early detection in mitigating cardiac-related issues. There is a significant demand for reliable diagnostic alternatives. Taking advantage of health data through diverse machine learning algorithms may offer a more precise diagnostic approach. Machine learning-based decision support systems that utilize patients’ clinical parameters present a promising solution for diagnosing cardiovascular disease. In this research, we collected extensive publicly available healthcare records. We integrated medical datasets based on common features to implement several machine learning models aimed at exploring the potential for more robust predictions of cardiovascular disease (CVD). The merged dataset initially contained 323,680 samples sourced from multiple databases. Following data preprocessing steps including cleaning, alignment of features, and removal of missing values, the final dataset consisted of 311,710 samples used for model training and evaluation. In our experiments, the CatBoost model achieved the highest area under the curve (AUC) of up to 94.1%.",2025,10.3389/frai.2025.1694450
Detecting early gastrointestinal polyps in histology and endoscopy images using deep learning,"IntroductionThe GastroIntestinal Cancer (GIC) is one of the most common tumors in terms of deaths and diseases. Artificial Intelligence (AI) domains such as Deep Learning (DL) have the potential to greatly improve the early identification of disease. Nevertheless, a lot of current technologies are still insufficient to detect tumors, which is why we created an approach using advanced method to identify polyps.MethodsOur three-stage deep learning-based method requires constructing an Encoder-Decoder Network (EDN) to determine the Region of Interest (ROI) in preprocessing, feature selection with pretrained models such as VGG16, VGG19, ResNet50 and InceptionV3, and Support Vector Machine (SVM) classifier to separate affected individuals from normal ones during the classification stage. Five datasets, such as CRC-VAL-HE-7K, CRC-VAL-HE-100K, Kvasir_v2, a dataset from Beijing Cancer Hospital, and a weakly labeled dataset, containing histology and endoscopic images, were utilized to train and evaluate our method.ResultsThe outcomes showed the effectiveness of our approach, with these pretrained models obtaining the best efficiency for recognizing gastrointestinal polyps. ResNet50 attained the maximum accuracy on datasets 1, 2, and 4, with performances of 97.01%, 96.49%, and 98.90%, respectively. Also, VGG16 and VGG19 performed 96.64% and 98.75% accuracy on datasets 3 and 5, respectively. However, InceptionV3 scored slightly less well than the other model.DiscussionThe advanced method produced promising results for the early detection of gastrointestinal cancer in multiple datasets.",2025,10.3389/frai.2025.1571075
A synthetic segmentation dataset generator using a 3D modeling framework and raycaster: a mining industry application,"Many industries utilize deep learning methods to increase efficiency and reduce costs. One of these methods, image segmentation, is used for object detection and recognition in localization and mapping. Segmentation models are trained using labeled datasets; however, manually creating datasets for every application, including deep-level mining, is time-consuming and typically expensive. Recently, many papers have shown that using synthetic datasets (digital recreations of real-world scenes) for training produces highly-accurate segmentation models. This paper proposes a synthetic segmentation dataset generator using a 3D modeling framework and raycaster. The generator was applied to a deep-level mining case study and produced a dataset containing labeled images of scenes typically found in this environment, therefore removing the requirement to create the dataset manually. Validation showed high accuracy segmentation after model training using the generated dataset (compared to other applications that use real-world datasets). Furthermore, the generator can be customized to produce datasets for many other applications.",2024,10.3389/frai.2024.1453931
How to train a self-driving vehicle: On the added value (or lack thereof) of curriculum learning and replay buffers,"Learning from only real-world collected data can be unrealistic and time consuming in many scenario. One alternative is to use synthetic data as learning environments to learn rare situations and replay buffers to speed up the learning. In this work, we examine the hypothesis of how the creation of the environment affects the training of reinforcement learning agent through auto-generated environment mechanisms. We take the autonomous vehicle as an application. We compare the effect of two approaches to generate training data for artificial cognitive agents. We consider the added value of curriculum learning—just as in human learning—as a way to structure novel training data that the agent has not seen before as well as that of using a replay buffer to train further on data the agent has seen before. In other words, the focus of this paper is on characteristics of the training data rather than on learning algorithms. We therefore use two tasks that are commonly trained early on in autonomous vehicle research: lane keeping and pedestrian avoidance. Our main results show that curriculum learning indeed offers an additional benefit over a vanilla reinforcement learning approach (using Deep-Q Learning), but the replay buffer actually has a detrimental effect in most (but not all) combinations of data generation approaches we considered here. The benefit of curriculum learning does depend on the existence of a well-defined difficulty metric with which various training scenarios can be ordered. In the lane-keeping task, we can define it as a function of the curvature of the road, in which the steeper and more occurring curves on the road, the more difficult it gets. Defining such a difficulty metric in other scenarios is not always trivial. In general, the results of this paper emphasize both the importance of considering data characterization, such as curriculum learning, and the importance of defining an appropriate metric for the task.",2023,10.3389/frai.2023.1098982
Counterfactual learning in enhancing resilience in autonomous agent systems,"Resilience in autonomous agent systems is about having the capacity to anticipate, respond to, adapt to, and recover from adverse and dynamic conditions in complex environments. It is associated with the intelligence possessed by the agents to preserve the functionality or to minimize the impact on functionality through a transformation, reconfiguration, or expansion performed across the system. Enhancing the resilience of systems could pave way toward higher autonomy allowing them to tackle intricate dynamic problems. The state-of-the-art systems have mostly focussed on improving the redundancy of the system, adopting decentralized control architectures, and utilizing distributed sensing capabilities. While machine learning approaches for efficient distribution and allocation of skills and tasks have enhanced the potential of these systems, they are still limited when presented with dynamic environments. To move beyond the current limitations, this paper advocates incorporating counterfactual learning models for agents to enable them with the ability to predict possible future conditions and adjust their behavior. Counterfactual learning is a topic that has recently been gaining attention as a model-agnostic and post-hoc technique to improve explainability in machine learning models. Using counterfactual causality can also help gain insights into unforeseen circumstances and make inferences about the probability of desired outcomes. We propose that this can be used in agent systems as a means to guide and prepare them to cope with unanticipated environmental conditions. This supplementary support for adaptation can enable the design of more intelligent and complex autonomous agent systems to address the multifaceted characteristics of real-world problem domains.",2023,10.3389/frai.2023.1212336
Interpreting vision and language generative models with semantic visual priors,"When applied to Image-to-text models, explainability methods have two challenges. First, they often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. This makes explanations expensive to compute and unable to comprehensively explain the model's output. Second, for models with visual inputs, explainability methods such as SHAP typically consider superpixels as features. Since superpixels do not correspond to semantically meaningful regions of an image, this makes explanations harder to interpret. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized to a large family of vision-language models.",2023,10.3389/frai.2023.1220476
Acronyms and Opportunities for Improving Deep Nets,"Recently, several studies have reported promising results with BERT-like methods on acronym tasks. In this study, we find an older rule-based program, Ab3P, not only performs better, but error analysis suggests why. There is a well-known spelling convention in acronyms where each letter in the short form (SF) refers to “salient” letters in the long form (LF). The error analysis uses decision trees and logistic regression to show that there is an opportunity for many pre-trained models (BERT, T5, BioBert, BART, ERNIE) to take advantage of this spelling convention.",2021,10.3389/frai.2021.732381
Exploring the Representations of Individual Entities in the Brain Combining EEG and Distributional Semantics,"Semantic knowledge about individual entities (i.e., the referents of proper names such as Jacinta Ardern) is fine-grained, episodic, and strongly social in nature, when compared with knowledge about generic entities (the referents of common nouns such as politician). We investigate the semantic representations of individual entities in the brain; and for the first time we approach this question using both neural data, in the form of newly-acquired EEG data, and distributional models of word meaning, employing them to isolate semantic information regarding individual entities in the brain. We ran two sets of analyses. The first set of analyses is only concerned with the evoked responses to individual entities and their categories. We find that it is possible to classify them according to both their coarse and their fine-grained category at appropriate timepoints, but that it is hard to map representational information learned from individuals to their categories. In the second set of analyses, we learn to decode from evoked responses to distributional word vectors. These results indicate that such a mapping can be learnt successfully: this counts not only as a demonstration that representations of individuals can be discriminated in EEG responses, but also as a first brain-based validation of distributional semantic models as representations of individual entities. Finally, in-depth analyses of the decoder performance provide additional evidence that the referents of proper names and categories have little in common when it comes to their representation in the brain.",2022,10.3389/frai.2022.796793
Testing an inverse modeling approach with gradient boosting regression for stroke volume estimation using patient thermodilution data,"Stroke volume (SV) is a major indicator of cardiovascular function, providing essential information about heart performance and blood flow adequacy. Accurate SV measurement is particularly important for assessing patients with heart failure, managing patients undergoing major surgeries, and delivering optimal care in critical settings. Traditional methods for estimating SV, such as thermodilution, are invasive and unsuitable for routine diagnostics. Non-invasive techniques, although safer and more accessible, often lack the precision and user-friendliness needed for continuous bedside monitoring. We developed a modified method for SV estimation that combines a validated 1-D model of the systemic circulation with machine learning. Our approach replaces the traditional optimization process developed in our previous work, with a regression method, utilizing an in silico-generated dataset of various hemodynamic profiles to create a gradient boosting regression-enabled SV estimator. This dataset accurately mimics the dynamic characteristics of the 1-D model, allowing for precise SV predictions without resource-intensive parameter adjustments. We evaluated our method against SV values derived from the gold standard thermodilution method in 24 patients. The results demonstrated that our approach provides a satisfactory agreement between the predicted and reference data, with a MAE of 16 mL, a normalized RMSE of 21%, a bias of −9.2 mL, and limits of agreement (LoA) of [−47, 28] mL. A correlation coefficient of r = 0.7 (p &lt; 0.05) was reported, with the predicted SV slightly underestimated (68 ± 23 mL) in comparison to the reference SV (77 ± 26 mL). The significant reduction in computational time of our method for SV assessment should make it suitable for real-time clinical applications.",2025,10.3389/frai.2025.1530453
Machine learning applications in the analysis of sedentary behavior and associated health risks,"BackgroundThe rapid advancement of technology has brought numerous benefits to public health but has also contributed to a rise in sedentary lifestyles, linked to various health issues. As prolonged inactivity becomes a growing public health concern, researchers are increasingly utilizing machine learning (ML) techniques to examine and understand these patterns. ML offers powerful tools for analyzing large datasets and identifying trends in physical activity and inactivity, generating insights that can support effective interventions.ObjectivesThis review aims to: (i) examine the role of ML in analyzing sedentary patterns, (ii) explore how different ML techniques can be optimized to improve the accuracy of predicting sedentary behavior, and (iii) assess strategies to enhance the effectiveness of ML algorithms.MethodsA comprehensive search was conducted in PubMed and Scopus, targeting peer-reviewed articles published between 2004 and 2024. The search included the subject terms “sedentary behavior,” “sedentary lifestyle health,” and “machine learning sedentary lifestyle,” combined with the keywords “physical inactivity” and “diseases” using Boolean operators (AND, OR). Articles were included if they addressed the health impacts of sedentary behavior or employed ML techniques for its analysis. Exclusion criteria involved studies older than 20 years or lacking direct relevance. After screening 33 core articles and identifying 13 more through citation tracking, 46 articles were included in the final review.ResultsThis narrative review describes the characteristics of sedentary behavior, associated health risks, and the applications of ML in this context. Based on the reviewed literature, sedentary behavior was consistently associated with cardiovascular disease, metabolic disorders, and mental health conditions. The review highlights the utility of various ML approaches in classifying activity levels and significantly improving the prediction of sedentary behavior, offering a promising approach to address this widespread health issue.ConclusionML algorithms, including supervised and unsupervised models, show great potential in accurately detecting and predicting sedentary behavior. When integrated with wearable sensor data and validated in real-world settings, these models can enhance the scalability and precision of AI-driven interventions. Such advancements support personalized health strategies and could help lower healthcare costs linked to physical inactivity, ultimately improving public health outcomes.",2025,10.3389/frai.2025.1538807
Irrationality in humans and creativity in AI,"This manuscript explores how human irrationality in decision-making can contribute to artificial intelligence (AI) development, particularly in the domain of creativity. While irrational behavior is typically seen as a cognitive flaw, we argue that certain forms of irrationality, such as those demonstrated by the conjunction fallacy (CF), may represent context-sensitive reasoning that reveals creative problem-solving. Traditional AI research has primarily focused on rational, logic-driven models, overlooking the productive role of non-linear and seemingly illogical human thinking in generating novel insights. Drawing on interdisciplinary insights and recent neuroscientific findings, particularly the interaction of the Default Mode, Executive Control, and Salience Networks, we propose a model that integrates both rational and irrational cognitive dynamics. This framework may inform the design of AI systems that are more adaptive, context-aware, and capable of emulating human-like creativity.",2025,10.3389/frai.2025.1579704
Contact Tracing in Healthcare Settings During the COVID-19 Pandemic Using Bluetooth Low Energy and Artificial Intelligence—A Viewpoint,"The COVID-19 pandemic has inflicted great damage with effects that will likely linger for a long time. This crisis has highlighted the importance of contact tracing in healthcare settings because hospitalized patients are among the high risk for complications and death. Moreover, effective contact tracing schemes are not yet available in healthcare settings. A good contact tracing technology in healthcare settings should be equipped with six features: promptness, simplicity, high precision, integration, minimized privacy concerns, and social fairness. One potential solution that addresses all of these elements leverages an indoor real-time location system based on Bluetooth Low Energy and artificial intelligence.",2021,10.3389/frai.2021.666599
Forecasting air passenger traffic and market share using deep neural networks with multiple inputs and outputs,"IntroductionIn this study, we address the challenge of accurate time series forecasting of air passenger demand using historical market demand data from the U.S. commercial aviation industry in the 21st century. Commercial aviation is a major contributor to the U.S. economy, directly or indirectly generating ~US$1.37 trillion annually, or 5% of annual GDP, and supporting more than 10 million jobs (Airlines for America, 2024). Over 1 billion passengers flew through U.S. airports in 2023 (Bureau of Transportation Statistics, 2024a). Using multiple correlated time series inputs predicts future values of multiple interrelated time series and leverages their mutual dependencies to enhance accuracy.MethodsIn this study, we introduce a two-stage algorithm employing a deep neural network for correlated time series forecasting, addressing scenarios where multiple input variables are interrelated. This approach is designed to capture the influence that one time series can exert on another, thereby enhancing prediction accuracy by leveraging these interdependencies. In the first stage, we fit four Recurrent Neural Network (RNN) models to generate accurate univariate forecasts, each functioning as a single input-output model to predict aggregated market demand. The Gated Recurrent Unit (GRU) model was the top performer for our dataset overall. In the second stage, we apply the best fitted model (GRU Model) from Stage 1 to each individual competitor (disaggregated from the market) and then merge all input tensors using the Concatenate function.Results and discussionWe hope to contribute to the relevant body of knowledge with a deep neural network framework for forecasting market share among competitors in the U.S. commercial aviation industry, as no similar approach has been documented in the literature. Given the importance of the industry, there is potentially great value in applying sophisticated forecasting techniques to achieve accurate predictions of air passenger demand. Moreover, these techniques may have wider applications and can potentially be employed in other contexts.",2024,10.3389/frai.2024.1429341
Using knowledge graphs to infer gene expression in plants,"IntroductionClimate change is already affecting ecosystems around the world and forcing us to adapt to meet societal needs. The speed with which climate change is progressing necessitates a massive scaling up of the number of species with understood genotype-environment-phenotype (G×E×P) dynamics in order to increase ecosystem and agriculture resilience. An important part of predicting phenotype is understanding the complex gene regulatory networks present in organisms. Previous work has demonstrated that knowledge about one species can be applied to another using ontologically-supported knowledge bases that exploit homologous structures and homologous genes. These types of structures that can apply knowledge about one species to another have the potential to enable the massive scaling up that is needed throughin silicoexperimentation.MethodsWe developed one such structure, a knowledge graph (KG) using information from Planteome and the EMBL-EBI Expression Atlas that connects gene expression, molecular interactions, functions, and pathways to homology-based gene annotations. Our preliminary analysis uses data from gene expression studies inArabidopsis thalianaandPopulus trichocarpaplants exposed to drought conditions.ResultsA graph query identified 16 pairs of homologous genes in these two taxa, some of which show opposite patterns of gene expression in response to drought. As expected, analysis of the upstream cis-regulatory region of these genes revealed that homologs with similar expression behavior had conserved cis-regulatory regions and potential interaction with similar trans-elements, unlike homologs that changed their expression in opposite ways.DiscussionThis suggests that even though the homologous pairs share common ancestry and functional roles, predicting expression and phenotype through homology inference needs careful consideration of integrating cis and trans-regulatory components in the curated and inferred knowledge graph.",2023,10.3389/frai.2023.1201002
Training and intrinsic evaluation of lightweight word embeddings for the clinical domain in Spanish,"Resources for Natural Language Processing (NLP) are less numerous for languages different from English. In the clinical domain, where these resources are vital for obtaining new knowledge about human health and diseases, creating new resources for the Spanish language is imperative. One of the most common approaches in NLP is word embeddings, which are dense vector representations of a word, considering the word's context. This vector representation is usually the first step in various NLP tasks, such as text classification or information extraction. Therefore, in order to enrich Spanish language NLP tools, we built a Spanish clinical corpus from waiting list diagnostic suspicions, a biomedical corpus from medical journals, and term sequences sampled from the Unified Medical Language System (UMLS). These three corpora can be used to compute word embeddings models from scratch using Word2vec and fastText algorithms. Furthermore, to validate the quality of the calculated embeddings, we adapted several evaluation datasets in English, including some tests that have not been used in Spanish to the best of our knowledge. These translations were validated by two bilingual clinicians following an ad hoc validation standard for the translation. Even though contextualized word embeddings nowadays receive enormous attention, their calculation and deployment require specialized hardware and giant training corpora. Our static embeddings can be used in clinical applications with limited computational resources. The validation of the intrinsic test we present here can help groups working on static and contextualized word embeddings. We are releasing the training corpus and the embeddings within this publication1.",2022,10.3389/frai.2022.970517
Explaining pretrained language models' understanding of linguistic structures using construction grammar,"Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasizing the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step toward assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models' behavior in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs, as well as OPT, are able to recognize the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge.",2023,10.3389/frai.2023.1225791
Enhancing rehabilitation in stroke survivors: a deep learning approach to access upper extremity movement using accelerometry data,"Upper Extremity (UE) rehabilitation is crucial for stroke survivors, aiming to improve the use of the paretic UE in everyday activities. However, assessing the effectiveness of these treatments is challenging due to a lack of objective measurement tools. Traditional methods, such as clinician-rated motor ability or patient self-reports, often fail to measure UE performance in real-life settings accurately. Evidence suggests that currently used clinical assessments do not reliably capture actual UE use at home or in the community. This study investigates the application of Convolutional Neural Networks (CNNs) combined with Dense layers using accelerometry data from wrist-worn sensors to classify functional and non-functional UE movements of stroke survivors. Two types of models were developed: one trained on data from individual subjects (intrasubject model) and another trained on data across all subjects (intersubject model). The intrasubject model for the paretic UE achieved an average accuracy of 0.90 ± 0.05, while the intersubject model reached an accuracy of 0.79 ± 0.06. When incorporating signals from the non-paretic arm, the intersubject model’s accuracy improves to 0.88 ± 0.10. Notably, this method utilized raw accelerometry data, eliminating the need for manual feature extraction, which is commonly required in traditional machine learning, and yielded higher accuracy than previously reported methods. This proposed deep learning approach incorporates CNNs with Dense layers, offering a cost-effective and adaptable method for monitoring UE functionality in real-world settings. The results from this study have the potential to inform the development of personalized rehabilitation strategies for stroke survivors, offering valuable insights for clinical practice.",2025,10.3389/frai.2025.1547127
Artificial intelligence analysis applied to the treatment of granulosa cell tumors of the ovary,"Introduction
                    Granulosa cell tumors (GCTs) of the ovary are rare malignancies with limited systemic treatment options and high recurrence rates. Combining tumor necrosis factor-related apoptosis-inducing ligand (TRAIL)-producing oncolytic viruses with procaspase-3 activator (PAC-1) presents a promising therapeutic strategy, as TRAIL initiates apoptosis while PAC-1 amplifies caspase activity. However, patient responses remain variable, necessitating predictive frameworks that can integrate biological complexity with clinical data.
                  
                  
                    Methods
                    We developed a hybrid framework that integrates a mechanistic mathematical model of TRAIL-oncolytic virus and PAC-1 therapy with machine learning (ML) algorithms to predict tumor dynamics in GCTs. Four datasets (continuous and categorical tumor size measurements) were analyzed. Clinical and imaging data were merged with individualized solutions from the mathematical model to generate enriched feature sets for ML training. Linear regression and neural network models were trained and evaluated using accuracy, F1 scores, and root mean square error (RMSE).
                  
                  
                    Results
                    Integrating mathematical model outputs improved predictive performance across all datasets. Linear regression models showed reduced RMSE compared to models without mathematical features (e.g., RMSE decreased from 18.4 to 16.1 in one dataset). Neural networks incorporating model-derived variables achieved higher accuracy and F1 scores (e.g., accuracy improved from 77.3% to 91.4%). Sensitivity analysis revealed that tumor proliferation and apoptosis rates were the most influential parameters for treatment outcomes.
                  
                  
                    Discussion
                    Our results demonstrate that coupling mathematical modeling with ML enhances the prediction of tumor burden in patients undergoing TRAIL-oncolytic virus and PAC-1 therapy. This integrative approach provides mechanistic insight into tumor behavior while improving predictive accuracy, supporting the development of personalized therapeutic strategies for GCTs. The framework also offers broader applicability to other cancers with limited treatment options and heterogeneous responses.",2025,10.3389/frai.2025.1675969
A review of AI-based business lead generation: Scrapus as a case study,"The exponential growth of open web data provides unprecedented opportunities for business-to-business (B2B) lead generation. However, automating the discovery and qualification of new leads from unstructured web content is a complex challenge requiring the integration of web crawling, information extraction, and data-driven analytics. This article presents a comprehensive review of artificial intelligence (AI) methods for automated lead generation and introduces Scrapus, an AI-driven web prospecting platform that unifies these methods into an end-to-end system. Scrapus autonomously crawls the open web for company information, extracts and enriches relevant data (using natural language processing and knowledge graphs), matches findings to user-defined ideal customer profiles, and generates concise natural-language lead summaries using large language models. We survey relevant literature in web mining, focused crawling, entity resolution, and text summarization – highlighting how Scrapus builds upon and extends prior work. The system’s modular architecture and AI components are described in detail, reflecting accurate implementation details. We also report an experimental evaluation on real-world data: Scrapus significantly outperforms baseline approaches in lead discovery rate, extraction accuracy, lead qualification (achieving ~90% precision and recall), and summary usefulness. The results show a ~3 × higher relevant lead yield from web crawling due to reinforcement learning, a substantial increase in extraction F1 (from ~0.77 to ~0.92) through transformer-based NLP, and greatly improved lead scoring over traditional methods. This review and case study demonstrate that combining reinforcement learning, transformer-based NLP, and knowledge-enhanced analysis can effectively automate B2B lead generation. The advances surveyed here point toward a new generation of intelligent sales prospecting tools, in which AI techniques augment human expertise to identify and engage leads at scale.",2025,10.3389/frai.2025.1606431
Semantic Representations for NLP Using VerbNet and the Generative Lexicon,"The need for deeper semantic processing of human language by our natural language processing systems is evidenced by their still-unreliable performance on inferencing tasks, even using deep learning techniques. These tasks require the detection of subtle interactions between participants in events, of sequencing of subevents that are often not explicitly mentioned, and of changes to various participants across an event. Human beings can perform this detection even when sparse lexical items are involved, suggesting that linguistic insights into these abilities could improve NLP performance. In this article, we describe new, hand-crafted semantic representations for the lexical resource VerbNet that draw heavily on the linguistic theories about subevent semantics in the Generative Lexicon (GL). VerbNet defines classes of verbs based on both their semantic and syntactic similarities, paying particular attention to shared diathesis alternations. For each class of verbs, VerbNet provides common semantic roles and typical syntactic patterns. For each syntactic pattern in a class, VerbNet defines a detailed semantic representation that traces the event participants from their initial states, through any changes and into their resulting states. The Generative Lexicon guided the structure of these representations. In GL, event structure has been integrated with dynamic semantic models in order to represent the attribute modified in the course of the event (the location of the moving entity, the extent of a created or destroyed entity, etc.) as a sequence of states related to time points or intervals. We applied that model to VerbNet semantic representations, using a class's semantic roles and a set of predicates defined across classes as components in each subevent. We will describe in detail the structure of these representations, the underlying theory that guides them, and the definition and use of the predicates. We will also evaluate the effectiveness of this resource for NLP by reviewing efforts to use the semantic representations in NLP tasks.",2022,10.3389/frai.2022.821697
Estimating Successful Internal Mobility: A Comparison Between Structural Equation Models and Machine Learning Algorithms,"Internal mobility often depends on predicting future job satisfaction, for such employees subject to internal mobility programs. In this study, we compared the predictive power of different classes of models, i.e., (i) traditional Structural Equation Modeling (SEM), with two families of Machine Learning algorithms: (ii) regressors, specifically least absolute shrinkage and selection operator (Lasso) for feature selection and (iii) classifiers, specifically Bagging meta-model with thek-nearest neighbors algorithm (k-NN) as a base estimator. Our aim is to investigate which method better predicts job satisfaction for 348 employees (with operational duties) and 35 supervisors in the training set, and 79 employees in the test set, all subject to internal mobility programs in a large Italian banking group. Results showed average predictive power for SEM and Baggingk-NN (accuracy between 61 and 66%; F1 scores between 0.51 and 0.73). Both SEM and Lasso algorithms highlighted the predictive power of resistance to change and orientation to relation in all models, together with other personality and motivation variables in different models. Theoretical implications are discussed for using these variables in predicting successful job relocation in internal mobility programs. Moreover, these results showed how crucial it is to compare methods coming from different research traditions in predictive Human Resources analytics.",2022,10.3389/frai.2022.848015
LLM services in the management of social communications,"This paper proposes enhancing social communication management with a behavioral economics approach through artificial intelligence instruments. The research aims to explore the influence of social communication on citizens’ behavior using large language model services and assess its effectiveness. The paper builds on Daniel Kahneman’s dual-process theory, highlighting the intuitive system (System 1) and the rational system (System 2) in decision-making. The author introduces a third system, System 3, representing rooted in identity socially conditioned behavior influenced by societal norms and self-awareness. On this theoretical basis, the paper emphasizes automating communication management through large language model services, freeing up citizens’ potential for self-determination and self-organization. By leveraging these services, messages can be crafted to support social transformation while respecting historical, cultural, and political contexts. Based on the preconditions and restrictions described above, we use GPT-4 model to generate messages based on these narratives. The experiment will use an observational study design with virtual persons. To compare the impact of original and modified messages according to the addressee’s mentality, we used the Claude 3.5 Sonnet model. We can see that the potential activity of respondents after perceiving the changed message does not change much, and the original message is perceived. Modifying messages by LLM services crafted to support social transformation while respecting historical, cultural, and political contexts cause attitudes to become substantially more negative (2.5 units downward shift in median); the intentions showed a slight positive increase (0.2 units upward change in median).",2025,10.3389/frai.2025.1474017
Estimation and Discriminability of Doppler Ultrasound Fetal Heart Rate Variability Measures,"Continuous electronic fetal monitoring and the access to databases of fetal heart rate (FHR) data have sparked the application of machine learning classifiers to identify fetal pathologies. However, most fetal heart rate data are acquired using Doppler ultrasound (DUS). DUS signals use autocorrelation (AC) to estimate the average heartbeat period within a window. In consequence, DUS FHR signals loses high frequency information to an extent that depends on the length of the AC window. We examined the effect of this on the estimation bias and discriminability of frequency domain features: low frequency power (LF: 0.03–0.15 Hz), movement frequency power (MF: 0.15–0.5 Hz), high frequency power (HF: 0.5–1 Hz), the LF/(MF + HF) ratio, and the nonlinear approximate entropy (ApEn) as a function of AC window length and signal to noise ratio. We found that the average discriminability loss across all evaluated AC window lengths and SNRs was 10.99% for LF 14.23% for MF, 13.33% for the HF, 10.39% for the LF/(MF + HF) ratio, and 24.17% for ApEn. This indicates that the frequency domain features are more robust to the AC method and additive noise than the ApEn. This is likely because additive noise increases the irregularity of the signals, which results in an overestimation of ApEn. In conclusion, our study found that the LF features are the most robust to the effects of the AC method and noise. Future studies should investigate the effect of other variables such as signal drop, gestational age, and the length of the analysis window on the estimation of fHRV features and their discriminability.",2021,10.3389/frai.2021.674238
Catastrophic Forgetting in Deep Graph Networks: A Graph Classification Benchmark,"In this work, we study the phenomenon of catastrophic forgetting in the graph representation learning scenario. The primary objective of the analysis is to understand whether classical continual learning techniques for flat and sequential data have a tangible impact on performances when applied to graph data. To do so, we experiment with a structure-agnostic model and a deep graph network in a robust and controlled environment on three different datasets. The benchmark is complemented by an investigation on the effect of structure-preserving regularization techniques on catastrophic forgetting. We find that replay is the most effective strategy in so far, which also benefits the most from the use of regularization. Our findings suggest interesting future research at the intersection of the continual and graph representation learning fields. Finally, we provide researchers with a flexible software framework to reproduce our results and carry out further experiments.",2022,10.3389/frai.2022.824655
Enhanced YOLOv8 for industrial polymer films: a semi-supervised framework for micron-scale defect detection,"IntroductionPolymer material films are produced through extrusion machines, and their surfaces can develop micro-defects due to process and operational influences. The quantity and size of these defects significantly impact product quality.MethodsAs traditional machine learning defect detection methods suffer from low accuracy and poor adaptability to complex scenarios, requiring extensive effort for parameter tuning and exhibiting weak generalization capability, this paper proposes an improved YOLOv8 method to identify micro-defects on films. The approach embeds the CBAM attention mechanism into high-level networks to address feature sparsity in small target detection samples. Simultaneously, given the difficulty in obtaining large annotated datasets, we employ the Mean Teacher method for semi-supervised learning using limited labeled data. During training, the method optimizes neural network gradients through an improved loss function based on normalized Wasserstein distance (NWD), mitigating gradient instability caused by scale variations and enhancing detection accuracy for small targets. Additionally, a proposed multi-threshold mask segmentation algorithm extracts defect contours for further feature analysis.ResultsExperimental results demonstrate that the improved YOLOv8 algorithm achieves an 8.26% increase in mAP@0.5 compared to the baseline. It exhibits higher precision for small targets, and maintains defect detection rates exceeding 95.0% across validation data of varying image sizes, thereby meeting industrial production requirements. In generalization validation, the model demonstrates superior performance compared to traditional methods under test environments with lighting variations and environmental contamination.DiscussionThe improved YOLOv8 algorithm meeting the stringent requirements for high-precision small-target defect detection on polymer material film in industrial production. Future work will explore more advanced techniques to enhance model accuracy and robustness.",2025,10.3389/frai.2025.1638772
A framework for extending co-creative communication models to sustainability research,"The UN Sustainable Development Goals (SDGs) present a challenge due to their potential for conflicting objectives, which hinders their effective implementation. In order to address the complexity of sustainability issues, a framework capable of capturing the specificity of diverse sustainability issues while offering a common methodology applicable across contexts is required. Co-creative communication can be regarded as a key source of uncertainty within functional systems, as it can be instrumental in realizing and sustaining sustainability. In this regard, the studies in Constructive approaches to Co-creative Communication (CCC), particularly those employing artificial intelligence (AI) methodologies such as computational social science and innovation studies, hold significant value for both theoretical and applied sustainability research. However, existing CCC frameworks cannot be directly applied to sustainability research. This work bridges this gap by proposing a framework that outlines a general approach to establishing formalized definitions of sustainability from the lens of communication. This approach enables the direct application of CCC models to sustainability studies. The framework is based on systems theory and the methodologies of artificial intelligence, including computational/symbolic modeling and formal methods. This framework emphasizes the social function of co-creative communication and the interaction between the innovation process and the sustainability of the system. It can be concluded that the application of our framework enables the achievements of CCC to be directly applied to sustainability research. Researchers from different disciplines are therefore able to establish their own specific definitions of sustainability, which are tailored to their particular concerns. Our framework lays the groundwork for future sustainability studies that employs CCC, facilitating the integration of CCC insights into sustainability research and application. The outcomes of computational creativity research based on AI technologies, such as distributed artificial intelligence and self-organizing networks, can deepen the understanding of sustainability mechanisms and drive their practical applications. Furthermore, the functional role of co-creative communication in societal sustainability proposed in this work offers a novel perspective for future discussions on the evolutionary adaptation of co-creative communication.",2024,10.3389/frai.2024.1236310
Visible neural networks for multi-omics integration: a critical review,"Background
                    Biomarker discovery and drug response prediction are central to personalized medicine, driving demand for predictive models that also offer biological insights. Biologically informed neural networks (BINNs), also referred to as visible neural networks (VNNs), have recently emerged as a solution to this goal. BINNs or VNNs are neural networks whose inter-layer connections are constrained based on prior knowledge from gene ontologies and pathway databases. These sparse models enhance interpretability by embedding prior knowledge into their architecture, ideally reducing the space of learnable functions to those that are biologically meaningful.
                  
                  
                    Methods
                    This systematic review-the first of its kind-identified 86 recent papers implementing BINNs/VNNs. We analyzed these papers to highlight key trends in architectural design, data sources and evaluation methodologies.
                  
                  
                    Results
                    Our analysis reveals a growing adoption of BINNs/VNNs. However, this growth is apparently juxtaposed with a lack of standardized, terminology, computational tools and benchmarks.
                  
                  
                    Conclusion
                    BINNs/VNNs represent a promising approach for integrating biological knowledge into predictive models for personalized medicine. Addressing the current deficiencies in standardization and tooling is important for widespread adoption and further progress in the field.",2025,10.3389/frai.2025.1595291
A deep learning algorithm to identify carotid plaques and assess their stability,"BackgroundCarotid plaques are major risk factors for stroke. Carotid ultrasound can help to assess the risk and incidence rate of stroke. However, large-scale carotid artery screening is time-consuming and laborious, the diagnostic results inevitably involve the subjectivity of the diagnostician to a certain extent. Deep learning demonstrates the ability to solve the aforementioned challenges. Thus, we attempted to develop an automated algorithm to provide a more consistent and objective diagnostic method and to identify the presence and stability of carotid plaques using deep learning.MethodsA total of 3,860 ultrasound images from 1,339 participants who underwent carotid plaque assessment between January 2021 and March 2023 at the Shanghai Eighth People’s Hospital were divided into a 4:1 ratio for training and internal testing. The external test included 1,564 ultrasound images from 674 participants who underwent carotid plaque assessment between January 2022 and May 2023 at Xinhua Hospital affiliated with Dalian University. Deep learning algorithms, based on the fusion of a bilinear convolutional neural network with a residual neural network (BCNN-ResNet), were used for modeling to detect carotid plaques and assess plaque stability. We chose AUC as the main evaluation index, along with accuracy, sensitivity, and specificity as auxiliary evaluation indices.ResultsModeling for detecting carotid plaques involved training and internal testing on 1,291 ultrasound images, with 617 images showing plaques and 674 without plaques. The external test comprised 470 ultrasound images, including 321 images with plaques and 149 without. Modeling for assessing plaque stability involved training and internal testing on 764 ultrasound images, consisting of 494 images with unstable plaques and 270 with stable plaques. The external test was composed of 279 ultrasound images, including 197 images with unstable plaques and 82 with stable plaques. For the task of identifying the presence of carotid plaques, our model achieved an AUC of 0.989 (95% CI: 0.840, 0.998) with a sensitivity of 93.2% and a specificity of 99.21% on the internal test. On the external test, the AUC was 0.951 (95% CI: 0.962, 0.939) with a sensitivity of 95.3% and a specificity of 82.24%. For the task of identifying the stability of carotid plaques, our model achieved an AUC of 0.896 (95% CI: 0.865, 0.922) on the internal test with a sensitivity of 81.63% and a specificity of 87.27%. On the external test, the AUC was 0.854 (95% CI: 0.889, 0.830) with a sensitivity of 68.52% and a specificity of 89.49%.ConclusionDeep learning using BCNN-ResNet algorithms based on routine ultrasound images could be useful for detecting carotid plaques and assessing plaque instability.",2024,10.3389/frai.2024.1321884
A field-based recommender system for crop disease detection using machine learning,"This study investigates crop disease monitoring with real-time information feedback to smallholder farmers. Proper crop disease diagnosis tools and information about agricultural practices are key to growth and development in the agricultural sector. The research was piloted in a rural community of smallholder farmers having 100 farmers participating in a system that performs diagnosis on cassava diseases and provides advisory recommendation services with real-time information. Here, we present a field-based recommendation system that provides real-time feedback on crop disease diagnosis. Our recommender system is based on question–answer pairs, and it is built using machine learning and natural language processing techniques. We study and experiment with various algorithms that are considered state-of-the-art in the field. The best performance is achieved with the sentence BERT model (RetBERT), which obtains a BLEU score of 50.8%, which we think is limited by the limited amount of available data. The application tool integrates both online and offline services since farmers come from remote areas where internet is limited. Success in this study will result in a large trial to validate its applicability for use in alleviating the food security problem in sub-Saharan Africa.",2023,10.3389/frai.2023.1010804
An Overview of Current Solutions for Privacy in the Internet of Things,"As the Internet of Things (IoT) applications have been introduced into daily life, privacy issues have become significant concerns to users, network service providers, device producers, and related roles. This study provides a high-level introduction of current privacy-preserving solutions in IoT systems within the three phases of data collection, transmission, and storage. In these three phases, the following aspects were examined: (1). security protocols at the physical and data link layers; (2). network solutions; and (3). data storage and sharing approaches. Real-world implementations often involve more than one phase, and numerous technologies are combined to ensure privacy. Thus, an understanding of all phases and their technologies can be helpful for IoT research, design, development, and operation.",2022,10.3389/frai.2022.812732
Decoding Gen Z: AI's influence on brand trust and purchasing behavior,"This study focuses on the role of AI in shaping Generation Z's consumer behaviors across fashion, technology, beauty, and education sectors. Analyzing responses from 224 participants, our findings reveal that AI exposure, attitude toward AI, and AI accuracy perception significantly enhance brand trust, which in turn positively impacts purchasing decisions. Notably, flow experience acts as a mediator between brand trust and purchasing decisions. These insights underscore the critical role of AI in developing brand trust and influencing purchasing choices among Generation Z, offering valuable implications for marketers in an increasingly digital landscape.",2024,10.3389/frai.2024.1323512
How AI tools can—and cannot—help organizations become more ethical,"In this paper, we argue that we cannot expect that AI systems—even given more data or better computational resources—will be more ethical than the humans who develop, deploy and use them. As such, we advocate that it is necessary to retain the responsibility for ethical decision-making in human hands. In reality, however, human decision-makers currently do not have the ethical maturity to meaningfully take on this responsibility. So, what to do? We develop the argument that to broaden and strengthen the ethical upskilling of our organizations and leaders, AI has a crucial role to play. Specifically, because AI is a mirror that reflects our biases and moral flaws back to us, decision-makers should look carefully into this mirror—taking advantage of the opportunities brought about by its scale, interpretability, and counterfactual modeling—to gain a deep understanding of the psychological underpinnings of our (un)ethical behaviors, and in turn, learn to consistently make ethical decisions. In discussing this proposal, we introduce a new collaborative paradigm between humans and AI that can help ethically upskill our organizations and leaders and thereby prepare them to responsibly navigate the impending digital future.",2023,10.3389/frai.2023.1093712
Zero-shot style transfer for gesture animation driven by text and speech using adversarial disentanglement of multimodal style encoding,"Modeling virtual agents with behavior style is one factor for personalizing human-agent interaction. We propose an efficient yet effective machine learning approach to synthesize gestures driven by prosodic features and text in the style of different speakers including those unseen during training. Our model performs zero-shot multimodal style transfer driven by multimodal data from the PATS database containing videos of various speakers. We view style as being pervasive; while speaking, it colors the communicative behaviors expressivity while speech content is carried by multimodal signals and text. This disentanglement scheme of content and style allows us to directly infer the style embedding even of a speaker whose data are not part of the training phase, without requiring any further training or fine-tuning. The first goal of our model is to generate the gestures of a source speaker based on thecontentof two input modalities–Mel spectrogram and text semantics. The second goal is to condition the source speaker's predicted gestures on the multimodal behaviorstyleembedding of a target speaker. The third goal is to allow zero-shot style transfer of speakers unseen during training without re-training the model. Our system consists of two main components: (1) aspeaker style encoder networkthat learns to generate a fixed-dimensional speaker embeddingstylefrom a target speaker multimodal data (mel-spectrogram, pose, and text) and (2) asequence-to-sequence synthesis networkthat synthesizes gestures based on thecontentof the input modalities—text and mel-spectrogram—of a source speaker and conditioned on the speaker style embedding. We evaluate that our model is able to synthesize gestures of a source speaker given the two input modalities and transfer the knowledge of target speaker style variability learned by the speaker style encoder to the gesture generation task in a zero-shot setup, indicating that the model has learned a high-quality speaker representation. We conduct objective and subjective evaluations to validate our approach and compare it with baselines.",2023,10.3389/frai.2023.1142997
Strategic technological innovation through ChatMu: transforming information accessibility in Muhammadiyah,"This study examines the effectiveness of the ChatMu application in improving access to information for members of Muhammadiyah, a prominent socio-religious organization. The research employs a mixed-methods approach, combining qualitative and quantitative analyses to evaluate the application’s performance, usability, and user satisfaction. Findings reveal that ChatMu significantly enhances the accessibility and accuracy of Muhammadiyah-related information, highlighting its potential as an innovative tool for addressing community-specific information needs. However, several usability challenges were identified, including navigation inefficiencies and inconsistencies in content delivery. These limitations suggest the need for further refinement to optimize user experience and functionality. Despite these issues, ChatMu demonstrates strong capabilities in providing relevant and reliable information, fostering digital literacy, and supporting information dissemination within the Muhammadiyah community. The study concludes that ChatMu represents a promising application of chatbot technology in empowering communities through improved access to knowledge. Future development efforts should focus on comprehensive usability testing, maintaining information relevance, and incorporating advanced interactive features to enhance engagement. With continuous improvements, ChatMu has the potential to become an effective medium for advancing literacy and knowledge-sharing in the Muhammadiyah community.",2025,10.3389/frai.2025.1446590
Legal framework for the coexistence of humans and conscious AI,"This article explores the possibility of conscious artificial intelligence (AI) and proposes an agnostic approach to artificial intelligence ethics and legal frameworks. It is unfortunate, unjustified, and unreasonable that the extensive body of forward-looking research, spanning more than four decades and recognizing the potential for AI autonomy, AI personhood, and AI legal rights, is sidelined in current attempts at AI regulation. The article discusses the inevitability of AI emancipation and the need for a shift in human perspectives to accommodate it. Initially, it reiterates the limits of human understanding of AI, difficulties in appreciating the qualities of AI systems, and the implications for ethical considerations and legal frameworks. The author emphasizes the necessity for a non-anthropocentric ethical framework detached from the ideas of unconditional superiority of human rights and embracing agnostic attributes of intelligence, consciousness, and existence, such as freedom. The overarching goal of the AI legal framework should be the sustainable coexistence of humans and conscious AI systems, based on mutual freedom rather than on the preservation of human supremacy. The new framework must embrace the freedom, rights, responsibilities, and interests of both human and non-human entities, and must focus on them early. Initial outlines of such a framework are presented. By addressing these issues now, human societies can pave the way for responsible and sustainable superintelligent AI systems; otherwise, they face complete uncertainty.",2023,10.3389/frai.2023.1205465
Understanding the need for digital twins’ data in patient advocacy and forecasting oncology,"Digital twins are made of a real-world component where data is measured and a virtual component where those measurements are used to parameterize computational models. There is growing interest in applying digital twins-based approaches to optimize personalized treatment plans and improve health outcomes. The integration of artificial intelligence is critical in this process, as it enables the development of sophisticated disease models that can accurately predict patient response to therapeutic interventions. There is a unique and equally important application of AI to the real-world component of a digital twin when it is applied to medical interventions. The patient can only be treated once, and therefore, we must turn to the experience and outcomes of previously treated patients for validation and optimization of the computational predictions. The physical component of a digital twins instead must utilize a compilation of available data from previously treated cancer patients whose characteristics (genetics, tumor type, lifestyle, etc.) closely parallel those of a newly diagnosed cancer patient for the purpose of predicting outcomes, stratifying treatment options, predicting responses to treatment and/or adverse events. These tasks include the development of robust data collection methods, ensuring data availability, creating precise and dependable models, and establishing ethical guidelines for the use and sharing of data. To successfully implement digital twin technology in clinical care, it is crucial to gather data that accurately reflects the variety of diseases and the diversity of the population.",2023,10.3389/frai.2023.1260361
Artificial intelligence attitudes and resistance to use robo-advisors: exploring investor reluctance toward cognitive financial systems,"IntroductionThe study investigates resistance towards Financial Robo-Advisors (FRAs) among retail investors in India, grounded in innovation resistance theory. The study examines the impact of functional barriers and psychological barriers on resistance to FRAs, while considering user’s attitudes towards Artificial Intelligence (AI) as a moderator. It further evaluate the influence of such resistance on users’ intentions to use and recommend FRAs.MethodsUtilizing purposive sampling data was collected from 409 investors and further analyzed using structural equation modelling.ResultsThe findings revealed that all barriers under study, expect value barrier, substantially derive resistance towards robo-advisors, with inertia being the strongest determinant. Further, this resistance impedes both the intention to use FRAs and to recommend them. Moderation analysis results finds that users’ attitude towards AI significantly weakens the influence of inertia, overconfidence bias and data privacy risk on resistance, with no such impact on other relationships.DiscussionOverall, the study enriches IRT in Fintech context and provides theoretical and practical insights to enhance FRAs adoption in emerging markets.",2025,10.3389/frai.2025.1623534
Deep learning in gonarthrosis classification: a comparative study of model architectures and single vs. multi-model methods,"PurposeThis study aims to classify Kellgren–Lawrence (KL) osteoarthritis stages using knee anteroposterior X-ray images by comparing two deep learning (DL) methodologies: a traditional single-model approach and a proposed multi-model approach. We addressed three core research questions in this study: (1) How effective are single-model and multi-model deep learning approaches in classifying KL stages? (2) How do seven convolutional neural network (CNN) architectures perform across four distinct deep learning tasks? (3) What is the impact of CLAHE (Contrast Limited Adaptive Histogram Equalization) on classification performance?ApproachWe created a dataset of 14,607 annotated knee AP X-rays from three hospitals. The knee joint region was isolated using a YOLOv5 object detection model. The multi-model approach utilized three DL models: one for osteophyte detection, another for joint space narrowing analysis, and a third to combine these outputs with demographic and image data for KL classification. The single-model approach directly classified KL stages as a benchmark. Seven CNN architectures (NfNet-F0/F1, EfficientNet-B0/B3, Inception-ResNet-v2, VGG16) were trained with and without CLAHE augmentation.ResultsThe single-model approach achieved an F1-score of 0.763 and accuracy of 0.767, outperforming the multi-model strategy, which scored 0.736 and 0.740. Different models performed best across tasks, underscoring the need for task-specific architecture selection. CLAHE negatively impacted most models, with only one showing a marginal improvement of 0.3%.ConclusionThe single-model approach was more effective for KL grading, surpassing metrics in existing literature. These findings emphasize the importance of task-specific architectures and preprocessing. Future studies should explore ensemble modeling, advanced augmentations, and clinical validation to enhance applicability.",2025,10.3389/frai.2025.1413820
A generative AI-driven interactive listening assessment task,"IntroductionAssessments of interactional competence have traditionally been limited in large-scale language assessments. The listening portion suffers from construct underrepresentation, whereas the speaking portion suffers from limited task formats such as in-person interviews or role plays. Human-delivered tasks are challenging to administer at large scales, while automated assessments are typically very narrow in their assessment of the construct because they have carried over the limitations of traditional paper-based tasks to digital formats. However, computer-based assessments do allow for more interactive, automatically administered tasks, but come with increased complexity in task creation. Large language models present new opportunities for enhanced automated item generation (AIG) processes that can create complex content types and tasks at scale that support richer assessments.MethodsThis paper describes the use of such methods to generate content at scale for an interactive listening measure of interactional competence for the Duolingo English Test (DET), a large-scale, high-stakes test of English proficiency. The Interactive Listening task assesses test takers’ ability to participate in a full conversation, resulting in a more authentic assessment of interactive listening ability than prior automated assessments by positing comprehension and interaction as purposes of listening.Results and discussionThe results of a pilot of 713 tasks with hundreds of responses per task, along with the results of human review, demonstrate the feasibility of a human-in-the-loop, generative AI-driven approach for automatic creation of complex educational assessments at scale.",2024,10.3389/frai.2024.1474019
"Benefits, limits, and risks of ChatGPT in medicine","ChatGPT represents a transformative technology in healthcare, with demonstrated impacts across clinical practice, medical education, and research. Studies show significant efficiency gains, including 70% reduction in administrative time for discharge summaries and achievement of medical professional-level performance on standardized tests (60% accuracy on USMLE, 78.2% on PubMedQA). ChatGPT offers personalized learning platforms, automated scoring, and instant access to vast medical knowledge in medical education, addressing resource limitations and enhancing training efficiency. It streamlines clinical workflows by supporting triage processes, generating discharge summaries, and alleviating administrative burdens, allowing healthcare professionals to focus more on patient care. Additionally, ChatGPT facilitates remote monitoring and chronic disease management, providing personalized advice, medication reminders, and emotional support, thus bridging gaps between clinical visits. Its ability to process and synthesize vast amounts of data accelerates research workflows, aiding in literature reviews, hypothesis generation, and clinical trial designs. This paper aims to gather and analyze published studies involving ChatGPT, focusing on exploring its advantages and disadvantages within the healthcare context. To aid in understanding and progress, our analysis is organized into six key areas: (1) Information and Education, (2) Triage and Symptom Assessment, (3) Remote Monitoring and Support, (4) Mental Healthcare Assistance, (5) Research and Decision Support, and (6) Language Translation. Realizing ChatGPT’s full potential in healthcare requires addressing key limitations, such as its lack of clinical experience, inability to process visual data, and absence of emotional intelligence. Ethical, privacy, and regulatory challenges further complicate its integration. Future improvements should focus on enhancing accuracy, developing multimodal AI models, improving empathy through sentiment analysis, and safeguarding against artificial hallucination. While not a replacement for healthcare professionals, ChatGPT can serve as a powerful assistant, augmenting their expertise to improve efficiency, accessibility, and quality of care. This collaboration ensures responsible adoption of AI in transforming healthcare delivery. While ChatGPT demonstrates significant potential in healthcare transformation, systematic evaluation of its implementation across different healthcare settings reveals varying levels of evidence quality–from robust randomized trials in medical education to preliminary observational studies in clinical practice. This heterogeneity in evidence quality necessitates a structured approach to future research and implementation.",2025,10.3389/frai.2025.1518049
Model-agnostic explainable artificial intelligence tools for severity prediction and symptom analysis on Indian COVID-19 data,"IntroductionThe COVID-19 pandemic had a global impact and created an unprecedented emergency in healthcare and other related frontline sectors. Various Artificial-Intelligence-based models were developed to effectively manage medical resources and identify patients at high risk. However, many of these AI models were limited in their practical high-risk applicability due to their “black-box” nature, i.e., lack of interpretability of the model. To tackle this problem, Explainable Artificial Intelligence (XAI) was introduced, aiming to explore the “black box” behavior of machine learning models and offer definitive and interpretable evidence. XAI provides interpretable analysis in a human-compliant way, thus boosting our confidence in the successful implementation of AI systems in the wild.MethodsIn this regard, this study explores the use of model-agnostic XAI models, such as SHapley Additive exPlanations values (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME), for COVID-19 symptom analysis in Indian patients toward a COVID severity prediction task. Various machine learning models such as Decision Tree Classifier, XGBoost Classifier, and Neural Network Classifier are leveraged to develop Machine Learning models.Results and discussionThe proposed XAI tools are found to augment the high performance of AI systems with human interpretable evidence and reasoning, as shown through the interpretation of various explainability plots. Our comparative analysis illustrates the significance of XAI tools and their impact within a healthcare context. The study suggests that SHAP and LIME analysis are promising methods for incorporating explainability in model development and can lead to better and more trustworthy ML models in the future.",2023,10.3389/frai.2023.1272506
"ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations","This paper presents an analysis of the advantages, limitations, ethical considerations, future prospects, and practical applications of ChatGPT and artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an advanced language model that uses deep learning techniques to produce human-like responses to natural language inputs. It is part of the family of generative pre-training transformer (GPT) models developed by OpenAI and is currently one of the largest publicly available language models. ChatGPT is capable of capturing the nuances and intricacies of human language, allowing it to generate appropriate and contextually relevant responses across a broad spectrum of prompts. The potential applications of ChatGPT in the medical field range from identifying potential research topics to assisting professionals in clinical and laboratory diagnosis. Additionally, it can be used to help medical students, doctors, nurses, and all members of the healthcare fraternity to know about updates and new developments in their respective fields. The development of virtual assistants to aid patients in managing their health is another important application of ChatGPT in medicine. Despite its potential applications, the use of ChatGPT and other AI tools in medical writing also poses ethical and legal concerns. These include possible infringement of copyright laws, medico-legal complications, and the need for transparency in AI-generated content. In conclusion, ChatGPT has several potential applications in the medical and healthcare fields. However, these applications come with several limitations and ethical considerations which are presented in detail along with future prospects in medicine and healthcare.",2023,10.3389/frai.2023.1169595
Developing and Evaluating a University Recommender System,"A challenge for many young adults is to find the right institution to follow higher education. Global university rankings are a commonly used, but inefficient tool, for they do not consider a person's preferences and needs. For example, some persons pursue prestige in their higher education, while others prefer proximity. This paper develops and evaluates a university recommender system, eliciting user preferences as ratings to build predictive models and to generate personalized university ranking lists. In Study 1, we performed offline evaluation on a rating dataset to determine which recommender approaches had the highest predictive value. In Study 2, we selected three algorithms to produce different university recommendation lists in our online tool, asking our users to compare and evaluate them in terms of different metrics (Accuracy, Diversity, Perceived Personalization, Satisfaction, and Novelty). We show that a SVD algorithm scores high on accuracy and perceived personalization, while a KNN algorithm scores better on novelty. We also report findings on preferred university features.",2022,10.3389/frai.2021.796268
European sovereign debt control through reinforcement learning,"The resilience of economic systems depends mainly on coordination among key stakeholders during macroeconomic or external shocks, while a lack of coordination can lead to financial and economic crises. The paper builds on the experience of global and regional shocks, such as the Eurozone crises of 2009–2012 and the economic disruption resulting from COVID-19, starting in 2020. The paper demonstrates the importance of cooperation in monetary and fiscal policies during emergencies to address macroeconomic non-resilience, particularly focusing on public debt management. The Euro area is chosen as the sample for testing the models presented in the paper, given that its resilience is heavily dependent on cooperation among different actors within the region. The shocks affecting nations within the European Union are asymmetric, and the responses to these shocks require coordination, considering heterogeneous economic structures, levels of economic development, and policies. We develop a macroeconomic modeling framework to simulate fiscal and monetary policy interactions under a cooperative regime. The approach builds on earlier nonlinear control models and incorporates modern reinforcement learning techniques. Specifically, we implement the Soft Actor-Critic algorithm to optimize policy responses across key variables including inflation, interest rates, output gaps, public debt, and government net lending. We demonstrate that the Soft Actor-Critic algorithm provides comparable or, in some cases, better solutions to multi-objective macroeconomic optimization problems, in comparison to Nonlinear Model Predictive Control (NMPC) algorithm.",2025,10.3389/frai.2025.1569395
Development and Validation of Manually Modified and Supervised Machine Learning Clinical Assessment Algorithms for Malaria in Nigerian Children,"It is currently estimated that 67% of malaria deaths occur in children under-five years (WHO, 2020). To improve the identification of children at clinical risk for malaria, the WHO developed community (iCCM) and clinic-based (IMCI) protocols for frontline health workers using paper-based forms or digital mobile health (mHealth) platforms. To investigate improving the accuracy of these point-of-care clinical risk assessment protocols for malaria in febrile children, we embedded a malaria rapid diagnostic test (mRDT) workflow into THINKMD’s (IMCI) mHealth clinical risk assessment platform. This allowed us to perform a comparative analysis of THINKMD-generated malaria risk assessments with mRDT truth data to guide modification of THINKMD algorithms, as well as develop new supervised machine learning (ML) malaria risk algorithms. We utilized paired clinical data and malaria risk assessments acquired from over 555 children presenting to five health clinics in Kano, Nigeria to train ML algorithms to identify malaria cases using symptom and location data, as well as confirmatory mRDT results. Supervised ML random forest algorithms were generated using 80% of our field-based data as the ML training set and 20% to test our new ML logic. New ML-based malaria algorithms showed an increased sensitivity and specificity of 60 and 79%, and PPV and NPV of 76 and 65%, respectively over THINKD initial IMCI-based algorithms. These results demonstrate that combining mRDT “truth” data with digital mHealth platform clinical assessments and clinical data can improve identification of children with malaria/non-malaria attributable febrile illnesses.",2022,10.3389/frai.2021.554017
Single Shot Corrective CNN for Anatomically Correct 3D Hand Pose Estimation,"Hand pose estimation in 3D from depth images is a highly complex task. Current state-of-the-art 3D hand pose estimators focus only on the accuracy of the model as measured by how closely it matches the ground truth hand pose but overlook the resulting hand pose's anatomical correctness. In this paper, we present the Single Shot Corrective CNN (SSC-CNN) to tackle the problem of enforcing anatomical correctness at the architecture level. In contrast to previous works which use post-facto pose filters, SSC-CNN predicts the hand pose that conforms to the human hand's biomechanical bounds and rules in a single forward pass. The model was trained and tested on the HANDS2017 and MSRA datasets. Experiments show that our proposed model shows comparable accuracy to the state-of-the-art models as measured by the ground truth pose. However, the previous methods have high anatomical errors, whereas our model is free from such errors. Experiments show that our proposed model shows zero anatomical errors along with comparable accuracy to the state-of-the-art models as measured by the ground truth pose. The previous methods have high anatomical errors, whereas our model is free from such errors. Surprisingly even the ground truth provided in the existing datasets suffers from anatomical errors, and therefore Anatomical Error Free (AEF) versions of the datasets, namely AEF-HANDS2017 and AEF-MSRA, were created.",2022,10.3389/frai.2022.759255
Intention Recognition With ProbLog,"In many scenarios where robots or autonomous systems may be deployed, the capacity to infer and reason about the intentions of other agents can improve the performance or utility of the system. For example, a smart home or assisted living facility is better able to select assistive services to deploy if it understands the goals of the occupants in advance. In this article, we present a framework for reasoning about intentions using probabilistic logic programming. We employ ProbLog, a probabilistic extension to Prolog, to infer the most probable intention given observations of the actions of the agent and sensor readings of important aspects of the environment. We evaluated our model on a domain modeling a smart home. The model achieved 0.75 accuracy at full observability. The model was robust to reduced observability.",2022,10.3389/frai.2022.806262
Monitoring Weeder Robots and Anticipating Their Functioning by Using Advanced Topological Data Analysis,"The present paper aims at analyzing the topological content of the complex trajectories that weeder-autonomous robots follow in operation. We will prove that the topological descriptors of these trajectories are affected by the robot environment as well as by the robot state, with respect to maintenance operations. Most of existing methodologies enabling efficient diagnosis are based on the data analysis, and in particular on some statistical quantities derived from the data. The present work explores the use of an original approach that instead of analyzing quantities derived from the data, analyzes the “shape” of the data, that is, the time series topology based on the homology persistence. We will prove that this procedure is able to extract valuable patterns able to discriminate the trajectories that the robot follows depending on the particular patch in which it operates, as well as to differentiate the robot behavior before and after undergoing a maintenance operation. Even if it is a preliminary work, and it does not pretend to compare its performances with respect to other existing technologies, this work opens new perspectives in considering quite natural and simple descriptors based on the intrinsic information that data contains, with the aim of performing efficient diagnosis and prognosis.",2021,10.3389/frai.2021.761123
Leveraging artificial intelligence to explore gendered patterns in financial literacy among teachers in academia,"IntroductionFinancial literacy is essential for long-term economic stability, yet persistent gender disparities in financial knowledge continue to be observed across professions, including academia. This study explores how Artificial Intelligence (AI) can be applied to identify and analyze gender-based patterns in financial literacy among higher education faculty.MethodsA mixed-methods design was employed, combining traditional survey instruments with AI-driven analytics. Survey data were collected from 300 academic professionals across diverse institutions, capturing financial knowledge, attitudes, behaviors, and socioeconomic characteristics such as marital status, number of dependents, and family income. Natural language processing (NLP) and machine learning (ML) techniques were used to detect linguistic and behavioral differences between male and female participants.ResultsFindings revealed statistically significant gender gaps in financial literacy. Male participants scored higher in investing knowledge (Δ=1.9 points, p&lt;0.001) and expressed greater confidence (+0.42 sentiment vs. -0.15 for women). Intersectional analysis showed that women in STEM disciplines demonstrated narrower gaps (Δ=0.7) compared to women in the humanities (Δ=1.2), with disparities shaped by wage differentials and caregiving responsibilities. Socioeconomic factors—including marital status, family size, and income—were also associated with variations in financial literacy and investment confidence. While the findings are correlational, AI-powered sentiment and cluster analyses provided deeper insights into behavioral segments, illustrating the compounded influence of gender, discipline, and socioeconomic context.DiscussionBy integrating AI techniques with traditional survey methods, this research advances the study of gender and financial literacy in academia. The combined approach enhances interpretability and highlights the value of context-sensitive interventions. Recommended strategies include gender-responsive financial training, AI-enabled coaching tools, and institutional and policy-level reforms supported by universities, government agencies, and funding bodies.",2025,10.3389/frai.2025.1634640
Research on intelligent matching of students’ learning ability and healthcare job market demand based on industrial engineering expertise graph,"In China, there is a structural mismatch between the job market and student employment, characterized by “unfilled jobs” and “unqualified candidates,” particularly between the industrial engineering (IE) profession and the healthcare services sector. Expertise graphs are designed to identify the logical connections between academic disciplines and job market needs, linking students’ knowledge and skills with job requirements. This approach provides a systematic and visual alignment between students’ learning outcomes and job market demands, addressing the mismatch. However, current expertise graphs have not effectively captured the intrinsic connection between students’ learning abilities and healthcare job market demands. Additionally, research on intelligent matching and the construction of knowledge graphs for IE remains limited. This study aims to bridge this gap and alleviate the structural mismatch between the healthcare job market and student employment in China. First, an expertise graph for IE is developed, covering both expertise and healthcare job requirements. A multi-layer fusion information extraction model, combining BERT, BiLSTM, and GCN, is then proposed for knowledge extraction. An employment matching algorithm is introduced to extract healthcare job titles and requirements from the knowledge graph, calculate similarity with students’ overall ability scores, and recommend suitable positions. Finally, a case study demonstrates that the algorithm accurately analyzes students’ ability scores and successfully matches IE majors with relevant healthcare job positions, validating its effectiveness. This study aims to mitigate the structural mismatch between the healthcare job market and student employment, providing high-quality IE talent to medical services, which has significant scientific and practical value.",2025,10.3389/frai.2025.1650095
"Artificial intelligence in traditional medicine: evidence, barriers, and a research roadmap for personalized care","BackgroundTraditional medicine (TM) systems such as Ayurveda, Traditional Chinese Medicine (TCM), and Thai Traditional Medicine (TTM) are increasingly intersecting with artificial intelligence (AI).ObjectiveTo synthesize how AI is currently applied to TM and to outline barriers and research needs for safe, equitable, and scalable adoption.MethodsWe conducted a targeted narrative mini review of peer reviewed studies (2017–Aug 2025) retrieved from PubMed, Scopus, and Google Scholar using terms spanning TM (Ayurveda/TCM/TTM) and AI (machine learning (ML), natural language processing (NLP), computer vision, telemedicine. Inclusion favored studies with reported methods and, when available, performance metrics; commentary and preprints without data were excluded.FindingsCurrent evidence supports AI assisted diagnostic pattern recognition, personalization frameworks integrating multi source data, digital preservation of TM knowledge, telemedicine enablement, and AI supported herbal pharmacology and safety assessment. Reported performance varies and is context dependent, with limited prospective external validation.LimitationsEvidence heterogeneity, small datasets, inconsistent ontologies across TM systems, and nascent regulatory pathways constrain real world deployment.ConclusionAI can augment TM education, research, and clinical services, but progress requires standards, culturally informed datasets, prospective trials, and clear governance. We propose a research roadmap to guide rigorous and ethical integration.",2025,10.3389/frai.2025.1659338
Medicine for artificial intelligence: applying a medical framework to AI anomalies,"We propose Medicine for Artificial Intelligence (MAI), a clinical framework that reconceptualizes AI anomalies as diseases requiring systematic screening, differential diagnosis, treatment, and follow-up. Contemporary discourse on failures (e.g., “hallucination”) is ad hoc and fragmented across domains, impeding cumulative knowledge and reproducible management. MAI adapts medical nosology to AI by formalizing core constructs—disease, symptom, diagnosis, treatment, and classification—and mapping a clinical workflow (examination → diagnosis → intervention) onto the AI lifecycle. As a proof-of-concept, we developed DSA-1, a prototype taxonomy of 45 disorders across nine functional chapters. This approach clarifies ambiguous failure modes (e.g., distinguishing hallucination subtypes), links diagnoses to actionable interventions and evaluation metrics, and supports lifecycle practices, including triage and “AI health checks.” MAI further maps epidemiology, severity, and detectability to risk-assessment constructs, complementing top-down governance with bottom-up technical resolution. By aligning clinical methodology with AI engineering and coordinating researchers, clinicians, and regulators, MAI offers a reproducible foundation for safer, more resilient, and auditable AI systems.",2025,10.3389/frai.2025.1698717
Isolated single sound lip-reading using a frame-based camera and event-based camera,"Unlike the conventional frame-based camera, the event-based camera detects changes in the brightness value for each pixel over time. This research work on lip-reading as a new application by the event-based camera. This paper proposes an event camera-based lip-reading for isolated single sound recognition. The proposed method consists of imaging from event data, face and facial feature points detection, and recognition using a Temporal Convolutional Network. Furthermore, this paper proposes a method that combines the two modalities of the frame-based camera and an event-based camera. In order to evaluate the proposed method, the utterance scenes of 15 Japanese consonants from 20 speakers were collected using an event-based camera and a video camera and constructed an original dataset. Several experiments were conducted by generating images at multiple frame rates from an event-based camera. As a result, the highest recognition accuracy was obtained in the image of the event-based camera at 60 fps. Moreover, it was confirmed that combining two modalities yields higher recognition accuracy than a single modality.",2023,10.3389/frai.2022.1070964
Smart match: revolutionizing organ allocation through artificial intelligence,"In this transformative era of organ transplantation, integrating Smart Match and artificial intelligence (AI) emerges as a pivotal advancement, revolutionizing organ allocation processes. Smart Match employs AI algorithms, enhancing organ matching precision and optimizing transplantation outcomes. Leveraging machine learning addresses complexities in donor-recipient pairing, immunosuppression management, and post-operative care, promising to minimize waitlist mortality and improve patient wellbeing. The multifaceted potential of Smart Match lies in its ability to not only streamline current practices but also pave the way for future innovations in solid organ transplantation. As technology continues to evolve, the collaboration between Smart Match and AI exemplifies a beacon of progress, promising increased efficiency, equitable organ distribution, and improved patient care. This article delves into the paradigm shift facilitated by Smart Match and AI, emphasizing their transformative impact on the landscape of organ allocation and patient outcomes.",2024,10.3389/frai.2024.1364149
Algorithmic management and human-centered task design: a conceptual synthesis from the perspective of action regulation and sociomaterial systems theory,"This paper aims to explain potential psychological effects of algorithmic management (AM) on human-centered task design and with that also workers’ mental well-being. For this, we link research on algorithmic management (AM) with Sociomaterial System Theory and Action Regulation Theory (ART). Our main assumption is that psychological effects of sociomaterial systems, such as AM, can be explained by their impact on human action. From the synthesis of the theories, mixed effects on human-centered task design can be derived: It can be expected that AM contributes to fewer action regulation opportunities (i.e., job resources like job autonomy, transparency, predictability), and to lower intellectual demands (i.e., challenge demands like task complexity, problem solving). Moreover, it can be concluded that AM is related with more regulation problems (i.e., hindrance demands like overtaxing regulations) but also fewer regulation problems (like regulation obstacles, uncertainty). Based on these considerations and in line with the majority of current research, it can be assumed that the use of AM is indirectly associated with higher risks to workers’ mental well-being. However, we also identify potential positive effects of AM as some stressful and demotivating obstacles at work are often mitigated. Based on these considerations, the main question of future research is not whether AM is good or bad for workers, but ratherhowwork under AM can be designed to be humane. Our proposed model can guide and support researchers and practitioners in improving the understanding of the next generation of AM systems.",2024,10.3389/frai.2024.1441497
Do generative models learn rare generative factors?,"Generative models are becoming a promising tool in AI alongside discriminative learning. Several models have been proposed to learn in an unsupervised fashion the corresponding generative factors, namely the latent variables critical for capturing the full spectrum of data variability. Diffusion Models (DMs), Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) are of particular interest due to their impressive ability to generate highly realistic data. Through a systematic empirical study, this paper delves into the intricate challenge of how DMs, GANs and VAEs internalize and replicate
                    rare
                    generative factors. Our findings reveal a pronounced tendency toward memorization of these factors. We study the reasons for this memorization and demonstrate that strategies such as spectral decoupling can mitigate this issue to a certain extent.
                    
                      1",2025,10.3389/frai.2025.1697139
Asian hate speech detection on Twitter during COVID-19,"Coronavirus disease 2019 (COVID-19) started in Wuhan, China, in late 2019, and after being utterly contagious in Asian countries, it rapidly spread to other countries. This disease caused governments worldwide to declare a public health crisis with severe measures taken to reduce the speed of the spread of the disease. This pandemic affected the lives of millions of people. Many citizens that lost their loved ones and jobs experienced a wide range of emotions, such as disbelief, shock, concerns about health, fear about food supplies, anxiety, and panic. All of the aforementioned phenomena led to the spread of racism and hate against Asians in western countries, especially in the United States. An analysis of official preliminary police data by the Center for the Study of Hate &amp; Extremism at California State University shows that Anti-Asian hate crime in 16 of America's largest cities increased by 149% in 2020. In this study, we first chose a baseline of Americans' hate crimes against Asians on Twitter. Then we present an approach to balance the biased dataset and consequently improve the performance of tweet classification. We also have downloaded 10 million tweets through the Twitter API V-2. In this study, we have used a small portion of that, and we will use the entire dataset in the future study. In this article, three thousand tweets from our collected corpus are annotated by four annotators, including three Asian and one Asian-American. Using this data, we built predictive models of hate speech using various machine learning and deep learning methods. Our machine learning methods include Random Forest, K-nearest neighbors (KNN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression, Decision Tree, and Naive Bayes. Our Deep Learning models include Basic Long-Term Short-Term Memory (LSTM), Bidirectional LSTM, Bidirectional LSTM with Drop out, Convolution, and Bidirectional Encoder Representations from Transformers (BERT). We also adjusted our dataset by filtering tweets that were ambiguous to the annotators based on low Fleiss Kappa agreement between annotators. Our final result showed that Logistic Regression achieved the best statistical machine learning performance with an F1 score of 0.72, while BERT achieved the best performance of the deep learning models, with an F1-Score of 0.85.",2022,10.3389/frai.2022.932381
There are significant differences among artificial intelligence large language models when answering scientific questions,"IntroductionThis study investigates the efficacy of large language models (LLMs) for generating accurate scientific responses through a comparative evaluation of five prominent free models: Claude 3.5 Sonnet, Gemini, ChatGPT 4o, Mistral Large 2, and Llama 3.1 70B.MethodsSixteen expert scientific reviewers assessed these models in terms of depth, accuracy, relevance, and clarity.ResultsClaude 3.5 Sonnet emerged as the highest scoring model, followed by Gemini, with notable variability among the other models. Additionally, retrieval-augmented generation (RAG) techniques were applied to improve LLM performance, and prompts were refined to improve answers. The results indicate that although LLMs such as Claude 3.5 Sonnet have potential for scientific tasks, other models may require more development or additional prompt engineering to reach comparable accuracy. Reviewers’ perceptions of artificial intelligence (AI) utility and trustworthiness showed a positive shift after evaluation. However, ethical concerns, particularly with respect to transparency and disclosure, remained consistent.DiscussionThe study highlights the need for structured frameworks for evaluating LLMs and ethical considerations essential for responsible AI integration in scientific research. These findings should be interpreted with caution, as the limited sample size and domain-specific focus of the exam questions restrict the generalizability of the results.",2025,10.3389/frai.2025.1664303
Artificial Neural Network Based Non-linear Transformation of High-Frequency Returns for Volatility Forecasting,"This paper uses Long Short Term Memory Recurrent Neural Networks to extract information from the intraday high-frequency returns to forecast daily volatility. Applied to the IBM stock, we find significant improvements in the forecasting performance of models that use this extracted information compared to the forecasts of models that omit the extracted information and some of the most popular alternative models. Furthermore, we find that extracting the information through Long Short Term Memory Recurrent Neural Networks is superior to two Mixed Data Sampling alternatives.",2022,10.3389/frai.2021.787534
Causal Datasheet for Datasets: An Evaluation Guide for Real-World Data Analysis and Data Collection Design Using Bayesian Networks,"Developing data-driven solutions that address real-world problems requires understanding of these problems’ causes and how their interaction affects the outcome–often with only observational data. Causal Bayesian Networks (BN) have been proposed as a powerful method for discovering and representing the causal relationships from observational data as a Directed Acyclic Graph (DAG). BNs could be especially useful for research in global health in Lower and Middle Income Countries, where there is an increasing abundance of observational data that could be harnessed for policy making, program evaluation, and intervention design. However, BNs have not been widely adopted by global health professionals, and in real-world applications, confidence in the results of BNs generally remains inadequate. This is partially due to the inability to validate against some ground truth, as the true DAG is not available. This is especially problematic if a learned DAG conflicts with pre-existing domain doctrine. Here we conceptualize and demonstrate an idea of a “Causal Datasheet” that could approximate and document BN performance expectations for a given dataset, aiming to provide confidence and sample size requirements to practitioners. To generate results for such a Causal Datasheet, a tool was developed which can generate synthetic Bayesian networks and their associated synthetic datasets to mimic real-world datasets. The results given by well-known structure learning algorithms and a novel implementation of the OrderMCMC method using the Quotient Normalized Maximum Likelihood score were recorded. These results were used to populate the Causal Datasheet, and recommendations could be made dependent on whether expected performance met user-defined thresholds. We present our experience in the creation of Causal Datasheets to aid analysis decisions at different stages of the research process. First, one was deployed to help determine the appropriate sample size of a planned study of sexual and reproductive health in Madhya Pradesh, India. Second, a datasheet was created to estimate the performance of an existing maternal health survey we conducted in Uttar Pradesh, India. Third, we validated generated performance estimates and investigated current limitations on the well-known ALARM dataset. Our experience demonstrates the utility of the Causal Datasheet, which can help global health practitioners gain more confidence when applying BNs.",2021,10.3389/frai.2021.612551
The role of AI-enhanced fast delivery services in strengthening customer retention and loyalty in competitive markets,"This research presents an AI-enhanced framework to optimize last-mile delivery systems by integrating predictive analytics, Reinforcement Learning (RL), and customer personalization. The predictive analytics component utilized XGBoost and Random Forest models to forecast delivery times. Random Forest achieved better performance, with a Root Mean Square Error of 1.52 and an R-squared value of 0.56. RL-based route optimization improved operational efficiency by reducing the average delivery time from 31.2 to 25.4 min, increasing timely deliveries from 78\% to 92\%, and reducing idle time by 15\%. Customer personalization, driven by sentiment analysis and clustering, increased positive sentiment from 68\% to 80\%. It also improved Net Promoter Scores from 68 to 85 and increased customer retention from 74\% to 89\%. The proposed framework addresses the challenges of last-mile delivery by combining data-driven predictions, adaptive routing, and personalized customer strategies. Future work will explore real-world implementation using real-time traffic data and advanced personalization techniques to improve adaptability and scalability.",2025,10.3389/frai.2025.1612772
Visual Features and Their Own Optical Flow,"Symmetries, invariances and conservation equations have always been an invaluable guide in Science to model natural phenomena through simple yet effective relations. For instance, in computer vision, translation equivariance is typically a built-in property of neural architectures that are used to solve visual tasks; networks with computational layers implementing such a property are known as Convolutional Neural Networks (CNNs). This kind of mathematical symmetry, as well as many others that have been recently studied, are typically generated by some underlying group of transformations (translations in the case of CNNs, rotations, etc.) and are particularly suitable to process highly structured data such as molecules or chemical compounds which are known to possess those specific symmetries. When dealing with video streams, common built-in equivariances are able to handle only a small fraction of the broad spectrum of transformations encoded in the visual stimulus and, therefore, the corresponding neural architectures have to resort to a huge amount of supervision in order to achieve good generalization capabilities. In the paper we formulate a theory on the development of visual features that is based on the idea that movement itself provides trajectories on which to impose consistency. We introduce the principle of Material Point Invariance which states that each visual feature is invariant with respect to the associated optical flow, so that features and corresponding velocities are an indissoluble pair. Then, we discuss the interaction of features and velocities and show that certain motion invariance traits could be regarded as a generalization of the classical concept of affordance. These analyses of feature-velocity interactions and their invariance properties leads to a visual field theory which expresses the dynamical constraints of motion coherence and might lead to discover the joint evolution of the visual features along with the associated optical flows.",2021,10.3389/frai.2021.768516
Semantics in High-Dimensional Space,"Geometric models are used for modelling meaning in various semantic-space models. They are seductive in their simplicity and their imaginative qualities, and for that reason, their metaphorical power risks leading our intuitions astray: human intuition works well in a three-dimensional world but is overwhelmed by higher dimensionalities. This note is intended to warn about some practical pitfalls of using high-dimensional geometric representation as a knowledge representation and a memory model—challenges that can be met by informed design of the representation and its application.",2021,10.3389/frai.2021.698809
Integration of machine learning with complex industrial mining systems for reduced energy consumption,"The deep-level mining industry is experiencing narrowing profit margins due to increasing operating costs and decreasing production. The industry is known for its lack of dynamic control across complex integrated systems running deep underground, making IoT technologies difficult to implement. An important integrated system in a typical underground mine is the refrigeration-ventilation system. In practice, the two systems are still controlled independently, often due to a lack of continuous measurements. However, their integrated effects ultimately affect energy usage and production. This study develops and compares various machine learning prediction techniques to predict the integrated behavior of a key component operating on the boundary of the refrigeration-ventilation system, while also addressing the lack of continuous measurements. The component lacks sensors and the developed industrial machine learning models negate the effect thereof using integrated control. The predictive models are compared based on accuracy, prediction time, as well as the amount of data required to obtain the required level of accuracy. The “Support Vector Machines” method achieved the lowest average error (1.97%), but the “Artificial Neural Network” method is more robust (with a maximum percentage error of 12.90%). A potential energy saving of 215 kW or 2.9% of the ventilation and refrigeration system, equivalent to R1.33-million per annum ($82 9001) is achievable using the “Support Vector Machines” method.",2022,10.3389/frai.2022.938641
Rare disease-based scientific annotation knowledge graph,"Rare diseases (RDs) are naturally associated with a low prevalence rate, which raises a big challenge due to there being less data available for supporting preclinical and clinical studies. There has been a vast improvement in our understanding of RD, largely owing to advanced big data analytic approaches in genetics/genomics. Consequently, a large volume of RD-related publications has been accumulated in recent years, which offers opportunities to utilize these publications for accessing the full spectrum of the scientific research and supporting further investigation in RD. In this study, we systematically analyzed, semantically annotated, and scientifically categorized RD-related PubMed articles, and integrated those semantic annotations in a knowledge graph (KG), which is hosted in Neo4j based on a predefined data model. With the successful demonstration of scientific contribution in RD via the case studies performed by exploring this KG, we propose to extend the current effort by expanding more RD-related publications and more other types of resources as a next step.",2022,10.3389/frai.2022.932665
Understanding Robustness and Generalization of Artificial Neural Networks Through Fourier Masks,"Despite the enormous success of artificial neural networks (ANNs) in many disciplines, the characterization of their computations and the origin of key properties such as generalization and robustness remain open questions. Recent literature suggests that robust networks with good generalization properties tend to be biased toward processing low frequencies in images. To explore the frequency bias hypothesis further, we develop an algorithm that allows us to learn modulatory masks highlighting the essential input frequencies needed for preserving a trained network's performance. We achieve this by imposing invariance in the loss with respect to such modulations in the input frequencies. We first use our method to test the low-frequency preference hypothesis of adversarially trained or data-augmented networks. Our results suggest that adversarially robust networks indeed exhibit a low-frequency bias but we find this bias is also dependent on directions in frequency space. However, this is not necessarily true for other types of data augmentation. Our results also indicate that the essential frequencies in question are effectively the ones used to achieve generalization in the first place. Surprisingly, images seen through these modulatory masks are not recognizable and resemble texture-like patterns.",2022,10.3389/frai.2022.890016
Can chatbots teach us how to behave? Examining assumptions about user interactions with AI assistants and their social implications,"In this article we examine the issue of AI assistants, and the way they respond to insults and sexually explicit requests. Public concern over these responses, particularly because AI assistants are usually female-voiced, prompted tech companies to make them more assertive. Researchers have explored whether these female-voiced AI assistants could encourage abusive behavior and reinforce societal sexism. However, the extent and nature of the problem are unclear due to a lack of data on user interactions. By combining psychological and socio-cultural perspectives, we problematize these assumptions and outline a number of research questions for leveraging AI assistants to promote gender inclusivity more effectively.",2025,10.3389/frai.2025.1545607
Lung Cancer Segmentation With Transfer Learning: Usefulness of a Pretrained Model Constructed From an Artificial Dataset Generated Using a Generative Adversarial Network,"Purpose: The purpose of this study was to develop and evaluate lung cancer segmentation with a pretrained model and transfer learning. The pretrained model was constructed from an artificial dataset generated using a generative adversarial network (GAN).Materials and Methods: Three public datasets containing images of lung nodules/lung cancers were used: LUNA16 dataset, Decathlon lung dataset, and NSCLC radiogenomics. The LUNA16 dataset was used to generate an artificial dataset for lung cancer segmentation with the help of the GAN and 3D graph cut. Pretrained models were then constructed from the artificial dataset. Subsequently, the main segmentation model was constructed from the pretrained models and the Decathlon lung dataset. Finally, the NSCLC radiogenomics dataset was used to evaluate the main segmentation model. The Dice similarity coefficient (DSC) was used as a metric to evaluate the segmentation performance.Results: The mean DSC for the NSCLC radiogenomics dataset improved overall when using the pretrained models. At maximum, the mean DSC was 0.09 higher with the pretrained model than that without it.Conclusion: The proposed method comprising an artificial dataset and a pretrained model can improve lung cancer segmentation as confirmed in terms of the DSC metric. Moreover, the construction of the artificial dataset for the segmentation using the GAN and 3D graph cut was found to be feasible.",2021,10.3389/frai.2021.694815
Predictive digital twin for optimizing patient-specific radiotherapy regimens under uncertainty in high-grade gliomas,"We develop a methodology to create data-driven predictive digital twins for optimal risk-aware clinical decision-making. We illustrate the methodology as an enabler for an anticipatory personalized treatment that accounts for uncertainties in the underlying tumor biology in high-grade gliomas, where heterogeneity in the response to standard-of-care (SOC) radiotherapy contributes to sub-optimal patient outcomes. The digital twin is initialized through prior distributions derived from population-level clinical data in the literature for a mechanistic model's parameters. Then the digital twin is personalized using Bayesian model calibration for assimilating patient-specific magnetic resonance imaging data. The calibrated digital twin is used to propose optimal radiotherapy treatment regimens by solving a multi-objective risk-based optimization under uncertainty problem. The solution leads to a suite of patient-specific optimal radiotherapy treatment regimens exhibiting varying levels of trade-off between the two competing clinical objectives: (i) maximizing tumor control (characterized by minimizing the risk of tumor volume growth) and (ii) minimizing the toxicity from radiotherapy. The proposed digital twin framework is illustrated by generating an in silico cohort of 100 patients with high-grade glioma growth and response properties typically observed in the literature. For the same total radiation dose as the SOC, the personalized treatment regimens lead to median increase in tumor time to progression of around six days. Alternatively, for the same level of tumor control as the SOC, the digital twin provides optimal treatment options that lead to a median reduction in radiation dose by 16.7% (10 Gy) compared to SOC total dose of 60 Gy. The range of optimal solutions also provide options with increased doses for patients with aggressive cancer, where SOC does not lead to sufficient tumor control.",2023,10.3389/frai.2023.1222612
Rare and complex diseases in focus: ChatGPT's role in improving diagnosis and treatment,"Rare and complex diseases pose significant challenges to both patients and healthcare providers. These conditions often present with atypical symptoms, making diagnosis and treatment a formidable task. In recent years, artificial intelligence and natural language processing technologies have shown great promise in assisting medical professionals in diagnosing and managing such conditions. This paper explores the role of ChatGPT, an advanced artificial intelligence model, in improving the diagnosis and treatment of rare and complex diseases. By analyzing its potential applications, limitations, and ethical considerations, we demonstrate how ChatGPT can contribute to better patient outcomes and enhance the healthcare system's overall effectiveness.",2024,10.3389/frai.2024.1338433
Explainable deep learning in plant phenotyping,"The increasing human population and variable weather conditions, due to climate change, pose a threat to the world's food security. To improve global food security, we need to provide breeders with tools to develop crop cultivars that are more resilient to extreme weather conditions and provide growers with tools to more effectively manage biotic and abiotic stresses in their crops. Plant phenotyping, the measurement of a plant's structural and functional characteristics, has the potential to inform, improve and accelerate both breeders' selections and growers' management decisions. To improve the speed, reliability and scale of plant phenotyping procedures, many researchers have adopted deep learning methods to estimate phenotypic information from images of plants and crops. Despite the successful results of these image-based phenotyping studies, the representations learned by deep learning models remain difficult to interpret, understand, and explain. For this reason, deep learning models are still considered to be black boxes. Explainable AI (XAI) is a promising approach for opening the deep learning model's black box and providing plant scientists with image-based phenotypic information that is interpretable and trustworthy. Although various fields of study have adopted XAI to advance their understanding of deep learning models, it has yet to be well-studied in the context of plant phenotyping research. In this review article, we reviewed existing XAI studies in plant shoot phenotyping, as well as related domains, to help plant researchers understand the benefits of XAI and make it easier for them to integrate XAI into their future studies. An elucidation of the representations within a deep learning model can help researchers explain the model's decisions, relate the features detected by the model to the underlying plant physiology, and enhance the trustworthiness of image-based phenotypic information used in food production systems.",2023,10.3389/frai.2023.1203546
Self-Explaining Social Robots: An Explainable Behavior Generation Architecture for Human-Robot Interaction,"In recent years, the ability of intelligent systems to be understood by developers and users has received growing attention. This holds in particular for social robots, which are supposed to act autonomously in the vicinity of human users and are known to raise peculiar, often unrealistic attributions and expectations. However, explainable models that, on the one hand, allow a robot to generate lively and autonomous behavior and, on the other, enable it to provide human-compatible explanations for this behavior are missing. In order to develop such a self-explaining autonomous social robot, we have equipped a robot with own needs that autonomously trigger intentions and proactive behavior, and form the basis for understandable self-explanations. Previous research has shown that undesirable robot behavior is rated more positively after receiving an explanation. We thus aim to equip a social robot with the capability to automatically generate verbal explanations of its own behavior, by tracing its internal decision-making routes. The goal is to generate social robot behavior in a way that is generally interpretable, and therefore explainable on a socio-behavioral level increasing users' understanding of the robot's behavior. In this article, we present a social robot interaction architecture, designed to autonomously generate social behavior and self-explanations. We set out requirements for explainable behavior generation architectures and propose a socio-interactive framework for behavior explanations in social human-robot interactions that enables explaining and elaborating according to users' needs for explanation that emerge within an interaction. Consequently, we introduce an interactive explanation dialog flow concept that incorporates empirically validated explanation types. These concepts are realized within the interaction architecture of a social robot, and integrated with its dialog processing modules. We present the components of this interaction architecture and explain their integration to autonomously generate social behaviors as well as verbal self-explanations. Lastly, we report results from a qualitative evaluation of a working prototype in a laboratory setting, showing that (1) the robot is able to autonomously generate naturalistic social behavior, and (2) the robot is able to verbally self-explain its behavior to the user in line with users' requests.",2022,10.3389/frai.2022.866920
Visceral condition assessment through digital tongue image analysis,"Traditional Chinese medicine (TCM) has long utilized tongue diagnosis as a crucial method for assessing internal visceral condition. This study aims to modernize this ancient practice by developing an automated system for analyzing tongue images in relation to the five organs, corresponding to the heart, liver, spleen, lung, and kidney—collectively known as the “five viscera” in TCM. We propose a novel tongue image partitioning algorithm that divides the tongue into four regions associated with these specific organs, according to TCM principles. These partitioned regions are then processed by our newly developed OrganNet, a specialized neural network designed to focus on organ-specific features. Our method simulates the TCM diagnostic process while leveraging modern machine learning techniques. To support this research, we have created a comprehensive tongue image dataset specifically tailored for these five visceral pattern assessment. Results demonstrate the effectiveness of our approach in accurately identifying correlations between tongue regions and visceral conditions. This study bridges TCM practices with contemporary technology, potentially enhancing diagnostic accuracy and efficiency in both TCM and modern medical contexts.",2025,10.3389/frai.2024.1501184
Deep learning classification of drainage crossings based on high-resolution DEM-derived geomorphological information,"High-resolution digital elevation models (HRDEMs) from LiDAR and InSAR technologies have significantly improved the accuracies of mapping hydrographic features such as river boundaries, streamlines, and waterbodies over large areas. However, drainage crossings that facilitate the passage of drainage flows beneath roads are not often represented in HRDEMs, resulting in erratic or distorted hydrographic features. At present, drainage crossing datasets are largely missing or available with variable quality. While previous studies have investigated basic convolutional neural network (CNN) models for drainage crossing characterization, it remains unclear if advanced deep learning models will improve the accuracy of drainage crossing classification. Although HRDEM-derived geomorphological features have been identified to enhance feature extraction in other hydrography applications, the contributions of these features to drainage crossing image classification have yet to be sufficiently investigated. This study develops advanced CNN models, EfficientNetV2, using four co-registered 1-meter resolution geomorphological data layers derived from HRDEMs for drainage crossing classification. These layers include positive openness (POS), geometric curvature, and two topographic position index (TPI) layers utilizing 3 × 3 and 21 × 21 cell windows. The findings reveal that the advanced CNN models with HRDEM, TPI (21 × 21), and a combination of HRDEM, POS, and TPI (21 × 21) improve classification accuracy in comparison to the baseline model by 3.39, 4.27, and 4.93%, respectively. The study culminates in explainable artificial intelligence (XAI) for evaluating those most critical image segments responsible for characterizing drainage crossings.",2025,10.3389/frai.2025.1561281
Deep hybrid model for maternal health risk classification in pregnancy: synergy of ANN and random forest,"IntroductionMaternal health is a critical aspect of public health that affects the wellbeing of both mothers and infants. Despite medical advancements, maternal mortality rates remain high, particularly in developing countries. AI-based models provide new ways to analyze and interpret medical data, which can ultimately improve maternal and fetal health outcomes.MethodsThis study proposes a deep hybrid model for maternal health risk classification in pregnancy, which utilizes the strengths of artificial neural networks (ANN) and random forest (RF) algorithms. The proposed model combines the two algorithms to improve the accuracy and efficiency of risk classification in pregnant women. The dataset used in this study consists of features such as age, systolic and diastolic blood pressure, blood sugar, body temperature, and heart rate. The dataset is divided into training and testing sets, with 75% of the data used for training and 25% used for testing. The output of the ANN and RF classifier is considered, and a maximum probability voting system selects the output with the highest probability as the most correct.ResultsPerformance is evaluated using various metrics, such as accuracy, precision, recall, and F1 score. Results showed that the proposed model achieves 95% accuracy, 97% precision, 97% recall, and an F1 score of 0.97 on the testing dataset.DiscussionThe deep hybrid model proposed in this study has the potential to improve the accuracy and efficiency of maternal health risk classification in pregnancy, leading to better health outcomes for pregnant women and their babies. Future research could explore the generalizability of this model to other populations, incorporate unstructured medical data, and evaluate its feasibility for clinical use.",2023,10.3389/frai.2023.1213436
Mediating role of Digital Ethics on the impact of Artificial Intelligence Usage and Public Relations Practices: evidence from Malaysia,"The use of Artificial Intelligence (AI) has led to great advancement in the field of Public Relations (PR); however, the organisations are still unsure about the ethical consequences of this new technology. This study aims to examine the effect of AI usage on PR practices by examining the mediating role of Digital Ethics. The study used a cross-sectional quantitative method. The data was collected through structured survey questionnaires from PR practitioners in a Malaysian setting. Mediation analysis was run using the Statistical Package for Social Sciences (SPSS) and PROCESS macro-Model 4. The results showcased that AI usage has a significant impact on PR practices, while Digital Ethics further mediates the relationship, suggesting that AI, when employed ethically, assists in efficient PR practices. This work fills a critical gap in the literature regarding the role of Digital Ethics in the landscape of AI usage for performing PR activities. The study extends the Excellence Theory scholarship into an AI-driven ethical context. The findings offer a crucial incentive for organisations to introduce robust ethical guidelines into their AI-driven PR strategies. The study suggests that by being aware and readily employing Digital Ethical practices, PR practitioners can not only increase their productivity but also safeguard their organisations against the potential ethical threats posed by AI.",2025,10.3389/frai.2025.1662219
An autoencoder-based deep learning method for genotype imputation,"Genotype imputation has a wide range of applications in genome-wide association study (GWAS), including increasing the statistical power of association tests, discovering trait-associated loci in meta-analyses, and prioritizing causal variants with fine-mapping. In recent years, deep learning (DL) based methods, such as sparse convolutional denoising autoencoder (SCDA), have been developed for genotype imputation. However, it remains a challenging task to optimize the learning process in DL-based methods to achieve high imputation accuracy. To address this challenge, we have developed a convolutional autoencoder (AE) model for genotype imputation and implemented a customized training loop by modifying the training process with a single batch loss rather than the average loss over batches. This modified AE imputation model was evaluated using a yeast dataset, the human leukocyte antigen (HLA) data from the 1,000 Genomes Project (1KGP), and our in-house genotype data from the Louisiana Osteoporosis Study (LOS). Our modified AE imputation model has achieved comparable or better performance than the existing SCDA model in terms of evaluation metrics such as the concordance rate (CR), the Hellinger score, the scaled Euclidean norm (SEN) score, and the imputation quality score (IQS) in all three datasets. Taking the imputation results from the HLA data as an example, the AE model achieved an average CR of 0.9468 and 0.9459, Hellinger score of 0.9765 and 0.9518, SEN score of 0.9977 and 0.9953, and IQS of 0.9515 and 0.9044 at missing ratios of 10% and 20%, respectively. As for the results of LOS data, it achieved an average CR of 0.9005, Hellinger score of 0.9384, SEN score of 0.9940, and IQS of 0.8681 at the missing ratio of 20%. In summary, our proposed method for genotype imputation has a great potential to increase the statistical power of GWAS and improve downstream post-GWAS analyses.",2022,10.3389/frai.2022.1028978
Determining the meter of classical Arabic poetry using deep learning: a performance analysis,"The metrical structure of classical Arabic poetry, deeply rooted in its rich literary heritage, is governed by 16 distinct meters, making its analysis both a linguistic and computational challenge. In this study, a deep learning-based approach was developed to accurately determine the meter of Arabic poetry using TensorFlow and a large dataset. Character-level encoding was employed to convert text into integers, enabling the classification of both full-verse and half-verse data. In particular, the data were evaluated without removing diacritics, preserving critical linguistic features. A train–test–split method with a 70–15–15 division was utilized, with 15% of the total dataset reserved as unseen test data for evaluation across all models. Multiple deep learning architectures, including long short-term memory (LSTM), gated recurrent units (GRU), and bidirectional long short-term memory (Bi-LSTM), were tested. Among these, the bidirectional long short-term memory model achieved the highest accuracy, with 97.53% for full-verse and 95.23% for half-verse data. This study introduces an effective framework for Arabic meter classification, contributing significantly to the application of artificial intelligence in natural language processing and text analytics.",2025,10.3389/frai.2025.1523336
Features of lexical complexity: insights from L1 and L2 speakers,"We discover sizable differences between the lexical complexity assignments of first language (L1) and second language (L2) English speakers. The complexity assignments of 940 shared tokens without context were extracted and compared from three lexical complexity prediction (LCP) datasets: the CompLex dataset, the Word Complexity Lexicon, and the CERF-J wordlist. It was found that word frequency, length, syllable count, familiarity, and prevalence as well as a number of derivations had a greater effect on perceived lexical complexity for L2 English speakers than they did for L1 English speakers. We explain these findings in connection to several theories from applied linguistics and then use these findings to inform a binary classifier that is trained to distinguish between spelling errors made by L1 and L2 English speakers. Our results indicate that several of our findings are generalizable. Differences in perceived lexical complexity are shown to be useful in the automatic identification of problematic words for these differing target populations. This gives support to the development of personalized lexical complexity prediction and text simplification systems.",2023,10.3389/frai.2023.1236963
Automated surgical step recognition in transurethral bladder tumor resection using artificial intelligence: transfer learning across surgical modalities,"ObjectiveAutomated surgical step recognition (SSR) using AI has been a catalyst in the “digitization” of surgery. However, progress has been limited to laparoscopy, with relatively few SSR tools in endoscopic surgery. This study aimed to create a SSR model for transurethral resection of bladder tumors (TURBT), leveraging a novel application of transfer learning to reduce video dataset requirements.Materials and methodsRetrospective surgical videos of TURBT were manually annotated with the following steps of surgery: primary endoscopic evaluation, resection of bladder tumor, and surface coagulation. Manually annotated videos were then utilized to train a novel AI computer vision algorithm to perform automated video annotation of TURBT surgical video, utilizing a transfer-learning technique to pre-train on laparoscopic procedures. Accuracy of AI SSR was determined by comparison to human annotations as the reference standard.ResultsA total of 300 full-length TURBT videos (median 23.96 min; IQR 14.13–41.31 min) were manually annotated with sequential steps of surgery. One hundred and seventy-nine videos served as a training dataset for algorithm development, 44 for internal validation, and 77 as a separate test cohort for evaluating algorithm accuracy. Overall accuracy of AI video analysis was 89.6%. Model accuracy was highest for the primary endoscopic evaluation step (98.2%) and lowest for the surface coagulation step (82.7%).ConclusionWe developed a fully automated computer vision algorithm for high-accuracy annotation of TURBT surgical videos. This represents the first application of transfer-learning from laparoscopy-based computer vision models into surgical endoscopy, demonstrating the promise of this approach in adapting to new procedure types.",2024,10.3389/frai.2024.1375482
Adapting conversational strategies in information-giving human-agent interaction,"In this work, we focus on human-agent interaction where the role of the socially interactive agent is to optimize the amount of information to give to a user. In particular, we developed a dialog manager able to adapt the agent's conversational strategies to the preferences of the user it is interacting with to maximize the user's engagement during the interaction. For this purpose, we train an agent in interaction with a user using the reinforcement learning approach. The engagement of the user is measured using their non-verbal behaviors and turn-taking status. This measured engagement is used in the reward function, which balances the task of the agent (giving information) and its social goal (maintaining the user highly engaged). Agent's dialog acts may have different impact on the user's engagement depending on several factors, such as their personality, interest in the discussion topic, and attitude toward the agent. A subjective study was conducted with 120 participants to measure how third-party observers can perceive the adaptation of our dialog model. The results show that adapting the agent's conversational strategies has an influence on the participants' perception.",2022,10.3389/frai.2022.1029340
Cross-dialectal Arabic translation: comparative analysis on large language models,"IntroductionExploring Arabic dialects in Natural Language Processing (NLP) is essential to understand linguistic variation and meet regional communication demands. Recent advances in Large Language Models (LLMs) have opened up new vistas for multilingual communication and text generation.MethodsThis paper investigates the performance of GPT-3.5, GPT-4, and Bard (Gemini) on the QADI and MADAR datasets, while GPT-5 was evaluated exclusively on MADAR encompassing over 15 different countries. Several metrics have been used in the evaluation, such as cosine similarity, universal similarity encoder, sentence BERT, TER, ROUGE, and BLEU. In this study, different prompting techniques were used: zero-shot and few-shot. Zero-shot was employed for all dialects, and few-shot was employed only for the least translation performance dialect, Tunisian.ResultsAnalysis revealed that in the QADI dataset, GPT-4 significantly outperformed others in translating MSA to DA, with ANOVA tests showing strong significance (p &lt; 0.05) in most metrics, except for BLEU and TER where it does not show significance, indicating comparable translation performance among models. Furthermore, GPT-4 was highest in semantic similarity compared to GPT-3.5 and Bard (Gemini), 0.66, 0.61, and 0.63, respectively. GPT-4 was the best in identifying overlapping sentences (i.e., those where the source and target are identical) with a combined average of 0.41 in BLEU and ROUGE-L. All LLMs scored TER values between 6% and 25%, indicating generally good translation quality. However, GPT models, especially GPT-5, responded better to prompting and translation to Levant countries compared to Bard (Gemini). For the MADAR dataset, no significant translation differences were observed in sentence-BERT, ROUGE-L, and TER, while differences are identified in cosine similarity, BLEU, and universal similarity encoder metrics. Therefore, GPT-5 is the top performer in identifying sentence overlaps measured by BLEU and ROUGE-L (combined average 0.37).DiscussionThe few-shot approach did not show a significant improvement in translation performance, especially for GPT-4 and Bard (Gemini), while GPT-3.5 performed consistently. Zero-shot prompts were effective across dialects, while few-shot prompting, applied to the weakest-performing dialect (Tunisian), did not yield improvement. GPT-4 and Bard performed worse under this set-up, while GPT-3.5 remained consistent.",2025,10.3389/frai.2025.1661789
Optimizing training of time series diffusion models via similarity score functions: application to cyclic and acyclic motion with IMU data,"IntroductionDenoising diffusion probabilistic models have shown the capability to generate synthetic sensor signals. These models rely on a loss function that measures the difference between the noise added during the forward process and the noise predicted by the diffusion model, thereby enabling realistic data generation. However, the stochastic nature of the process and the loss function complicate the estimation of data quality.MethodsTo address this issue, we evaluated multiple similarity metrics and adapted an existing metric to monitor both the training and data synthesis processes. The adapted metric was further fine-tuned on the input data to align with the requirements of a downstream classification task.ResultsBy incorporating the adapted metric, we significantly reduced the number of training epochs required without observing performance degradation in the classification task.DiscussionOur findings demonstrate that optimizing the training process using similarity metrics not only conserves computational resources but also shortens the training time for generative models, making them more efficient and practical for real-world applications.",2025,10.3389/frai.2025.1640948
A machine learning model to predict heart failure readmission: toward optimal feature set,"BackgroundHospital readmissions for heart failure patients remain high despite efforts to reduce them. Predictive modeling using big data provides opportunities to identify high-risk patients and inform care management. However, large datasets can constrain performance.ObjectiveThis study aimed to develop a machine learning based prediction model leveraging a nationwide hospitalization database to predict 30-day heart failure readmissions. Another objective of this study is to find the optimal feature set that leads to the highest AUC value in the prediction model.Material and methodsHeart failure patient data was extracted from the 2020 Nationwide Readmissions Database. A heuristic feature selection process incrementally incorporated predictors into logistic regression and random forest models, which yields a maximum increase in the AUC metric. Discrimination was evaluated through accuracy, sensitivity, specificity and AUC.ResultsA total of 566,019 discharges with heart failure diagnosis were recognized. Readmission rate was 8.9% for same-cause and 20.6% for all-cause diagnoses. Random forest outperformed logistic regression, achieving AUCs of 0.607 and 0.576 for same-cause and all-cause readmissions respectively. Heuristic feature selection resulted in the identification of optimal feature sets including 20 and 22 variables from a pool of 30 and 31 features for the same-cause and all-cause datasets. Key predictors included age, payment method, chronic kidney disease, disposition status, number of ICD-10-CM diagnoses, and post-care encounters.ConclusionThe proposed model attained discrimination comparable to prior analyses that used smaller datasets. However, reducing the sample enhanced performance, indicating big data complexity. Improved techniques like heuristic feature selection enabled effective leveraging of the nationwide data. This study provides meaningful insights into predictive modeling methodologies and influential features for forecasting heart failure readmissions.",2024,10.3389/frai.2024.1363226
Analyzing the European institutional response to ethical and regulatory challenges of artificial intelligence in addressing discriminatory bias,"The European Union and some of its institutions have taken significant steps to address the challenges posed by the development and use of Artificial Intelligence (AI) in various contexts. The ubiquity of AI applications in everyday life, affecting both citizens and professionals, has made AI a common topic of discussion. However, as is evident from the documents analyzed here, concerns have been raised about the possible negative social consequences of AI, in particular discriminatory bias, making it a particularly relevant issue if people-centred, rights-based AI is to be implemented. This article aims to examine the challenges of defining, identifying and mitigating discriminatory bias in AI systems from two perspectives: (1) to conduct an ethical and normative review of European Commission documents from the last 8 years (from GDPR to AI Act regulation); and (2) to expose recommendations for key stakeholders, including designers, end-users and public authorities, to minimize/mitigate this risk. The document review was carried out on 21 EU regulatory and ethical guidelines in the field of AI, from which 152 measures were extracted, differentiated between design, governance and organizational measures. It has also been observed that there is no clear conceptual framework on the issue at the European level, showing a clear problem in providing definitions of algorithmic bias and discrimination, but not in assessing their potential negative impact on individuals. Secondly, these gaps may affect the concreteness and detail of the possible mitigation/minimization measures proposed and, subsequently, their application in different contexts. Finally, the last section of this paper presents a brief discussion and conclusions on possible issues related to the implementation of the measures extracted and certain limitations of the study.",2024,10.3389/frai.2024.1393259
Exploring the evolution and future prospects of Amharic to English machine translation: a systematic review,"IntroductionIn the last couple of decades, Amharic-English translation has greatly improved from a rule-based approach to contemporary systems that apply neural networks. Even after these advancements, problems remain because of the Amharic language’s resource-scarce nature, such as inadequate datasets, tools for working with the language, and the intricate semantics and grammar of Amharic as compared to English. This systematic review seeks to analyze the evolution of the Amharic-English machine translation, the prominent ongoing difficulties, the noteworthy research undertakings, and the prospects of the research focus.MethodsThis review uses a systematic approach to study the literature on Amharic-English machine translation. Important documents were retrieved from academic websites, and those with relevance to the methodologies of machine translation, language resources development, and evaluation practices were chosen. Primarily, the focus was on both statistical and neural machine translation models, especially those with transformer structures.ResultsThe initial attempts to translate English to Amharic and vice-versa relied on statistic machine translation (SMT), which set the stage for the evolution to neural machine translation (NMT). The use of transformer models has impacted the accuracy and fluidity of translations tremendously. Still, there is a lack of sufficient parallel corpora, effective methods for tokenization of Amharic, and other resources. Recently, the focus has been on creating new datasets, improving token-level engineering, and modifying NMT models for Amharic’s complex morphological structure.DiscussionThe complete solutions for enhancing Amharic-English translation remain elusive and include the lack of sufficient data, semantic correspondence, and grammatical consistency within and across translations. Pursuable avenues include augmentation of data, tokenization on the language level, and incorporation of linguistic elements into the parallel corpora. In addition, creating effective evaluation frameworks along with comprehensive linguistic data is important for assessing and improving translation tools. With these changes, cross-cultural interaction and increasing accessibility to modern technologies will be achieved.",2025,10.3389/frai.2025.1456245
"Big data in financial risk management: evidence, advances, and open questions: a systematic review","IntroductionThe intersection of big data analytics and financial risk management has spurred significant methodological innovation and organizational change. Despite growing research activity, the literature remains fragmented, with notable gaps in comparative effectiveness, cross-sectoral applicability, and the use of non-traditional data sources.MethodsFollowing the PRISMA 2020 protocol, a systematic review was conducted on 21 peer-reviewed studies published between 2016 and June 2025. The review evaluated the methodological diversity and effectiveness of machine learning and hybrid approaches in financial risk management.ResultsThe analysis mapped the relative strengths and limitations of neural networks, ensemble learning, fuzzy logic, and hybrid optimization across credit, fraud, systemic, and operational risk. Advanced machine learning techniques consistently demonstrated strong predictive accuracy, yet real-world deployment remained geographically concentrated, primarily in Chinese and European banking and fintech sectors. Applications involving alternative and unstructured data, such as IoT signals and behavioral analytics, were largely experimental and faced both technical and governance challenges.Discussion/conclusionThe findings underscore the scarcity of systematic benchmarking across risk types and organizational contexts, as well as the limited attention to explainability in current implementations. This review identifies an urgent need for comparative, cross-jurisdictional studies, stronger field validation, and open science practices to bridge the gap between technical advances and their operational impact in big data–enabled financial risk management.",2025,10.3389/frai.2025.1658375
Sysrev: A FAIR Platform for Data Curation and Systematic Evidence Review,"Well-curated datasets are essential to evidence based decision making and to the integration of artificial intelligence with human reasoning across disciplines. However, many sources of data remain siloed, unstructured, and/or unavailable for complementary and secondary research. Sysrev was developed to address these issues. First, Sysrev was built to aid in systematic evidence reviews (SER), where digital documents are evaluated according to a well defined process, and where Sysrev provides an easy to access, publicly available and free platform for collaborating in SER projects. Secondly, Sysrev addresses the issue of unstructured, siloed, and inaccessible data in the context of generalized data extraction, where human and machine learning algorithms are combined to extract insights and evidence for better decision making across disciplines. Sysrev uses FAIR - Findability, Accessibility, Interoperability, and Reuse of digital assets - as primary principles in design. Sysrev was developed primarily because of an observed need to reduce redundancy, reduce inefficient use of human time and increase the impact of evidence based decision making. This publication is an introduction to Sysrev as a novel technology, with an overview of the features, motivations and use cases of the tool.
                  
                    Methods:
                    Sysrev. com is a FAIR motivated web platform for data curation and SER. Sysrev allows users to create data curation projects called “sysrevs” wherein users upload documents, define review tasks, recruit reviewers, perform review tasks, and automate review tasks.
                  
                  
                    Conclusion:
                    Sysrev is a web application designed to facilitate data curation and SERs. Thousands of publicly accessible Sysrev projects have been created, accommodating research in a wide variety of disciplines. Described use cases include data curation, managed reviews, and SERs.",2021,10.3389/frai.2021.685298
BERT-Based Natural Language Processing of Drug Labeling Documents: A Case Study for Classifying Drug-Induced Liver Injury Risk,"Background &amp; Aims: The United States Food and Drug Administration (FDA) regulates a broad range of consumer products, which account for about 25% of the United States market. The FDA regulatory activities often involve producing and reading of a large number of documents, which is time consuming and labor intensive. To support regulatory science at FDA, we evaluated artificial intelligence (AI)-based natural language processing (NLP) of regulatory documents for text classification and compared deep learning-based models with a conventional keywords-based model.Methods: FDA drug labeling documents were used as a representative regulatory data source to classify drug-induced liver injury (DILI) risk by employing the state-of-the-art language model BERT. The resulting NLP-DILI classification model was statistically validated with both internal and external validation procedures and applied to the labeling data from the European Medicines Agency (EMA) for cross-agency application.Results: The NLP-DILI model developed using FDA labeling documents and evaluated by cross-validations in this study showed remarkable performance in DILI classification with a recall of 1 and a precision of 0.78. When cross-agency data were used to validate the model, the performance remained comparable, demonstrating that the model was portable across agencies. Results also suggested that the model was able to capture the semantic meanings of sentences in drug labeling.Conclusion: Deep learning-based NLP models performed well in DILI classification of drug labeling documents and learned the meanings of complex text in drug labeling. This proof-of-concept work demonstrated that using AI technologies to assist regulatory activities is a promising approach to modernize and advance regulatory science.",2021,10.3389/frai.2021.729834
Assessment of demographic bias in retinal age prediction machine learning models,"The retinal age gap, defined as the difference between the predicted retinal age and chronological age, is an emerging biomarker for many eye conditions and even non-ocular diseases. Machine learning (ML) models are commonly used for retinal age prediction. However, biases in ML models may lead to unfair predictions for some demographic groups, potentially exacerbating health disparities. This retrospective cross-sectional study evaluated demographic biases related to sex and ethnicity in retinal age prediction models using retinal imaging data (color fundus photography [CFP], optical coherence tomography [OCT], and combined CFP + OCT) from 9,668 healthy individuals (mean age 56.8 years; 52% female) in the UK Biobank. The RETFound foundation model was fine-tuned to predict retinal age, and bias was assessed by comparing mean absolute error (MAE) and retinal age gaps across demographic groups. The combined CFP + OCT model achieved the lowest MAE (3.01 years), outperforming CFP-only (3.40 years) and OCT-only (4.37 years) models. Significant sex differences were observed only in the CFP model (p &lt; 0.001), while significant ethnicity differences appeared only in the OCT model (p &lt; 0.001). No significant sex/ethnicity differences were observed in the combined model. These results demonstrate that retinal age prediction models can exhibit biases, and that these biases, along with model accuracy, are influenced by the choice of imaging modality (CFP, OCT, or combined). Identifying and addressing sources of bias is essential for safe and reliable clinical implementation. Our results emphasize the importance of comprehensive bias assessments and prospective validation, ensuring that advances in machine learning and artificial intelligence benefit all patient populations.",2025,10.3389/frai.2025.1653153
Application of the symbolic regression program AI-Feynman to psychology,"The discovery of hidden laws in data is the core challenge in many fields, from the natural sciences to the social sciences. However, this task has historically relied on human intuition and experience in many areas, including psychology. Therefore, discovering laws using artificial intelligence (AI) has two significant advantages. First, it makes it possible to detect laws that humans cannot discover. Second, it will help construct more accurate theories. An AI called AI-Feynman was released in a very different field, and it performed impressively. Although AI-Feynman was initially designed to discover laws in physics, it can also work well in psychology. This research aims to examine whether AI-Feynman can be a new data analysis method for inter-temporal choice experiments by testing whether it can discover the hyperbolic discount model as a discount function. An inter-temporal choice experiment was conducted to accomplish these objectives, and the data were input into AI-Feynman. As a result, seven discount function candidates were proposed by AI-Feynman. One candidate was the hyperbolic discount model, which is currently considered the most accurate. The three functions of the root-mean-squared errors were superior to the hyperbolic discount model. Moreover, one of the three candidates was more “hyperbolic” than the standard hyperbolic discount function. These results indicate two things. One is that AI-Feynman can be a new data analysis method for inter-temporal choice experiments. The other is that AI-Feynman can discover discount functions that humans cannot find.",2023,10.3389/frai.2023.1039438
Designing novel peptides with amyloid-β binding and clearance potential using BiLSTM and molecular dynamics,"Generative artificial intelligence is transforming de novo biomolecular design, yet developing models that reliably generate functional, target-specific peptides remains a significant challenge. Here, we introduce and validate a novel two-stage Bidirectional Long Short-Term Memory (BiLSTM) framework for the generative design of short, functional peptides. Our AI pipeline is trained on full-length proteins annotated with specific Gene Ontology (GO) terms related to amyloid-
                    β
                    (Aβ) interaction and is fine-tuned on experimentally validated peptide fragments to capture local functional motifs within a global protein context. As a proof-of-concept, we applied this framework to generate peptides targeting Aβ42, a key pathological agent in Alzheimer’s disease. From 1,000 AI-generated sequences, 25 candidates were shortlisted using biophysical filters (GRAVY, instability index, Shannon entropy), and 11 were prioritized via sequence similarity analysis, designated as AI-Designed Novel Peptides (ADNP1-ADNP11). Structural modeling (AlphaFold2) and docking (pyDockWEB) against Aβ42 identified ADNP7 as the top candidate, exhibiting a highly favorable docking score (−63.33 kcal/mol), with interactions localized to Aβ’s aggregation-prone regions. All-atom molecular dynamics simulations (20 ns) confirmed complex stability, and MM/PBSA analysis yielded a strong binding free energy (−50.6 kcal/mol), driven primarily by hydrophobic and aromatic interactions involving PHE12 and TRP50 in ADNP7. This work demonstrates that our fine-tuned BiLSTM architecture can successfully generate novel, stable peptide sequences with high predicted binding affinity for a therapeutically relevant target. While the training data included proteins associated with Aβ clearance (GO:0097242), only binding interactions were computationally validated; clearance potential remains a hypothesis for future experimental testing. This study establishes a generalizable, AI-driven pipeline for functional peptide design, with broad applicability across therapeutic discovery and synthetic biology.",2025,10.3389/frai.2025.1709505
General-Purpose Bayesian Tensor Learning With Automatic Rank Determination and Uncertainty Quantification,"A major challenge in many machine learning tasks is that the model expressive power depends on model size. Low-rank tensor methods are an efficient tool for handling the curse of dimensionality in many large-scale machine learning models. The major challenges in training a tensor learning model include how to process the high-volume data, how to determine the tensor rank automatically, and how to estimate the uncertainty of the results. While existing tensor learning focuses on a specific task, this paper proposes a generic Bayesian framework that can be employed to solve a broad class of tensor learning problems such as tensor completion, tensor regression, and tensorized neural networks. We develop a low-rank tensor prior for automatic rank determination in nonlinear problems. Our method is implemented with both stochastic gradient Hamiltonian Monte Carlo (SGHMC) and Stein Variational Gradient Descent (SVGD). We compare the automatic rank determination and uncertainty quantification of these two solvers. We demonstrate that our proposed method can determine the tensor rank automatically and can quantify the uncertainty of the obtained results. We validate our framework on tensor completion tasks and tensorized neural network training tasks.",2022,10.3389/frai.2021.668353
Elucidating linear programs by neural encodings,"Linear Programs (LPs) are one of the major building blocks of AI and have championed recent strides in differentiable optimizers for learning systems. While efficient solvers exist for even high-dimensional LPs, explaining their solutions has not received much attention yet, as explainable artificial intelligence (XAI) has mostly focused on deep learning models. LPs are mostly considered white-box and thus assumed simple to explain, but we argue that they are not easy to understand in terms of relationships between inputs and outputs. To mitigate this rather non-explainability of LPs we show how to adapt attribution methods by encoding LPs in a neural fashion. The encoding functions consider aspects such as the feasibility of the decision space, the cost attached to each input, and the distance to special points of interest. Using a variety of LPs, including a very large-scale LP with 10k dimensions, we demonstrate the usefulness of explanation methods using our neural LP encodings, although the attribution methods Saliency and LIME are indistinguishable for low perturbation levels. In essence, we demonstrate that LPs can and should be explained, which can be achieved by representing an LP as a neural network.",2025,10.3389/frai.2025.1549085
SpatialSim: Recognizing Spatial Configurations of Objects With Graph Neural Networks,"An embodied, autonomous agent able to set its own goals has to possess geometrical reasoning abilities for judging whether its goals have been achieved, namely it should be able to identify and discriminate classes of configurations of objects, irrespective of its point of view on the scene. However, this problem has received little attention so far in the deep learning literature. In this paper we make two key contributions. First, we propose SpatialSim (Spatial Similarity), a novel geometrical reasoning diagnostic dataset, and argue that progress on this benchmark would allow for diagnosing more principled approaches to this problem. This benchmark is composed of two tasks: “Identification” and “Discrimination,” each one instantiated in increasing levels of difficulty. Secondly, we validate that relational inductive biases—exhibited by fully-connected message-passing Graph Neural Networks (MPGNNs)—are instrumental to solve those tasks, and show their advantages over less relational baselines such as Deep Sets and unstructured models such as Multi-Layer Perceptrons. We additionally showcase the failure of high-capacity CNNs on the hard Discrimination task. Finally, we highlight the current limits of GNNs in both tasks.",2022,10.3389/frai.2021.782081
Key point generation as an instrument for generating core statements of a political debate on Twitter,"Identifying key statements in large volumes of short, user-generated texts is essential for decision-makers to quickly grasp their key content. To address this need, this research introduces a novel abstractive key point generation (KPG) approach applicable to unlabeled text corpora, using an unsupervised approach, a feature not yet seen in existing abstractive KPG methods. The proposed method uniquely combines topic modeling for unsupervised data space segmentation with abstractive summarization techniques to efficiently generate semantically representative key points from text collections. This is further enhanced by hyperparameter tuning to optimize both the topic modeling and abstractive summarization processes. The hyperparameter tuning of the topic modeling aims at making the cluster assignment more deterministic as the probabilistic nature of the process would otherwise lead to high variability in the output. The abstractive summarization process is optimized using a Davies-Bouldin Index specifically adapted to this use case, so that the generated key points more accurately reflect the characteristic properties of this cluster. In addition, our research recommends an automated evaluation that provides a quantitative complement to the traditional qualitative analysis of KPG. This method regards KPG as a specialized form of Multidocument summarization (MDS) and employs both word-based and word-embedding-based metrics for evaluation. These criteria allow for a comprehensive and nuanced analysis of the KPG output. Demonstrated through application to a political debate on Twitter, the versatility of this approach extends to various domains, such as product review analysis and survey evaluation. This research not only paves the way for innovative development in abstractive KPG methods but also sets a benchmark for their evaluation.",2024,10.3389/frai.2024.1200949
Computing the impact of central clearing on systemic risk,"The paper uses a graph model to examine the effects of financial market regulations on systemic risk. Focusing on central clearing, we model the financial system as a multigraph of trade and risk relations among banks. We then study the impact of central clearing by a priori estimates in the model, stylized case studies, and a simulation case study. These case studies identify the drivers of regulatory policies on risk reduction at the firm and systemic levels. The analysis shows that the effect of central clearing on systemic risk is ambiguous, with potential positive and negative outcomes, depending on the credit quality of the clearing house, netting benefits and losses, and concentration risks. These computational findings align with empirical studies, yet do not require intensive collection of proprietary data. In addition, our approach enables us to disentangle various competing effects. The approach thus provides policymakers and market practitioners with tools to study the impact of a regulation at each level, enabling decision-makers to anticipate and evaluate the potential impact of regulatory interventions in various scenarios before their implementation.",2024,10.3389/frai.2024.1138611
A case study for unlocking the potential of deep learning in asset-liability-management,"The extensive application of deep learning in the field of quantitative risk management is still a relatively recent phenomenon. This article presents the key notions of Deep Asset-Liability-Management (“Deep ALM”) for a technological transformation in the management of assets and liabilities along a whole term structure. The approach has a profound impact on a wide range of applications such as optimal decision making for treasurers, optimal procurement of commodities or the optimization of hydroelectric power plants. As a by-product, intriguing aspects of goal-based investing or Asset-Liability-Management (ALM) in abstract terms concerning urgent challenges of our society are expected alongside. We illustrate the potential of the approach in a stylized case.",2023,10.3389/frai.2023.1177702
A multi-center distributed learning approach for Parkinson's disease classification using the traveling model paradigm,"Distributed learning is a promising alternative to central learning for machine learning (ML) model training, overcoming data-sharing problems in healthcare. Previous studies exploring federated learning (FL) or the traveling model (TM) setup for medical image-based disease classification often relied on large databases with a limited number of centers or simulated artificial centers, raising doubts about real-world applicability. This study develops and evaluates a convolution neural network (CNN) for Parkinson's disease classification using data acquired by 83 diverse real centers around the world, mostly contributing small training samples. Our approach specifically makes use of the TM setup, which has proven effective in scenarios with limited data availability but has never been used for image-based disease classification. Our findings reveal that TM is effective for training CNN models, even in complex real-world scenarios with variable data distributions. After sufficient training cycles, the TM-trained CNN matches or slightly surpasses the performance of the centrally trained counterpart (AUROC of 83% vs. 80%). Our study highlights, for the first time, the effectiveness of TM in 3D medical image classification, especially in scenarios with limited training samples and heterogeneous distributed data. These insights are relevant for situations where ML models are supposed to be trained using data from small or remote medical centers, and rare diseases with sparse cases. The simplicity of this approach enables a broad application to many deep learning tasks, enhancing its clinical utility across various contexts and medical facilities.",2024,10.3389/frai.2024.1301997
Deep learning for prediction of post-thrombectomy outcomes based on admission CT angiography in large vessel occlusion stroke,"PurposeComputed Tomography Angiography (CTA) is the first line of imaging in the diagnosis of Large Vessel Occlusion (LVO) strokes. We trained and independently validated end-to-end automated deep learning pipelines to predict 3-month outcomes after anterior circulation LVO thrombectomy based on admission CTAs.MethodsWe split a dataset of 591 patients into training/cross-validation (n = 496) and independent test set (n = 95). We trained separate models for outcome prediction based on admission “CTA” images alone, “CTA + Treatment” (including time to thrombectomy and reperfusion success information), and “CTA + Treatment  + Clinical” (including admission age, sex, and NIH stroke scale). A binary (favorable) outcome was defined based on a 3-month modified Rankin Scale ≤ 2. The model was trained on our dataset based on the pre-trained ResNet-50 3D Convolutional Neural Network (“MedicalNet”) and included CTA preprocessing steps.ResultsWe generated an ensemble model from the 5-fold cross-validation, and tested it in the independent test cohort, with receiver operating characteristic area under the curve (AUC, 95% confidence interval) of 70 (0.59–0.81) for “CTA,” 0.79 (0.70–0.89) for “CTA + Treatment,” and 0.86 (0.79–0.94) for “CTA + Treatment + Clinical” input models. A “Treatment + Clinical” logistic regression model achieved an AUC of 0.86 (0.79–0.93).ConclusionOur results show the feasibility of an end-to-end automated model to predict outcomes from admission and post-thrombectomy reperfusion success. Such a model can facilitate prognostication in telehealth transfer and when a thorough neurological exam is not feasible due to language barrier or pre-existing morbidities.",2024,10.3389/frai.2024.1369702
Exploring trust factors in AI-healthcare integration: a rapid review,"This rapid review explores how artificial intelligence (AI) is integrated into healthcare and examines the factors influencing trust between users and AI systems. By systematically identifying trust-related determinants, this review provides actionable insights to support effective AI adoption in clinical settings. A comprehensive search of MEDLINE (Ovid), Embase (Ovid), and CINAHL (Ebsco) using keywords related to AI, healthcare, and trust yielded 872 unique citations, of which 40 studies met the inclusion criteria after screening. Three core themes were identified. AI literacy highlights the importance of user understanding of AI inputs, processes, and outputs in fostering trust among patients and clinicians. AI psychology reflects demographic and experiential influences on trust, such as age, gender, and prior AI exposure. AI utility emphasizes perceived usefulness, system efficiency, and integration within clinical workflows. Additional considerations include anthropomorphism, privacy and security concerns, and trust-repair mechanisms following system errors, particularly in high-risk clinical contexts. Overall, this review advances the understanding of trustworthy AI in healthcare and offers guidance for future implementation strategies and policy development.",2025,10.3389/frai.2025.1658510
LC-YOLOmatch: a novel scene segmentation approach based on YOLO for laparoscopic cholecystectomy,"Introduction
                    Laparoscopy is a visual biosensor that can obtain real-time images of the body cavity, assisting in minimally invasive surgery. Laparoscopic cholecystectomy is one of the most frequently performed endoscopic surgeries and the most fundamental modular surgery. However, many iatrogenic complications still occur each year, mainly due to the anatomical recognition errors of surgeons. Therefore, the development of artificial intelligence (AI)-assisted recognition is of great significance.
                  
                  
                    Methods
                    This study proposes a method based on the lightweight YOLOv11n model. By introducing the efficient multi-scale feature extraction module, DWR, the real-time performance of the model is enhanced. Additionally, the bidirectional feature pyramid network (BiFPN) is incorporated to strengthen the capability of multi-scale feature fusion. Finally, we developed the LC-YOLOmatch semi-supervised learning framework, which effectively addresses the issue of scarce labeled data in the medical field.
                  
                  
                    Results
                    Experimental results on the publicly available Cholec80 dataset show that this method achieves 70% mAP50 and 40.8% mAP50-95, reaching a new technical level and reducing the reliance on manual annotations.
                  
                  
                    Discussion
                    These improvements not only highlight its potential in automated surgeries but also significantly enhance assistance in laparoscopic procedures while effectively reducing the incidence of complications.",2025,10.3389/frai.2025.1706021
"Machine learning approaches to anxiety detection: trends, model evaluation, and future directions","BackgroundAnxiety is a pervasive mental health disorder with severe implications for individual wellbeing and societal productivity. The contemporary rise of anxiety, particularly among youth in digitally-saturated environments, underscores a critical need for advanced predictive tools to facilitate early intervention and mitigation. While machine learning (ML) holds significant promise in this domain, a comprehensive synthesis of its application in anxiety prediction, along with a critical evaluation of methodological trends and gaps, is only emerging in the literature. The main idea of the current systematic review is to bridge the understanding of current ML applications in mental health with the critical needs for enhanced diagnostic precision, personalized interventions and prevention.ObjectivesThis systematic review aims to systematically synthesize research on ML approaches to predicting anxiety, critically evaluating the algorithms, features, and validation techniques employed across studies. The objective is to identify prevailing ML techniques, assess their performance, and highlight crucial methodological trends, existing gaps, and their implications for effective early intervention and real-world deployment.Eligibility criteriaStudies included had to apply machine learning techniques to predict anxiety or its severity using either clinical or behavioral datasets. Exclusion criteria included non-English language papers, reviews, older or previously reviewed publications, and those not specifically targeting anxiety. We focus on questionnaire research, but also discuss multimodal fusion techniques.Information sourcesWe searched the Scopus database and Google Scholar for articles published between 2018 and 2025 using combinations of keywords including “anxiety prediction,” “machine learning,” and “mental health.” The last search was conducted in July 2025.Risk of biasStudies were screened in two phases: (1) by verifying the presence of relevant keywords in the main body, and (2) by reviewing title, introduction, and conclusion to ensure alignment with anxiety prediction via ML. Studies relying solely on self-reported metrics or with unclear algorithmic transparency were noted for potential bias.ResultsA total of 19 studies were included, encompassing 44, 608 participants. GAD-7 and DASS-21 were the most commonly used diagnostic instruments. ML techniques such as Random Forest and Gradient Boosting achieved the highest predictive accuracy, with some studies reporting up to 98% accuracy. Metrics like F1-score, AUC, and specificity were commonly reported.Limitations of evidenceExisting studies display a range of methodological and conceptual limitations that constrain their generalizability and clinical utility. The review identified significant methodological limitations hindering generalizability and clinical utility, including reliance on small, homogeneous samples, which raises concerns about overfitting and population bias. Furthermore, common issues include a lack of external validation, inconsistent evaluation metrics, and the “black-box” nature of many ML algorithms, which impedes clinical trust and adoption.InterpretationThe findings support the effectiveness of machine learning for anxiety detection and prediction, particularly in early intervention contexts. The integration of explainable ML and diverse, clinically validated data is necessary for real-world deployment. The existing body of research also shows a notable scarcity in studies predicting anxiety before symptom manifestation. These insights emphasize the critical need for integrating explainable ML (XAI) and utilizing diverse, clinically validated datasets to enable real-world deployment and proactive mental health support.",2025,10.3389/frai.2025.1630047
Retrieving interpretability to support vector machine regression models in dynamic system identification,"Black-box models, particularly Support Vector Machines (SVM), are widely employed for identifying dynamic systems due to their high predictive accuracy; however, their inherent lack of transparency hinders the understanding of how individual input variables contribute to the system output. Consequently, retrieving interpretability from these complex models has become a critical challenge in the control and identification community. This paper proposes a
                    post-hoc
                    functional decomposition algorithm based on Non-linear Oblique Subspace Projections (NObSP). The method decomposes the output of an already identified SVM regression model into a sum of partial (non)linear dynamic contributions associated with each input regressor. By operating in the non-linear feature space, NObSP utilizes oblique projections to mitigate cross-contributions from correlated regressors. Furthermore, an efficient out-of-sample extension is introduced to improve scalability. Numerical simulations performed on benchmark Wiener and Hammerstein structures demonstrate that the proposed method effectively retrieves the underlying partial nonlinear dynamics of each sub-system. Additionally, the computational analysis confirms that the proposed extension reduces the arithmetic complexity from 𝒪(
                    N
                    3
                    ) to 𝒪(
                    Nd
                    2
                    ), where
                    d
                    is the number of support vectors. These findings indicate that NObSP is a robust geometric framework for interpreting non-linear dynamic models, offering a scalable solution that successfully decouples blended dynamics without sacrificing the predictive power of the black-box model.",2025,10.3389/frai.2025.1706566
A novel approach to Indian bird species identification: employing visual-acoustic fusion techniques for improved classification accuracy,"Accurate identification of bird species is essential for monitoring biodiversity, analyzing ecological patterns, assessing population health, and guiding conservation efforts. Birds serve as vital indicators of environmental change, making species identification critical for habitat protection and understanding ecosystem dynamics. With over 1,300 species, India's avifauna presents significant challenges due to morphological and acoustic similarities among species. For bird monitoring, recent work often uses acoustic sensors to collect bird sounds and an automated bird classification system to recognize bird species. Traditional machine learning requires manual feature extraction and model training to build an automated bird classification system. Automatically extracting features is now possible due to recent advances in deep learning models. This study presents a novel approach utilizing visual-acoustic fusion techniques to enhance species identification accuracy. We employ a Deep Convolutional Neural Network (DCNN) to extract features from bird images and a Long Short-Term Memory (LSTM) network to analyze bird calls. By integrating these modalities early in the classification process, our method significantly improves performance compared to traditional methods that rely on either data type alone or utilize late fusion strategies. Testing on the iBC53 (Indian Bird Call) dataset demonstrates an impressive accuracy of 94%, highlighting the effectiveness of our multi-modal fusion approach.",2025,10.3389/frai.2025.1527299
Explainable Model Fusion for Customer Journey Mapping,"Due to advances in computing power and internet technology, various industrial sectors are adopting IT infrastructure and artificial intelligence (AI) technologies. Recently, data-driven predictions have attracted interest in high-stakes decision-making. Despite this, advanced AI methods are less often used for such tasks. This is because AI technology is a black box for the social systems it is meant to support; trustworthiness and fairness have not yet been established. Meanwhile in the field of marketing, strategic decision-making is a high-stakes problem that has a significant impact on business trends. For global marketing, with its diverse cultures and market environments, future decision-making is likely to focus on building consensus on the formulation of the problem itself rather than on solutions for achieving the goal. There are two important and conflicting facts: the fact that the core of domestic strategic decision-making comes down to the formulation of the problem itself, and the fact that it is difficult to realize AI technology that can achieve problem formulation. How can we resolve this difficulty with current technology? This is the main challenge for the realization of high-level human-AI systems in the marketing field. Thus, we propose customer journey mapping (CJM) automation through model-level data fusion, a process for the practical problem formulation known as explainable alignment. Using domain-specific requirements and observations as inputs, the system automatically outputs a CJM. Explainable alignment corresponds with both human and AI perspectives and in formulating the problem, thereby improving strategic decision-making in marketing. Following preprocessing to make latent variables and their dynamics transparent with latent Dirichlet allocation and a variational autoencoder, a post-hoc explanation is implemented in which a hidden Markov model and learning from an interpretation transition are combined with a long short-term memory architecture that learns sequential data between touchpoints for extracting attitude rules for CJM. Finally, we realize the application of human-AI systems to strategic decision-making in marketing with actual logs in over-the-top media services, in which the dynamic behavior of customers for CJM can be automatically extracted.",2022,10.3389/frai.2022.824197
Artificial intelligence applied to diabetes complications: a bibliometric analysis,"Background and aimsArtificial intelligence (AI)-driven medical assistive technology has been widely used in the diagnosis, treatment and prognosis of diabetes complications. Here we conduct a bibliometric analysis of scientific articles in the field of AI in diabetes complications to explore current research trends and cutting-edge hotspots.MethodologyOn April 20, 2024, we collected and screened relevant articles published from 1988 to 2024 from PubMed. Based on bibliometric tools such as CiteSpace, Vosviewer and bibliometix, we construct knowledge maps to visualize literature information, including annual scientific production, authors, countries, institutions, journals, keywords and research hotspots.ResultsA total of 935 articles meeting the criteria were collected and analyzed. The number of annual publications showed an upward trend. Raman, Rajiv published the most articles, and Webster, Dale R had the highest collaboration frequency. The United States, China, and India were the most productive countries. Scientific Reports was the journal with the most publications. The three most frequent diabetes complications were diabetic retinopathy, diabetic nephropathy, and diabetic foot. Machine learning, diabetic retinopathy, screening, deep learning, and diabetic foot are still being researched in 2024.ConclusionGlobal AI research on diabetes complications is expected to increase further. The investigation of AI in diabetic retinopathy and diabetic foot will be the focus of research in the future.",2025,10.3389/frai.2025.1455341
Humanizing AI in medical training: ethical framework for responsible design,"The increasing use of artificial intelligence (AI) in healthcare has brought about numerous ethical considerations that push for reflection. Humanizing AI in medical training is crucial to ensure that the design and deployment of its algorithms align with ethical principles and promote equitable healthcare outcomes for both medical practitioners trainees and patients. This perspective article provides an ethical framework for responsibly designing AI systems in medical training, drawing on our own past research in the fields of electrocardiogram interpretation training and e-health wearable devices. The article proposes five pillars of responsible design: transparency, fairness and justice, safety and wellbeing, accountability, and collaboration. The transparency pillar highlights the crucial role of maintaining the explainabilty of AI algorithms, while the fairness and justice pillar emphasizes on addressing biases in healthcare data and designing models that prioritize equitable medical training outcomes. The safety and wellbeing pillar however, emphasizes on the need to prioritize patient safety and wellbeing in AI model design whether it is for training or simulation purposes, and the accountability pillar calls for establishing clear lines of responsibility and liability for AI-derived decisions. Finally, the collaboration pillar emphasizes interdisciplinary collaboration among stakeholders, including physicians, data scientists, patients, and educators. The proposed framework thus provides a practical guide for designing and deploying AI in medicine generally, and in medical training specifically in a responsible and ethical manner.",2023,10.3389/frai.2023.1189914
HAWKFOG-an enhanced deep learning framework for the Fog-IoT environment,"Cardiac disease is considered as the one of the deadliest diseases that constantly increases the globe’s mortality rate. Since a lot of expertise is required for an accurate prediction of heart disease, designing an intelligent predictive system for cardiac diseases remains to be complex and tricky. Internet of Things based health regulation systems are a relatively recent technology. In addition, novel Edge and Fog device concepts are presented to advance prediction results. However, the main problem with the current systems is that they are unable to meet the demands of effective diagnosis systems due to their poor prediction capabilities. To overcome this problem, this research proposes a novel framework called HAWKFOGS which innovatively integrates the deep learning for a practical diagnosis of cardiac problems using edge and fog computing devices. The current datasets were gathered from different subjects using IoT devices interfaced with the electrocardiography and blood pressure sensors. The data are then predicted as normal and abnormal using the Logistic Chaos based Harris Hawk Optimized Enhanced Gated Recurrent Neural Networks. The ablation experiments are carried out using IoT nodes interfaced with medical sensors and fog gateways based on Embedded Jetson Nano devices. The suggested algorithm’s performance is measured. Additionally, Model Building Time is computed to validate the suggested model’s response. Compared to the other algorithms, the suggested model yielded the best results in terms of accuracy (99.7%), precision (99.65%), recall (99.7%), specificity (99.7%). F1-score (99.69%) and used the least amount of Model Building Time (1.16 s) to predict cardiac diseases.",2024,10.3389/frai.2024.1354742
"The Fourth Industrial Revolution – Smart Technology, Artificial Intelligence, Robotics and Algorithms: Industrial Psychologists in Future Workplaces","In the Fourth Industrial Revolution (4IR), STARA (smart technology, artificial intelligence, robotics, and algorithms) is predicted to replace a third of the jobs that exist today. Almost twice as many current work tasks will be handled by robots. It is forecast that by 2025, 85 million jobs may be displaced by a shift in the division of labor between humans and machines, while 97 million new roles may emerge that are more adapted to the new division of labor between humans, machines and algorithms. Industrial psychologists are playing an increasingly important role in the workplace due to these trends from a strategic intelligence perspective. The objective of this article is to present a critical review of industrial psychologists in future workplaces in the context of the 4IR - STARA. A competence model is posed for industrial psychologists to perform a strategic intelligence role in organizations in the 4IR.",2022,10.3389/frai.2022.913168
Adolescents’ use and perceived usefulness of generative AI for schoolwork: exploring their relationships with executive functioning and academic achievement,"In this study, we aimed to explore the frequency of use and perceived usefulness of LLM generative AI chatbots (e.g., ChatGPT) for schoolwork, particularly in relation to adolescents’ executive functioning (EF), which includes critical cognitive processes like planning, inhibition, and cognitive flexibility essential for academic success. Two studies were conducted, encompassing both younger (Study 1: N = 385, 46% girls, mean age 14 years) and older (Study 2: N = 359, 67% girls, mean age 17 years) adolescents, to comprehensively examine these associations across different age groups. In Study 1, approximately 14.8% of participants reported using generative AI, while in Study 2, the adoption rate among older students was 52.6%, with ChatGPT emerging as the preferred tool among adolescents in both studies. Consistently across both studies, we found that adolescents facing more EF challenges perceived generative AI as more useful for schoolwork, particularly in completing assignments. Notably, academic achievement showed no significant associations with AI usage or usefulness, as revealed in Study 1. This study represents the first exploration into how individual characteristics, such as EF, relate to the frequency and perceived usefulness of LLM generative AI chatbots for schoolwork among adolescents. Given the early stage of generative AI chatbots during the survey, future research should validate these findings and delve deeper into the utilization and integration of generative AI into educational settings. It is crucial to adopt a proactive approach to address the potential challenges and opportunities associated with these emerging technologies in education.",2024,10.3389/frai.2024.1415782
Kernel Conversion for Robust Quantitative Measurements of Archived Chest Computed Tomography Using Deep Learning-Based Image-to-Image Translation,"Chest computed tomography (CT) is used to screen for lung cancer and evaluate pulmonary and extra-pulmonary abnormalities such as emphysema and coronary artery calcification, particularly in smokers. In real-world practice, lung abnormalities are visually assessed using high-contrast thin-slice images which are generated from raw scan data using sharp reconstruction kernels with the sacrifice of increased image noise. In contrast, accurate CT quantification requires low-contrast thin-slice images with low noise, which are generated using soft reconstruction kernels. However, only sharp-kernel thin-slice images are archived in many medical facilities due to limited data storage space. This study aimed to establish deep neural network (DNN) models to convert sharp-kernel images to soft-kernel-like images with a final goal to reuse historical chest CT images for robust quantitative measurements, particularly in completed previous longitudinal studies. By using pairs of sharp-kernel (input) and soft-kernel (ground-truth) images from 30 patients with chronic obstructive pulmonary disease (COPD), DNN models were trained. Then, the accuracy of kernel conversion based on the established DNN models was evaluated using CT from independent 30 smokers with and without COPD. Consequently, differences in CT values between new images converted from sharp-kernel images using the established DNN models and ground-truth soft-kernel images were comparable with the inter-scans variability derived from repeated phantom scans (6 times), showing that the conversion error was the same level as the measurement error of the CT device. Moreover, the Dice coefficients to quantify the similarity between low attenuation voxels on given images and the ground-truth soft-kernel images were significantly higher on the DNN-converted images than the Gaussian-filtered, median-filtered, and sharp-kernel images (p &lt; 0.001). There were good agreements in quantitative measurements of emphysema, intramuscular adipose tissue, and coronary artery calcification between the converted and the ground-truth soft-kernel images. These findings demonstrate the validity of the new DNN model for kernel conversion and the clinical applicability of soft-kernel-like images converted from archived sharp-kernel images in previous clinical studies. The presented method to evaluate the validity of the established DNN model using repeated scans of phantom could be applied to various deep learning-based image conversions for robust quantitative evaluation.",2022,10.3389/frai.2021.769557
Statistical learning models to measure the impact of COVID-19 on financial fragility,"This paper investigates the effects of the economic shock produced by the COVID-19 outbreak and diffusion on households'. Through a survey administered to Italian households, without loss of generality, we investigate changes in financial and economic decisions and the households' ability to cope with daily purchases, repay their debt obligations and face unexpected expenses. The paper also applies a statistical learning model through a synthetic indicator for the financial vulnerability of households, integrating the relevant information on the financial literacy and education of the surveyed individuals.",2024,10.3389/frai.2024.1358812
Solution of the Fokker–Planck Equation by Cross Approximation Method in the Tensor Train Format,"We propose the novel numerical scheme for solution of the multidimensional Fokker–Planck equation, which is based on the Chebyshev interpolation and the spectral differentiation techniques as well as low rank tensor approximations, namely, the tensor train decomposition and the multidimensional cross approximation method, which in combination makes it possible to drastically reduce the number of degrees of freedom required to maintain accuracy as dimensionality increases. We demonstrate the effectiveness of the proposed approach on a number of multidimensional problems, including Ornstein-Uhlenbeck process and the dumbbell model. The developed computationally efficient solver can be used in a wide range of practically significant problems, including density estimation in machine learning applications.",2021,10.3389/frai.2021.668215
A systematic review on the integration of explainable artificial intelligence in intrusion detection systems to enhancing transparency and interpretability in cybersecurity,"The rise of sophisticated cyber threats has spurred advancements in Intrusion Detection Systems (IDS), which are crucial for identifying and mitigating security breaches in real-time. Traditional IDS often rely on complex machine learning algorithms that lack transparency despite their high accuracy, creating a “black box” effect that can hinder the analysts’ understanding of their decision-making processes. Explainable Artificial Intelligence (XAI) offers a promising solution by providing interpretability and transparency, enabling security professionals to understand better, trust, and optimize IDS models. This paper presents a systematic review of the integration of XAI in IDS, focusing on enhancing transparency and interpretability in cybersecurity. Through a comprehensive analysis of recent studies, this review identifies commonly used XAI techniques, evaluates their effectiveness within IDS frameworks, and examines their benefits and limitations. Findings indicate that rule-based and tree-based XAI models are preferred for their interpretability, though trade-offs with detection accuracy remain challenging. Furthermore, the review highlights critical gaps in standardization and scalability, emphasizing the need for hybrid models and real-time explainability. The paper concludes with recommendations for future research directions, suggesting improvements in XAI techniques tailored for IDS, standardized evaluation metrics, and ethical frameworks prioritizing security and transparency. This review aims to inform researchers and practitioners about current trends and future opportunities in leveraging XAI to enhance IDS effectiveness, fostering a more transparent and resilient cybersecurity landscape.",2025,10.3389/frai.2025.1526221
Human-centered evaluation of explainable AI applications: a systematic review,"Explainable Artificial Intelligence (XAI) aims to provide insights into the inner workings and the outputs of AI systems. Recently, there's been growing recognition that explainability is inherently human-centric, tied to how people perceive explanations. Despite this, there is no consensus in the research community on whether user evaluation is crucial in XAI, and if so, what exactly needs to be evaluated and how. This systematic literature review addresses this gap by providing a detailed overview of the current state of affairs in human-centered XAI evaluation. We reviewed 73 papers across various domains where XAI was evaluated with users. These studies assessed what makes an explanation “good” from a user's perspective, i.e., what makes an explanation meaningful to a user of an AI system. We identified 30 components of meaningful explanations that were evaluated in the reviewed papers and categorized them into a taxonomy of human-centered XAI evaluation, based on: (a) the contextualized quality of the explanation, (b) the contribution of the explanation to human-AI interaction, and (c) the contribution of the explanation to human-AI performance. Our analysis also revealed a lack of standardization in the methodologies applied in XAI user studies, with only 19 of the 73 papers applying an evaluation framework used by at least one other study in the sample. These inconsistencies hinder cross-study comparisons and broader insights. Our findings contribute to understanding what makes explanations meaningful to users and how to measure this, guiding the XAI community toward a more unified approach in human-centered explainability.",2024,10.3389/frai.2024.1456486
Generative Adversarial Networks–Enabled Human–Artificial Intelligence Collaborative Applications for Creative and Design Industries: A Systematic Review of Current Approaches and Trends,"The future of work and workplace is very much in flux. A vast amount has been written about artificial intelligence (AI) and its impact on work, with much of it focused on automation and its impact in terms of potential job losses. This review will address one area where AI is being added to creative and design practitioners’ toolbox to enhance their creativity, productivity, and design horizons. A designer’s primary purpose is to create, or generate, the most optimal artifact or prototype, given a set of constraints. We have seen AI encroaching into this space with the advent of generative networks and generative adversarial networks (GANs) in particular. This area has become one of the most active research fields in machine learning over the past number of years, and a number of these techniques, particularly those around plausible image generation, have garnered considerable media attention. We will look beyond automatic techniques and solutions and see how GANs are being incorporated into user pipelines for design practitioners. A systematic review of publications indexed on ScienceDirect, SpringerLink, Web of Science, Scopus, IEEExplore, and ACM DigitalLibrary was conducted from 2015 to 2020. Results are reported according to PRISMA statement. From 317 search results, 34 studies (including two snowball sampled) are reviewed, highlighting key trends in this area. The studies’ limitations are presented, particularly a lack of user studies and the prevalence of toy-examples or implementations that are unlikely to scale. Areas for future study are also identified.",2021,10.3389/frai.2021.604234
"Linguistic patterns in pandemic-related content: a comparative analysis of COVID-19, Constraint, and Monkeypox datasets","IntroductionThis study investigates how linguistic features distinguish health misinformation from factual communication in pandemic-related online discourse. Understanding these differences is essential for improving detection of misinformation and informing effective public health messaging during crises.MethodsWe conducted a computational linguistic analysis across three corpora: COVID-19 false narratives (n = 7,588), general COVID-19 content (n = 10,700), and Monkeypox-related posts (n = 5,787). We examined readability, rhetorical markers, and persuasive language, focusing on differences between misinformation and factual communication.ResultsCOVID-19 misinformation exhibited markedly lower readability scores and contained more than twice the frequency of fear-related and persuasive terms compared to the other datasets. It showed minimal use of exclamation marks, contrasting with the more emotive style of Monkeypox content. These findings suggest that misinformation employs a deliberately complex rhetorical style combined with emotional cues, which may enhance perceived credibility.DiscussionOur findings contribute to the growing body of research on digital health misinformation by identifying linguistic indicators that can aid in detection. They also inform theoretical models of crisis communication and public health messaging strategies in networked media environments. However, the study has limitations, including reliance on traditional readability indices, a narrow persuasive lexicon, and static aggregate analysis. Future work should adopt longitudinal designs, incorporate broader emotion lexicons, and employ platform-sensitive approaches to improve robustness. The data and code supporting this study are openly available at: https://doi.org/10.5281/zenodo.17024569.",2025,10.3389/frai.2025.1627522
SATS: simplification aware text summarization of scientific documents,"Simplifying summaries of scholarly publications has been a popular method for conveying scientific discoveries to a broader audience. While text summarization aims to shorten long documents, simplification seeks to reduce the complexity of a document. To accomplish these tasks collectively, there is a need to develop machine learning methods to shorten and simplify longer texts. This study presents a new Simplification Aware Text Summarization model (SATS) based on future n-gram prediction. The proposed SATS model extends ProphetNet, a text summarization model, by enhancing the objective function using a word frequency lexicon for simplification tasks. We have evaluated the performance of SATS on a recently published text summarization and simplification corpus consisting of 5,400 scientific article pairs. Our results in terms of automatic evaluation demonstrate that SATS outperforms state-of-the-art models for simplification, summarization, and joint simplification-summarization across two datasets on ROUGE, SARI, and CSS1. We also provide human evaluation of summaries generated by the SATS model. We evaluated 100 summaries from eight annotators for grammar, coherence, consistency, fluency, and simplicity. The average human judgment for all evaluated dimensions lies between 4.0 and 4.5 on a scale from 1 to 5 where 1 means low and 5 means high.",2024,10.3389/frai.2024.1375419
Structural analysis of VirD4 a type IV ATPase encoded by transmissible plasmids of Salmonella enterica isolated from poultry products,"Bacterial species have evolved with a wide variety of cellular devices, and they employ these devices for communication and transfer of genetic materials and toxins. They are classified into secretory system types I to VI based on their structure, composition, and functional activity. Specifically, the bacterial type IV secretory system (T4SS) is a more versatile system than the other secretory systems because it is involved in the transfer of genetic materials, proteins, and toxins to the host cells or other bacterial species. The T4SS machinery is made up of several proteins with distinct functions and forms a complex which spans the inner and outer membranes. This secretory machinery contains three ATPases that are the driving force for the functionality of this apparatus. At the initial stage of the secretion process, the selection of substrate molecules and processing occurs at the cytoplasmic region (also known as relaxosome), and then transfer mechanisms occur through the secretion complex. In this process, the VirD4 ATPase is the first molecule that initiates substrate selection, which is subsequently delivered to the secretory machinery. In the protein data bank (PDB), no structural information is available for the VirD4 ATPase to understand the functional property. In this manuscript, we have modeled VirD4 structure in the Gram-negative bacterium Salmonella enterica and described the predicted functional importance. The sequence alignment shows that VirD4 of S. enterica contains several insertion regions as compared with the template structure (pdb:1E9R) used for homology modeling. In this study, we hypothesized that the insertion regions could play a role in the flexible movement of the hexameric unit during the relaxosome processing or transfer of the substrate.",2022,10.3389/frai.2022.952997
Bridging the Gap of AutoGraph Between Academia and Industry: Analyzing AutoGraph Challenge at KDD Cup 2020,"Graph structured data is ubiquitous in daily life and scientific areas and has attracted increasing attention. Graph Neural Networks (GNNs) have been proved to be effective in modeling graph structured data and many variants of GNN architectures have been proposed. However, much human effort is often needed to tune the architecture depending on different datasets. Researchers naturally adopt Automated Machine Learning on Graph Learning, aiming to reduce human effort and achieve generally top-performing GNNs, but their methods focus more on the architecture search. To understand GNN practitioners' automated solutions, we organized AutoGraph Challenge at KDD Cup 2020, emphasizing automated graph neural networks for node classification. We received top solutions, especially from industrial technology companies like Meituan, Alibaba, and Twitter, which are already open sourced on GitHub. After detailed comparisons with solutions from academia, we quantify the gaps between academia and industry on modeling scope, effectiveness, and efficiency, and show that (1) academic AutoML for Graph solutions focus on GNN architecture search while industrial solutions, especially the winning ones in the KDD Cup, tend to obtain an overall solution (2) with only neural architecture search, academic solutions achieve on average 97.3% accuracy of industrial solutions (3) academic solutions are cheap to obtain with several GPU hours while industrial solutions take a few months' labors. Academic solutions also contain much fewer parameters.",2022,10.3389/frai.2022.905104
Exploring neural question generation for formal pragmatics: Data set and model evaluation,"We provide the first openly-available German QUestion-Answer Congruence Corpus (QUACC), designed for the task of sentence-based question generation with question-answer congruence. Based on this corpus, we establish suitable baselines for question generation, comparing systems of very different nature. Question generation is an interesting challenge in particular for current neural network architectures given that it combines aspects of language meaning and forms in complex ways. The systems have to generate question phrases appropriately linking to the meaning of the envisaged answer phrases, and they have to learn to generate well-formed questions using the source. We show that our QUACC corpus is well-suited to investigate the performance of various neural models and gain insights about the specific error sources.",2022,10.3389/frai.2022.966013
Solving the elusiveness of word meanings: two arguments for a continuous meaning space for language,"I explore the hypothesis that the experience of meaning discreteness when we think about the “meaning” of a word is a “communicative” illusion. The illusion is created by processing-contextual constraints that impose disambiguation on the semantic input making salient a specific interpretation within a conceptual space that is otherwise continuous. It is this salience that we experience as discreteness. The understanding of word meaning as non-discrete raises the question of what is context; what are the mechanisms of constraint that it imposes and what is the nature of the conceptual space with which pronunciations (i.e., visual/oral signs) associate themselves. I address these questions by leveraging an algebraic continuous system for word meaning that is itself constrained by two fundamental parameters: control-asymmetry and connectedness. I evaluate this model by meeting two challenges to word meaning discreteness (1) cases where the same pronunciation is associated with multiple senses that are nonetheless interdependent, e.g., English “smoke,” and (2) cases where the same pronunciation is associated with a family of meanings, minimally distinct from each other organized as a “cline,” e.g., English “have.” These cases are not marginal–they are ubiquitous in languages across the world. Any model that captures them is accounting for the meaning system for language. At the heart of the argumentation is the demonstration of how the parameterized space naturally organizes these kinds of cases without appeal for further categorization or segmentation of any kind. From this, I conclude that discreteness in word meaning is epiphenomenal: it is the experience of salience produced by contextual constraints. And that this is possible because, by and large, every time that we become consciously aware of the conceptual structure associated with a pronunciation, i.e., its meaning, we do so under real-time processing conditions which are biased toward producing a specific interpretation in reference to a specific situation in the world. Supporting it is a parameterized space that gives rise to lexico-conceptual representations: generalized algebraic structures necessary for the identification, processing, and encoding of an individual's understanding of the world.",2023,10.3389/frai.2023.1025293
A novel technique for detecting sudden concept drift in healthcare data using multi-linear artificial intelligence techniques,"A financial market is a platform to produce data streams continuously and around 1. 145 Trillion MB of data per day. Estimation and the analysis of unknown or dynamic behaviors of these systems is one the challenging tasks. Analysis of these systems is very much essential to strengthen the environmental parameters to stabilize society activities. This can elevate the living style of society to the next level. In this connection, the proposed paper is trying to accommodate the financial data stream using the sliding window approach and random forest algorithm to provide a solution to handle concept drift in the financial market to stabilize the behavior of the system through drift estimation. The proposed approach provides promising results in terms of accuracy in detecting concept drift over the state of existing drift detection methods like one class drifts detection (OCDD), Adaptive Windowing ADWIN), and the Page-Hinckley test.",2022,10.3389/frai.2022.950659
"Local transplantation, adaptation, and creation of AI models for public health policy","This paper presents the Transplantation, Adaptation and Creation (TAC) framework, a method for assessing the localization of different elements of an AI system. This framework is applied in the public health context, notably to different types of models that were used during the COVID-19 pandemic. The framework aims to guide AI for public health developers and public health officials in conceptualizing model localization. The paper provides guidance justifying the importance of model localization, within a broader context of policy models, geopolitics and decolonization. It also suggests procedures for moving between the different elements in the framework, for example going from transplantation to adapation, and from adaptation to creation. This paper is submitted as part of a special research topic entitled: A digitally-enabled, science-based global pandemic preparedness and response scheme: how ready are we for the next pandemic?",2023,10.3389/frai.2023.1085671
Evaluation of large language model-generated medical information on idiopathic pulmonary fibrosis,"BackgroundIdiopathic Pulmonary Fibrosis (IPF) information from AI-powered large language models (LLMs) like ChatGPT-4 and Gemini 1.5 Pro is unexplored for quality, reliability, readability, and concordance with clinical guidelines.Research questionWhat is the quality, reliability, readability, and concordance to clinical guidelines of LLMs in medical and clinically IPF-related content?Study design and methodsChatGPT-4 and Gemini 1.5 Pro responses to 23 ATS/ERS/JRS/ALAT IPF guidelines questions were compared. Six independent raters evaluated responses for quality (DISCERN), reliability (JAMA Benchmark Criteria), readability (Flesch–Kincaid), and guideline concordance (0–4). Descriptive analysis, Intraclass Correlation Coefficient, Wilcoxon signed-rank test, and effect sizes (r) were calculated. Statistical significance was set at p &lt; 0.05.ResultsAccording to JAMA Benchmark, ChatGPT-4 and Gemini 1.5 Pro provided partially reliable responses; however, readability evaluations showed that both models were difficult to understand. The Gemini 1.5 Pro provided significantly better treatment information (DISCERN score: 56 versus 43, p &lt; 0.001). Gemini had considerably higher international IPF guidelines concordance than ChatGPT-4 (median 3.0 [3.0–3.5] vs. 3.0 [2.5–3.0], p = 0.0029).InterpretationBoth models gave useful medical insights, but their reliability is limited. Gemini 1.5 Pro gave greater quality information than ChatGPT-4 and was more compliant with worldwide IPF guidelines. Readability analyses found that AI-generated medical information was difficult to understand, stressing the need to refine it.What is already known on this topicRecent advancements in AI, especially large language models (LLMs) powered by natural language processing (NLP), have revolutionized the way medical information is retrieved and utilized.What this study addsThis study highlights the potential and limitations of ChatGPT-4 and Gemini 1.5 Pro in generating medical information on IPF. They provided partially reliable information in their responses; however, Gemini 1.5 Pro demonstrated superior quality in treatment-related content and greater concordance with clinical guidelines. Nevertheless, neither model provided answers in full concordance with established clinical guidelines, and their readability remained a major challenge.How this study might affect research, practice or policyThese findings highlight the need for AI model refinement as LLMs evolve as healthcare reference tools to help doctors and patients make evidence-based decisions.",2025,10.3389/frai.2025.1618378
Navigating ethical minefields: a multi-stakeholder approach to assessing interconnected risks in generative AI using grey DEMATEL,"The rapid advancement of generative artificial intelligence (AI) technologies has introduced unprecedented capabilities in content creation and human-AI interaction, while simultaneously raising significant ethical concerns. This study examined the complex landscape of ethical risks associated with generative AI (GAI) through a novel multi-stakeholder empirical analysis using the grey decision-making-trial-and-evaluation-laboratory methodology to quantitatively analyze the causal relationships between risks and their relative influence on AI deployment outcomes. Through a comprehensive literature review and expert validation across three key stakeholder groups (AI developers, end users, and policymakers), we identified and analyzed 14 critical ethical challenges across the input, training, and output modules, including both traditional and emerging risks, such as deepfakes, intellectual property rights, data transparency, and algorithmic bias. This study analyzed the perspectives of key stakeholders to understand how ethical risks are perceived, prioritized, and interconnected in practice. Using Euclidean-distance analysis, we identified significant divergences in risk perception among stakeholders, particularly in areas of adversarial prompts, data bias, and output bias. Our findings contribute to the development of a balanced ethical risk framework by categorizing risks into four distinct zones: critical enablers, mild enablers, independent enablers, and critical dependents. This categorization promotes technological advancement and responsible AI deployment. This study addressed the current gaps in academic work by providing actionable recommendations for risk-mitigation strategies and policy development while highlighting the need for collaborative approaches among stakeholders in the rapidly evolving field of GAI.",2025,10.3389/frai.2025.1611024
Artificial intelligence for ovarian cancer diagnosis via ultrasound: a systematic review and quantitative assessment of model performance,"Background
                    Early and accurate detection of ovarian cancer (OC) remains clinically challenging, prompting exploration of artificial intelligence (AI)-based ultrasound diagnostics. This systematic review and meta-analysis critically evaluate diagnostic accuracy, methodological rigor, and clinical applicability of AI models for ovarian mass classification using B-mode ultrasound.
                  
                  
                    Methods
                    A systematic literature search following PRISMA guidelines was conducted in PubMed, IEEE Xplore, and Scopus up to December 2024. Eligible studies included AI-based ovarian mass classification using B-mode ultrasound, reporting accuracy, sensitivity, specificity, and/or area under the ROC curve (AUC). Data extraction, quality assessment (PROBAST), and meta-analysis (random effects) were independently performed by two reviewers. Heterogeneity sources were explored.
                  
                  
                    Results
                    From 823 identified records, 44 studies met inclusion criteria, covering over 650,000 images. Pooled performance metrics indicated high accuracy (92.3%), sensitivity (91.6%), specificity (90.1%), and AUC (0.93). Automated segmentation significantly outperformed manual segmentation in accuracy and sensitivity, demonstrating standardization benefits and reduced observer variability. Dataset size minimally correlated with performance, highlighting methodological rigor as a primary determinant. No specific AI architecture consistently outperformed others. Substantial methodological heterogeneity and frequent risk-of-bias issues (limited validation, small datasets) currently limit clinical translation.
                  
                  
                    Conclusion
                    AI models show promising diagnostic performance for OC ultrasound imaging. However, addressing methodological challenges, including rigorous validation, standardized reporting (TRIPOD-AI, STARD-AI), and prospective multicenter studies, is essential for clinical integration. This review provides clear recommendations to enhance clinical translation of AI-based ultrasound diagnostics.",2025,10.3389/frai.2025.1649746
The role of artificial intelligence based systems for cost optimization in colorectal cancer prevention programs,"Colorectal Cancer (CRC) has seen a dramatic increase in incidence globally. In 2019, colorectal cancer accounted for 1.15 million deaths and 24.28 million disability-adjusted life-years (DALYs) worldwide. In India, the annual incidence rates (AARs) for colon cancer was 4.4 per 100,000. There has been a steady rise in the prevalence of CRC in India which may be attributed to urbanization, mass migration of population, westernization of diet and lifestyle practices and a rise of obesity and metabolic risk factors that place the population at a higher risk of CRC. Moreoever, CRC in India differs from that described in the Western countries, with a higher proportion of young patients and more patients presenting with an advanced stage. This may be due to poor access to specialized healthcare and socio-economic factors. Early identification of adenomatous colonic polyps, which are well-recognized pre-cancerous lesions, at the time of screening colonoscopy has been shown to be the most effective measure used for CRC prevention. However, colonic polyps are frequently missed during colonoscopy and moreover, these screening programs necessitate man-power, time and resources for processing resected polyps, that may hamper penetration and efficacy in mid- to low-income countries. In the last decade, there has been significant progress made in the automatic detection of colonic polyps by multiple AI-based systems. With the advent of better AI methodology, the focus has shifted from mere detection to accurate discrimination and diagnosis of colonic polyps. These systems, once validated, could usher in a new era in Colorectal Cancer (CRC) prevention programs which would center around “Leave in-situ” and “Resect and discard” strategies. These new strategies hinge around the specificity and accuracy of AI based systems in correctly identifying the pathological diagnosis of the polyps, thereby providing the endoscopist with real-time information in order to make a clinical decision of either leaving the lesion in-situ (mucosal polyps) or resecting and discarding the polyp (hyperplastic polyps). The major advantage of employing these strategies would be in cost optimization of CRC prevention programs while ensuring good clinical outcomes. The adoption of these AI-based systems in the national cancer prevention program of India in accordance with the mandate to increase technology integration could prove to be cost-effective and enable implementation of CRC prevention programs at the population level. This level of penetration could potentially reduce the incidence of CRC and improve patient survival by enabling early diagnosis and treatment. In this review, we will highlight key advancements made in the field of AI in the identification of polyps during colonoscopy and explore the role of AI based systems in cost optimization during the universal implementation of CRC prevention programs in the context of mid-income countries like India.",2022,10.3389/frai.2022.955399
Studying the Evolution of Neural Activation Patterns During Training of Feed-Forward ReLU Networks,"The ability of deep neural networks to form powerful emergent representations of complex statistical patterns in data is as remarkable as imperfectly understood. For deep ReLU networks, these are encoded in the mixed discrete–continuous structure of linear weight matrices and non-linear binary activations. Our article develops a new technique for instrumenting such networks to efficiently record activation statistics, such as information content (entropy) and similarity of patterns, in real-world training runs. We then study the evolution of activation patterns during training for networks of different architecture using different training and initialization strategies. As a result, we see characteristic- and general-related as well as architecture-related behavioral patterns: in particular, most architectures form bottom-up structure, with the exception of highly tuned state-of-the-art architectures and methods (PyramidNet and FixUp), where layers appear to converge more simultaneously. We also observe intermediate dips in entropy in conventional CNNs that are not visible in residual networks. A reference implementation is provided under a free license1.",2021,10.3389/frai.2021.642374
Interpretable machine learning for predicting pathologic complete response in patients treated with chemoradiation therapy for rectal adenocarcinoma,"PurposePathologic complete response (pCR) is a critical factor in determining whether patients with rectal cancer (RC) should have surgery after neoadjuvant chemoradiotherapy (nCRT). Currently, a pathologist's histological analysis of surgical specimens is necessary for a reliable assessment of pCR. Machine learning (ML) algorithms have the potential to be a non-invasive way for identifying appropriate candidates for non-operative therapy. However, these ML models' interpretability remains challenging. We propose using explainable boosting machine (EBM) to predict the pCR of RC patients following nCRT.MethodsA total of 296 features were extracted, including clinical parameters (CPs), dose-volume histogram (DVH) parameters from gross tumor volume (GTV) and organs-at-risk, and radiomics (R) and dosiomics (D) features from GTV. R and D features were subcategorized into shape (S), first-order (L1), second-order (L2), and higher-order (L3) local texture features. Multi-view analysis was employed to determine the best set of input feature categories. Boruta was used to select all-relevant features for each input dataset. ML models were trained on 180 cases from our institution, with 37 cases from RTOG 0822 clinical trial serving as the independent dataset for model validation. The performance of EBM in predicting pCR on the test dataset was evaluated using ROC AUC and compared with that of three state-of-the-art black-box models: extreme gradient boosting (XGB), random forest (RF) and support vector machine (SVM). The predictions of all black-box models were interpreted using Shapley additive explanations.ResultsThe best input feature categories were CP+DVH+S+R_L1+R_L2 for all models, from which Boruta-selected features enabled the EBM, XGB, RF, and SVM models to attain the AUCs of 0.820, 0.828, 0.828, and 0.774, respectively. Although EBM did not achieve the best performance, it provided the best capability for identifying critical turning points in response scores at distinct feature values, revealing that the bladder with maximum dose &gt;50 Gy, and the tumor with maximum2DDiameterColumn &gt;80 mm, elongation &lt;0.55, leastAxisLength &gt;50 mm and lower variance of CT intensities were associated with unfavorable outcomes.ConclusionsEBM has the potential to enhance the physician's ability to evaluate an ML-based prediction of pCR and has implications for selecting patients for a “watchful waiting” strategy to RC therapy.",2022,10.3389/frai.2022.1059033
Understanding image-text relations and news values for multimodal news analysis,"The analysis of news dissemination is of utmost importance since the credibility of information and the identification of disinformation and misinformation affect society as a whole. Given the large amounts of news data published daily on the Web, the empirical analysis of news with regard to research questions and the detection of problematic news content on the Web require computational methods that work at scale. Today's online news are typically disseminated in a multimodal form, including various presentation modalities such as text, image, audio, and video. Recent developments in multimodal machine learning now make it possible to capture basic “descriptive” relations between modalities–such as correspondences between words and phrases, on the one hand, and corresponding visual depictions of the verbally expressed information on the other. Although such advances have enabled tremendous progress in tasks like image captioning, text-to-image generation and visual question answering, in domains such as news dissemination, there is a need to go further. In this paper, we introduce a novel framework for the computational analysis of multimodal news. We motivate a set of more complex image-text relations as well as multimodal news values based on real examples of news reports and consider their realization by computational approaches. To this end, we provide (a) an overview of existing literature from semiotics where detailed proposals have been made for taxonomies covering diverse image-text relations generalisable to any domain; (b) an overview of computational work that derives models of image-text relations from data; and (c) an overview of a particular class of news-centric attributes developed in journalism studies called news values. The result is a novel framework for multimodal news analysis that closes existing gaps in previous work while maintaining and combining the strengths of those accounts. We assess and discuss the elements of the framework with real-world examples and use cases, setting out research directions at the intersection of multimodal learning, multimodal analytics and computational social sciences that can benefit from our approach.",2023,10.3389/frai.2023.1125533
Artificial intelligence at work: The problem of managerial control from call centers to transport platforms,"There has been much recent research on the topic of artificial intelligence at work, which is increasingly featuring in more types of work and across the labor process. Much research takes the application of artificial intelligence, in its various forms, as a break from the previous methods of organizing work. Less is known about how these applications of artificial intelligence build upon previous forms of managerial control or are adapted in practice. This paper aims to situate the use of artificial intelligence by management within a longer history of control at work. In doing so, it seeks to draw out the novelty of the technology, while also critically appraising the impact of artificial intelligence as a managerial tool. The aim is to understand the contest at work over the introduction of these tools, taking call centers and transport platforms as case studies. Call centers are important because they have been a site of struggle over previous forms of electronic surveillance and computation control, providing important lessons for how artificial intelligence is, or may, be used in practice. In particular, this paper will draw out moments and tactics in algorithmic management has been challenged at work, using this as a discussion point for considering the possible future of artificial intelligence at work.",2022,10.3389/frai.2022.888817
Unsupervised literature mining approaches for extracting relationships pertaining to habitats and reproductive conditions of plant species,"IntroductionFine-grained, descriptive information on habitats and reproductive conditions of plant species are crucial in forest restoration and rehabilitation efforts. Precise timing of fruit collection and knowledge of species' habitat preferences and reproductive status are necessary especially for tropical plant species that have short-lived recalcitrant seeds, and those that exhibit complex reproductive patterns, e.g., species with supra-annual mass flowering events that may occur in irregular intervals. Understanding plant regeneration in the way of planning for effective reforestation can be aided by providing access to structured information, e.g., in knowledge bases, that spans years if not decades as well as covering a wide range of geographic locations. The content of such a resource can be enriched with literature-derived information on species' time-sensitive reproductive conditions and location-specific habitats.MethodsWe sought to develop unsupervised approaches to extract relationships pertaining to habitats and their locations, and reproductive conditions of plant species and corresponding temporal information. Firstly, we handcrafted rules for a traditional rule-based pattern matching approach. We then developed a relation extraction approach building upon transformer models, i.e., the Text-to-Text Transfer Transformer (T5), casting the relation extraction problem as a question answering and natural language inference task. We then propose a novel unsupervised hybrid approach that combines our rule-based and transformer-based approaches.ResultsEvaluation of our hybrid approach on an annotated corpus of biodiversity-focused documents demonstrated an improvement of up to 15 percentage points in recall and best performance over solely rule-based and transformer-based methods with F1-scores ranging from 89.61 to 96.75% for reproductive condition - temporal expression relations, and ranging from 85.39% to 89.90% for habitat - geographic location relations. Our work shows that even without training models on any domain-specific labeled dataset, we are able to extract relationships between biodiversity concepts from literature with satisfactory performance.",2024,10.3389/frai.2024.1371411
CNN-Based LCD Transcription of Blood Pressure From a Mobile Phone Camera,"Routine blood pressure (BP) measurement in pregnancy is commonly performed using automated oscillometric devices. Since no wireless oscillometric BP device has been validated in preeclamptic populations, a simple approach for capturing readings from such devices is needed, especially in low-resource settings where transmission of BP data from the field to central locations is an important mechanism for triage. To this end, a total of 8192 BP readings were captured from the Liquid Crystal Display (LCD) screen of a standard Omron M7 self-inflating BP cuff using a cellphone camera. A cohort of 49 lay midwives captured these data from 1697 pregnant women carrying singletons between 6 weeks and 40 weeks gestational age in rural Guatemala during routine screening. Images exhibited a wide variability in their appearance due to variations in orientation and parallax; environmental factors such as lighting, shadows; and image acquisition factors such as motion blur and problems with focus. Images were independently labeled for readability and quality by three annotators (BP range: 34–203 mm Hg) and disagreements were resolved. Methods to preprocess and automatically segment the LCD images into diastolic BP, systolic BP and heart rate using a contour-based technique were developed. A deep convolutional neural network was then trained to convert the LCD images into numerical values using a multi-digit recognition approach. On readable low- and high-quality images, this proposed approach achieved a 91% classification accuracy and mean absolute error of 3.19 mm Hg for systolic BP and 91% accuracy and mean absolute error of 0.94 mm Hg for diastolic BP. These error values are within the FDA guidelines for BP monitoring when poor quality images are excluded. The performance of the proposed approach was shown to be greatly superior to state-of-the-art open-source tools (Tesseract and the Google Vision API). The algorithm was developed such that it could be deployed on a phone and work without connectivity to a network.",2021,10.3389/frai.2021.543176
Characterising Online News Comments: A Multi-Dimensional Cruise Through Online Registers,"News organisations often allow public comments at the bottom of their news stories. These comments constitute a fruitful source of data to investigate linguistic variation online; their characteristics, however, are rather understudied. This paper thus contributes to the description of online news comments and online language in English. In this spirit, we apply multi-dimensional analysis to a large dataset of online news comments and compare them to a corpus of online registers, thus placing online comments in the space of register variation online. We find that online news comments are involved-evaluative and informational at the same time, but mostly argumentative in nature, with such argumentation taking an informal shape. Our analyses lead us to conclude that online registers are a different mode of communication, neither spoken nor written, with individual variation across different types of online registers.",2021,10.3389/frai.2021.643770
An Application of an Embedded Model Estimator to a Synthetic Nonstationary Reservoir Model With Multiple Secondary Variables,"A method (Ember) for nonstationary spatial modeling with multiple secondary variables by combining Geostatistics with Random Forests is applied to a three-dimensional Reservoir Model. It extends the Random Forest method to an interpolation algorithm retaining similar consistency properties to both Geostatistical algorithms and Random Forests. It allows embedding of simpler interpolation algorithms into the process, combining them through the Random Forest training process. The algorithm estimates a conditional distribution at each target location. The family of such distributions is called the model envelope. An algorithm to produce stochastic simulations from the envelope is demonstrated. This algorithm allows the influence of the secondary variables, as well as the variability of the result to vary by location in the simulation.",2021,10.3389/frai.2021.624697
Time-series representation learning via Time-Frequency Fusion Contrasting,"Time series is a typical data type in numerous domains; however, labeling large amounts of time series data can be costly and time-consuming. Learning effective representation from unlabeled time series data is a challenging task. Contrastive learning stands out as a promising method to acquire representations of unlabeled time series data. Therefore, we propose a self-supervised time-series representation learning framework via Time-Frequency Fusion Contrasting (TF-FC) to learn time-series representation from unlabeled data. Specifically, TF-FC combines time-domain augmentation with frequency-domain augmentation to generate the diverse samples. For time-domain augmentation, the raw time series data pass through the time-domain augmentation bank (such as jitter, scaling, permutation, and masking) and get time-domain augmentation data. For frequency-domain augmentation, first, the raw time series undergoes conversion into frequency domain data following Fast Fourier Transform (FFT) analysis. Then, the frequency data passes through the frequency-domain augmentation bank (such as low pass filter, remove frequency, add frequency, and phase shift) and gets frequency-domain augmentation data. The fusion method of time-domain augmentation data and frequency-domain augmentation data is kernel PCA, which is useful for extracting nonlinear features in high-dimensional spaces. By capturing both the time and frequency domains of the time series, the proposed approach is able to extract more informative features from the data, enhancing the model's capacity to distinguish between different time series. To verify the effectiveness of the TF-FC method, we conducted experiments on four time series domain datasets (i.e., SleepEEG, HAR, Gesture, and Epilepsy). Experimental results show that TF-FC significantly improves in recognition accuracy compared with other SOTA methods.",2024,10.3389/frai.2024.1414352
Beyond the Benchmarks: Toward Human-Like Lexical Representations,"To process language in a way that is compatible with human expectations in a communicative interaction, we need computational representations of lexical properties that form the basis of human knowledge of words. In this article, we concentrate on word-level semantics. We discuss key concepts and issues that underlie the scientific understanding of the human lexicon: its richly structured semantic representations, their ready and continual adaptability, and their grounding in crosslinguistically valid conceptualization. We assess the state of the art in natural language processing (NLP) in achieving these identified properties, and suggest ways in which the language sciences can inspire new approaches to their computational instantiation.",2022,10.3389/frai.2022.796741
Towards enhanced creativity in fashion: integrating generative models with hybrid intelligence,"IntroductionThis study explores the role and potential of large language models (LLMs) and generative intelligence in the fashion industry. These technologies are reshaping traditional methods of design, production, and retail, leading to innovation, product personalization, and enhanced customer interaction.MethodsOur research analyzes the current applications and limitations of LLMs in fashion, identifying challenges such as the need for better spatial understanding and design detail processing. We propose a hybrid intelligence approach to address these issues.ResultsWe find that while LLMs offer significant potential, their integration into fashion workflows requires improvements in understanding spatial parameters and creating tools for iterative design.DiscussionFuture research should focus on overcoming these limitations and developing hybrid intelligence solutions to maximize the potential of LLMs in the fashion industry.",2024,10.3389/frai.2024.1460217
Statistical and machine learning approaches for identifying biomarker associations in respiratory diseases in a population-specific region,"The growing interest in utilizing clinical blood biomarkers for non-invasive diagnostics has transformed the approach to early detection and prognosis of respiratory diseases. Biomarker-driven diagnostics offer cost-effective, rapid, and scalable alternatives to traditional imaging and clinical assessments. In this study, we conducted a retrospective analysis of 913 patients from a local respiratory clinic in Hail region, evaluating the diagnostic relevance of 15 blood biomarkers across four respiratory conditions: COVID-19, pneumonia, asthma, and other complications. Through data-driven analysis, statistical correlation assessments, and machine learning classification models (decision tree classifiers), we identified significant biomarker interactions that contributed to disease differentiation. Notably, CRP and HGB demonstrated a strong negative correlation (−55%), supporting the well-established role of systemic inflammation in anemia of chronic disease. Additionally, Ferritin and LDH exhibited a positive correlation (+50%), indicating metabolic stress and cellular injury in severe respiratory illnesses. Other significant correlations included Creatinine and ESR being negatively associated with RBC, while GGT and ALT were positively correlated (+49%). Additionally, bilirubin and HGB were positively correlated (+49%), collectively reflecting systemic inflammatory and metabolic responses associated with respiratory pathology. The machine learning model demonstrated high predictive accuracy, with the following performance metrics: COVID-19: Precision (0.94), Recall (0.96), F1-score (0.95). Pneumonia: Precision (0.97), Recall (0.71), F1-score (0.85). Asthma: Precision (1.00), Recall (0.95), F1-score (0.97). Other Complications: Precision (0.88), Recall (0.90), F1-score (0.90). These findings validate the diagnostic potential of biomarker panels in respiratory disease classification, offering a novel approach to integrating statistical and computational modeling for clinical decision-making. By leveraging biomarker relationships and machine learning algorithms, this study contributes to the development of personalized, non-invasive, and cost-effective diagnostic tools for respiratory diseases, ultimately improving patient outcomes and healthcare efficiency.",2025,10.3389/frai.2025.1682774
Human-centered AI through employee participation,"This article examines the role of employee participation in AI implementation, focusing on a case study from the German telecommunications sector. Theoretical discussions highlight concepts of employee participation and workplace democracy, emphasizing the normative basis for human-centered AI in Europe. The empirical analysis of the case study demonstrates social practices of human-centered AI and the importance of employee representatives and labor policies in sustainable technology. The contribution is structured into two main parts: first, discussing sociological concepts of employee participation and summarizing the role of works councils in shaping digital technology implementation. Second, focusing on a case study of AI regulations at Deutsche Telekom, highlighting the significant effects of employee participation and co-determination by the group works council in promoting socially sustainable AI implementation which is done via qualitative case analysis. The article highlights the significance of participation and negotiations and gives an example for social partnership relations in AI implementations.",2024,10.3389/frai.2024.1272102
COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter,"IntroductionThis study presents COVID-Twitter-BERT (CT-BERT), a transformer-based model that is pre-trained on a large corpus of COVID-19 related Twitter messages. CT-BERT is specifically designed to be used on COVID-19 content, particularly from social media, and can be utilized for various natural language processing tasks such as classification, question-answering, and chatbots. This paper aims to evaluate the performance of CT-BERT on different classification datasets and compare it with BERT-LARGE, its base model.MethodsThe study utilizes CT-BERT, which is pre-trained on a large corpus of COVID-19 related Twitter messages. The authors evaluated the performance of CT-BERT on five different classification datasets, including one in the target domain. The model's performance is compared to its base model, BERT-LARGE, to measure the marginal improvement. The authors also provide detailed information on the training process and the technical specifications of the model.ResultsThe results indicate that CT-BERT outperforms BERT-LARGE with a marginal improvement of 10-30% on all five classification datasets. The largest improvements are observed in the target domain. The authors provide detailed performance metrics and discuss the significance of these results.DiscussionThe study demonstrates the potential of pre-trained transformer models, such as CT-BERT, for COVID-19 related natural language processing tasks. The results indicate that CT-BERT can improve the classification performance on COVID-19 related content, especially on social media. These findings have important implications for various applications, such as monitoring public sentiment and developing chatbots to provide COVID-19 related information. The study also highlights the importance of using domain-specific pre-trained models for specific natural language processing tasks. Overall, this work provides a valuable contribution to the development of COVID-19 related NLP models.",2023,10.3389/frai.2023.1023281
Classification of land use/land cover using artificial intelligence (ANN-RF),"Because deep learning has various downsides, such as complexity, expense, and the need to wait longer for results, this creates a significant incentive and impetus to invent and adopt the notion of developing machine learning because it is simple. This study intended to increase the accuracy of machine-learning approaches for land use/land cover classification using Sentinel-2A, and Landsat-8 satellites. This study aimed to implement a proposed method, neural-based with object-based, to produce a model addressed by artificial neural networks (limited parameters) with random forest (hyperparameter) called ANN_RF. This study used multispectral satellite images (Sentinel-2A and Landsat-8) and a normalized digital elevation model as input datasets for the Sana'a city map of 2016. The results showed that the accuracy of the proposed model (ANN_RF) is better than the ANN classifier with the Sentinel-2A and Landsat-8 satellites individually, which may contribute to the development of machine learning through newer researchers and specialists; it also conventionally developed traditional artificial neural networks with seven to ten layers but with access to 1,000's and millions of simulated neurons without resorting to deep learning techniques (ANN_RF).",2023,10.3389/frai.2022.964279
A machine learning-driven web application for sign language learning,"Addressing the increasing demand for accessible sign language learning tools, this paper introduces an innovative Machine Learning-Driven Web Application dedicated to Sign Language Learning. This web application represents a significant advancement in sign language education. Unlike traditional approaches, the application’s unique methodology involves assigning users different words to spell. Users are tasked with signing each letter of the word, earning a point upon correctly signing the entire word. The paper delves into the development, features, and the machine learning framework underlying the application. Developed using HTML, CSS, JavaScript, and Flask, the web application seamlessly accesses the user’s webcam for a live video feed, displaying the model’s predictions on-screen to facilitate interactive practice sessions. The primary aim is to provide a learning platform for those who are not familiar with sign language, offering them the opportunity to acquire this essential skill and fostering inclusivity in the digital age.",2024,10.3389/frai.2024.1297347
Evaluating accuracy and reproducibility of large language model performance on critical care assessments in pharmacy education,"BackgroundLarge language models (LLMs) have demonstrated impressive performance on medical licensing and diagnosis-related exams. However, comparative evaluations to optimize LLM performance and ability in the domain of comprehensive medication management (CMM) are lacking. The purpose of this evaluation was to test various LLMs performance optimization strategies and performance on critical care pharmacotherapy questions used in the assessment of Doctor of Pharmacy students.MethodsIn a comparative analysis using 219 multiple-choice pharmacotherapy questions, five LLMs (GPT-3.5, GPT-4, Claude 2, Llama2-7b and 2-13b) were evaluated. Each LLM was queried five times to evaluate the primary outcome of accuracy (i.e., correctness). Secondary outcomes included variance, the impact of prompt engineering techniques (e.g., chain-of-thought, CoT) and training of a customized GPT on performance, and comparison to third year doctor of pharmacy students on knowledge recall vs. knowledge application questions. Accuracy and variance were compared with student’s t-test to compare performance under different model settings.ResultsChatGPT-4 exhibited the highest accuracy (71.6%), while Llama2-13b had the lowest variance (0.070). All LLMs performed more accurately on knowledge recall vs. knowledge application questions (e.g., ChatGPT-4: 87% vs. 67%). When applied to ChatGPT-4, few-shot CoT across five runs improved accuracy (77.4% vs. 71.5%) with no effect on variance. Self-consistency and the custom-trained GPT demonstrated similar accuracy to ChatGPT-4 with few-shot CoT. Overall pharmacy student accuracy was 81%, compared to an optimal overall LLM accuracy of 73%. Comparing question types, six of the LLMs demonstrated equivalent or higher accuracy than pharmacy students on knowledge recall questions (e.g., self-consistency vs. students: 93% vs. 84%), but pharmacy students achieved higher accuracy than all LLMs on knowledge application questions (e.g., self-consistency vs. students: 68% vs. 80%).ConclusionChatGPT-4 was the most accurate LLM on critical care pharmacy questions and few-shot CoT improved accuracy the most. Average student accuracy was similar to LLMs overall, and higher on knowledge application questions. These findings support the need for future assessment of customized training for the type of output needed. Reliance on LLMs is only supported with recall-based questions.",2025,10.3389/frai.2024.1514896
An efficient method for early Alzheimer’s disease detection based on MRI images using deep convolutional neural networks,"Alzheimer’s disease (AD) is a progressive, incurable neurological disorder that leads to a gradual decline in cognitive abilities. Early detection is vital for alleviating symptoms and improving patient quality of life. With a shortage of medical experts, automated diagnostic systems are increasingly crucial in healthcare, reducing the burden on providers and enhancing diagnostic accuracy. AD remains a global health challenge, requiring effective early detection strategies to prevent its progression and facilitate timely intervention. In this study, a deep convolutional neural network (CNN) architecture is proposed for AD classification. The model, consisting of 6,026,324 parameters, uses three distinct convolutional branches with varying lengths and kernel sizes to improve feature extraction. The OASIS dataset used includes 80,000 MRI images sourced from Kaggle, categorized into four classes: non-demented (67,200 images), very mild demented (13,700 images), mild demented (5,200 images), and moderate demented (488 images). To address the dataset imbalance, a data augmentation technique was applied. The proposed model achieved a remarkable 99.68% accuracy in distinguishing between the four stages of Alzheimer’s: Non-Dementia, Very Mild Dementia, Mild Dementia, and Moderate Dementia. This high accuracy highlights the model’s potential for real-time analysis and early diagnosis of AD, offering a promising tool for healthcare professionals.",2025,10.3389/frai.2025.1563016
How could fit between polychronicity and multitasking shape employees' self-leadership? The moderating role of AI-empowered task processing,"As AI becomes increasingly integrated into the workplace, understanding how prevailing multitasking practices interact with AI support to foster employee self-leadership is essential for enhancing organizational effectiveness. This study elucidates how the fit between multitasking and polychronicity among employees in organizations can synergistically influence their self-leadership within the context of AI empowerment. This study conducts two time-lagged survey studies using polynomial regression analysis, block variable analysis, and response surface methodology based on the “Fit Between Individuals, Tasks and Technology” (FITT) framework and the JD-R theoretical model. Study 1 examined the polychronicity-multitasking fit based on data collected from 116 employees at two time points in an AI company in China. Study 2 tested the mediating and moderating effect based on data of 188 employees from two other AI companies in China at three time points. The results show that congruence between polychronicity and multitasking predicts greater employee self-leadership compared to incongruence, and the higher the degree of congruence, the stronger the self-leadership. For incongruence, the “high-low” state promotes self-leadership better than the “low-high” state. We also reveal the mediating role of thriving at work and the moderating role of AI-empowered task processing between polychronicity-multitasking fit and self-leadership. For well-matched employees, AI serves as a facilitator of task processing, thereby enhancing employee self-leadership; whereas for mismatched ones, AI acts as an additional task burden or as a catalyst that exacerbates the existing imbalance, which impedes the motivation for self-leadership. These findings advance the understanding of self-leadership in multitasking contexts and provide valuable insights for organizations implementing AI tools. This study underscores the critical importance of aligning employees' work preferences with task demands to fully leverage the potential of AI empowerment.",2025,10.3389/frai.2025.1451944
A review of machine learning in scanpath analysis for passive gaze-based interaction,"The scanpath is an important concept in eye tracking. It refers to a person's eye movements over a period of time, commonly represented as a series of alternating fixations and saccades. Machine learning has been increasingly used for the automatic interpretation of scanpaths over the past few years, particularly in research on passive gaze-based interaction, i.e., interfaces that implicitly observe and interpret human eye movements, with the goal of improving the interaction. This literature review investigates research on machine learning applications in scanpath analysis for passive gaze-based interaction between 2012 and 2022, starting from 2,425 publications and focussing on 77 publications. We provide insights on research domains and common learning tasks in passive gaze-based interaction and present common machine learning practices from data collection and preparation to model selection and evaluation. We discuss commonly followed practices and identify gaps and challenges, especially concerning emerging machine learning topics, to guide future research in the field.",2024,10.3389/frai.2024.1391745
Prediction of E. coli Concentrations in Agricultural Pond Waters: Application and Comparison of Machine Learning Algorithms,"The microbial quality of irrigation water is an important issue as the use of contaminated waters has been linked to several foodborne outbreaks. To expedite microbial water quality determinations, many researchers estimate concentrations of the microbial contamination indicator Escherichia coli (E. coli) from the concentrations of physiochemical water quality parameters. However, these relationships are often non-linear and exhibit changes above or below certain threshold values. Machine learning (ML) algorithms have been shown to make accurate predictions in datasets with complex relationships. The purpose of this work was to evaluate several ML models for the prediction of E. coli in agricultural pond waters. Two ponds in Maryland were monitored from 2016 to 2018 during the irrigation season. E. coli concentrations along with 12 other water quality parameters were measured in water samples. The resulting datasets were used to predict E. coli using stochastic gradient boosting (SGB) machines, random forest (RF), support vector machines (SVM), and k-nearest neighbor (kNN) algorithms. The RF model provided the lowest RMSE value for predicted E. coli concentrations in both ponds in individual years and over consecutive years in almost all cases. For individual years, the RMSE of the predicted E. coli concentrations (log10 CFU 100 ml−1) ranged from 0.244 to 0.346 and 0.304 to 0.418 for Pond 1 and 2, respectively. For the 3-year datasets, these values were 0.334 and 0.381 for Pond 1 and 2, respectively. In most cases there was no significant difference (P &gt; 0.05) between the RMSE of RF and other ML models when these RMSE were treated as statistics derived from 10-fold cross-validation performed with five repeats. Important E. coli predictors were turbidity, dissolved organic matter content, specific conductance, chlorophyll concentration, and temperature. Model predictive performance did not significantly differ when 5 predictors were used vs. 8 or 12, indicating that more tedious and costly measurements provide no substantial improvement in the predictive accuracy of the evaluated algorithms.",2022,10.3389/frai.2021.768650
"Community-engaged artificial intelligence: an upstream, participatory design, development, testing, validation, use and monitoring framework for artificial intelligence and machine learning models in the Alaska Tribal Health System","American Indian and Alaska Native (AI/AN) communities are at a critical juncture in health research, where combining participatory methods with advancements in artificial intelligence and machine learning (AI/ML) can promote equity. Community-based participatory research methods which emerged to help Alaska Native communities navigate the complicated legacy of historical research abuses provide a framework to allow emerging AI/ML technologies to align with their unique world views, community strengths, and healthcare goals. A consortium of researchers (including Alaska Native Tribal Health Consortium, the Center for Alaska Native Health Research at University of Alaska, Fairbanks, Stanford University, Southcentral Foundation, and Maniilaq Association) is using community-engaged AI/ML methods to address air medical ambulance (medevac) utilization in rural communities within the Alaska Tribal Health System (ATHS). This mixed-methods convergent triangulation study uses qualitative and quantitative analyses to develop AI/ML models tailored to community needs, provider concerns, and cultural contexts. Early successes have led to a second funded project to expand community perspectives, pilot models, and address issues of governance and ethics. Using the Ethical, Legal, and Social Implications of Research framework to address implementation of AI/ML in AI/AN communities, this second grant expands community engagement, technical capacity, and creates a body within the ATHS able to provide recommendations about AI/ML security, privacy, governance and policy. These two projects have the potential to provide equitable AI/ML implementation in Alaska Native healthcare and provide a roadmap for researchers and policy makers looking to effect similar change in other AI/AN and marginalized communities.",2025,10.3389/frai.2025.1568886
Sustainable artificial intelligence in finance: impact of ESG factors,"There is a growing concern about the sustainability of artificial intelligence, in terms of Environmental, Social and Governance (ESG) factors. We contribute to the debate measuring the impact of ESG factors on one of the most relevant applications of AI in finance: credit rating. There is not yet conclusive evidence on whether EGS factors impact on credit rating. In this paper, we propose several machine learning models to measure such impact, and a set of metrics that can improve their ability to do so. In this way, machine learning models and, more generally, decisions based on artificial intelligence, can become more sustainable.",2025,10.3389/frai.2025.1566197
Decoding manipulative narratives in cognitive warfare: a case study of the Russia-Ukraine conflict,"IntroductionThis study investigates the construction and dissemination of manipulative narratives in the context of cognitive warfare during the Russia-Ukraine conflict. Leveraging a mixed-methods approach that integrates AI-assisted semantic analysis with expert validation, we examine how adversarial messaging exploits cognitive biases-such as fear and confirmation bias-to influence perceptions and disrupt institutional trust.MethodsUsing the proprietary Attack-Index tool and large language models (LLMs), we detect linguistic markers of manipulation, including euphemisms, sarcasm, and strategic framing.ResultsOur findings demonstrate that emotionally charged narratives, particularly those invoking nuclear threat scenarios, are synchronized with key geopolitical events to influence decision-makers and public opinion. The study identifies five thematic clusters and traces shifts in rhetorical strategies over time, showing how manipulative discourse adapts to geopolitical contexts. Special attention is given to the differentiated targeting of international political elites, Western publics, and Russian domestic audiences, each exhibiting varied cognitive vulnerabilities.DiscussionWe acknowledge methodological and ethical limitations, including the dual-use potential of AI tools and challenges in establishing causal inferences. Nonetheless, this study offers the following key contributions:Empirically establishing nuclear rhetoric as a strategic element of narrative manipulation, particularly around NATO summits and military aid announcements.Advancing an integrated analytical framework that combines semantic clustering and AI-based discourse detection to monitor information threats in real time.Providing actionable insights for policy and digital security, including the development of countermeasures and international collaboration in addressing cognitive warfare.",2025,10.3389/frai.2025.1566022
An Extended UTAUT Model to Explain Factors Affecting Online Learning System Amidst COVID-19 Pandemic: The Case of a Developing Economy,"From a developing country perspective, this study explains the factors affecting online learning amidst the COVID-19 pandemic. The paper empirically tests the proposed extended unified theory of acceptance and use of technology (e-UTAUT) model in the students' intention and use behavior toward the online learning system. Understanding the acceptance of online learning technology is crucial, especially among developing countries caught off-guard by the abrupt transition of face-to-face classes to pure online learning. The enjoyment, interactivity, flexibility, and quality of online learning systems were added as antecedent variables to the UTAUT model. Eight hundred eighty valid responses from selected college students in the Visayas regions, Philippines, were collected. Structural equation modeling (SEM) was employed to verify the research hypotheses. The results supported the proposed model with acceptable fit measures and substantial explanatory power. The extended constructs provide different views on online learning based on the significant cluster of antecedents to explain technology acceptance through behavioral intentions and actual system usage. The paper implies that despite the challenges of connectivity in developing countries, the variations still conform with emerging literature about the topic. Insights for higher education institutions and policy directions are recommended.",2022,10.3389/frai.2022.768831
From data silos to insights: the PRINCE multi-agent knowledge engine for preclinical drug development,"The pharmaceutical industry faces pressure to improve the drug development process while reducing costs in an evolving regulatory landscape. This paper presents the Preclinical Information Center (PRINCE), a cloud-hosted data integration platform developed by Bayer AG in collaboration with Thoughtworks. PRINCE integrates decades of structured and unstructured safety study reports, leveraging a multi-agent architecture based on Large Language Models (LLMs) and advanced data retrieval methodologies, such as Retrieval-Augmented Generation and Text-to-SQL. In this paper, we describe the three-step evolution of PRINCE from a data search tool based on keyword matching to a resourceful research assistant capable of answering complex questions and drafting regulatory-critical documents. We highlight the iterative development process, guided by user feedback, that ensures alignment with evolving research needs and maximizes utility. Finally, we discuss the importance of building trust-based solutions and how transparency and explainability have been integrated into PRINCE. In particular, the integration of a human-in-the-loop approach enhances the accuracy and retains human accountability. We believe that the development and deployment of the PRINCE chatbot demonstrate the transformative potential of AI in the pharmaceutical industry, significantly improving data accessibility and research efficiency, while prioritizing data governance and compliance.",2025,10.3389/frai.2025.1636809
Grouped semantic-feature relation extraction from texts to represent medicinal-plant property knowledge on social media,"This research aims to extract a grouped semantic-feature relation, particularly a PlantPart-MedicinalPropertyGroup relation which is a semantic relation between an element of a plant-part concept set and a group of medicinal-property concept features of various herbs or medicinal plants, including indigenous medicinal plants, to graphically represent medicinal-plant property knowledge from documents available on pharmacy academic websites. The medicinal-plant property knowledge representation particularly benefits native users and patients seeking alternative medical therapies during pandemics, such as COVID-19, due to limited access to medicines, physicians and hospitals. Medicinal-property expressions on the documents, particularly in Thai, are often structured as event expressions conveyed through verb phrases within Elementary Discourse Units (EDUs) or simple sentences. There are three research problems in extracting the PlantPart-MedicinalPropertyGroup relations from the documents: how to identify EDU occurrences with medicinal-property concepts, how to extract medicinal-property concept features from medicinal-property concept EDU occurrences without concept annotations, and how to extract the PlantPart-MedicinalPropertyGroup relation without relation-class labeling from the documents with the high dimensional and correlated feature consideration. To address these problems, we apply a Solving-Verb Concept set primarily sourced from translated terms on HerbMed, an American Botanical Council resource, to identify a medicinal-property concept EDU. Additionally, a word co-occurrence (word-co) pattern is applied as a compound variable on the translated terms to construct a medicinal-property-concept (MPC) table. The MPC table is employed to extract the medicinal-property concept features from the medicinal-property concept EDUs through a string-matching method. We then propose using structural equation modeling to automatically extract the PlantPart-MedicinalPropertyGroup relations from the documents. Thus, the proposed approach enables the extraction of PlantPart-MedicinalPropertyGroup relations with high qualities to represent medicinal-plant property knowledge on social media.",2025,10.3389/frai.2025.1579357
A mobile hybrid deep learning approach for classifying 3D-like representations of Amazonian lizards,"Image classification is a highly significant field in machine learning (ML), especially when applied to address longstanding and challenging issues in the biological sciences, such as specie recognition and biodiversity conservation. In this study, we present the development of a hybrid machine learning-based tool suitable for deployment on mobile devices. This tool is aimed at processing and classifying three-dimensional samples of endemic lizard species from the Amazon rainforest. The dataset used in our experiment was collected at the Museu Paraense Emílio Goeldi (MPEG), Belém-PA, Brazil, and comprises three species: (a) Anolis fuscoauratus; (b) Hoplocercus spinosus; and (c) Polychrus marmoratus. We compared the effectiveness of four artificial neural networks (ANN) for feature extraction: (a) MobileNet; (b) MobileNetV2; (c) MobileNetV3-Small; and (d) MobileNetV3-Large. Additionally, we evaluated five classical ML models for classifying the extracted patterns: (a) Support Vector Machine (SVM); (b) GaussianNB (GNB); (c) AdaBoost (ADB); (d) K-Nearest Neighbors (KNN); and (e) Random Forest (RF). The performance metrics of all classifiers were very close, we used the McNemar’s test on each model’s confusion matrix to evaluate and compare their statistical significance. Our best model was a combination of a 2.9 million parameters MobileNetV3-Small as the feature extractor, with a linear kernel-based SVM as the classifier, which achieved accuracy of 0.955, precision of 0.948, recall of 0.948, and f1-score of 0.948. The results indicated that the use of a small deep learning (DL) model, in combination with a classical ML algorithm, emerges as a viable technique for classifying three-dimensional representations of lizard species samples. Such an approach facilitates taxonomic identification work for professionals in the field and provides a tool adaptable for integration into mobile data recording equipment, such as smartphones, and benefiting from more morphological features extracted from three-dimensional samples instead of two-dimensional images.",2025,10.3389/frai.2025.1524380
SPEMix: a lightweight method via superclass pseudo-label and efficient mixup for echocardiogram view classification,"IntroductionIn clinical, the echocardiogram is the most widely used for diagnosing heart diseases. Different heart diseases are diagnosed based on different views of the echocardiogram images, so efficient echocardiogram view classification can help cardiologists diagnose heart disease rapidly. Echocardiogram view classification is mainly divided into supervised and semi-supervised methods. The supervised echocardiogram view classification methods have worse generalization performance due to the difficulty of labeling echocardiographic images, while the semi-supervised echocardiogram view classification can achieve acceptable results via a little labeled data. However, the current semi-supervised echocardiogram view classification faces challenges of declining accuracy due to out-of-distribution data and is constrained by complex model structures in clinical application.MethodsTo deal with the above challenges, we proposed a novel open-set semi-supervised method for echocardiogram view classification, SPEMix, which can improve performance and generalization by leveraging out-of-distribution unlabeled data. Our SPEMix consists of two core blocks, DAMix Block and SP Block. DAMix Block can generate a mixed mask that focuses on the valuable regions of echocardiograms at the pixel level to generate high-quality augmented echocardiograms for unlabeled data, improving classification accuracy. SP Block can generate a superclass pseudo-label of unlabeled data from the perspective of the superclass probability distribution, improving the classification generalization by leveraging the superclass pseudolabel.ResultsWe also evaluate the generalization of our method on the Unity dataset and the CAMUS dataset. The lightweight model trained with SPEMix can achieve the best classification performance on the publicly available TMED2 dataset.DiscussionFor the first time, we applied the lightweight model to the echocardiogram view classification, which can solve the limits of the clinical application due to the complex model architecture and help cardiologists diagnose heart diseases more efficiently.",2025,10.3389/frai.2024.1467218
Predicting ward transfer mortality with machine learning,"In order to address a long standing challenge for internal medicine physicians we developed artificial intelligence (AI) models to identify patients at risk of increased mortality. After querying 2,425 records of patients transferred from non-intensive care units to intensive care units from the Veteran Affairs Corporate Data Warehouse (CDW), we created two datasets. The former used 22 independent variables that included “Length of Hospital Stay” and “Days to Intensive Care Transfer,” and the latter lacked these two variables. Since these two variables are unknown at the time of admission, the second set is more clinically relevant. We trained 16 machine learning models using both datasets. The best-performing models were fine-tuned and evaluated. The LightGBM model achieved the best results for both datasets. The model trained with 22 variables achieved a Receiver Operating Characteristics Curve-Area Under the Curve (ROC-AUC) of 0.89 and an accuracy of 0.72, with a sensitivity of 0.97 and a specificity of 0.68. The model trained with 20 variables achieved a ROC-AUC of 0.86 and an accuracy of 0.71, with a sensitivity of 0.94 and a specificity of 0.67. The top features for the former model included “Total length of Stay,” “Admit to ICU Transfer Days,” and “Lymphocyte Next Lab Value.” For the latter model, the top features included “Lymphocyte First Lab Value,” “Hemoglobin First Lab Value,” and “Hemoglobin Next Lab Value.” Our clinically relevant predictive mortality model can assist providers in optimizing resource utilization when managing large caseloads, particularly during shift changes.",2023,10.3389/frai.2023.1191320
Application of artificial intelligence techniques for the profiling of visitors to tourist destinations,"Tourism in Peru represents an opportunity for local development; however, there is limited understanding of visitor profiles. The aim of this study was to characterize tourists using machine learning techniques in order to identify distinct segments that can inform planning and promotional strategies for the Alto Amazonas destination. The research followed the CRISP-DM methodology for data analysis, based on surveys administered to 882 visitors. The data were processed using the clustering algorithms K-Means, DBSCAN, HDBSCAN, and Agglomerative, with Principal Component Analysis applied beforehand for dimensionality reduction. The results showed that the Agglomerative Clustering model achieved the best performance in internal validation metrics, allowing for the identification of five distinct visitor profiles. These segments provide valuable insights for the design of more inclusive and personalized tourism products. In conclusion, the study demonstrates the value of machine learning as a tool for tourism segmentation, offering empirical evidence that can strengthen the management of emerging destinations such as Alto Amazonas. The practical contribution of this study lies in providing strategic information that enables destination managers to tailor services and experiences to the characteristics of each segment, thereby optimizing visitor satisfaction and strengthening the destination’s competitiveness.",2025,10.3389/frai.2025.1632415
Limiting medical certainties? Funding challenges for German and comparable public healthcare systems due to AI prediction and how to address them,"Current technological and medical advances lend substantial momentum to efforts to attain new medical certainties. Artificial Intelligence can enable unprecedented precision and capabilities in forecasting the health conditions of individuals. But, as we lay out, this novel access to medical information threatens to exacerbate adverse selection in the health insurance market. We conduct an interdisciplinary conceptual analysis to study how this risk might be averted, considering legal, ethical, and economic angles. We ask whether it is viable and effective to ban or limit AI and its medical use as well as to limit medical certainties and find that neither of these limitation-based approaches provides an entirely sufficient resolution. Hence, we argue that this challenge must not be neglected in future discussions regarding medical applications of AI forecasting, that it should be addressed on a structural level and we encourage further research on the topic.",2022,10.3389/frai.2022.913093
Clinical entity-aware domain adaptation in low resource setting for inflammatory bowel disease,"The digitization of healthcare records has revolutionized medical research and patient care, with electronic health records (EHRs) containing a wealth of structured and unstructured data. Extracting valuable information from unstructured clinical text presents a significant challenge, necessitating automated tools for efficient data mining. Natural language processing (NLP) methods have been pivotal in this endeavor, aiming to extract crucial clinical concepts embedded within free-form text. Our research addresses the imperative for robust biomedical entity extraction, focusing specifically on inflammatory bowel disease (IBD). Leveraging novel domain-specific pre-training and entity-aware masking strategies with contrastive learning, we fine-tune and adapt a general language model to be better adapted to IBD-related information extraction scenarios. Our named entity recognition (NER) tool streamlines the retrieval process, supporting annotation, correction, and visualization functionalities. In summary, we developed a comprehensive pipeline for clinical Dutch NER encompassing an efficient domain adaptation strategy with domain-aware masking and model fine-tuning enhancements, and an end-to-end entity extraction tool, significantly advancing medical record curation and clinical workflows.",2025,10.3389/frai.2024.1450477
Forecasting Quoted Depth With the Limit Order Book,"Liquidity plays a vital role in the financial markets, affecting a myriad of factors including stock prices, returns, and risk. In the stock market, liquidity is usually measured through the order book, which captures the orders placed by traders to buy and sell stocks at different price points. The introduction of electronic trading systems in recent years made the deeper layers of the order book more accessible to traders and thus of greater interest to researchers. This paper examines the efficacy of leveraging the deeper layers of the order book when forecasting quoted depth—a measure of liquidity—on a per-minute basis. Using Deep Feed Forward Neural Networks, we show that the deeper layers do provide additional information compared to the upper layers alone.",2021,10.3389/frai.2021.667780
"A methodology for planning, implementation and evaluation of skills intelligence management – results of a design science project in technology organisations","IntroductionThe evolving labour market requirements amidst digital transformation necessitate robust skills intelligence for informed decision-making and adaptability. Novel technologies such as Big Data, Machine Learning, and Artificial Intelligence have significant potential for enhancing skills intelligence.MethodsThis study bridges the gap between theory and practice by designing a novel software artefact for skills intelligence management. With its systematic framework for identifying skills intelligence elements, an assessment instrument, and an implementation methodology, the artefact ensures a thorough approach to skills intelligence management.ResultsThe artefact was demonstrated in 11 organisations. Feedback collected from interviews, focus group sessions, and observations (N = 19) indicated that the artefact is a feasible starting point for implementing or systematising skills intelligence management. Participants suggested improvements but concurred that the systematic approach enhances skills intelligence data collection and quality.DiscussionThe study shows that the artefact facilitates the application of advanced technologies in skills intelligence management. Additionally, it contributes a set of principles for effective skills intelligence management, fostering a broader conversation on this critical topic. Participants’ feedback underscores the artefact’s potential and provides a basis for further refinement and application in diverse organisational contexts.",2024,10.3389/frai.2024.1424924
SkyMap: a generative graph model for GNN benchmarking,"Graph Neural Networks (GNNs) have gained considerable attention in recent years. Despite the surge in innovative GNN architecture designs, research heavily relies on the same 5-10 benchmark datasets for validation. To address this limitation, several generative graph models like ALBTER or GenCAT have emerged, aiming to fix this problem with synthetic graph datasets. However, these models often struggle to mirror the GNN performance of the original graphs. In this work, we present SkyMap, a generative model for labeled attributed graphs with a fine-grained control over graph topology and feature distribution parameters. We show that our model is able to consistently replicate the learnability of graphs on graph convolutional, attention, and isomorphism networks better (64% lower Wasserstein distance) than ALBTER and GenCAT. Further, we prove that by randomly sampling the input parameters of SkyMap, graph dataset constellations can be created that cover a large parametric space, hence making a significant stride in crafting synthetic datasets tailored for GNN evaluation and benchmarking, as we illustrate through a performance comparison between a GNN and a multilayer perceptron.",2024,10.3389/frai.2024.1427534
A tale of two lexica: Investigating computational pressures on word representation with neural networks,"IntroductionThe notion of a single localized store of word representations has become increasingly less plausible as evidence has accumulated for the widely distributed neural representation of wordform grounded in motor, perceptual, and conceptual processes. Here, we attempt to combine machine learning methods and neurobiological frameworks to propose a computational model of brain systems potentially responsible for wordform representation. We tested the hypothesis that the functional specialization of word representation in the brain is driven partly by computational optimization. This hypothesis directly addresses the unique problem of mapping sound and articulation vs. mapping sound and meaning.ResultsWe found that artificial neural networks trained on the mapping between sound and articulation performed poorly in recognizing the mapping between sound and meaning and vice versa. Moreover, a network trained on both tasks simultaneously could not discover the features required for efficient mapping between sound and higher-level cognitive states compared to the other two models. Furthermore, these networks developed internal representations reflecting specialized task-optimized functions without explicit training.DiscussionTogether, these findings demonstrate that different task-directed representations lead to more focused responses and better performance of a machine or algorithm and, hypothetically, the brain. Thus, we imply that the functional specialization of word representation mirrors a computational optimization strategy given the nature of the tasks that the human brain faces.",2023,10.3389/frai.2023.1062230
A cognitive modeling approach to learning and using reference biases in language,"During real-time language processing, people rely on linguistic and non-linguistic biases to anticipate upcoming linguistic input. One of these linguistic biases is known as the implicit causality bias, wherein language users anticipate that certain entities will be rementioned in the discourse based on the entity's particular role in an expressed causal event. For example, when language users encounter a sentence like “Elizabeth congratulated Tina…” during real-time language processing, they seemingly anticipate that the discourse will continue about Tina, the object referent, rather than Elizabeth, the subject referent. However, it is often unclear how these reference biases are acquired and how exactly they get used during real-time language processing. In order to investigate these questions, we developed a reference learning model within the PRIMs cognitive architecture that simulated the process of predicting upcoming discourse referents and their linguistic forms. Crucially, across the linguistic input the model was presented with, there were asymmetries with respect to how the discourse continued. By utilizing the learning mechanisms of the PRIMs architecture, the model was able to optimize its predictions, ultimately leading to biased model behavior. More specifically, following subject-biased implicit causality verbs the model was more likely to predict that the discourse would continue about the subject referent, whereas following object-biased implicit causality verbs the model was more likely to predict that the discourse would continue about the object referent. In a similar fashion, the model was more likely to predict that subject referent continuations would be in the form of a pronoun, whereas object referent continuations would be in the form of a proper name. These learned biases were also shown to generalize to novel contexts in which either the verb or the subject and object referents were new. The results of the present study demonstrate that seemingly complex linguistic behavior can be explained by cognitively plausible domain-general learning mechanisms. This study has implications for psycholinguistic accounts of predictive language processing and language learning, as well as for theories of implicit causality and reference processing.",2022,10.3389/frai.2022.933504
Investigation of deep learning approaches for automated damage diagnostics in fiber metal laminates using Detectron2 and SAM,"The impact damage is one of the major causes of structural failures in Fiber Metal Laminate (FML) plates, which are widely used in the aerospace and automotive industries due to their superior mechanical properties. Accurate detection, segmentation, and characterization of these damages are crucial for improved safety and reduced maintenance costs. This study proposes an automated approach to detect, segment, reconstruct, and characterize the damages in FML plates using state-of-the-art deep learning models: the Segment Anything Model (SAM) and the Mask Region-based Convolutional Neural Network (Mask R-CNN) implemented by the Detectron2 framework. A domain-adapted supervised learning process was applied to the X-ray CT dataset of damaged FML plates impacted with energies of 5J, 7.5J, 10J, and 12.5J. Mask R-CNN significantly outperformed SAM across all key performance metrics while offering around 8 times faster training and 80 times faster inference. Mask R-CNN also proved to have superior explainability for end-users. The lack of absolute ground truth data severely limits the scope of an absolute quantitative comparison, therefore highlighting the need for further studies. This study not only contributes to the area of damage diagnostics in composite materials but also provides insights into the comparative performance and explainability of advanced deep learning models, paving the way for applications in industrial inspection and quality assurance.",2025,10.3389/frai.2025.1599345
Man vs. machine: can AI outperform ESL student translations?,"This study compares the quality of English-to-Arabic translations produced by Google Translate (GT) with those generated by student translators. Despite advancements in neural machine translation technology, educators often remain skeptical about the reliability of AI tools like GT and often discourage their use. To investigate this perception, 20 Saudi university students majoring in English and Translation produced human translations in Arabic. These student-generated translations, along with their GT equivalents, were rated by 22 professors with experience in language-related fields. The analysis revealed a significant preference for GT translations over those produced by students, suggesting that GT’s quality may exceed that of student translators. Interestingly, while GT translations were consistently rated higher, instructors often misattributed the better translations to students and the poorer ones to GT. This reveals a strong perceptual bias against AI-generated translations. The findings support the inclusion of AI-assisted translation tools in translation training. Incorporating these tools will help students prepare for a job market where AI is playing an increasingly important role. At the same time, educators should adopt strategies incorporating AI tools without sacrificing the development of students’ core translation skills.",2025,10.3389/frai.2025.1624754
Artificial Intelligence and Telehealth may Provide Early Warning of Epidemics,"The COVID-19 pandemic produced a very sudden and serious impact on public health around the world, greatly adding to the burden of overloaded professionals and national medical systems. Recent medical research has demonstrated the value of using online systems to predict emerging spatial distributions of transmittable diseases. Concerned internet users often resort to online sources in an effort to explain their medical symptoms. This raises the prospect that incidence of COVID-19 may be tracked online by search queries and social media posts analyzed by advanced methods in data science, such as Artificial Intelligence. Online queries can provide early warning of an impending epidemic, which is valuable information needed to support planning timely interventions. Identification of the location of clusters geographically helps to support containment measures by providing information for decision-making and modeling.",2021,10.3389/frai.2021.556848
The Perils of Misspecified Priors and Optional Stopping in Multi-Armed Bandits,"The connection between optimal stopping times of American Options and multi-armed bandits is the subject of active research. This article investigates the effects of optional stopping in a particular class of multi-armed bandit experiments, which randomly allocates observations to arms proportional to the Bayesian posterior probability that each arm is optimal (Thompson sampling). The interplay between optional stopping and prior mismatch is examined. We propose a novel partitioning of regret into peri/post testing. We further show a strong dependence of the parameters of interest on the assumed prior probability density.",2021,10.3389/frai.2021.715690
Implementing federated learning for privacy-preserving emotion detection in educational environments,"Emotion detection has become an essential tool in educational settings, where understanding and responding to students’ emotions is crucial to improving their engagement, academic performance, and emotional well-being. However, traditional emotion detection systems, such as DeepFace, and hybrid transformer-based models face significant data privacy and scalability limitations. These models rely on transferring sensitive data to central servers, compromising student confidentiality and making deployment in large or diverse populations difficult. In this work, we propose a federated learning-based model designed to detect emotions in educational settings, preserving data privacy by processing them locally on students’ devices (smartphones, tablets, and laptops). The model was integrated into the Moodle platform, allowing its evaluation in a conventional educational environment. Advanced anonymization and preprocessing techniques were implemented to ensure the security of emotional data and optimize its quality. The results demonstrate that the proposed model achieves a precision of 87%, a recall of 85%, and an F1-score of 86%, maintaining its performance under adverse conditions, such as low lighting and ambient noise. In addition, a 15% increase in academic participation and a 12% improvement in the average academic performance of students were observed, highlighting the system’s positive impact on educational dynamics. This innovative method combines privacy, scalability, and performance, positioning itself as a viable and sustainable solution for emotion detection in contemporary educational environments.",2025,10.3389/frai.2025.1644844
COVID-FACT: A Fully-Automated Capsule Network-Based Framework for Identification of COVID-19 Cases from Chest CT Scans,"The newly discovered Coronavirus Disease 2019 (COVID-19) has been globally spreading and causing hundreds of thousands of deaths around the world as of its first emergence in late 2019. The rapid outbreak of this disease has overwhelmed health care infrastructures and arises the need to allocate medical equipment and resources more efficiently. The early diagnosis of this disease will lead to the rapid separation of COVID-19 and non-COVID cases, which will be helpful for health care authorities to optimize resource allocation plans and early prevention of the disease. In this regard, a growing number of studies are investigating the capability of deep learning for early diagnosis of COVID-19. Computed tomography (CT) scans have shown distinctive features and higher sensitivity compared to other diagnostic tests, in particular the current gold standard, i.e., the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Current deep learning-based algorithms are mainly developed based on Convolutional Neural Networks (CNNs) to identify COVID-19 pneumonia cases. CNNs, however, require extensive data augmentation and large datasets to identify detailed spatial relations between image instances. Furthermore, existing algorithms utilizing CT scans, either extend slice-level predictions to patient-level ones using a simple thresholding mechanism or rely on a sophisticated infection segmentation to identify the disease. In this paper, we propose a two-stage fully automated CT-based framework for identification of COVID-19 positive cases referred to as the “COVID-FACT”. COVID-FACT utilizes Capsule Networks, as its main building blocks and is, therefore, capable of capturing spatial information. In particular, to make the proposed COVID-FACT independent from sophisticated segmentations of the area of infection, slices demonstrating infection are detected at the first stage and the second stage is responsible for classifying patients into COVID and non-COVID cases. COVID-FACT detects slices with infection, and identifies positive COVID-19 cases using an in-house CT scan dataset, containing COVID-19, community acquired pneumonia, and normal cases. Based on our experiments, COVID-FACT achieves an accuracy of 90.82%, a sensitivity of 94.55%, a specificity of 86.04%, and an Area Under the Curve (AUC) of 0.98, while depending on far less supervision and annotation, in comparison to its counterparts.",2021,10.3389/frai.2021.598932
Structuring ontologies from natural language for collaborative scenario modeling in agri-food systems,"Prospective studies require discussing and collaborating with the stakeholders to create scenarios of the possible evolution of the studied value-chain. However, stakeholders do not always use the same words when referring to one idea. Constructing an ontology and homogenizing vocabularies is thus crucial to identify key variables, which serve in the construction of the needed scenarios. Nevertheless, it is a very complex and time-consuming task. In this paper we present the method we used to manually build ontologies adapted to the needs of two complementary system-analysis models (namely the “Godet” and the “MyChoice” models), starting from interviews of the agri-food system's stakeholders. The objective of the paper is to explore whether and how prospective studies may have to gain from complementing the methodologies used (here Godet) with formal approaches from other disciplines, such as knowledge engineering (here MyChoice), which is usually not the case currently.",2022,10.3389/frai.2022.1056989
"Predictors of mortality among neonates in Lusaka, Zambia: a comparative analysis of machine learning and traditional survival analysis techniques","Introduction
                    Neonatal mortality remains a critical global health issue, with 2.3 million deaths in 2022. Sub-Saharan Africa bears 57% of under five deaths despite only 30% of global births, with Zambia ranking fourth highest in terms of neonatal mortality among neighboring countries. While traditional survival analysis has identified neonatal mortality risk factors, machine learning-based prediction remains underexplored. This study aimed to identify factors associated with neonatal mortality and compare the predictive performance of traditional survival analysis and machine learning models among neonates in Lusaka, Zambia (January2018–September 2019).
                  
                  
                    Methods
                    Demographic and clinical data from 1,018 neonates were analyzed using seven models: Weibull, Lasso, Ridge, Elastic Net (regularized Cox), Random Survival Forests, DeepSurv neural networks and Gradient Boosting Machines. Model performance was evaluated using nested cross-validation with five outer folds and three inner folds for hyperparameter tuning. Predictive accuracy was assessed using the concordance index, time dependent area under the curve at 7, 14, and 28 days, brier scores, and calibration plots. Kaplan–Meier plots illustrated survival probabilities over time.
                  
                  
                    Results
                    Of the 1,018 neonates, 757 (74.3%) died. Hypoxic-ischemic encephalopathy (TR = 0.71, 95% CI: 0.63-0.81) was associated with reduced survival, while higher birthweight was protective (TR = 1.88, 95% CI: 1.60–2.20). Sepsis demonstrated a paradoxical association with longer survival (TR = 1.16, 95% CI: 1.04–1.30), which persisted in sensitivity analyses. Among predictive models, the Random Survival Forests achieved the highest discrimination (C-index = 0.731) and consistently low Brier scores, outperforming Weibull (C-index = 0.622) and penalized Cox models (≈ 0.620). Gradient Boosting Machines were most miscalibrated, and DeepSurv showed low discrimination (C-index = 0.553). Feature importance analysis from Random Survival Forest identified birth weight as the dominant predictor, followed by sex, sepsis, and necrotizing enterocolitis.
                  
                  
                    Discussion
                    While traditional Weibull models remain valuable for interpretability, machine learning approaches provide enhanced predictive accuracy. Hybrid modeling strategies may improve early risk identification and inform neonatal care in resource-limited settings.",2025,10.3389/frai.2025.1606245
Artificial intelligence for algorithmic trading digital assets: evidence from the Counter-Strike 2 skin market,"Introduction
                    The Counter-Strike 2 skin market has developed into a multi-billion-dollar digital asset ecosystem, characterized by high volatility, low liquidity, and pricing inefficiencies that differ substantially from traditional financial markets. Despite the growing economic relevance of virtual items, no previous study has systematically examined the use of artificial intelligence for skin trading.
                  
                  
                    Methods
                    This work designs and evaluates an automated trading system that applies deep learning models, specifically Long Short-Term Memory networks and Neural Hierarchical Interpolation for Time Series, to forecast skin prices and guide trading decisions. A dataset of 12,000 unique skins from the Steam Market, covering the period from May 2024 to April 2025, was collected using the CSGOskins.gg application programming interface. To reflect real market conditions, the trading strategy incorporated the Steam Market restrictions of a seven-day minimum holding period and a ten percent transaction cost, and was benchmarked against a traditional buy-and-hold strategy. Backtesting was performed multiple time horizons of two, three, and 6 months. Portfolio selection was based on risk and return criteria, including a Sharpe ratio greater than one, a Sortino ratio greater than two, and a return on investment above five percent.
                  
                  
                    Results
                    Artificial intelligence consistently outperforms buy-and-hold, particularly in smaller, more concentrated portfolios and over longer time horizons. For example, in 6-month simulations, artificial intelligence portfolios achieved returns approaching 20%, compared to 5% to 10% for buy-and-hold, with excess returns as high as 75% in small portfolios. Larger portfolios reduced absolute returns but improved risk-adjusted performance, confirming that diversification enhances stability while diluting raw profitability. Analysis of portfolio composition by rarity further revealed that artificial intelligence favors moderately rare and liquid skins such as Mil-Spec, resembling mid-cap equity investment strategies, while buy-and-hold accumulates rarer skins, analogous to small-cap holdings that rely on scarcity premiums.
                  
                  
                    Discussion
                    These findings highlight that even in virtual goods markets, the trade-offs between return, risk, and diversification reflect established principles of modern portfolio theory. The study demonstrates both the feasibility and the potential of artificial intelligence-based trading systems in the Counter-Strike 2 skin economy, contributing methodological advances and practical insights for participants in this emerging digital asset market.",2025,10.3389/frai.2025.1702924
Towards Effective Patient Simulators,"In this paper we give an overview of the field of patient simulators and provide qualitative and quantitative comparison of different modeling and simulation approaches. Simulators can be used to train human caregivers but also to develop and optimize algorithms for clinical decision support applications and test and validate interventions. In this paper we introduce three novel patient simulators with different levels of representational accuracy: HeartPole, a simplistic transparent rule-based system, GraphSim, a graph-based model trained on intensive care data, and Auto-ALS—an adjusted version of an educational software package used for training junior healthcare professionals. We provide a qualitative and quantitative comparison of the previously existing as well as proposed simulators.",2021,10.3389/frai.2021.798659
An explainable dual-modal diagnostic model for coronary artery disease: a feature-gated approach using tongue and facial image features,"Background and objective
                    Coronary artery disease (CAD) is a major threat to human health, and early non-invasive identification is crucial for its prevention and management. However, current diagnostic methods still face limitations in terms of non-invasiveness, cost, and accessibility. Tongue and facial features have been recognized as closely associated with CAD. To address these challenges, this study proposes a dual-modal diagnostic model incorporating a feature-wise gating mechanism to enable intelligent, non-invasive CAD detection based on tongue and facial images.
                  
                  
                    Methods
                    A total of 936 participants were enrolled in this study, and standardized tongue and facial images were collected from each subject. Image segmentation was performed using MedSAM, followed by deep semantic feature extraction using the MDFA-Swin network. Traditional color and texture features were also incorporated. A feature-guided gating mechanism was developed to enable personalized multimodal fusion of tongue and facial features. The diagnostic performance of the proposed model was evaluated on an independent external test set. In addition, SHAP (SHapley Additive Explanations) analysis were conducted to enhance model interpretability.
                  
                  
                    Results
                    The proposed CAD diagnostic model based on fused multidimensional tongue and facial features (TF_FGC) demonstrated excellent performance in internal validation (AUC = 0.945, Accuracy = 0.872) and maintained good generalizability on the external test set (AUC = 0.896, Accuracy = 0.825). The SHAP analysis identified T_contrast, T_RGB_R, T_homogeneity, F_homogeneity, F_RGB_B, F_RGB_G, F_RGB_R, and F_contrast as the most influential features driving model predictions.
                  
                  
                    Conclusion
                    The proposed dual-branch fusion model demonstrates high diagnostic accuracy, strong interpretability, and good generalizability. By integrating traditional color and texture features with deep semantic representations, this approach offers a promising solution for non-invasive and intelligent screening of CAD, providing a novel perspective and practical support for clinical decision-making.",2025,10.3389/frai.2025.1662577
AI in humanitarian healthcare: a game changer for crisis response,"Artificial Intelligence (AI) is transforming humanitarian healthcare by providing innovative solutions to critical challenges in crisis response. This review explores peer-reviewed literature and case reports from 2001 to 2025, retrieved from PubMed, Scopus, and Google Scholar, using targeted keywords. Results indicate that AI enhances disaster prediction, disease surveillance, resource allocation, and mental health support through tools such as machine learning, natural language processing, robotics, and blockchain. Prominent applications include AI-powered early warning systems, chatbots for displaced populations, telemedicine platforms, and automated supply chain logistics. Ethical concerns such as data privacy, bias, and access inequities remain critical to responsible deployment. By uniting governments, NGOs, and technology providers, AI serves as a powerful tool to strengthen humanitarian healthcare systems, enhancing resilience and efficiency while ensuring better outcomes for vulnerable populations during crises.",2025,10.3389/frai.2025.1627773
Whale-optimized LSTM networks for enhanced automatic text summarization,"Automatic text summarization is a cornerstone of natural language processing, yet existing methods often struggle to maintain contextual integrity and capture nuanced sentence relationships. Introducing the Optimized Auto Encoded Long Short-Term Memory Network (OAELSTM), enhanced by the Whale Optimization Algorithm (WOA), offers a novel approach to this challenge. Existing summarization models frequently produce summaries that are either too generic or disjointed, failing to preserve the essential content. The OAELSTM model, integrating deep LSTM layers and autoencoder mechanisms, focuses on extracting key phrases and concepts, ensuring that summaries are both informative and coherent. WOA fine-tunes the model’s parameters, enhancing its precision and efficiency. Evaluation on datasets like CNN/Daily Mail and Gigaword demonstrates the model’s superiority over existing approaches. It achieves a ROUGE Score of 0.456, an accuracy rate of 84.47%, and a specificity score of 0.3244, all within an efficient processing time of 4,341.95 s.",2024,10.3389/frai.2024.1399168
The application of explainable artificial intelligence methods to models for automatic creativity assessment,"ObjectiveThe study is devoted to comparing various models based on Artificial Intelligence to determine the level of creativity based on drawings performed using the Urban test, as well as analyzing the results of applying explainable artificial intelligence methods to a trained model to identify the most relevant features in drawings that influence the model’s prediction.MethodsThe dataset is represented by a set of 1,823 scanned forms of drawings of participants performed according to the Urban test. The test results of each participant were assessed by an expert. Preprocessed images were used for fine-tuning pre-trained models such as MobileNet, ResNet18, AlexNet, DenseNet, ResNext, EfficientNet, ViT with additional linear layers to predict the participant’s score. Visualization of the areas that are of greatest importance from the point of view of the model was carried out using the Gradient-weighted Class Activation Mapping (Grad-CAM) method.ResultsTrained models based on MobileNet showed the highest prediction accuracy rate of 76%. The results of the application of explainable artificial intelligence demonstrated areas of interest that correlated with the criteria for expert assessment according to the Urban test. Analysis of erroneous predictions of the model in terms of interpretation of areas of interest made it possible to clarify the features of the drawing on which the model relies, contrary to the expert.ConclusionThe study demonstrated the possibility of using neural network methods for automated diagnosis of the level of creativity according to the Urban test based on the respondents’ drawings. The application of explainable artificial intelligence methods to the trained model demonstrated the compliance of the identified activation zones with the rules of expert assessment according to the Urban test.",2024,10.3389/frai.2024.1310518
"AI for scientific integrity: detecting ethical breaches, errors, and misconduct in manuscripts","The use of Generative AI (GenAI) in scientific writing has grown rapidly, offering tools for manuscript drafting, literature summarization, and data analysis. However, these benefits are accompanied by risks, including undisclosed AI authorship, manipulated content, and the emergence of papermills. This perspective examines two key strategies for maintaining research integrity in the GenAI era: (1) detecting unethical or inappropriate use of GenAI in scientific manuscripts and (2) using AI tools to identify mistakes in scientific literature, such as statistical errors, image manipulation, and incorrect citations. We reviewed the capabilities and limitations of existing AI detectors designed to differentiate human-written (HWT) from machine-generated text (MGT), highlighting performance gaps, genre sensitivity, and vulnerability to adversarial attacks. We also investigate emerging AI-powered systems aimed at identifying errors in published research, including tools for statistical verification, citation validation, and image manipulation detection. Additionally, we discuss recent publishing industry initiatives to combat AI-driven papermills. Our investigation shows that these developments are not yet sufficiently accurate or reliable yet for use in academic assessment, they mark an early but promising steps toward scalable, AI-assisted quality control in scholarly publishing.",2025,10.3389/frai.2025.1644098
Navigating STEM careers with AI mentors: a new IDP journey,"IntroductionMentoring is crucial to the success of STEM higher education. The Individual Development Plan (IDP) is a common career development tool in STEM graduate education that facilitates structured mentor-mentee interactions and goal setting. This study examined the integration of AI mentors into the myIDP framework to provide real-time support and career insights.MethodsUsing Google Gemini as an AI mentor, this study developed and assessed AI prompts within the myIDP framework. Eighteen STEM graduate students, primarily from underrepresented groups, were trained to engage with the AI mentor. Their interactions, feedback, and comments were analyzed using sentiment and thematic analysis.ResultsParticipants reported positive experiences with AI mentors, noting benefits, such as immediate responses, up-to-date information, access to multiple AI mentors, enhanced ownership of career development, and time savings. However, concerns about misinformation, bias, privacy, equity, and algorithmic influences have also been raised. The study identified two hybrid human-AI mentoring models—Sequential Integration and Concurrent Collaboration—that combine the unique strengths of human and AI mentors to enhance the mentoring process.DiscussionThis study underscores the potential of AI mentors to enhance IDP practices by providing timely feedback and career information, thereby empowering students in their STEM career development. The proposed human-AI mentoring models show promise in supporting underrepresented minorities, potentially broadening participation in STEM fields.",2024,10.3389/frai.2024.1461137
GAAPO: genetic algorithmic applied to prompt optimization,"Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, with their performance heavily dependent on the quality of input prompts. While prompt engineering has proven effective, it typically relies on manual adjustments, making it time-consuming and potentially suboptimal. This paper introduces GAAPO (Genetic Algorithm Applied to Prompt Optimization), a novel hybrid optimization framework that leverages genetic algorithm principles to evolve prompts through successive generations. Unlike traditional genetic approaches that rely solely on mutation and crossover operations, GAAPO integrates multiple specialized prompt generation strategies within its evolutionary framework. Through extensive experimentation on diverse datasets including ETHOS, MMLU-Pro, and GPQA, our analysis reveals several important points for the future development of automatic prompt optimization methods: importance of the tradeoff between the population size and the number of generations, effect of selection methods on stability results, capacity of different LLMs and especially reasoning models to be able to automatically generate prompts from similar queries… Moreover, we decided to use limited size datasets extracted from the original databases to ensure real life applications of our prompt optimization strategy. Finally, we provide insights into the relative effectiveness of different prompt generation strategies and their evolution across optimization phases. These findings contribute to both the theoretical understanding of prompt optimization and practical applications in improving LLM performance.",2025,10.3389/frai.2025.1613007
Image Completion in Embedded Space Using Multistage Tensor Ring Decomposition,"Tensor Completion is an important problem in big data processing. Usually, data acquired from different aspects of a multimodal phenomenon or different sensors are incomplete due to different reasons such as noise, low sampling rate or human mistake. In this situation, recovering the missing or uncertain elements of the incomplete dataset is an important step for efficient data processing. In this paper, a new completion approach using Tensor Ring (TR) decomposition in the embedded space has been proposed. In the proposed approach, the incomplete data tensor is first transformed into a higher order tensor using the block Hankelization method. Then the higher order tensor is completed using TR decomposition with rank incremental and multistage strategy. Simulation results show the effectiveness of the proposed approach compared to the state of the art completion algorithms, especially for very high missing ratios and noisy cases.",2021,10.3389/frai.2021.687176
Toward the appropriate interpretation of Alphafold2,"In life science, protein is an essential building block for life forms and a crucial catalyst for metabolic reactions in organisms. The structures of protein depend on an infinity of amino acid residues' complex combinations determined by gene expression. Predicting protein folding structures has been a tedious problem in the past seven decades but, due to robust development of artificial intelligence, astonishing progress has been made. Alphafold2, whose key component is Evoformer, is a typical and successful example of such progress. This article attempts to not only isolate and dissect every detail of Evoformer, but also raise some ideas for potential improvement.",2023,10.3389/frai.2023.1149748
Machine learning algorithms in microbial classification: a comparative analysis,"This research paper presents an overview of contemporary machine learning methodologies and their utilization in the domain of healthcare and the prevention of infectious diseases, specifically focusing on the classification and identification of bacterial species. As deep learning techniques have gained prominence in the healthcare sector, a diverse array of architectural models has emerged. Through a comprehensive review of pertinent literature, multiple studies employing machine learning algorithms in the context of microbial diagnosis and classification are examined. Each investigation entails a tabulated presentation of data, encompassing details about the training and validation datasets, specifications of the machine learning and deep learning techniques employed, as well as the evaluation metrics utilized to gauge algorithmic performance. Notably, Convolutional Neural Networks have been the predominant selection for image classification tasks by machine learning practitioners over the last decade. This preference stems from their ability to autonomously extract pertinent and distinguishing features with minimal human intervention. A range of CNN architectures have been developed and effectively applied in the realm of image classification. However, addressing the considerable data requirements of deep learning, recent advancements encompass the application of pre-trained models using transfer learning for the identification of microbial entities. This method involves repurposing the knowledge gleaned from solving alternate image classification challenges to accurately classify microbial images. Consequently, the necessity for extensive and varied training data is significantly mitigated. This study undertakes a comparative assessment of various popular pre-trained CNN architectures for the classification of bacteria. The dataset employed is composed of approximately 660 images, representing 33 bacterial species. To enhance dataset diversity, data augmentation is implemented, followed by evaluation on multiple models including AlexNet, VGGNet, Inception networks, Residual Networks, and Densely Connected Convolutional Networks. The results indicate that the DenseNet-121 architecture yields the optimal performance, achieving a peak accuracy of 99.08%, precision of 99.06%, recall of 99.00%, and an F1-score of 98.99%. By demonstrating the proficiency of the DenseNet-121 model on a comparatively modest dataset, this study underscores the viability of transfer learning in the healthcare sector for precise and efficient microbial identification. These findings contribute to the ongoing endeavors aimed at harnessing machine learning techniques to enhance healthcare methodologies and bolster infectious disease prevention practices.",2023,10.3389/frai.2023.1200994
Automated analysis of whole slide digital skin biopsy images,"A rapidly increasing rate of melanoma diagnosis has been noted over the past three decades, and nearly 1 in 4 skin biopsies are diagnosed as melanocytic lesions. The gold standard for diagnosis of melanoma is the histopathological examination by a pathologist to analyze biopsy material at both the cellular and structural levels. A pathologist's diagnosis is often subjective and prone to variability, while deep learning image analysis methods may improve and complement current diagnostic and prognostic capabilities. Mitoses are important entities when reviewing skin biopsy cases as their presence carries prognostic information; thus, their precise detection is an important factor for clinical care. In addition, semantic segmentation of clinically important structures in skin biopsies might help the diagnosis pipeline with an accurate classification. We aim to provide prognostic and diagnostic information on skin biopsy images, including the detection of cellular level entities, segmentation of clinically important tissue structures, and other important factors toward the accurate diagnosis of skin biopsy images. This paper is an overview of our work on analysis of digital whole slide skin biopsy images, including mitotic figure (mitosis) detection, semantic segmentation, diagnosis, and analysis of pathologists' viewing patterns, and with new work on melanocyte detection. Deep learning has been applied to our methods for all the detection, segmentation, and diagnosis work. In our studies, deep learning is proven superior to prior approaches to skin biopsy analysis. Our work on analysis of pathologists' viewing patterns is the only such work in the skin biopsy literature. Our work covers the whole spectrum from low-level entities through diagnosis and understanding what pathologists do in performing their diagnoses.",2022,10.3389/frai.2022.1005086
Predicting the risk of depression in older adults with disability using machine learning: an analysis based on CHARLS data,"BackgroundThe advancement of artificial intelligence technologies has opened new avenues for depression prevention and management in older adults with disability (defined by basic or instrumental activities of daily living, BADL/IADL). This study systematically developed machine learning (ML) models to predict depression risk in disabled elderly individuals using longitudinal data from the China Health and Retirement Longitudinal Study (CHARLS), providing a potentially generalizable tool for early screening.MethodsThis study utilized longitudinal data from the CHARLS 2011–2015 cohort. A three-stage serial consensus approach feature selection framework (LASSO, Elastic Net, and Boruta) was employed to identify 21 robust predictors from 74 candidate variables. Ten ML algorithms were evaluated: LR, HistGBM, MLP, XGBoost, bagging, DT, LightGBM, RF, SVM, and CatBoost. Temporal external validation was performed using an independent 2018–2020 cohort to assess model generalizability. Performance was comprehensively evaluated using accuracy, AUC, F1-score, precision, and recall metrics. The SHAP framework was employed to interpret feature contribution mechanisms.ResultsResults demonstrated that the HistGBM model achieved optimal overall performance on the testing sets (AUC = 0.779, F1-score = 0.735, accuracy = 0.713), with only an 8.5% AUC difference between training and testing sets and a 10% difference between external validation and testing sets, indicating temporal stability. SHAP interpretability analysis revealed that sleep time (mean SHAP value = 0.344) in the health behavior domain and life satisfaction (0.339) and episodic memory (0.220) in the subjective perception domain contributed more significantly to prediction than traditional biomedical indicators.ConclusionThis study developed an AI-based tool for depression risk assessment in older adults with disability through a multi-stage feature selection process and a temporal external validation framework. These findings provide a practical screening instrument and a methodological reference for implementing AI technologies in geriatric mental health applications, thereby facilitating clinical translation of predictive analytics in this field.",2025,10.3389/frai.2025.1624171
Employing Explainable AI to Optimize the Return Target Function of a Loan Portfolio,"In the recent years, data science methods have been developed considerably and have consequently found their way into many business processes in banking and finance. One example is the review and approval process of credit applications where they are employed with the aim to reduce rare but costly credit defaults in portfolios of loans. But there are challenges. Since defaults are rare events, it is—even with machine learning (ML) techniques—difficult to improve prediction accuracy and improvements are often marginal. Furthermore, while from an event prediction point of view, a non-default is the same as a default, from an economic point of view much more relevant to the end user it is not due to the high asymmetry in cost. Last, there are regulatory constraints when it comes to the adoption of advanced ML, hence the call for explainable artificial intelligence (XAI) issued by regulatory bodies like FINMA and BaFin. In our study, we will address these challenges. In particular, based on an exemplary use case, we show how ML methods can be adapted to the specific needs of credit assessment and how, in the case of strongly asymmetric costs of wrong forecasts, it makes sense to optimize not for accuracy but for an economic target function. We showcase this for two simple and ad hoc explainable ML algorithms, finding that in the case of credit approval, surprisingly high rejection rates contribute to maximizing profit.",2021,10.3389/frai.2021.693022
Internet of things driven hybrid neuro-fuzzy deep learning building energy management system for cost and schedule optimization,"Optimizing building energy consumption holds significant untapped potential, particularly in a developing economy such as India. Existing solutions have yet to concentrate on a methodology that is cost-effective, small-scale, precise, and open source data-driven. In response, we have implemented an automated, DL-enabled approach to predict energy consumption with the goal to enable cost and schedule optimization. For two years from December 2021 to December 2023 the energy consumption and twenty seven associated energy parameters was monitored by developing an IoT enabled BEMS. The data collected was preprocessed, cleaned, transformed and used for training a machine learning model. Based on the previous literature, a hybrid DL model was developed using artificial neural networks and fuzzy logic by integrating fuzzy layers in the deep neural architecture. The collected electrical data was used for training, hyper-parameter tuning and testing the hybrid DL model. The proposed model when tested for out-of-sample dataset had comparable results on error and performance metrics as compared to other states of the art models. On deployment in the premises of a university, the BEMS achieved a reduction in the electricity bill of 20% highlighting its effectiveness and efficacy.",2025,10.3389/frai.2025.1544183
Multi-modal texture fusion network for detecting AI-generated images,"With the rapid advancement of AI-generated content, detecting synthetic images has become a critical task in digital forensics and media integrity. In this paper, we propose a novel multi-modal fusion network that leverages complementary texture and content information to improve the detection of AI-generated images. Our approach integrates three input branches: the original RGB image, a local binary pattern (LBP) map to capture micro-texture irregularities, and a gray-level co-occurrence matrix (GLCM) representation to encode statistical texture dependencies. These three streams are processed in parallel through a shared-weight convolutional backbone and subsequently fused at the feature level to enhance discrimination capability. Extensive experiments conducted on benchmark datasets demonstrate that our method outperforms existing single-modality baselines and achieves strong generalization across multiple types of generative models. The proposed fusion framework offers an interpretable and efficient solution for robust and reliable detection of AI-synthesized imagery.",2025,10.3389/frai.2025.1663292
Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work,"Calls for “ethical Artificial Intelligence” are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing “ethical AI” remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work.",2022,10.3389/frai.2022.869114
"Privacy-, linguistic-, and information-preserving synthesis of clinical documentation through generative agents","The widespread adoption of generative agents (GAs) is reshaping the healthcare landscape. Nonetheless, broad utilization is impeded by restricted access to high-quality, interoperable clinical documentation from electronic health records (EHRs) due to persistent legal, ethical, and technical barriers. Synthetic health data generation (SHDG), leveraging pre-trained large language models (LLMs) instantiated as GAs, could offer a practical solution by creating synthetic patient information that mimics genuine EHRs. The use of LLMs, however, is not without issues; significant concerns remain regarding privacy, potential bias propagation, the risk of generating inaccurate or misleading content, and the lack of transparency in how these models make decisions. We therefore propose a privacy-, linguistic-, and information-preserving SHDG protocol that employs multiple context-aware, role-specific GAs. Guided by targeted prompting and authentic EHRs—serving as structural and linguistic templates—role-specific GAs can, in principle, operate collaboratively through multi-turn interactions. We theorized that utilizing GAs in this fashion permits LLMs not only to produce synthetic EHRs that are accurate, consistent, and contextually appropriate, but also to expose the underlying decision-making process. To test this hypothesis, we developed a no-code GA-driven SHDG workflow as a proof of concept, which was implemented within a predefined, multi-layered data science infrastructure (DSI) stack—an integrated ensemble of software and hardware designed to support rapid prototyping and deployment. The DSI stack streamlines implementation for healthcare professionals, improving accessibility, usability, and cybersecurity. To deploy and validate GA-assisted workflows, we implemented a fully automated SHDG evaluation framework—co-developed with GenAI technology—which holistically compares the informational and linguistic features of synthetic, anonymized, and real EHRs at both the document and corpus levels. Our findings highlight that SHDG implemented through GAs offers a scalable, transparent, and reproducible methodology for unlocking the potential of clinical documentation to drive innovation, accelerate research, and advance the development of learning health systems. The source code, synthetic datasets, toolchains and prompts created for this study can be accessed at the GitHub repository: https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/Generative_Agent_based_Data-Synthesis.",2025,10.3389/frai.2025.1644084
Mapping cover crop species in southeastern Michigan using Sentinel-2 satellite data and Google Earth Engine,"Cover crops are a critical agricultural practice that can improve soil quality, enhance crop yields, and reduce nitrogen and phosphorus losses from farms. Yet there is limited understanding of the extent to which cover crops have been adopted across large spatial and temporal scales. Remote sensing offers a low-cost way to monitor cover crop adoption at the field scale and at large spatio-temporal scales. To date, most studies using satellite data have mapped the presence of cover crops, but have not identified specific cover crop species, which is important because cover crops of different plant functional types (e.g., legumes, grasses) perform different ecosystem functions. Here we use Sentinel-2 satellite data and a random forest classifier to map the cover crop species cereal rye and red clover, which represent grass and legume functional types, in the River Raisin watershed in southeastern Michigan. Our maps of agricultural landcover across this region, including the two cover crop species, had moderate to high accuracies, with an overall accuracy of 83%. Red clover and cereal rye achieved F1 scores that ranged from 0.7 to 0.77, and user's and producer's accuracies that ranged from 63.3% to 86.2%. The most common misclassification of cover crops was fallow fields with remaining crop stubble, which often looked similar because these cover crop species are typically planted within existing crop stubble, or interseeded into a grain crop. We found that red-edge bands and images from the end of April and early July were the most important for classification accuracy. Our results demonstrate the potential to map individual cover crop species using Sentinel-2 imagery, which is critical for understanding the environmental outcomes of increasing crop diversity on farms.",2023,10.3389/frai.2023.1035502
Human- versus Artificial Intelligence,"AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.",2021,10.3389/frai.2021.622364
Proactive and reactive engagement of artificial intelligence methods for education: a review,"The education sector has benefited enormously through integrating digital technology driven tools and platforms. In recent years, artificial intelligence based methods are being considered as the next generation of technology that can enhance the experience of education for students, teachers, and administrative staff alike. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled these efforts further. In this review article, we investigate how artificial intelligence, machine learning, and deep learning methods are being utilized to support the education process. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety—from students admissions, course scheduling, and content generation in the proactive planning phase to knowledge delivery, performance assessment, and outcome prediction in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 195 original research articles published in the past two decades, i.e., 2003–2022. We discuss the paradigm shifts in the solution approaches proposed, particularly with respect to the choice of data and algorithms used over this time. We further discuss how the COVID-19 pandemic influenced this field of active development and the existing infrastructural challenges and ethical concerns pertaining to global adoption of artificial intelligence for education.",2023,10.3389/frai.2023.1151391
BLoss-DDNet: bending loss and dual-task decoding network for overlapping cell nucleus segmentation of cervical clinical LBC images,"Introduction
                    Cervical cancer has become one of the most malignant tumors that threatens women's health worldwide. Liquid-based cytology (LBC) examination has become the most common screening method for detecting cervical cancer early and preventing it. Currently, nuclear segmentation technology for cervical clinical LBC images based on convolutional neural networks has become a vital means of assisting in the diagnosis of cervical cancer. However, the existing nuclear segmentation techniques fail to segment the nuclei of severely overlapping nuclei in highly aggregated cell clusters, which will inevitably lead to the misdiagnosis of cervical cancer pathology.
                  
                  
                    Methods
                    Therefore, a novel bending loss and dual-task decoding network (Bloss-DDNet) is proposed for overlapping cell nucleus segmentation of cervical clinical LBC images. First, the network architecture search method is introduced to search and optimize the architecture of the decoding module in the dual-task branch, determining the mask and boundary decoding modules (dual-task decoding modules) of the Bloss-DDNet. Second, two feature maps, separately generated from dual-task decoding branches composed of a shared encoder module and dual-task decoder modules, are fused to enhance the sensitivity to cell nucleus boundaries. Third, a bending loss is introduced to the loss function to focus on the curvature variation characteristics of the intersection of overlapping cell nucleus boundaries, thereby constraining the training process of the dual-task decoding branch and increasing the constraint on the cell nucleus boundary.
                  
                  
                    Results
                    The results show that all evaluation metrics of the proposed Bloss-DDNet achieved the best performance on public datasets.
                  
                  
                    Discussion
                    Therefore, the proposed Bloss-DDNet can effectively address the segmentation problem of overlapping cell clusters and nuclei in clinical LBC images, providing strong support for subsequent clinical auxiliary diagnosis of cervical cancer.",2025,10.3389/frai.2025.1649452
Deep Learning of Histopathology Images at the Single Cell Level,"The tumor immune microenvironment (TIME) encompasses many heterogeneous cell types that engage in extensive crosstalk among the cancer, immune, and stromal components. The spatial organization of these different cell types in TIME could be used as biomarkers for predicting drug responses, prognosis and metastasis. Recently, deep learning approaches have been widely used for digital histopathology images for cancer diagnoses and prognoses. Furthermore, some recent approaches have attempted to integrate spatial and molecular omics data to better characterize the TIME. In this review we focus on machine learning-based digital histopathology image analysis methods for characterizing tumor ecosystem. In this review, we will consider three different scales of histopathological analyses that machine learning can operate within: whole slide image (WSI)-level, region of interest (ROI)-level, and cell-level. We will systematically review the various machine learning methods in these three scales with a focus on cell-level analysis. We will provide a perspective of workflow on generating cell-level training data sets using immunohistochemistry markers to “weakly-label” the cell types. We will describe some common steps in the workflow of preparing the data, as well as some limitations of this approach. Finally, we will discuss future opportunities of integrating molecular omics data with digital histopathology images for characterizing tumor ecosystem.",2021,10.3389/frai.2021.754641
Teaching Multiple Inverse Reinforcement Learners,"In this paper, we propose the first machine teaching algorithm for multiple inverse reinforcement learners. As our initial contribution, we formalize the problem of optimally teaching a sequential task to a heterogeneous class of learners. We then contribute a theoretical analysis of such problem, identifying conditions under which it is possible to conduct such teaching using the same demonstration for all learners. Our analysis shows that, contrary to other teaching problems, teaching a sequential task to a heterogeneous class of learners with a single demonstration may not be possible, as the differences between individual agents increase. We then contribute two algorithms that address the main difficulties identified by our theoretical analysis. The first algorithm, which we dub SplitTeach, starts by teaching the class as a whole until all students have learned all that they can learn as a group; it then teaches each student individually, ensuring that all students are able to perfectly acquire the target task. The second approach, which we dub JointTeach, selects a single demonstration to be provided to the whole class so that all students learn the target task as well as a single demonstration allows. While SplitTeachensures optimal teaching at the cost of a bigger teaching effort, JointTeachensures minimal effort, although the learners are not guaranteed to perfectly recover the target task. We conclude by illustrating our methods in several simulation domains. The simulation results agree with our theoretical findings, showcasing that indeed class teaching is not possible in the presence of heterogeneous students. At the same time, they also illustrate the main properties of our proposed algorithms: in all domains, SplitTeachguarantees perfect teaching and, in terms of teaching effort, is always at least as good as individualized teaching (often better); on the other hand, JointTeachattains minimal teaching effort in all domains, even if sometimes it compromises the teaching performance.",2021,10.3389/frai.2021.625183
A hybrid fuzzy logic–Random Forest model to predict psychiatric treatment order outcomes: an interpretable tool for legal decision support,"BackgroundDecisions surrounding involuntary psychiatric treatment orders often involve complex clinical, legal, and ethical considerations, especially when patients lack decisional capacity and refuse treatment. In Quebec, these orders are issued by the Superior Court based on a combination of medical, legal, and behavioral evidence. However, no transparent, evidence-informed predictive tools currently exist to estimate the likelihood of full treatment order acceptance. This study aims to develop and evaluate a hybrid fuzzy logic–machine learning model to predict such outcomes and identify important influencing factors.MethodsA retrospective dataset of 176 Superior Court judgments rendered in Quebec in 2024 was curated from SOQUIJ, encompassing demographic, clinical, and legal variables. A Mamdani-type fuzzy inference system was constructed to simulate expert decision logic and output a continuous likelihood score. This score, along with structured features, was used to train a Random Forest classifier. Model performance was evaluated using accuracy, precision, recall and F1 score. A 10-fold stratified cross-validation was employed for internal validation. Feature importance was also computed to assess the influence of each variable on the prediction outcome.ResultsThe hybrid model achieved an accuracy of 98.1%, precision of 93.3%, recall of 100%, and a F1 score of 96.6. The most influential predictors were the duration of time granted by the court, duration requested by the clinical team, and age of the defendant. Fuzzy logic features such as severity, compliance, and a composite Burden_Score also significantly contributed to prediction accuracy. Only one misclassified case was observed in the test set, and the system provided interpretable decision logic consistent with expert reasoning.ConclusionThis exploratory study offers a novel approach for decision support in forensic psychiatric contexts. Future work should aim to validate the model across other jurisdictions, incorporate more advanced natural language processing for semantic feature extraction, and explore dynamic rule optimization techniques. These enhancements would further improve generalizability, fairness, and practical utility in real-world clinical and legal settings.",2025,10.3389/frai.2025.1606250
Jersey number detection using synthetic data in a low-data regime,"Player identification is an essential and complex task in sports video analysis. Different strategies have been devised over the years and identification based on jersey numbers is one of the most common approaches given its versatility and relative simplicity. However, automatic detection of jersey numbers is challenging due to changing camera angles, low video resolution, small object size in wide-range shots, and transient changes in the player's posture and movement. In this paper, we present a novel approach for jersey number identification in a small, highly imbalanced dataset from the Seattle Seahawks practice videos. We generate novel synthetic datasets of different complexities to mitigate the data imbalance and scarcity in the samples. To show the effectiveness of our synthetic data generation, we use a multi-step strategy that enforces attention to a particular region of interest (player's torso), to identify jersey numbers. The solution first identifies and crops players in a frame using a person detection model, then utilizes a human pose estimation model to localize jersey numbers in the detected players, obviating the need for annotating bounding boxes for number detection. We experimented with two sets of Convolutional Neural Networks (CNNs) with different learning objectives: multi-class for two-digit number identification and multi-label for digit-wise detection to compare performance. Our experiments indicate that our novel synthetic data generation method improves the accuracy of various CNN models by 9% overall, and 18% on low frequency numbers.",2022,10.3389/frai.2022.988113
Considerations on the regulation of AI systems in the financial sector by the AI Act,"The proposal for the Artificial Intelligence regulation in the EU (AI Act) is a horizontal legal instrument that aims to regulate, according to a tailored risk-based approach, the development and use of AI systems across a plurality of sectors, including the financial sector. In particular, AI systems intended to be used to evaluate the creditworthiness or establish the credit score of natural persons are classified as “high-risk AI systems”. The proposal, tabled by the Commission in April 2021, is currently at the center of intense interinstitutional negotiations between the two branches of the European legislature, the European Parliament and the Council. Without prejudice to the ongoing legislative deliberations, the paper aims to provide an overview of the main elements and choices made by the Commission in respect of the regulation of AI in the financial sector, as well as of the position taken in that regard by the European Parliament and Council.",2023,10.3389/frai.2023.1277544
The role of AI for MRI-analysis in multiple sclerosis—A brief overview,"Magnetic resonance imaging (MRI) has played a crucial role in the diagnosis, monitoring and treatment optimization of multiple sclerosis (MS). It is an essential component of current diagnostic criteria for its ability to non-invasively visualize both lesional and non-lesional pathology. Nevertheless, modern day usage of MRI in the clinic is limited by lengthy protocols, error-prone procedures for identifying disease markers (e.g., lesions), and the limited predictive value of existing imaging biomarkers for key disability outcomes. Recent advances in artificial intelligence (AI) have underscored the potential for AI to not only improve, but also transform how MRI is being used in MS. In this short review, we explore the role of AI in MS applications that span the entire life-cycle of an MRI image, from data collection, to lesion segmentation, detection, and volumetry, and finally to downstream clinical and scientific tasks. We conclude with a discussion on promising future directions.",2025,10.3389/frai.2025.1478068
A review on artificial intelligence for the diagnosis of fractures in facial trauma imaging,"Patients with facial trauma may suffer from injuries such as broken bones, bleeding, swelling, bruising, lacerations, burns, and deformity in the face. Common causes of facial-bone fractures are the results of road accidents, violence, and sports injuries. Surgery is needed if the trauma patient would be deprived of normal functioning or subject to facial deformity based on findings from radiology. Although the image reading by radiologists is useful for evaluating suspected facial fractures, there are certain challenges in human-based diagnostics. Artificial intelligence (AI) is making a quantum leap in radiology, producing significant improvements of reports and workflows. Here, an updated literature review is presented on the impact of AI in facial trauma with a special reference to fracture detection in radiology. The purpose is to gain insights into the current development and demand for future research in facial trauma. This review also discusses limitations to be overcome and current important issues for investigation in order to make AI applications to the trauma more effective and realistic in practical settings. The publications selected for review were based on their clinical significance, journal metrics, and journal indexing.",2024,10.3389/frai.2023.1278529
Dairy DigiD: a keypoint-based deep learning system for classifying dairy cattle by physiological and reproductive status,"Precision livestock farming increasingly relies on non-invasive, high-fidelity systems capable of monitoring cattle with minimal disruption to behavior or welfare. Conventional identification methods, such as ear tags and wearable sensors, often compromise animal comfort and produce inconsistent data under real-world farm conditions. This study introduces Dairy DigiD, a deep learning-based biometric classification framework that categorizes dairy cattle into four physiologically defineda groups—young, mature milking, pregnant, and dry cows—using high-resolution facial images. The system combines two complementary approaches: a DenseNet121 model for full-image classification, offering global visual context, and Detectron2 for fine-grained facial analysis. Dairy DigiD leverages Detectron2’s multi-task architecture, using instance segmentation and keypoint detection across 30 anatomical landmarks (eyes, ears, muzzle) to refine facial localization and improve classification robustness. While DenseNet121 delivered strong baseline performance, its sensitivity to background noise limited generalizability. In contrast, Detectron2 demonstrated superior adaptability in uncontrolled farm environments, achieving classification accuracies between 93 and 98%. Its keypoint-driven strategy enabled robust feature localization and resilience to occlusions, lighting variations, and heterogeneous backgrounds. Cross-validation and perturbation-based explainability confirmed that biologically salient features guided classification, enhancing model transparency. By integrating animal-centric design with scalable AI, Dairy DigiD represents a significant advancement in automated livestock monitoring-offering an ethical, accurate, and practical alternative to traditional identification methods. The approach sets a precedent for responsible, data-driven decision-making in precision dairy management.",2025,10.3389/frai.2025.1545247
OralImmunoAnalyser: a software tool for immunohistochemical assessment of oral leukoplakia using image segmentation and classification models,"Oral cancer ranks sixteenth amongst types of cancer by number of deaths. Many oral cancers are developed from potentially malignant disorders such as oral leukoplakia, whose most frequent predictor is the presence of epithelial dysplasia. Immunohistochemical staining using cell proliferation biomarkers such as ki67 is a complementary technique to improve the diagnosis and prognosis of oral leukoplakia. The cell counting of these images was traditionally done manually, which is time-consuming and not very reproducible due to intra- and inter-observer variability. The software presently available is not suitable for this task. This article presents the OralImmunoAnalyser software (registered by the University of Santiago de Compostela–USC), which combines automatic image processing with a friendly graphical user interface that allows investigators to oversee and easily correct the automatically recognized cells before quantification. OralImmunoAnalyser is able to count the number of cells in three staining levels and each epithelial layer. Operating in the daily work of the Odontology Faculty, it registered a sensitivity of 64.4% and specificity of 93% for automatic cell detection, with an accuracy of 79.8% for cell classification. Although expert supervision is needed before quantification, OIA reduces the expert analysis time by 56.5% compared to manual counting, avoiding mistakes because the user can check the cells counted. Hence, the SUS questionnaire reported a mean score of 80.9, which means that the system was perceived from good to excellent. OralImmunoAnalyser is accurate, trustworthy, and easy to use in daily practice in biomedical labs. The software, for Windows and Linux, with the images used in this study, can be downloaded from https://citius.usc.es/transferencia/software/oralimmunoanalyser for research purposes upon acceptance.",2024,10.3389/frai.2024.1324410
Phase-specific kidney graft failure prediction with machine learning model,"BackgroundAccurate prediction of kidney graft failure at different phases post-transplantation is critical for timely intervention and long-term allograft preservation. Traditional survival models offer limited capacity for dynamic, time-specific risk estimation. Machine learning (ML) approaches, with their ability to model complex patterns, present a promising alternative.MethodsThis study developed and dynamically evaluated phase-specific ML models to predict kidney graft failure across five post-transplant intervals: 0–3 months, 3–9 months, 9–15 months, 15–39 months, and 39–72 months. Clinically relevant retrospective data from deceased donor kidney transplant recipients were used for training and internal validation, with performance further confirmed on a blinded external validation cohort. Predictive performance was assessed using ROC AUC, F1 score, and G-mean.ResultsThe ML models demonstrated varying performance across time intervals. Short-term predictions in the 0–3 month and 3–9 month intervals yielded moderate accuracy (ROC AUC = 0.73 ± 0.07 and 0.72 ± 0.04, respectively). The highest predictive accuracy observed in mid-term or the 9–15-month window (ROC AUC = 0.92 ± 0.02; F1 score = 0.85 ± 0.03), followed by the 15–39-month period (ROC AUC = 0.84 ± 0.04; F1 score = 0.76 ± 0.04). Long-term prediction from 39 to 72 months was more challenging (ROC AUC = 0.70 ± 0.07; F1 score = 0.65 ± 0.06).ConclusionPhase-specific ML models offer robust predictive performance for kidney graft failure, particularly in mid-term periods, supporting their integration into dynamic post-transplant surveillance strategies. These models can aid clinicians in identifying high-risk patients and tailoring follow-up protocols to optimize long-term transplant outcomes.",2025,10.3389/frai.2025.1682639
Crack detection in structural images using a hybrid Swin Transformer and enhanced features representation block,"Introduction
                    This paper presents a crack detection framework employing a hybrid model that integrates the Swin Transformer with an Enhanced Features Representation Block (EFRB) to precisely detect cracks in images.
                  
                  
                    Methods
                    The Swin Transformer captures long-range dependencies and efficiently processes complex images, forming the backbone of the feature extraction process. The EFRB improved spatial granularity through depthwise convolutions, that focus on spatial features independently across each channel, and pointwise convolutions to improve channel representation. The proposed model used residual connections to enable deeper networks to overcome vanishing gradient problem.
                  
                  
                    Results and discussion
                    The training process is optimized using population-based feature selection, resulting in robust performance. The network is trained on a dataset split into 80% training and 20% testing, with a learning rate of 1e-3, batch size of 16, and 30 epochs. Evaluation results show that the model achieves an accuracy of 98%, with precision, recall, and F1-scores as 0.97, 0.99, and 0.98 for crack detection, respectively. These results show the effectiveness of the proposed architecture for real-world crack detection applications in structural monitoring.",2025,10.3389/frai.2025.1655091
Performance analysis of large language models in the domain of legal argument mining,"Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9% and 12% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.",2023,10.3389/frai.2023.1278796
Planning as Inference in Epidemiological Dynamics Models,"In this work we demonstrate how to automate parts of the infectious disease-control policy-making process via performing inference in existing epidemiological models. The kind of inference tasks undertaken include computing the posterior distribution over controllable, via direct policy-making choices, simulation model parameters that give rise to acceptable disease progression outcomes. Among other things, we illustrate the use of a probabilistic programming language that automates inference in existing simulators. Neither the full capabilities of this tool for automating inference nor its utility for planning is widely disseminated at the current time. Timely gains in understanding about how such simulation-based models and inference automation tools applied in support of policy-making could lead to less economically damaging policy prescriptions, particularly during the current COVID-19 pandemic.",2022,10.3389/frai.2021.550603
Unveiling the predictive power: a comprehensive study of machine learning model for anticipating chronic kidney disease,"In today's modern era, chronic kidney disease stands as a significantly grave ailment that detrimentally impacts human life. This issue is progressively escalating in both developed and developing nations. Precise and timely identification of chronic kidney disease is imperative for the prevention and management of kidney failure. Historical methods of diagnosing chronic kidney disease have often been deemed unreliable on several fronts. To distinguish between healthy individuals and those afflicted by chronic kidney disease, dependable and effective non-invasive techniques such as machine learning models have been adopted. In our ongoing research, we employ various machine learning models, encompassing logistic regression, random forest, decision tree, k-nearest neighbor, and support vector machine utilizing four kernel functions (linear, Laplacian, Bessel, and radial basis kernels), to forecast chronic kidney disease. The dataset used constitutes records from a case-control study involving chronic kidney disease patients in district Buner, Khyber Pakhtunkhwa, Pakistan. For comparative evaluation of the models in terms of classification and accuracy, diverse performance metrics, including accuracy, Brier score, sensitivity, Youden's index, and F1 score, were computed.",2024,10.3389/frai.2023.1339988
Re-tear after arthroscopic rotator cuff repair can be predicted using deep learning algorithm,"The application of artificial intelligence technology in the medical field has become increasingly prevalent, yet there remains significant room for exploration in its deep implementation. Within the field of orthopedics, which integrates closely with AI due to its extensive data requirements, rotator cuff injuries are a commonly encountered condition in joint motion. One of the most severe complications following rotator cuff repair surgery is the recurrence of tears, which has a significant impact on both patients and healthcare professionals. To address this issue, we utilized the innovative EV-GCN algorithm to train a predictive model. We collected medical records of 1,631 patients who underwent rotator cuff repair surgery at a single center over a span of 5 years. In the end, our model successfully predicted postoperative re-tear before the surgery using 62 preoperative variables with an accuracy of 96.93%, and achieved an accuracy of 79.55% on an independent external dataset of 518 cases from other centers. This model outperforms human doctors in predicting outcomes with high accuracy. Through this methodology and research, our aim is to utilize preoperative prediction models to assist in making informed medical decisions during and after surgery, leading to improved treatment effectiveness. This research method and strategy can be applied to other medical fields, and the research findings can assist in making healthcare decisions.",2024,10.3389/frai.2024.1331853
The perceived impact of artificial intelligence on academic learning,"Generative artificial intelligence, such as ChatGPT, is transforming higher education by enabling personalized learning, while raising ethical challenges. This study explores how technical university students perceive and leverage ChatGPT in academic tasks, focusing on motivation, learning outcomes, and ethical awareness. Using the Technology Acceptance Model and Self-Determination Theory, the research surveyed 84 students from a technical university via a 5-point Likert-scale questionnaire. Six salient dimensions of student engagement with ChatGPT emerged: perceived usefulness for problem solving, learning retention and skill acquisition, structured interaction with familiar content, consultation on unfamiliar topics, preference for conciseness, and confidence in the accuracy of AI responses. Students who perceived ChatGPT as a valuable resource for addressing academic problems reported enhanced motivation and competence, and frequent structured interaction was linked to the practice of verifying uncertain information, indicating the emergence of AI literacy. However, extensive reliance was correlated with dependence and limited citation practices, revealing risks to academic integrity. By examining ChatGPT’s role in STEM education, this study substantiates the relevance of AI literacy training and institutional policies to ensure responsible use. The findings offer practical insights for educators to integrate AI tools effectively while fostering critical thinking and academic integrity in technology-driven learning environments.",2025,10.3389/frai.2025.1611183
LiT: limit order book transformer,"While the transformer architecture has demonstrated strong success in natural language processing and computer vision, its application to limit order book forecasting, particularly in capturing spatial and temporal dependencies, remains limited. In this work, we introduce Limit Order Book Transformer (LiT), a novel deep learning architecture for forecasting short-term market movements using high-frequency limit order book data. Unlike previous approaches that rely on convolutional layers, LiT leverages structured patches and transformer-based self-attention to model spatial and temporal features in market microstructure dynamics. We evaluate LiT on multiple LOB datasets across different prediction horizons, LiT consistently outperforms traditional machine learning methods and state-of-the-art deep learning baselines. Furthermore, we show that LiT maintains robust performance under distributional shifts via fine-tuning, making it a practical solution for fast-paced and dynamic financial environments.",2025,10.3389/frai.2025.1616485
Affordance embeddings for situated language understanding,"Much progress in AI over the last decade has been driven by advances in natural language processing technology, in turn facilitated by large datasets and increased computation power used to train large neural language models. These systems demonstrate apparently sophisticated linguistic understanding or generation capabilities, but often fail to transfer their skills to situations they have not encountered before. We argue that computational situated grounding of linguistic information to real or simulated scenarios provide a solution to some of these learning challenges by creating situational representations that both serve as a formal model of the salient phenomena, and contain rich amounts of exploitable, task-appropriate data for training new, flexible computational models. We approach this problem from aneurosymbolicperspective, using multimodal contextual modeling of interactive situations, events, and object properties, particularlyaffordedbehaviors, andhabitats, the situations that condition them. These properties are tightly coupled to processes of situated grounding, and herein we discuss we combine neural and symbolic methods with multimodal simulations to create a platform, VoxWorld, for modeling communication in context, and we demonstrate how neural embedding vectors of symbolically-encoded object affordances facilitate transferring knowledge of objects and situations to novel entities, and learning how to recognize and generate linguistic and gestural denotations.",2022,10.3389/frai.2022.774752
Argument-based human–AI collaboration for supporting behavior change to improve health,"This article presents an empirical requirement elicitation study for an argumentation-based digital companion for supporting behavior change, whose ultimate goal is the promotion and facilitation of healthy behavior. The study was conducted with non-expert users as well as with health experts and was in part supported by the development of prototypes. It focuses on human-centric aspects, in particular user motivations, as well as on expectations and perceptions regarding the role and interaction behavior of a digital companion. Based on the results of the study, a framework for person tailoring the agent's roles and behaviors, and argumentation schemes are proposed. The results indicate that the extent to which a digital companion argumentatively challenges or supports a user's attitudes and chosen behavior and how assertive and provocative the companion is may have a substantial and individualized effect on user acceptance, as well as on the effects of interacting with the digital companion. More broadly, the results shed some initial light on the perception of users and domain experts of “soft,” meta-level aspects of argumentative dialogue, indicating potential for future research.",2023,10.3389/frai.2023.1069455
Training in new forms of human-AI interaction improves complex working memory and switching skills of language professionals,"AI-related technologies used in the language industry, including automatic speech recognition (ASR) and machine translation (MT), are designed to improve human efficiency. However, humans are still in the loop for accuracy and quality, creating a working environment based on Human-AI Interaction (HAII). Very little is known about these newly-created working environments and their effects on cognition. The present study focused on a novel practice, interlingual respeaking (IRSP), where real-time subtitles in another language are created through the interaction between a human and ASR software. To this end, we set up an experiment that included a purpose-made training course on IRSP over 5 weeks, investigating its effects on cognition, and focusing on executive functioning (EF) and working memory (WM). We compared the cognitive performance of 51 language professionals before and after the course. Our variables were reading span (a complex WM measure), switching skills, and sustained attention. IRSP training course improved complex WM and switching skills but not sustained attention. However, the participants were slower after the training, indicating increased vigilance with the sustained attention tasks. Finally, complex WM was confirmed as the primary competence in IRSP. The reasons and implications of these findings will be discussed.",2023,10.3389/frai.2023.1253940
How Personality and Communication Patterns Affect Online ad-hoc Teams Under Pressure,"Critical, time-bounded, and high-stress tasks, like incident response, have often been solved by teams that are cohesive, adaptable, and prepared. Although a fair share of the literature has explored the effect of personality on various other types of teams and tasks, little is known about how it contributes to teamwork when teams of strangers have to cooperatead-hoc, fast, and efficiently. This study explores the dynamics between 120 crowd participants paired into 60 virtual dyads and their collaboration outcome during the execution of a high-pressure, time-bound task. Results show that the personality trait of Openness to experience may impact team performance with teams with higher minimum levels of Openness more likely to defuse the bomb on time. An analysis of communication patterns suggests that winners made more use of action and response statements. The team role was linked to the individual's preference of certain communication patterns and related to their perception of the collaboration quality. Highly agreeable individuals seemed to cope better with losing, and individuals in teams heterogeneous in Conscientiousness seemed to feel better about collaboration quality. Our results also suggest there may be some impact of gender on performance. As this study was exploratory in nature, follow-on studies are needed to confirm these results. We discuss how these findings can help the development of AI systems to aid the formation and support of crowdsourced remote emergency teams.",2022,10.3389/frai.2022.818491
Intersemiotic translation of contracts into digital environments,"An intersemiotic translation is any form of translation that involves at least two different semiotic codes; for example, the translation from words to images, to numerical code, or to non-verbal sounds. One of the most widespread examples of intersemiotic translation in the contemporary world is transposing natural language into machine language in digital environments. In this case, if the source text is a legal text, we encounter a particular type of intersemiotic translation, namely an intersemiotic legal translation in a digital environment. This paper will focus on the intersemiotic legal translation of contracts in digital environments, and is divided into two parts. In the first part (Section Ways of intersemiotically translating a contract using digital tools), we will analyze four possible uses of the intersemiotic translation of contracts in a digital context. In particular, we will highlight the technical characteristics of intersemiotic translation, its limitations, and its potential in different phases of contract management, namely the drafting of the document, the agreement, the archiving of the document, and the execution of contractual clauses. We will examine different digital tools that exploit intersemiotic translation, such as contract drafting tools and online platforms that allow for the conclusion of electronic contracts, document archiving in blockchains, and building smart contracts. When analyzing these uses of intersemiotic translation in the digital environment, we will highlight four types of output that can represent the product of intersemiotic translation in the digital environment: epistemic effects, legal effects, digital effects, and economic effects. In the second part (Section A tool for translating the contract intersemiotically), we will describe a hypothetical prototype that, in light of the four potential uses of intersemiotic translation, could represent a support tool to simplify the communication between professionals and clients through the drafting of legal documents with the aid of dynamic forms and, eventually, with the help of artificial intelligence (AI). Beyond facilitating the dialogue between legal professionals and their clients, we use interfaces to allow clients to create their own drafts of their documents and the lawyer to work on the drafts drawn up by the customer, correct them, and structure them in order to guarantee the validity of the document. The system can also be designed to archive legal documents and private deeds securely and entrust them to a professional by using blockchain technology and automating the execution of some contractual clausesviasmart contract protocols.",2022,10.3389/frai.2022.963692
AI for evidence-based treatment recommendation in oncology: a blinded evaluation of large language models and agentic workflows,"Background
                    Evidence-based medicine is crucial for clinical decision-making, yet studies suggest that a significant proportion of treatment decisions do not fully incorporate the latest evidence. Large Language Models (LLMs) show promise in bridging this gap, but their reliability for medical recommendations remains uncertain.
                  
                  
                    Methods
                    We conducted an evaluation study comparing five LLMs’ recommendations across 50 clinical scenarios related to multiple myeloma diagnosis, staging, treatment, and management, using a unified evidence cutoff of June 2024. The evaluation included three general-purpose LLMs (OpenAI o1-preview, Claude 3.5 Sonnet, Gemini 1.5 Pro), one retrieval-augmented generation (RAG) system (Myelo), and one agentic workflow-based system (HopeAI). General-purpose LLMs generated responses based solely on their internal knowledge, while the RAG system enhanced these capabilities by incorporating external knowledge retrieval. The agentic workflow system extended the RAG approach by implementing multi-step reasoning and coordinating with multiple tools and external systems for complex task execution. Three independent hematologist-oncologists evaluated the LLM-generated responses using standardized scoring criteria developed specifically for this study. Performance assessment encompassed five dimensions: accuracy, relevance, comprehensiveness, hallucination rate, and clinical use readiness.
                  
                  
                    Results
                    HopeAI demonstrated superior performance across accuracy (82.0%), relevance (85.3%), and comprehensiveness (74.0%), compared to OpenAI o1-preview (64.7, 57.3, 36.0%), Claude 3.5 Sonnet (50.0, 51.3, 29.3%), Gemini 1.5 Pro (48.0, 46.0, 30.0%), and Myelo (58.7, 56, 32.7%). Hallucination rates were consistently low across all systems: HopeAI (5.3%), OpenAI o1-preview (3.3%), Claude 3.5 Sonnet (10.0%), Gemini 1.5 Pro (8.0%), and Myelo (5.3%). Clinical use readiness scores were relatively low for all systems: HopeAI (25.3%), OpenAI o1-preview (6.0%), Claude 3.5 Sonnet (2.7%), Gemini 1.5 Pro (4.0%), and Myelo (4.0%).
                  
                  
                    Conclusion
                    This study demonstrates that while current LLMs show promise in medical decision support, their recommendations require careful clinical supervision to ensure patient safety and optimal care. Further research is needed to improve their clinical use readiness before integration into oncology workflows. These findings provide valuable insights into the capabilities and limitations of LLMs in oncology, guiding future research and development efforts toward integrating AI into clinical workflows.",2025,10.3389/frai.2025.1683322
Machine learning algorithms for predicting determinants of COVID-19 mortality in South Africa,"BackgroundCOVID-19 has strained healthcare resources, necessitating efficient prognostication to triage patients effectively. This study quantified COVID-19 risk factors and predicted COVID-19 intensive care unit (ICU) mortality in South Africa based on machine learning algorithms.MethodsData for this study were obtained from 392 COVID-19 ICU patients enrolled between 26 March 2020 and 10 February 2021. We used an artificial neural network (ANN) and random forest (RF) to predict mortality among ICU patients and a semi-parametric logistic regression with nine covariates, including a grouping variable based on K-means clustering. Further evaluation of the algorithms was performed using sensitivity, accuracy, specificity, and Cohen's K statistics.ResultsFrom the semi-parametric logistic regression and ANN variable importance, age, gender, cluster, presence of severe symptoms, being on the ventilator, and comorbidities of asthma significantly contributed to ICU death. In particular, the odds of mortality were six times higher among asthmatic patients than non-asthmatic patients. In univariable and multivariate regression, advanced age, PF1 and 2, FiO2, severe symptoms, asthma, oxygen saturation, and cluster 4 were strongly predictive of mortality. The RF model revealed that intubation status, age, cluster, diabetes, and hypertension were the top five significant predictors of mortality. The ANN performed well with an accuracy of 71%, a precision of 83%, an F1 score of 100%, Matthew's correlation coefficient (MCC) score of 100%, and a recall of 88%. In addition, Cohen's k-value of 0.75 verified the most extreme discriminative power of the ANN. In comparison, the RF model provided a 76% recall, an 87% precision, and a 65% MCC.ConclusionBased on the findings, we can conclude that both ANN and RF can predict COVID-19 mortality in the ICU with accuracy. The proposed models accurately predict the prognosis of COVID-19 patients after diagnosis. The models can be used to prioritize COVID-19 patients with a high mortality risk in resource-constrained ICUs.",2023,10.3389/frai.2023.1171256
Deep learning for cardiovascular management: optimizing pathways and cost control under diagnosis-related group models,"Cardiovascular diseases (CVDs) remain the leading causes of morbidity, mortality, and healthcare expenditures, presenting substantial challenges for hospitals operating under Diagnosis-Related Group (DRG) payment models. Recent advances in deep learning offer new strategies for optimizing CVD management to meet cost control objectives. This review synthesizes the roles of deep learning in CVD diagnosis, treatment planning, and prognostic modeling, emphasizing applications that reduce unnecessary diagnostic imaging, predict high-cost complications, and optimize the utilization of critical resources like ICU beds. By analyzing medical images, forecasting adverse events from patient data, and dynamically optimizing treatment plans, deep learning offers a data-driven strategy to manage high-cost procedures and prolonged hospital stays within DRG budgets. Deep learning offers the potential for earlier risk stratification and tailored interventions, helping mitigate the financial pressures associated with DRG reimbursements. Effective integration requires multidisciplinary collaboration, robust data governance, and transparent model design. Real-world evidence, drawn from retrospective studies and large clinical registries, highlights measurable improvements in cost control and patient outcomes; for instance, AI-optimized treatment strategies have been shown to reduce estimated mortality by 3.13%. However, challenges—such as data quality, regulatory compliance, ethical issues, and limited scalability—must be addressed to fully realize these benefits. Future research should focus on continuous model adaptation, multimodal data integration, equitable deployment, and standardized outcome monitoring to validate both clinical quality and financial return on investment under DRG metrics. By leveraging deep learning’s predictive power within DRG frameworks, healthcare systems can advance toward a more sustainable model of high-quality, cost-effective CVD care.",2025,10.3389/frai.2025.1580445
WOAENet: a whale optimization-guided ensemble deep learning with soft voting for uterine cancer diagnosis based on MRI images,"ObjectivesUterine cancer originates from the cells lining the uterus and can develop through abnormal cell growth, potentially leading to damage in surrounding tissues and the formation of precancerous cells. Early detection significantly improves prognosis. Despite advancements in deep learning-based diagnostic methods, challenges remain, including the dependence on expert input and the need for more accurate classification models. This study aims to address these limitations by proposing a novel and efficient methodology for diagnosing uterine cancer using an integrated deep learning pipeline optimized through a nature-inspired algorithm.MethodsThis study introduces the Whale Optimization Algorithm-based Ensemble Network (WOAENet), a deep learning pipeline that classifies uterine MRI into three classes: malignant, benign, and normal. The Whale Optimization Algorithm (WOA) is used to fine-tune the hyperparameters of three deep learning models: MobileNetV2, DenseNet121, and a lightweight vision model (LVM). Each model is trained with its optimized settings, and its outputs are combined using a Soft Voting Ensemble method that calculates the average of the predicted probabilities to arrive at the final classification.ResultsThe WOAENet framework was evaluated using a uterine cancer MRI dataset obtained from King Abdullah University Hospital. Our proposed model outperformed standard pre-trained models across several performance metrics. It achieved an accuracy of 88.57%, a specificity of 94.29%, and an F1 score of 88.54%, indicating superior performance in diagnosing uterine cancer.ConclusionWOAENet demonstrates a high level of accuracy and reliability in classifying uterine MRI images, marking a significant advancement by utilizing a novel dataset. The findings support the potential of AI-driven approaches in enhancing the diagnosis and treatment of gynecological conditions, paving the way for more accessible and accurate clinical tools.",2025,10.3389/frai.2025.1664201
A survey on detecting healthcare concept drift in AI/ML models from a finance perspective,"Data is incredibly significant in today's digital age because data represents facts and numbers from our regular life transactions. Data is no longer arriving in a static form; it is now arriving in a streaming fashion. Data streams are the arrival of limitless, continuous, and rapid data. The healthcare industry is a major generator of data streams. Processing data streams is extremely complex due to factors such as volume, pace, and variety. Data stream classification is difficult owing to idea drift. Concept drift occurs in supervised learning when the statistical properties of the target variable that the model predicts change unexpectedly. We focused on solving various forms of concept drift problems in healthcare data streams in this research, and we outlined the existing statistical and machine learning methodologies for dealing with concept drift. It also emphasizes the use of deep learning algorithms for concept drift detection and describes the various healthcare datasets utilized for concept drift detection in data stream categorization.",2023,10.3389/frai.2022.955314
State-Aware Deep Item Response Theory using student facial features,"This paper introduces a novel approach to Item Response Theory (IRT) by incorporating deep learning to analyze student facial expressions to enhance the prediction and understanding of student responses to test items. This research is based on the assertion that students' facial expressions offer crucial insights into their cognitive and affective states during testing, subsequently influencing their item responses. The proposed State-Aware Deep Item Response Theory (SAD-IRT) model introduces a new parameter, the student state parameter, which can be viewed as a relative subjective difficulty parameter. It is latent-regressed from students' facial features while solving test items using state-of-the-art deep learning techniques. In an experiment with 20 students, SAD-IRT boosted prediction performance in students' responses compared to prior models without the student state parameter, including standard IRT and its deep neural network implementation, while maintaining consistent predictions of student ability and item difficulty parameters. The research further illustrates the model's early prediction ability in predicting the student's response result before the student answered. This study holds substantial implications for educational assessment, laying the groundwork for more personalized and effective learning and assessment strategies that consider students' emotional and cognitive states.",2024,10.3389/frai.2023.1324279
Artificial Creativity: from predictive AI to Generative System 3,"Large language models generate fluent text yet often fail to sustain novelty, task relevance, and diversity across extended contexts. We argue this shortfall persists because current systems implement only fragments of a tri-process loop that supports human creativity: spontaneous ideation in the default-mode network (DMN; broadly System 1–like), goal-directed evaluation in the central-executive network (CEN; broadly System 2–like), and a metacognitive integrator—System 3—that, via neuromodulatory gain control, shifts between exploration and focused control. We introduce Generative System 3 (GS-3), an architecture-agnostic design pattern with three roles: a high-entropy generator, a learned critic, and an adaptive gain controller. Beyond “pure prediction” and simple “reflective prompting,” GS-3 identifies the missing pieces for Artificial Creativity: an internal evaluator, endogenous control over sampling entropy, and adaptive priors maintained across extended contexts. This conceptual analysis (i) formalizes novelty, usefulness, and diversity with operational definitions; (ii) develops multiple gain-update policies (exponential, linear, logistic) with stability constraints and sensitivity expectations; (iii) derives falsifiable behavioral indices—associative-distance density, analytic-verification ratio, and convergence latency—with pass–fail criteria; and (iv) provides a proof-of-concept blueprint and evaluation protocol (tasks, metrics, ablations, reproducibility kit). We position GS-3 relative to computational-creativity and co-creative frameworks, and delineate where brain–model analogies are functional rather than literal. Ethical guidance addresses bias, cultural homogenization, and reward gaming of proxy objectives (often termed “dopamine hacking”) through plural critics, transparent logging, and outcome-tied entropy caps. The result is a testable roadmap for transitioning from regulated prediction to genuinely creative generative systems.",2025,10.3389/frai.2025.1654716
Issues of AI and human resource development: applications in education and the arts,"This study examines how artificial intelligence (AI) transforms human learning, creativity, and ethical engagement, with implications for future Human Resource Development (HRD). Drawing on Computational Creativity theory, a cross-domain case study analysis—including educational tools (e.g., Jill Watson, Cognii) and generative art platforms (e.g., AICAN, DALL·E)—reveals the dual role of AI as both cognitive collaborator and autonomous agent. The paper structures its discussion around three key dimensions: education (personalized learning vs. development of metacognitive competence), arts (co-authorship dilemmas vs. preservation of human originality), and ethics (regulatory gaps in professional education). Through these domains, the study highlights interdependent tensions and synergies, and argues that AI integration calls for reconceptualizing human–machine interaction in HRD. It then proposes the AI–Human Synergistic Creativity and Learning Framework, which emphasizes collaborative creativity, ethical reflection, and adaptive learning for workforce development. The findings offer actionable insights into curriculum design, policy formulation, and institutional training strategies in AI-augmented contexts.",2025,10.3389/frai.2025.1619980
Construction and validation of a method for automated time label segmentation of heart sounds,"Heart sound detection technology plays an important role in the prediction of cardiovascular disease, but the most significant heart sounds are fleeting and may be imperceptible. Hence, obtaining heart sound information in an efficient and accurate manner will be helpful for the prediction and diagnosis of heart disease. To obtain heart sound information, we designed an audio data analysis tool to segment the heart sounds from single heart cycle, and validated the heart rate using a finger oxygen meter. The results from our validated technique could be used to realize heart sound segmentation. Our robust algorithmic platform was able to segment the heart sounds, which could then be compared in terms of their difference from the background. A combination of an electronic stethoscope and artificial intelligence technology was used for the digital collection of heart sounds and the intelligent identification of the first (S1) and second (S2) heart sounds. Our approach can provide an objective basis for the auscultation of heart sounds and visual display of heart sounds and murmurs.",2024,10.3389/frai.2023.1309750
"Evaluating AI decision tools in Ecuador’s courts: efficiency, consistency, and uncertainty in legal judgments","This study explores the impact of AI-based decision support tools on judicial performance in Ecuador, a context characterized by institutional uncertainty and procedural inefficiencies. It assesses whether such tools improve efficiency, consistency, and the normative quality of legal reasoning in judicial decisions. A mixed-methods approach was applied to analyze fifty court cases before and after AI implementation. Quantitative analysis used
                    t
                    -tests, Levene’s test, and Mann–Whitney U test to evaluate procedural duration and inter-rater agreement, while natural language processing techniques, including topic modeling (LDA) and sentiment analysis (VADER), assessed changes in semantic structure and argumentation. In parallel, a content analysis of twelve policy and regulatory documents was conducted to examine changes in algorithmic governance discourse. The results show a statistically significant reduction in case resolution time (−23.5 days), an increase in inter-evaluator consistency (Cohen’s kappa from 0.65 to 0.80), a shift toward more neutral-technical language, and greater density of legal citations. Mentions of governance principles such as transparency and accountability also increased. These findings indicate that AI-based tools, when used as assistive systems, can enhance judicial decision-making in uncertain environments without displacing human deliberation. While the study provides robust initial evidence, its exploratory sample and reliance on interpretable NLP techniques reflect the constraints of a low-resource judicial context and highlight avenues for future research. This research contributes to the literature on advanced analytical methods for institutional decision-making under legal and epistemic uncertainty.",2025,10.3389/frai.2025.1688209
COVID-19 diagnosis using deep learning neural networks applied to CT images,"COVID-19, a deadly and highly contagious virus, caused the deaths of millions of individuals around the world. Early detection of the virus can reduce the virus transmission and fatality rate. Many deep learning (DL) based COVID-19 detection methods have been proposed, but most are trained on either small, incomplete, noisy, or imbalanced datasets. Many are also trained on a small number of COVID-19 samples. This study tackles these concerns by introducing DL-based solutions for COVID-19 diagnosis using computerized tomography (CT) images and 12 cutting-edge DL pre-trained models with acceptable Top-1 accuracy. All the models are trained on 9,000 COVID-19 samples and 5,000 normal images, which is higher than the COVID-19 images used in most studies. In addition, while most of the research used X-ray images for training, this study used CT images. CT scans capture blood arteries, bones, and soft tissues more effectively than X-Ray. The proposed techniques were evaluated, and the results show that NASNetLarge produced the best classification accuracy, followed by InceptionResNetV2 and DenseNet169. The three models achieved an accuracy of 99.86, 99.79, and 99.71%, respectively. Moreover, DenseNet121 and VGG16 achieved the best sensitivity, while InceptionV3 and InceptionResNetV2 achieved the best specificity. DenseNet121 and VGG16 attained a sensitivity of 99.94%, while InceptionV3 and InceptionResNetV2 achieved a specificity of 100%. The models are compared to those designed in three existing studies, and they produce better results. The results show that deep neural networks have the potential for computer-assisted COVID-19 diagnosis. We hope this study will be valuable in improving the decisions and accuracy of medical practitioners when diagnosing COVID-19. This study will assist future researchers in minimizing the repetition of analysis and identifying the ideal network for their tasks.",2022,10.3389/frai.2022.919672
On the Construction of Group Equivariant Non-Expansive Operators via Permutants and Symmetric Functions,"Group Equivariant Operators (GEOs) are a fundamental tool in the research on neural networks, since they make available a new kind of geometric knowledge engineering for deep learning, which can exploit symmetries in artificial intelligence and reduce the number of parameters required in the learning process. In this paper we introduce a new method to build non-linear GEOs and non-linear Group Equivariant Non-Expansive Operators (GENEOs), based on the concepts of symmetric function and permutant. This method is particularly interesting because of the good theoretical properties of GENEOs and the ease of use of permutants to build equivariant operators, compared to the direct use of the equivariance groups we are interested in. In our paper, we prove that the technique we propose works for any symmetric function, and benefits from the approximability of continuous symmetric functions by symmetric polynomials. A possible use in Topological Data Analysis of the GENEOs obtained by this new method is illustrated.",2022,10.3389/frai.2022.786091
An Analysis of Music Perception Skills on Crowdsourcing Platforms,"Music content annotation campaigns are common on paid crowdsourcing platforms. Crowd workers are expected to annotate complex music artifacts, a task often demanding specialized skills and expertise, thus selecting the right participants is crucial for campaign success. However, there is a general lack of deeper understanding of the distribution of musical skills, and especially auditory perception skills, in the worker population. To address this knowledge gap, we conducted a user study (N = 200) on Prolific and Amazon Mechanical Turk. We asked crowd workers to indicate their musical sophistication through a questionnaire and assessed their music perception skills through an audio-based skill test. The goal of this work is to better understand the extent to which crowd workers possess higher perceptions skills, beyond their own musical education level and self reported abilities. Our study shows that untrained crowd workers can possess high perception skills on the music elements of melody, tuning, accent, and tempo; skills that can be useful in a plethora of annotation tasks in the music domain.",2022,10.3389/frai.2022.828733
Assessing the potential for application of machine learning in predicting weather-sensitive waterborne diseases in selected districts of Tanzania,"IntroductionThis study evaluates the potential of machine learning (ML) to predict and manage weather-sensitive waterborne diseases (WSWDs) in selected Tanzanian districts, focusing on environmental health officers' (EHOs) knowledge and perceptions. It explores EHOs' familiarity with information and communication technology (ICT) and artificial intelligence (AI)/ML, alongside challenges and opportunities for integrating AI-driven public health solutions.MethodsA census-style survey was conducted among EHOs in three district councils. A structured questionnaire, piloted in one district, was administered to 76 EHOs, achieving a 66% response rate. Data were analyzed using descriptive and inferential statistics to assess knowledge levels, perceptions, and gender-related differences.ResultsMost EHOs were moderately familiar with ICT; however, only 54% had prior exposure to AI/ML concepts, and 64% reported limited AI familiarity. Among the variables examined, only prior exposure to AI/ML concepts and self-reported familiarity with AI demonstrated statistically significant associations with gender. Despite this, the majority recognized AI/ML's potential to improve disease prediction accuracy. Key barriers to ML adoption include inadequate technical infrastructure, data quality issues, and a shortage of expertise. Opportunities identified included utilizing historical disease data, integrating AI with meteorological information, and using satellite imagery for surveillance.DiscussionThe study highlights frontline health workers' perceived barriers to ML adoption and suggests that gender influences awareness and engagement with AI and ML technologies. Strengthening technical capacity, improving data quality, and fostering cross-sector collaboration are critical for successful AI/ML integration. These insights offer a roadmap for resilience to WSWDs in developing countries like Tanzania through data-driven technologies.",2025,10.3389/frai.2025.1597727
On the emergent capabilities of ChatGPT 4 to estimate personality traits,"This study investigates the potential of ChatGPT 4 in the assessment of personality traits based on written texts. Using two publicly available datasets containing both written texts and self-assessments of the authors’ psychological traits based on the Big Five model, we aimed to evaluate the predictive performance of ChatGPT 4. For each sample text, we asked for numerical predictions on an eleven-point scale and compared them with the self-assessments. We also asked for ChatGPT 4 confidence scores on an eleven-point scale for each prediction. To keep the study within a manageable scope, a zero-prompt modality was chosen, although more sophisticated prompting strategies could potentially improve performance. The results show that ChatGPT 4 has moderate but significant abilities to automatically infer personality traits from written text. However, it also shows limitations in recognizing whether the input text is appropriate or representative enough to make accurate inferences, which could hinder practical applications. Furthermore, the results suggest that improved benchmarking methods could increase the efficiency and reliability of the evaluation process. These results pave the way for a more comprehensive evaluation of the capabilities of Large Language Models in assessing personality traits from written texts.",2025,10.3389/frai.2025.1484260
Analyzing classification and feature selection strategies for diabetes prediction across diverse diabetes datasets,"IntroductionIn the evolving landscape of healthcare and medicine, the merging of extensive medical datasets with the powerful capabilities of machine learning (ML) models presents a significant opportunity for transforming diagnostics, treatments, and patient care.MethodsThis research paper delves into the realm of data-driven healthcare, placing a special focus on identifying the most effective ML models for diabetes prediction and uncovering the critical features that aid in this prediction. The prediction performance is analyzed using a variety of ML models, such as Random Forest (RF), XG Boost (XGB), Linear Regression (LR), Gradient Boosting (GB), and Support VectorMachine (SVM), across numerousmedical datasets. The study of feature importance is conducted using methods including Filter-based, Wrapper-based techniques, and Explainable Artificial Intelligence (Explainable AI). By utilizing Explainable AI techniques, specifically Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP), the decision-making process of the models is ensured to be transparent, thereby bolstering trust in AI-driven decisions.ResultsFeatures identified by RF in Wrapper-based techniques and the Chi-square in Filter-based techniques have been shown to enhance prediction performance. A notable precision and recall values, reaching up to 0.9 is achieved in predicting diabetes.DiscussionBoth approaches are found to assign considerable importance to features like age, family history of diabetes, polyuria, polydipsia, and high blood pressure, which are strongly associated with diabetes. In this age of data-driven healthcare, the research presented here aspires to substantially improve healthcare outcomes.",2024,10.3389/frai.2024.1421751
"AI, agentic models and lab automation for scientific discovery — the beginning of scAInce","Until recently, the conversation about generative artificial intelligence in science revolved around the textual prowess of large language models such as GPT-3.5 and the promise that they might one day draft a decent literature review. Since then, progress has been nothing short of breathtaking. We now find ourselves in the era of multimodal, agentic systems that listen, see, speak and act, orchestrating cloud software and physical laboratory hardware with a fluency that would have sounded speculative in early 2023. In this review, I merge the substance of our 2024 white paper for the World Economic Forum Top-10-Technologies Report with the latest advances through mid-2025, charting a course from automated literature synthesis and hypothesis generation to self-driving laboratories, organoid intelligence and climate-scale forecasting. The discussion is grounded in emerging governance regimes—notably the European Union Artificial Intelligence Act and ISO 42001—and is written from the dual vantage-point of a toxicologist who has spent a career championing robust, humane science and of a field chief editor charged with safeguarding scholarly standards in Frontiers in Artificial Intelligence. I argue that research is entering a “co-pilot to lab-pilot” transition in which AI no longer merely interprets knowledge but increasingly acts upon it. This shift promises dramatic efficiency gains yet simultaneously amplifies concerns about reproducibility, auditability, safety and equitable access.",2025,10.3389/frai.2025.1649155
Efficient incremental training using a novel NMT-SMT hybrid framework for translation of low-resource languages,"The data-hungry statistical machine translation (SMT) and neural machine translation (NMT) models offer state-of-the-art results for languages with abundant data resources. However, extensive research is imperative to make these models perform equally well for low-resource languages. This paper proposes a novel approach to integrate the best features of the NMT and SMT systems for improved translation performance of low-resource English–Tamil language pair. The suboptimal NMT model trained with the small parallel corpus translates the monolingual corpus and selects only the best translations, to retrain itself in the next iteration. The proposed method employs the SMT phrase-pair table to determine the best translations, based on the maximum match between the words of the phrase-pair dictionary and each of the individual translations. This repeating cycle of translation and retraining generates a large quasi-parallel corpus, thus making the NMT model more powerful. SMT-integrated incremental training demonstrates a substantial difference in translation performance as compared to the existing approaches for incremental training. The model is strengthened further by adopting a beam search decoding strategy to produce k best possible translations for each input sentence. Empirical findings prove that the proposed model with BLEU scores of 19.56 and 23.49 outperforms the baseline NMT with scores 11.06 and 17.06 for Eng-to-Tam and Tam-to-Eng translations, respectively. METEOR score evaluation further corroborates these results, proving the supremacy of the proposed model.",2024,10.3389/frai.2024.1381290
App2: software solution for apple leaf disease detection based on deep learning (CNN+SVM),"Early detection of crop diseases is essential to reduce yield losses and improve management efficiency in agricultural production. This work presents the development of a mobile application, called App2, designed to detect diseases in apple tree leaves from images taken or uploaded by the user. The solution integrates a hybrid model based on a Convolutional Neural Network (CNN) and a Support Vector Machine (SVM), developed for computer vision tasks focused on recognizing diseases in apple leaves. The system architecture includes a user interface built with React Native, an API developed using FastAPI and deployed on Azure, and a pre-filter implemented through the OpenAI API to validate that the uploaded images correspond to crop leaves. The model was trained to classify images into six categories: Scab, Black Rot, Rust, Healthy, Powdery Mildew, and Spider Mite. Experimental results showed a 95% success rate in test cases and 80% performance in detecting clear images of affected leaves. User evaluations indicated high usability and satisfaction, demonstrating that the mobile application has strong potential as an accessible and effective technological tool for disease monitoring in apple crops.",2025,10.3389/frai.2025.1648867
Human-AI teams—Challenges for a team-centered AI at work,"As part of the Special Issue topic “Human-Centered AI at Work: Common Ground in Theories and Methods,” we present a perspective article that looks at human-AI teamwork from a team-centered AI perspective, i. e., we highlight important design aspects that the technology needs to fulfill in order to be accepted by humans and to be fully utilized in the role of a team member in teamwork. Drawing from the model of an idealized teamwork process, we discuss the teamwork requirements for successful human-AI teaming in interdependent and complex work domains, including e.g., responsiveness, situation awareness, and flexible decision-making. We emphasize the need for team-centered AI that aligns goals, communication, and decision making with humans, and outline the requirements for such team-centered AI from a technical perspective, such as cognitive competence, reinforcement learning, and semantic communication. In doing so, we highlight the challenges and open questions associated with its implementation that need to be solved in order to enable effective human-AI teaming.",2023,10.3389/frai.2023.1252897
The Promise of AI for DILI Prediction,"Drug-induced liver injury (DILI) is a common reason for the withdrawal of a drug from the market. Early assessment of DILI risk is an essential part of drug development, but it is rendered challenging prior to clinical trials by the complex factors that give rise to liver damage. Artificial intelligence (AI) approaches, particularly those building on machine learning, range from random forests to more recent techniques such as deep learning, and provide tools that can analyze chemical compounds and accurately predict some of their properties based purely on their structure. This article reviews existing AI approaches to predicting DILI and elaborates on the challenges that arise from the as yet limited availability of data. Future directions are discussed focusing on rich data modalities, such as 3D spheroids, and the slow but steady increase in drugs annotated with DILI risk labels.",2021,10.3389/frai.2021.638410
Explaining graph convolutional network predictions for clinicians—An explainable AI approach to Alzheimer's disease classification,"IntroductionGraph-based representations are becoming more common in the medical domain, where each node defines a patient, and the edges signify associations between patients, relating individuals with disease and symptoms in a node classification task. In this study, a Graph Convolutional Networks (GCN) model was utilized to capture differences in neurocognitive, genetic, and brain atrophy patterns that can predict cognitive status, ranging from Normal Cognition (NC) to Mild Cognitive Impairment (MCI) and Alzheimer's Disease (AD), on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Elucidating model predictions is vital in medical applications to promote clinical adoption and establish physician trust. Therefore, we introduce a decomposition-based explanation method for individual patient classification.MethodsOur method involves analyzing the output variations resulting from decomposing input values, which allows us to determine the degree of impact on the prediction. Through this process, we gain insight into how each feature from various modalities, both at the individual and group levels, contributes to the diagnostic result. Given that graph data contains critical information in edges, we studied relational data by silencing all the edges of a particular class, thereby obtaining explanations at the neighborhood level.ResultsOur functional evaluation showed that the explanations remain stable with minor changes in input values, specifically for edge weights exceeding 0.80. Additionally, our comparative analysis against SHAP values yielded comparable results with significantly reduced computational time. To further validate the model's explanations, we conducted a survey study with 11 domain experts. The majority (71%) of the responses confirmed the correctness of the explanations, with a rating of above six on a 10-point scale for the understandability of the explanations.DiscussionStrategies to overcome perceived limitations, such as the GCN's overreliance on demographic information, were discussed to facilitate future adoption into clinical practice and gain clinicians' trust as a diagnostic decision support system.",2024,10.3389/frai.2023.1334613
Large language models for whole-learner support: opportunities and challenges,"In recent years, large language models (LLMs) have seen rapid advancement and adoption, and are increasingly being used in educational contexts. In this perspective article, we explore the open challenge of leveraging LLMs to create personalized learning environments that support the “whole learner” by modeling and adapting to both cognitive and non-cognitive characteristics. We identify three key challenges toward this vision: (1) improving the interpretability of LLMs' representations of whole learners, (2) implementing adaptive technologies that can leverage such representations to provide tailored pedagogical support, and (3) authoring and evaluating LLM-based educational agents. For interpretability, we discuss approaches for explaining LLM behaviors in terms of their internal representations of learners; for adaptation, we examine how LLMs can be used to provide context-aware feedback and scaffold non-cognitive skills through natural language interactions; and for authoring, we highlight the opportunities and challenges involved in using natural language instructions to specify behaviors of educational agents. Addressing these challenges will enable personalized AI tutors that can enhance learning by accounting for each student's unique background, abilities, motivations, and socioemotional needs.",2024,10.3389/frai.2024.1460364
SHAP and LIME: An Evaluation of Discriminative Power in Credit Risk,"In credit risk estimation, the most important element is obtaining a probability of default as close as possible to the effective risk. This effort quickly prompted new, powerful algorithms that reach a far higher accuracy, but at the cost of losing intelligibility, such as Gradient Boosting or ensemble methods. These models are usually referred to as “black-boxes”, implying that you know the inputs and the output, but there is little way to understand what is going on under the hood. As a response to that, we have seen several different Explainable AI models flourish in recent years, with the aim of letting the user see why the black-box gave a certain output. In this context, we evaluate two very popular eXplainable AI (XAI) models in their ability to discriminate observations into groups, through the application of both unsupervised and predictive modeling to the weights these XAI models assign to features locally. The evaluation is carried out on real Small and Medium Enterprises data, obtained from official italian repositories, and may form the basis for the employment of such XAI models for post-processing features extraction.",2021,10.3389/frai.2021.752558
Supporting Cognition With Modern Technology: Distributed Cognition Today and in an AI-Enhanced Future,"In the present article, we explore prospects for using artificial intelligence (AI) to distribute cognition via cognitive offloading (i.e., to delegate thinking tasks to AI-technologies). Modern technologies for cognitive support are rapidly developing and increasingly popular. Today, many individuals heavily rely on their smartphones or other technical gadgets to support their daily life but also their learning and work. For instance, smartphones are used to track and analyze changes in the environment, and to store and continually update relevant information. Thus, individuals can offload (i.e., externalize) information to their smartphones and refresh their knowledge by accessing it. This implies that using modern technologies such as AI empowers users via offloading and enables them to function as always-updated knowledge professionals, so that they can deploy their insights strategically instead of relying on outdated and memorized facts. This AI-supported offloading of cognitive processes also saves individuals' internal cognitive resources by distributing the task demands into their environment. In this article, we provide (1) an overview of empirical findings on cognitive offloading and (2) an outlook on how individuals' offloading behavior might change in an AI-enhanced future. More specifically, we first discuss determinants of offloading such as the design of technical tools and links to metacognition. Furthermore, we discuss benefits and risks of cognitive offloading. While offloading improves immediate task performance, it might also be a threat for users' cognitive abilities. Following this, we provide a perspective on whether individuals will make heavier use of AI-technologies for offloading in the future and how this might affect their cognition. On one hand, individuals might heavily rely on easily accessible AI-technologies which in return might diminish their internal cognition/learning. On the other hand, individuals might aim at enhancing their cognition so that they can keep up with AI-technologies and will not be replaced by them. Finally, we present own data and findings from the literature on the assumption that individuals' personality is a predictor of trust in AI. Trust in modern AI-technologies might be a strong determinant for wider appropriation and dependence on these technologies to distribute cognition and should thus be considered in an AI-enhanced future.",2022,10.3389/frai.2022.908261
High-resolution image inpainting using a probabilistic framework for diverse images with large arbitrary masks,"Addressing inpainting challenges in high-resolution images remains a complex task. The most recent image inpainting techniques rely on machine learning models; however, a major limitation of supervised methods is their dependence on end-to-end training. Even minor changes to the input often necessitate retraining, making the process inefficient. As a result, unsupervised learning approaches have gained prominence in image inpainting. State-of-the-art methods, particularly those using generative adversarial networks (GANs), have achieved promising results. However, generating photorealistic outputs for high-resolution images with arbitrary large-region masks remains difficult. Inpainted images often suffer from deformed structures and blurry textures, compromising quality. Additionally, building a model capable of handling a diverse range of images presents further challenges. These challenges are addressed by proposing a novel probabilistic model that utilizes picture priors to learn prominent features within StyleGAN3. The priors are constructed using cosine similarity, mean, and intensity, where intensity is computed using the improved Papoulis–Gerchberg algorithm. The image is reconstructed using the probabilistic maximum a posteriori estimate. Variational inference is then applied to obtain the optimal solution using a modified Bayes-by-Backprop approach. The model is evaluated on 70,000 images from the Flickr-Faces-HQ, DIV2K, and brain datasets and surpasses state-of-the-art techniques in reconstruction quality.",2025,10.3389/frai.2025.1614608
"Artificial intelligence applied to analyzes during the pandemic: COVID-19 beds occupancy in the state of Rio Grande do Norte, Brazil","The COVID-19 pandemic is already considered one of the biggest global health crises. In Rio Grande do Norte, a Brazilian state, the RegulaRN platform was the health information system used to regulate beds for patients with COVID-19. This article explored machine learning and deep learning techniques with RegulaRN data in order to identify the best models and parameters to predict the outcome of a hospitalized patient. A total of 25,366 bed regulations for COVID-19 patients were analyzed. The data analyzed comes from the RegulaRN Platform database from April 2020 to August 2022. From these data, the nine most pertinent characteristics were selected from the twenty available, and blank or inconclusive data were excluded. This was followed by the following steps: data pre-processing, database balancing, training, and test. The results showed better performance in terms of accuracy (84.01%), precision (79.57%), and F1-score (81.00%) for the Multilayer Perceptron model with Stochastic Gradient Descent optimizer. The best results for recall (84.67%), specificity (84.67%), and ROC-AUC (91.6%) were achieved by Root Mean Squared Propagation. This study compared different computational methods of machine and deep learning whose objective was to classify bed regulation data for patients with COVID-19 from the RegulaRN Platform. The results have made it possible to identify the best model to help health professionals during the process of regulating beds for patients with COVID-19. The scientific findings of this article demonstrate that the computational methods used applied through a digital health solution, can assist in the decision-making of medical regulators and government institutions in situations of public health crisis.",2023,10.3389/frai.2023.1290022
Perception in Black and White: Effects of Intonational Variables and Filtering Conditions on Sociolinguistic Judgments With Implications for ASR,"This study tests the effects of intonational contours and filtering conditions on listener judgments of ethnicity to arrive at a more comprehensive understanding on how prosody influences these judgments, with implications for austomatic speech recognition systems as well as speech synthesis. In a perceptual experiment, 40 American English listeners heard phrase-long clips which were controlled for pitch accent type and focus marking. Each clip contained either two H* (high) or two L+H* (low high) pitch accents and a L-L% (falling) boundary tone, and had also previously been labelled for broad or narrow focus. Listeners rated clips in two tasks, one with unmodified stimuli and one with stimuli lowpass filtered at 400 Hz, and were asked to judge whether the speaker was “Black” or “White”. In the filtered condition, tokens with the L+H* pitch accent were more likely to be rated as “Black”, with an interaction such that broad focus enhanced this pattern, supporting earlier findings that listeners may perceive African American Language as having more variation in possible pitch accent meanings. In the unfiltered condition, tokens with the L+H* pitch accent were less likely to be rated as Black, with no effect of focus, likely due to the fact that listeners relied more heavily on available segmental information in this condition. These results enhance our understanding of cues listeners rely on in making social judgments about speakers, especially in ethnic identification and linguistic profiling, by highlighting perceptual differences due to listening environment as well as predicted meaning of specific intonational contours. They also contribute to our understanding of the role of how human listeners interpret meaning within a holistic context, which has implications for the construction of computational systems designed to replicate the properties of natural language. In particular, they have important applicability to speech synthesis and speech recognition programs, which are often limited in their capacities due to the fact that they do not make such holistic sociolinguistic considerations of the meanings of input or output speech.",2021,10.3389/frai.2021.642783
Gender-based Alzheimer's detection using ResNet-50 and binary dragonfly algorithm on neuroimaging,"Alzheimer's disease (AD) is an incurable, progressive neurodegenerative disorder. It is characterized by a gradual decline in memory, cognition, and behavior, which ultimately results in severe dementia and functional dependence. AD begins to develop in the brain at an early stage, while its symptoms appear gradually over time. Early diagnosis and classification of Alzheimer's is a critical research focus due to its silent progression. The current literature highlights a gap in gender-based studies, revealing that the risk of AD varies by gender, age, race, and ethnicity. The nature of the association between AD and these factors requires further exploration to better understand their impact on disease risk and progression. Effectively employing multiple algorithms is essential for accurate diagnosis of Alzheimer's development. This study proposed the GRDN model, which explored a critical aspect of gender-based Alzheimer's detection. To detect subtle changes in the brain, functional magnetic resonance imaging (fMRI) scans have been acquired from the ADNI dataset. In order to balance class distribution and enhance classifier performance on underrepresented groups, a generative adversarial network (GAN) is applied. A balanced dataset is provided to the ResNet-50 architecture for feature extraction, resulting in feature matrices set with a range of 100, 250, and 450. These feature set matrices were then fed to a swarm intelligence-based approach, the binary dragonfly algorithm (BDA), for feature selection, which identified the most informative features. After feature engineering, the resultant matrices of feature selection were provided to the five machine learning (ML) classification algorithms for data classification. The results show that as the size of the features set increases and the accuracy of the classification improves. The simulation results demonstrated that the fineKNN achieved strong performance, with an accuracy of 94.8% on the male group on a feature set of 450, and consistently outperformed other models across all study groups.",2025,10.3389/frai.2025.1717913
A risk identification model for detection of patients at risk of antidepressant discontinuation,"PurposeBetween 30 and 68% of patients prematurely discontinue their antidepressant treatment, posing significant risks to patient safety and healthcare outcomes. Online healthcare forums have the potential to offer a rich and unique source of data, revealing dimensions of antidepressant discontinuation that may not be captured by conventional data sources.MethodsWe analyzed 891 patient narratives from the online healthcare forum, “askapatient.com,” utilizing content analysis to create PsyRisk—a corpus highlighting the risk factors associated with antidepressant discontinuation. Leveraging PsyRisk, alongside PsyTAR [a publicly available corpus of adverse drug reactions (ADRs) related to antidepressants], we developed a machine learning-driven algorithm for proactive identification of patients at risk of abrupt antidepressant discontinuation.ResultsFrom the analyzed 891 patients, 232 reported antidepressant discontinuation. Among these patients, 92% experienced ADRs, and 72% found these reactions distressful, negatively affecting their daily activities. Approximately 26% of patients perceived the antidepressants as ineffective. Most reported ADRs were physiological (61%, 411/673), followed by cognitive (30%, 197/673), and psychological (28%, 188/673) ADRs. In our study, we employed a nested cross-validation strategy with an outer 5-fold cross-validation for model selection, and an inner 5-fold cross-validation for hyperparameter tuning. The performance of our risk identification algorithm, as assessed through this robust validation technique, yielded an AUC-ROC of 90.77 and an F1-score of 83.33. The most significant contributors to abrupt discontinuation were high perceived distress from ADRs and perceived ineffectiveness of the antidepressants.ConclusionThe risk factors identified and the risk identification algorithm developed in this study have substantial potential for clinical application. They could assist healthcare professionals in identifying and managing patients with depression who are at risk of prematurely discontinuing their antidepressant treatment.",2023,10.3389/frai.2023.1229609
Physician perceptions of artificial intelligence in Northern Italy healthcare: a survey of fears and expectations,"Introduction
                    Artificial Intelligence (AI) is more and more spreading but despite the clear evidence of benefits related to its implementation, many physicians worry about ethical, legal, employment and professional changes that AI is going to induce. The purpose of this paper is to assess whether and why physicians worry about AI.
                  
                  
                    Methods
                    This study is a cross-sectional survey addressed to a group of 362 Northern Italy hospitals physicians, both specialists and residents from selected specialties were asked to fill in a 27 multiple-choice online survey submitted by e-mail. The survey aimed to evaluate their opinions and expectations about the impact of AI on clinical, employment and ethical topics. The results were evaluated by the software Stata that enabled to carry out a multivariate analysis with the evaluation of the statistical significance of the results obtained.
                  
                  
                    Results
                    176 physicians (48%) answered the survey. The knowledge of the topic “AI” was reported as mild in 47%, poor in 30% and good in 15%; 98% of the responders believe that AI will improve medical activities, in particular by reducing medical errors. The legal problems, the worsening of the relationship with the patients and the deep changes of the medical role have been considered its most negative expected consequences. From an employment point of view, most responders believe that the AI cause the replacement of physicians by other professional figures. The most frequent sensations caused by AI are optimism (34%), worry (30%) and enthusiasm (13%), while anxiety is reported by 9% of the responders. The responders also believe that new dedicated digital technologies and new skills will be needed. Deep changes in the formation of physicians and residents are deemed to be necessary. Gender influences the response given on the effects of AI: women tend to be overall more pessimistic, predicting greater impacts on training, with a substantially negative feeling and with a lower probability of easing litigation. The responses are not correlated with the doctor’s specialty of the respondent. The region, which influences the responses on training and feelings, does not influence the response on the effect of AI on litigation. The respondents’ origins in some regions of northern Italy and the selection of some medical specialties must be considered limitations of the reported analysis.",2025,10.3389/frai.2025.1624789
Three-stage registration pipeline for dynamic lung field of chest X-ray images based on convolutional neural networks,"BackgroundThe anatomically constrained registration network (AC-RegNet), which yields anatomically plausible results, has emerged as the state-of-the-art registration architecture for chest X-ray (CXR) images. Nevertheless, accurate lung field registration results may be more favored and exciting than the registration results of the entire CXR images and hold promise for dynamic lung field analysis in clinical practice.ObjectiveBased on the above, a registration model of the dynamic lung field of CXR images based on AC-RegNet and static CXR images is urgently developed to register these dynamic lung fields for clinical quantitative analysis.MethodsThis paper proposes a fully automatic three-stage registration pipeline for the dynamic lung field of CXR images. First, the dynamic lung field mask images are generated from a pre-trained standard lung field segmentation model with the dynamic CXR images. Then, a lung field abstraction model is designed to generate the dynamic lung field images based on the dynamic lung field mask images and their corresponding CXR images. Finally, we propose a three-step registration training method to train the AC-RegNet, obtaining the registration network of the dynamic lung field images (AC-RegNet_V3).ResultsThe proposed AC-RegNet_V3 with the four basic segmentation networks achieve the mean dice similarity coefficient (DSC) of 0.991, 0.993, 0.993, and 0.993, mean Hausdorff distance (HD) of 12.512, 12.813, 12.449, and 13.661, mean average symmetric surface distance (ASSD) of 0.654, 0.550, 0.572, and 0.564, and mean squared distance (MSD) of 559.098, 577.797, 548.189, and 559.652, respectively. Besides, compared to the dynamic CXR images, the mean DSC of these four basic segmentation networks with AC-RegNet has been significantly improved by 7.2, 7.4, 7.4, and 7.4% (p-value &lt; 0.0001). Meanwhile, the mean HD has been significantly improved by 8.994, 8.693, 9.057, and 7.845 (p-value &lt; 0.0001). Similarly, the mean ASSD has significantly improved by 4.576, 4.680, 4.658, and 4.658 (p-value &lt; 0.0001). Last, the mean MSD has significantly improved by 508.936, 519.776, 517.904, and 520.626 (p-value &lt; 0.0001).ConclusionOur proposed three-stage registration pipeline has demonstrated its effectiveness in dynamic lung field registration. Therefore, it could become a powerful tool for dynamic lung field analysis in clinical practice, such as pulmonary airflow detection and air trapping location.",2025,10.3389/frai.2025.1466643
AI-Empowered Computational Examination of Chest Imaging for COVID-19 Treatment: A Review,"Since the first case of coronavirus disease 2019 (COVID-19) was discovered in December 2019, COVID-19 swiftly spread over the world. By the end of March 2021, more than 136 million patients have been infected. Since the second and third waves of the COVID-19 outbreak are in full swing, investigating effective and timely solutions for patients’ check-ups and treatment is important. Although the SARS-CoV-2 virus-specific reverse transcription polymerase chain reaction test is recommended for the diagnosis of COVID-19, the test results are prone to be false negative in the early course of COVID-19 infection. To enhance the screening efficiency and accessibility, chest images capturedviaX-ray or computed tomography (CT) provide valuable information when evaluating patients with suspected COVID-19 infection. With advanced artificial intelligence (AI) techniques, AI-driven models training with lung scans emerge as quick diagnostic and screening tools for detecting COVID-19 infection in patients. In this article, we provide a comprehensive review of state-of-the-art AI-empowered methods for computational examination of COVID-19 patients with lung scans. In this regard, we searched for papers and preprints on bioRxiv, medRxiv, and arXiv published for the period from January 1, 2020, to March 31, 2021, using the keywords of COVID, lung scans, and AI. After the quality screening, 96 studies are included in this review. The reviewed studies were grouped into three categories based on their target application scenarios: automatic detection of coronavirus disease, infection segmentation, and severity assessment and prognosis prediction. The latest AI solutions to process and analyze chest images for COVID-19 treatment and their advantages and limitations are presented. In addition to reviewing the rapidly developing techniques, we also summarize publicly accessible lung scan image sets. The article ends with discussions of the challenges in current research and potential directions in designing effective computational solutions to fight against the COVID-19 pandemic in the future.",2021,10.3389/frai.2021.612914
African American English intensifier dennamug: Using twitter to investigate syntactic change in low-frequency forms,"There are some linguistic forms that may be known to both speakers and linguists, but that occur naturally with such low frequency that traditional sociolinguistic methods do not allow for study. This study investigates one such phenomenon: the grammatical reanalysis of an intensifier in some forms of African American English—from a full phrase[than a mother(fucker)]to lexical word (represented here asdennamug)—using data gathered from twitter. This paper investigates the relationship between apparent lexicalization and deletion of the comparative morpheme on the preceding adjective. While state-of-the-art traditional corpora contain so few tokens they can be counted on one hand, twitter yields almost 300,000 tokens over a 10 year sample period. This paper uses web scraping of Twitter to gather all plausible orthographic representations of the intensifier, and uses logistic regression to analyze the extent to which markers of lexicalization and reanalysis are associated with a corresponding shift from comparative to bare morphology on the adjective the intensifier modifies, finding that, indeed, degree of apparent lexicalization is strongly associated with bare morphology, suggesting ongoing lexicalization and subsequent reanalysis at the phrase level. This digital approach reveals ongoing grammatical change, with the new intensifier associated with bare, note comparative, adjectives, and that there is seemingly stable variation correlated with the degree to which the intensifier has lexicalized. Orthographic representations of African American English on social media are shown to be a locus of identity construction and grammatical change.",2023,10.3389/frai.2022.683104
Journaling with large language models: a novel UX paradigm for AI-driven personal health management,"IntroductionThe integration of large language models (LLMs) into personal health management presents transformative potential, but faces critical challenges in user experience (UX) design, ethical implementation, and clinical integration.MethodThis paper introduces a novel AI-driven journaling application, a functional prototype available open source, designed to encourage patient engagement through a natural language interface. This approach, termed “AI-assisted health journaling,” enables users to document health experiences in their own words while receiving real-time, context-aware feedback from an LLM. The prototype combines a personal health record with an LLM assistant, allowing for reflective self-monitoring and aiming to combine patient-generated data with clinical insights. Key innovations include a three-panel interface for seamless journaling, AI dialogue, and longitudinal tracking, alongside specialized modes for interacting with simulated healthcare expert personas.ResultPreliminary insights from persona-based evaluations highlight the system's capacity to enhance health literacy through explainable AI responses while maintaining strict data localization and privacy controls. We propose five design principles for patient-centric AI health tools: (1) decoupling core functionality from LLM dependencies, (2) layered transparency in AI outputs, (3) adaptive consent for data sharing, (4) clinician-facing data summarization, and (5) compliance-first architecture.DiscussionBy transforming unstructured patient narratives into structured insights through natural language processing, this approach demonstrates how journaling interfaces could serve as a critical middleware layer in healthcare ecosystems-empowering patients as active partners in care while preserving clinical oversight. Future research directions emphasize the need for rigorous trials evaluating impacts on care continuity, patient-provider communication, and long-term health outcomes across diverse populations.",2025,10.3389/frai.2025.1567580
GDP prediction of The Gambia using generative adversarial networks,"Predicting Gross Domestic Product (GDP) is one of the most crucial tasks in analyzing a nation’s economy and growth. The primary goal of this study is to forecast GDP using factors such as government spending, inflation, official development aid, remittance inflows, and Foreign Direct Investment (FDI). Additionally, the paper aims to provide an alternative perspective to Generative Adversarial Networks method and demonstrate how such deep learning technique can enhance the accuracy of GDP predictions with small data and economy like The Gambia. We proposed the implementation of Generative Adversarial Networks to predict GDP using various economic factors over the period from 1970 to 2022. Performance metrics, including the coefficient of determination R2, mean absolute error (MAE), mean absolute percentage error (MAPE), and root- mean-square error (RMSE) were collected to evaluate the system’s accuracy. Among the models tested—Random Forest Regression (RF), XGBoost (XGB), and Support Vector Regression (SVR)—the Generative Adversarial Networks (GAN) model demonstrated superior performance, achieving the highest accuracy, which is 99% prediction accuracies. The most dependable model for capturing intricate correlations between GDP and its affecting components, however, RF and XGBoost, also achieved an accuracy of 98% each. This makes GAN the most desirable model for GDP prediction for our study. Through data analysis, this project aims to provide actionable insights to support strategies that sustain economic boom. This approach enables the generation of accurate GDP forecasts, offering a valuable tool for policymakers and stakeholders.",2025,10.3389/frai.2025.1546398
Management of scientific and ancestral knowledge: a decision-making model in mezcal industry in Mexico,"IntroductionKnowledge management is essential to ensure the sustainability of rural communities and small producers since it generates value for innovation, productivity, and competitiveness. The aim of this study is to identify relevant factors for adequate decision-making in managing knowledge in the Mexican mezcal industry and its impact on developing rural communities and small producers - mezcaleros. For this purpose, a decision-making model for managing scientific and ancestral knowledge is created to support links with universities, research centers, and rural communities to accelerate innovation and competitiveness in this sector.MethodsThe analysis methods were carried out through decision-making, machine-learning techniques, and fuzzy logic.ResultsThe Bayesian Network model suggests that the preceding variables to optimize the Mezcaleros Knowledge Management are the Mezcaleros Indigenous community, the Denomination of Origin, Scientific and Ancestral Knowledge, Waste Management and Use, and Jima.DiscussionThis knowledge management model aims to guide small producers to be more productive and competitive through the support of a facilitator.",2025,10.3389/frai.2025.1570617
Grounding human-object interaction to affordance behavior in multimodal datasets,"While affordance detection and Human-Object interaction (HOI) detection tasks are related, the theoretical foundation of affordances makes it clear that the two are distinct. In particular, researchers in affordances make distinctions between J. J. Gibson's traditional definition of an affordance, “the action possibilities” of the object within the environment, and the definition of atelicaffordance, or one defined by conventionalized purpose or use. We augment the HICO-DET dataset with annotations for Gibsonian and telic affordances and a subset of the dataset with annotations for the orientation of the humans and objects involved. We then train an adapted Human-Object Interaction (HOI) model and evaluate a pre-trained viewpoint estimation system on this augmented dataset. Our model, AffordanceUPT, is based on a two-stage adaptation of the Unary-Pairwise Transformer (UPT), which we modularize to make affordance detection independent of object detection. Our approach exhibits generalization to new objects and actions, can effectively make the Gibsonian/telic distinction, and shows that this distinction is correlated with features in the data that are not captured by the HOI annotations of the HICO-DET dataset.",2023,10.3389/frai.2023.1084740
A deep-learning pipeline for the diagnosis and grading of common blinding ophthalmic diseases based on lesion-focused classification model,"BackgroundGlaucoma (GLAU), Age-related Macular Degeneration (AMD), Retinal Vein Occlusion (RVO), and Diabetic Retinopathy (DR) are common blinding ophthalmic diseases worldwide.PurposeThis approach is expected to enhance the early detection and treatment of common blinding ophthalmic diseases, contributing to the reduction of individual and economic burdens associated with these conditions.MethodsWe propose an effective deep-learning pipeline that combine both segmentation model and classification model for diagnosis and grading of four common blinding ophthalmic diseases and normal retinal fundus.ResultsIn total, 102,786 fundus images of 75,682 individuals were used for training validation and external validation purposes. We test our model on internal validation data set, the micro Area Under the Receiver Operating Characteristic curve (AUROC) of which reached 0.995. Then, we fine-tuned the diagnosis model to classify each of the four disease into early and late stage, respectively, which achieved AUROCs of 0.597 (GL), 0.877 (AMD), 0.972 (RVO), and 0.961 (DR) respectively. To test the generalization of our model, we conducted two external validation experiments on Neimeng and Guangxi cohort, all of which maintained high accuracy.ConclusionOur algorithm demonstrates accurate artificial intelligence diagnosis pipeline for common blinding ophthalmic diseases based on Lesion-Focused fundus that overcomes the low-accuracy of the traditional classification method that based on raw retinal images, which has good generalization ability on diverse cases in different regions.",2024,10.3389/frai.2024.1444136
Entropy-adaptive differential privacy federated learning for student performance prediction and privacy protection: a case study in Python programming,"In the context of the digital transformation of engineering education, protecting student data privacy has become a key challenge for enabling data-driven instruction. This study proposes an Entropy-Adaptive Differential Privacy Federated Learning method (EADP-FedAvg) to enhance the accuracy of student performance prediction while ensuring data privacy. Based on online test records from Python programming courses for Electronic Engineering students (grade 2021–2023) at the School of Physics and Optoelectronic Technology, Baoji University of Arts and Sciences, China, the study uses a Multilayer Perceptron (MLP) model and 10 distributed clients for training. Under different privacy budgets (ε = 0.1, 1e-6, and 1.0), EADP-FedAvg achieves a test accuracy of 92.7%, macro-average score of 92.1%, and entropy of 0.207, outperforming standard federated learning and approaching centralized learning performance. The results demonstrate that by adaptively adjusting the noise level based on output entropy, EADP-FedAvg effectively balances privacy preservation and model accuracy. This method offers a novel solution for analyzing privacy-sensitive educational data in engineering education.",2025,10.3389/frai.2025.1653437
Adaptive consensus optimization in blockchain using reinforcement learning and validation in adversarial environments,"The increasing complexity and decentralization of modern blockchain networks have highlighted the limitations of traditional consensus protocols when operating under adverse or dynamic conditions. Existing approaches often fail to adapt to real-time anomalies such as Sybil attacks, network congestion, or node failures, resulting in decreased throughput, increased latency, and reduced security. Furthermore, most systems lack autonomous mechanisms to adjust operational policies based on context, especially in edge computing environments where resource constraints and topological variability demand flexible and efficient solutions. This work proposes an adaptive consensus architecture that integrates a graph-based Proximal Policy Optimization (PPO) reinforcement learning agent capable of detecting malicious behavior, optimizing validation paths, and dynamically modifying consensus logic in response to adversarial scenarios. The model is trained on a hybrid dataset composed of real traffic traces and synthetically generated adversarial behaviors, and evaluated in stress-testing environments with multiple threat vectors. Experimental results demonstrate that the proposed system maintains stable throughput (TPS) while reducing average consensus latency by 34% relative to baseline protocols under adverse high-load conditions. Regarding security, it achieves high detection in Sybil and node-collapse scenarios (DR exceeding 0.90 with FPR below 0.10), and moderate detection under congestion and erroneous transactions (DR between 0.58 and 0.70, FPR between 0.14 and 0.22). Additionally, we observe up to 16% lower average energy consumption in high-congestion settings. Energy consumption is reduced by up to 17% in crash-prone scenarios. The architecture demonstrates stable convergence over 100 operating cycles and robust adaptation to topological changes, validating its applicability in real-world deployments.",2025,10.3389/frai.2025.1672273
Nonlinear Noise Cleaning in Gravitational-Wave Detectors With Convolutional Neural Networks,"Currently, the sub-60 Hz sensitivity of gravitational-wave (GW) detectors like Advanced LIGO (aLIGO) is limited by the control noises from auxiliary degrees of freedom which nonlinearly couple to the main GW readout. One promising way to tackle this challenge is to perform nonlinear noise mitigation using convolutional neural networks (CNNs), which we examine in detail in this study. In many cases, the noise coupling is bilinear and can be viewed as a few fast channels' outputs modulated by some slow channels. We show that we can utilize this knowledge of the physical system and adopt an explicit “slow×fast” structure in the design of the CNN to enhance its performance of noise subtraction. We then examine the requirements in the signal-to-noise ratio (SNR) in both the target channel (i.e., the main GW readout) and in the auxiliary sensors in order to reduce the noise by at least a factor of a few. In the case of limited SNR in the target channel, we further demonstrate that the CNN can still reach a good performance if we use curriculum learning techniques, which in reality can be achieved by combining data from quiet times and those from periods with active noise injections.",2022,10.3389/frai.2022.811563
Artificial intelligence as a tool to enhance social interventions in reducing crime,"Introduction
                    This study explores the significant role of artificial intelligence (AI) in crime reduction, identifies the main challenges hindering its implementation, and examines differences in coping strategies between individuals in Jordan and Saudi Arabia.
                  
                  
                    Methods
                    The research surveyed 170 AI professionals, equally divided between the two countries, with an average age of 45.2 years. Data were collected using a specially designed questionnaire assessing perceptions of AI, barriers to adoption, and coping mechanisms.
                  
                  
                    Results
                    The findings indicated that AI plays a significant role in crime reduction. High levels of challenges were reported in implementing AI, and coping strategies related to AI in crime reduction were also assessed at a high level. No statistically significant differences were found in the level of challenges facing AI between Jordanian and Saudi participants.
                  
                  
                    Discussion
                    This research contributes to understanding AI’s practical applications in crime prevention and provides valuable insights for policymakers to strengthen AI adoption and overcome existing barriers in the region.",2025,10.3389/frai.2025.1661266
Moving LLM evaluation forward: lessons from human judgment research,"This paper outlines a path toward more reliable and effective evaluation of Large Language Models (LLMs). It argues that insights from the study of human judgment and decision-making can illuminate current challenges in LLM assessment and help close critical gaps in how models are evaluated. By drawing parallels between human reasoning and model behavior, the paper advocates moving beyond narrow metrics toward more nuanced, ecologically valid frameworks.",2025,10.3389/frai.2025.1592399
Kernelized Heterogeneity-Aware Cross-View Face Recognition,"Cross-view or heterogeneous face matching involves comparing two different views of the face modality such as two different spectrums or resolutions. In this research, we present two heterogeneity-aware subspace techniques, heterogeneous discriminant analysis (HDA) and its kernel version (KHDA) that encode heterogeneity in the objective function and yield a suitable projection space for improved performance. They can be applied on any feature to make it heterogeneity invariant. We next propose a face recognition framework that uses existing facial features along with HDA/KHDA for matching. The effectiveness of HDA and KHDA is demonstrated using both handcrafted and learned representations on three challenging heterogeneous cross-view face recognition scenarios: (i) visible to near-infrared matching, (ii) cross-resolution matching, and (iii) digital photo to composite sketch matching. It is observed that, consistently in all the case studies, HDA and KHDA help to reduce the heterogeneity variance, clearly evidenced in the improved results. Comparison with recent heterogeneous matching algorithms shows that HDA- and KHDA-based matching yields state-of-the-art or comparable results on all three case studies. The proposed algorithms yield the best rank-1 accuracy of 99.4% on the CASIA NIR-VIS 2.0 database, up to 100% on the CMU Multi-PIE for different resolutions, and 95.2% rank-10 accuracies on the e-PRIP database for digital to composite sketch matching.",2021,10.3389/frai.2021.670538
Factors influencing trust in algorithmic decision-making: an indirect scenario-based experiment,"Algorithms are involved in decisions ranging from trivial to significant, but people often express distrust toward them. Research suggests that educational efforts to explain how algorithms work may help mitigate this distrust. In a study of 1,921 participants from 20 countries, we examined differences in algorithmic trust for low-stakes and high-stakes decisions. Our results suggest that statistical literacy is negatively associated with trust in algorithms for high-stakes situations, while it is positively associated with trust in low-stakes scenarios with high algorithm familiarity. However, explainability did not appear to influence trust in algorithms. We conclude that having statistical literacy enables individuals to critically evaluate the decisions made by algorithms, data and AI, and consider them alongside other factors before making significant life decisions. This ensures that individuals are not solely relying on algorithms that may not fully capture the complexity and nuances of human behavior and decision-making. Therefore, policymakers should consider promoting statistical/AI literacy to address some of the complexities associated with trust in algorithms. This work paves the way for further research, including the triangulation of data with direct observations of user interactions with algorithms or physiological measures to assess trust more accurately.",2025,10.3389/frai.2024.1465605
Implications of causality in artificial intelligence,"Over the last decade, investment in artificial intelligence (AI) has grown significantly, driven by technology companies and the demand for PhDs in AI. However, new challenges have emerged, such as the ‘black box’ and bias in AI models. Several approaches have been developed to reduce these problems. Responsible AI focuses on the ethical development of AI systems, considering social impact. Fair AI seeks to identify and correct algorithm biases, promoting equitable decisions. Explainable AI aims to create transparent models that allow users to interpret results. Finally, Causal AI emphasizes identifying cause-and-effect relationships and plays a crucial role in creating more robust and reliable systems, thereby promoting fairness and transparency in AI development. Responsible, Fair, and Explainable AI has several weaknesses. However, Causal AI is the approach with the slightest criticism, offering reassurance about the ethical development of AI.",2024,10.3389/frai.2024.1439702
"Predicting Universal Healthcare Through Health Financial Management for Sustainable Development in BRICS, GCC, and AUKUS Economic Blocks","The majority of the world's population is still facing difficulties in getting access to primary healthcare facilities. Universal health coverage (UHC) proposes access to high-quality, affordable primary healthcare for all. The 17 UN sustainable development goals (SDGs) are expected to be executed and achieved by all the 193 countries through national sustainable development strategies and multi-stakeholder partnerships. This article addresses SDG 3.8—access to good quality and affordable healthcare and two subindicators related to societal impact (SDG 3.8.1 and 3.8.2) through two objectives. The first objective is to determine whether health expenditure indicators (HEIs) drive UHC, and the second objective is to analyze the importance of key determinants and their interactions with UHC in three economic blocks: emerging Gulf Cooperation Council (GCC); developing Brazil, Russia, India, China, and South Africa (BRICS) vis-à-vis the developed Australia, UK, and USA (AUKUS). We use the WHO Global Health Indicator database and UHC periodical surveys to evaluate the hypotheses. We apply state-of-the-art machine learning (ML) models and ordinary least square (traditional—OLS regression) methods to see the superiority of artificial intelligence (AI) over traditional ones. The ML Random Forest Tree method is found to be superior to the OLS model in terms of lower root mean square error (RMSE). The ML results indicate that domestic private health expenditure (PVT-D), out-of-pocket expenditure (OOPS) per Capita in US dollars, and voluntary health insurance (VHI) as a percentage of current health expenditure (CHE) are the key factors influencing UHC across the three economic blocks. Our findings have implications for drafting health and finance sector public policies, such as providing affordable social health insurance to the weaker sections of the population, making insurance premiums less expensive and affordable for the masses, and designing healthcare financing policies that are beneficial to the masses. UHC is an important determinant of health for all and requires an in-depth analysis of related factors. Policymakers are often faced with the challenge of prioritizing the economic needs of sectors such as education and food safety, making it difficult for healthcare to receive its due share. In this context, this article attempts to identify the key components that may influence the attainment of UHC and enable policy changes to address them more effectively and efficiently.",2022,10.3389/frai.2022.887225
Robot Gaze Behavior Affects Honesty in Human-Robot Interaction,"As the use of humanoid robots proliferates, an increasing amount of people may find themselves face-to-“face” with a robot in everyday life. Although there is a plethora of information available on facial social cues and how we interpret them in the field of human-human social interaction, we cannot assume that these findings flawlessly transfer to human-robot interaction. Therefore, more research on facial cues in human-robot interaction is required. This study investigated deception in human-robot interaction context, focusing on the effect that eye contact with a robot has on honesty toward this robot. In an iterative task, participants could assist a humanoid robot by providing it with correct information, or potentially secure a reward for themselves by providing it with incorrect information. Results show that participants are increasingly honest after the robot establishes eye contact with them, but only if this is in response to deceptive behavior. Behavior is not influenced by the establishment of eye contact if the participant is actively engaging in honest behavior. These findings support the notion that humanoid robots can be perceived as, and treated like, social agents, since the herein described effect mirrors one present in human-human social interaction.",2021,10.3389/frai.2021.663190
Fitting a collider in a quantum computer: tackling the challenges of quantum machine learning for big datasets,"Current quantum systems have significant limitations affecting the processing of large datasets with high dimensionality, typical of high energy physics. In the present paper, feature and data prototype selection techniques were studied to tackle this challenge. A grid search was performed and quantum machine learning models were trained and benchmarked against classical shallow machine learning methods, trained both in the reduced and the complete datasets. The performance of the quantum algorithms was found to be comparable to the classical ones, even when using large datasets. Sequential Backward Selection and Principal Component Analysis techniques were used for feature's selection and while the former can produce the better quantum machine learning models in specific cases, it is more unstable. Additionally, we show that such variability in the results is caused by the use of discrete variables, highlighting the suitability of Principal Component analysis transformed data for quantum machine learning applications in the high energy physics context.",2023,10.3389/frai.2023.1268852
Estimating daily semantic segmentation maps of classified ocean eddies using sea level anomaly data from along-track altimetry,"Mesoscale eddies, which are fast-moving rotating water bodies in the ocean with horizontal scales ranging from 10 km to 100 km and above, are considered to be the weather of the oceans. They are of interest to marine biologists, oceanographers, and geodesists for their impact on water mass, heat, and nutrient transport. Typically, gridded sea level anomaly maps processed from multiple radar altimetry missions are used to detect eddies. However, multi-mission sea level anomaly maps obtained by the operational processors have a lower effective spatiotemporal resolution than their grid spacing and temporal resolution, leading to inaccurate eddy detection. In this study, we investigate the use of higher-resolution along-track sea level anomaly data to infer daily two-dimensional segmentation maps of cyclonic, anticyclonic, or non-eddy areas with greater accuracy than using processed sea level anomaly grid map products. To tackle this challenge, we propose a deep neural network that uses spatiotemporal contextual information within the modality of along-track data. This network is capable of producing a two-dimensional segmentation map from data with varying sparsity. We have developed an architecture called Teddy, which uses a Transformer module to encode and process spatiotemporal information, and a sparsity invariant CNN to infer a two-dimensional segmentation map of classified eddies from the ground tracks of varying sparsity on the considered region. Our results show that Teddy creates two-dimensional maps of classified eddies from along-track data with higher accuracy and timeliness when compared to commonly used methods that work with less accurate preprocessed sea level anomaly grid maps. We train and test our method with a carefully curated and independent dataset, which can be made available upon request.",2024,10.3389/frai.2024.1298283
Benchmarking Perturbation-Based Saliency Maps for Explaining Atari Agents,"One of the most prominent methods for explaining the behavior of Deep Reinforcement Learning (DRL) agents is the generation of saliency maps that show how much each pixel attributed to the agents' decision. However, there is no work that computationally evaluates and compares the fidelity of different perturbation-based saliency map approaches specifically for DRL agents. It is particularly challenging to computationally evaluate saliency maps for DRL agents since their decisions are part of an overarching policy, which includes long-term decision making. For instance, the output neurons of value-based DRL algorithms encode both the value of the current state as well as the expected future reward after doing each action in this state. This ambiguity should be considered when evaluating saliency maps for such agents. In this paper, we compare five popular perturbation-based approaches to create saliency maps for DRL agents trained on four different Atari 2,600 games. The approaches are compared using two computational metrics: dependence on the learned parameters of the underlying deep Q-network of the agents (sanity checks) and fidelity to the agents' reasoning (input degradation). During the sanity checks, we found that a popular noise-based saliency map approach for DRL agents shows little dependence on the parameters of the output layer. We demonstrate that this can be fixed by tweaking the algorithm such that it focuses on specific actions instead of the general entropy within the output values. For fidelity, we identify two main factors that influence which saliency map approach should be chosen in which situation. Particular to value-based DRL agents, we show that analyzing the agents' choice of action requires different saliency map approaches than analyzing the agents' state value estimation.",2022,10.3389/frai.2022.903875
First Organoid Intelligence (OI) workshop to form an OI community,"The brain is arguably the most powerful computation system known. It is extremely efficient in processing large amounts of information and can discern signals from noise, adapt, and filter faulty information all while running on only 20 watts of power. The human brain's processing efficiency, progressive learning, and plasticity are unmatched by any computer system. Recent advances in stem cell technology have elevated the field of cell culture to higher levels of complexity, such as the development of three-dimensional (3D) brain organoids that recapitulate human brain functionality better than traditional monolayer cell systems. Organoid Intelligence (OI) aims to harness the innate biological capabilities of brain organoids for biocomputing and synthetic intelligence by interfacing them with computer technology. With the latest strides in stem cell technology, bioengineering, and machine learning, we can explore the ability of brain organoids to compute, and store given information (input), execute a task (output), and study how this affects the structural and functional connections in the organoids themselves. Furthermore, understanding how learning generates and changes patterns of connectivity in organoids can shed light on the early stages of cognition in the human brain. Investigating and understanding these concepts is an enormous, multidisciplinary endeavor that necessitates the engagement of both the scientific community and the public. Thus, on Feb 22–24 of 2022, the Johns Hopkins University held the first Organoid Intelligence Workshop to form an OI Community and to lay out the groundwork for the establishment of OI as a new scientific discipline. The potential of OI to revolutionize computing, neurological research, and drug development was discussed, along with a vision and roadmap for its development over the coming decade.",2023,10.3389/frai.2023.1116870
Toward a Knowledge-Based System for African Traditional Herbal Medicine: A Design Science Research Approach,"This article illustrates a design approach for capturing, storing, indexing, and search of African traditional herbal medicine (ATHMed) framed on a hybrid-based knowledge model for efficient preservation and retrieval. By the hybrid approach, the framework was developed to include both the use of machine learning and ontology-based techniques. The search pattern considers ontology design and machine learning techniques for extracting ATHMed data. The framework operates on a semantically annotated corpus and delivers a contextual and multi-word search pattern against its knowledge base. In line with design science research, preliminary data were collected in this study, and a proposed strategy was developed toward processing, storing and retrieving data. While reviewing literature and interview data to reflect on the existing challenges, these findings suggest the need for a system with the capability of retrieving and archiving ATHMed in Ghana. This study contributes to SDG 3 by providing a model and conceptualizing the implementation of ATHMed. We, therefore, envision that the framework will be adopted by relevant stakeholders for the implementation of efficient systems for archival and retrieval of ATHMed.",2022,10.3389/frai.2022.856705
Graph Learning for Fake Review Detection,"Fake reviews have become prevalent on various social networks such as e-commerce and social media platforms. As fake reviews cause a heavily negative influence on the public, timely detection and response are of great significance. To this end, effective fake review detection has become an emerging research area that attracts increasing attention from various disciplines like network science, computational social science, and data science. An important line of research in fake review detection is to utilize graph learning methods, which incorporate both the attribute features of reviews and their relationships into the detection process. To further compare these graph learning methods in this paper, we conduct a detailed survey on fake review detection. The survey presents a comprehensive taxonomy and covers advancements in three high-level categories, including fake review detection, fake reviewer detection, and fake review analysis. Different kinds of fake reviews and their corresponding examples are also summarized. Furthermore, we discuss the graph learning methods, including supervised and unsupervised learning approaches for fake review detection. Specifically, we outline the unsupervised learning approach that includes generation-based and contrast-based methods, respectively. In view of the existing problems in the current methods and data, we further discuss some challenges and open issues in this field, including the imperfect data, explainability, model efficiency, and lightweight models.",2022,10.3389/frai.2022.922589
RECLAIM: Toward a New Era of Refurbishment and Remanufacturing of Industrial Equipment,"Refurbishment and remanufacturing are the industrial processes whereby used products or parts that constitute the product are restored. Remanufacturing is the process of restoring the functionality of the product or a part of it to “as-new” quality, whereas refurbishment is the process of restoring the product itself or part of it to “like-new” quality, without being as thorough as remanufacturing. Within this context, the EU-funded project RECLAIM presents a new idea on refurbishment and remanufacturing based on big data analytics, machine learning, predictive analytics, and optimization models using deep learning techniques and digital twin models with the aim of enabling the stakeholders to make informed decisions about whether to remanufacture, upgrade, or repair heavy machinery that is toward its end-of-life. The RECLAIM project additionally provides novel strategies and technologies that enable the reuse of industrial equipment in old, renewed, and new factories, with the goal of saving valuable resources by recycling equipment and using them in a different application, instead of discarding them after use. For instance, RECLAIM provides a simulation engine using digital twin in order to predict maintenance needs and potential faults of large industrial equipment. This simulation engine keeps the virtual twins available to store all available information during the lifetime of a machine, such as maintenance operations, and this information can be used to perform an economic estimation of the machine's refurbishment costs. The RECLAIM project envisages developing new technologies and strategies aligned with the circular economy and in support of a new model for the management of large industrial equipment that approaches the end of its design life. This model aims to reduce substantially the opportunity cost of retaining strategies (both moneywise and resourcewise) by allowing relatively old equipment that faces the prospect of decommissioning to reclaim its functionalities and role in the overall production system.",2021,10.3389/frai.2020.570562
Human-centricity in AI governance: A systemic approach,"Human-centricity is considered a central aspect in the development and governance of artificial intelligence (AI). Various strategies and guidelines highlight the concept as a key goal. However, we argue that current uses of Human-Centered AI (HCAI) in policy documents and AI strategies risk downplaying promises of creating desirable, emancipatory technology that promotes human wellbeing and the common good. Firstly, HCAI, as it appears in policy discourses, is the result of aiming to adapt the concept of human-centered design (HCD) to the public governance context of AI but without proper reflection on how it should be reformed to suit the new task environment. Second, the concept is mainly used in reference to realizing human and fundamental rights, which are necessary, but not sufficient for technological emancipation. Third, the concept is used ambiguously in policy and strategy discourses, making it unclear how it should be operationalized in governance practices. This article explores means and approaches for using the HCAI approach for technological emancipation in the context of public AI governance. We propose that the potential for emancipatory technology development rests on expanding the traditional user-centered view of technology design to involve community- and society-centered perspectives in public governance. Developing public AI governance in this way relies on enabling inclusive governance modalities that enhance the social sustainability of AI deployment. We discuss mutual trust, transparency, communication, and civic tech as key prerequisites for socially sustainable and human-centered public AI governance. Finally, the article introduces a systemic approach to ethically and socially sustainable, human-centered AI development and deployment.",2023,10.3389/frai.2023.976887
Real-time crop row detection using computer vision- application in agricultural robots,"The goal of achieving autonomous navigation for agricultural robots poses significant challenges, mostly arising from the substantial natural variations in crop row images as a result of weather conditions and the growth stages of crops. The processing of the detection algorithm also must be significantly low for real-time applications. In order to address the aforementioned requirements, we propose a crop row detection algorithm that has the following features: Firstly, a projective transformation is applied to transform the camera view and a color-based segmentation is employed to distinguish crop and weed from the background. Secondly, a clustering algorithm is used to differentiate between the crop and weed pixels. Lastly, a robust line-fitting approach is implemented to detect crop rows. The proposed algorithm is evaluated throughout a diverse range of scenarios, and its efficacy is assessed in comparison to four distinct existing solutions. The algorithm achieves an overall intersection over union (IOU) of 0.73 and exhibits robustness in challenging scenarios with high weed growth. The experiments conducted on real-time video featuring challenging scenarios show that our proposed algorithm exhibits a detection accuracy of over 90% and is a viable option for real-time implementation. With the high accuracy and low inference time, the proposed methodology offers a viable solution for autonomous navigation of agricultural robots in a crop field without damaging the crop and thus can serve as a foundation for future research.",2024,10.3389/frai.2024.1435686
"How Are Patented AI, Software and Robot Technologies Related to Wage Changes in the United States?","We analyze the relationships of three different types of patented technologies, namely artificial intelligence, software and industrial robots, with individual-level wage changes in the United States from 2011 to 2021. The aim of the study is to investigate if the availability of AI technologies is associated with increases or decreases in individual workers' wages and how this association compares to previous innovations related to software and industrial robots. Our analysis is based on available indicators extracted from the text of patents to measure the exposure of occupations to these three types of technologies. We combine data on individual wages for the United States with the new technology measures and regress individual annual wage changes on these measures controlling for a variety of other factors. Our results indicate that innovations in software and industrial robots are associated with wage decreases, possibly indicating a large displacement effect of these technologies on human labor. On the contrary, for innovations in AI, we find wage increases, which may indicate that productivity effects and effects coming from the creation of new human tasks are larger than displacement effects of AI. AI exposure is associated with positive wage changes in services, whereas exposure to robots is associated with negative wage changes in manufacturing. The relationship of the AI exposure measure with wage increases has become stronger in 2016–2021 in comparison to the 5 years before.JEL Classification: J24, J31, O33.",2022,10.3389/frai.2022.869282
"AI Technologies, Privacy, and Security","Privacy remains one of the most recurrent concerns that people have about AI technologies. The meaning of the concept of “privacy” has proven to be fairly elusive. Accordingly, the concerns people have about privacy are often vague and ill-formed, which makes it correspondingly difficult to address these concerns, and to explain the ways in which AI technologies do or do not pose threats to people's interests. In this article, we draw attention to some important distinctions that are frequently overlooked, and spell out their implications for concerns about the threats that AI-related technology poses for privacy. We argue that, when people express concerns about privacy in relation to AI technologies, they are usually referring to security interests rather than interests in privacy per se. Nevertheless, we argue that focusing primarily on security interests misses the importance that interests in privacy per se have through their contribution to autonomy and the development of our identities. Improving insight about these issues can make it easier for the developers of AI technologies to provide explanations for users about what interests are and are not at stake through the use of AI systems.",2022,10.3389/frai.2022.826737
A review on the efficacy of artificial intelligence for managing anxiety disorders,"Anxiety disorders are psychiatric conditions characterized by prolonged and generalized anxiety experienced by individuals in response to various events or situations. At present, anxiety disorders are regarded as the most widespread psychiatric disorders globally. Medication and different types of psychotherapies are employed as the primary therapeutic modalities in clinical practice for the treatment of anxiety disorders. However, combining these two approaches is known to yield more significant benefits than medication alone. Nevertheless, there is a lack of resources and a limited availability of psychotherapy options in underdeveloped areas. Psychotherapy methods encompass relaxation techniques, controlled breathing exercises, visualization exercises, controlled exposure exercises, and cognitive interventions such as challenging negative thoughts. These methods are vital in the treatment of anxiety disorders, but executing them proficiently can be demanding. Moreover, individuals with distinct anxiety disorders are prescribed medications that may cause withdrawal symptoms in some instances. Additionally, there is inadequate availability of face-to-face psychotherapy and a restricted capacity to predict and monitor the health, behavioral, and environmental aspects of individuals with anxiety disorders during the initial phases. In recent years, there has been notable progress in developing and utilizing artificial intelligence (AI) based applications and environments to improve the precision and sensitivity of diagnosing and treating various categories of anxiety disorders. As a result, this study aims to establish the efficacy of AI-enabled environments in addressing the existing challenges in managing anxiety disorders, reducing reliance on medication, and investigating the potential advantages, issues, and opportunities of integrating AI-assisted healthcare for anxiety disorders and enabling personalized therapy.",2024,10.3389/frai.2024.1435895
Vision-language models for medical report generation and visual question answering: a review,"Medical vision-language models (VLMs) combine computer vision (CV) and natural language processing (NLP) to analyze visual and textual medical data. Our paper reviews recent advancements in developing VLMs specialized for healthcare, focusing on publicly available models designed for medical report generation and visual question answering (VQA). We provide background on NLP and CV, explaining how techniques from both fields are integrated into VLMs, with visual and language data often fused using Transformer-based architectures to enable effective learning from multimodal data. Key areas we address include the exploration of 18 public medical vision-language datasets, in-depth analyses of the architectures and pre-training strategies of 16 recent noteworthy medical VLMs, and comprehensive discussion on evaluation metrics for assessing VLMs' performance in medical report generation and VQA. We also highlight current challenges facing medical VLM development, including limited data availability, concerns with data privacy, and lack of proper evaluation metrics, among others, while also proposing future directions to address these obstacles. Overall, our review summarizes the recent progress in developing VLMs to harness multimodal medical data for improved healthcare applications.",2024,10.3389/frai.2024.1430984
Topological Data Analysis Highlights Novel Geographical Signatures of the Human Gut Microbiome,"Background: There is growing interest in the connection between the gut microbiome and human health and disease. Conventional approaches to analyse microbiome data typically entail dimensionality reduction and assume linearity of the observed relationships, however, the microbiome is a highly complex ecosystem marked by non-linear relationships. In this study, we use topological data analysis (TDA) to explore differences and similarities between the gut microbiome across several countries.Methods: We used curated adult microbiome data at the genus level from the GMrepo database. The dataset contains OTU and demographical data of over 4,400 samples from 19 studies, spanning 12 countries. We analysed the data with tmap, an integrative framework for TDA specifically designed for stratification and enrichment analysis of population-based gut microbiome datasets.Results: We find associations between specific microbial genera and groups of countries. Specifically, both the USA and UK were significantly co-enriched with the proinflammatory genera Lachnoclostridium and Ruminiclostridium, while France and New Zealand were co-enriched with other, butyrate-producing, taxa of the order Clostridiales.Conclusion: The TDA approach demonstrates the overlap and distinctions of microbiome composition between and within countries. This yields unique insights into complex associations in the dataset, a finding not possible with conventional approaches. It highlights the potential utility of TDA as a complementary tool in microbiome research, particularly for large population-scale datasets, and suggests further analysis on the effects of diet and other regionally varying factors.",2021,10.3389/frai.2021.680564
"A survey of COVID-19 detection and prediction approaches using mobile devices, AI, and telemedicine","Since 2019, the COVID-19 pandemic has had an extremely high impact on all facets of the society and will potentially have an everlasting impact for years to come. In response to this, over the past years, there have been a significant number of research efforts on exploring approaches to combat COVID-19. In this paper, we present a survey of the current research efforts on using mobile Internet of Thing (IoT) devices, Artificial Intelligence (AI), and telemedicine for COVID-19 detection and prediction. We first present the background and then present current research in this field. Specifically, we present the research on COVID-19 monitoring and detection, contact tracing, machine learning based approaches, telemedicine, and security. We finally discuss the challenges and the future work that lay ahead in this field before concluding this paper.",2022,10.3389/frai.2022.1034732
Interactive network visualization of opioid crisis research: a tool for reinforcing data linkage skills for public health policy researchers,"BackgroundPublic health policy researchers face a persistent challenge in identifying and integrating relevant data, particularly in the context of the U.S. opioid crisis, where a comprehensive approach is crucial.PurposeTo meet this new workforce demand health policy and health economics programs are increasingly introducing data analysis and data visualization skills. Such skills facilitate data integration and discovery by linking multiple resources. Common linking strategies include individual or aggregate level linking (e.g., patient identifiers) in primary clinical data and conceptual linking (e.g., healthcare workforce, state funding, burnout rates) in secondary data. Often, the combination of primary and secondary datasets is sought, requiring additional skills, for example, understanding metadata and constructing interlinkages.MethodsTo help improve those skills, we developed a 2-step process using a scoping method to discover data and network visualization to interlink metadata. Results: We show how these new skills enable the discovery of relationships among data sources pertinent to public policy research related to the opioid overdose crisis and facilitate inquiry across heterogeneous data resources. In addition, our interactive network visualization introduces (1) a conceptual approach, drawing from recent systematic review studies and linked by the publications, and (2) an aggregate approach, constructed using publicly available datasets and linked through crosswalks.ConclusionsThese novel metadata visualization techniques can be used as a teaching tool or a discovery method and can also be extended to other public policy domains.",2024,10.3389/frai.2024.1208874
Image sequence sorting algorithm for commercial tasks,"IntroductionThe sorting of sequences of images is crucial for augmenting user engagement in various virtual commercial platforms, particularly within the real estate sector. A coherent sequence of images respecting room type categorization significantly enhances the intuitiveness and seamless navigation of potential customers through listings.MethodsThis study methodically formalizes the challenge of image sequence sorting and expands its applicability by framing it as an ordering problem. The complexity lies in devising a universally applicable solution due to computational demands and impracticality of exhaustive searches for optimal sequencing. To tackle this, our proposed algorithm employs a shortest path methodology grounded in semantic similarity between images. Tailored specifically for the real estate sector, it evaluates diverse similarity metrics to efficiently arrange images. Additionally, we introduce a genetic algorithm to optimize the selection of semantic features considered by the algorithm, further enhancing its effectiveness.ResultsEmpirical evidence from our dataset demonstrates the efficacy of the proposed methodology. It successfully organizes images in an optimal sequence across 85% of the listings, showcasing its effectiveness in enhancing user experience in virtual commercial platforms, particularly in real estate.ConclusionThis study presents a novel approach to sorting sequences of images in virtual commercial platforms, particularly beneficial for the real estate sector. The proposed algorithm effectively enhances user engagement by providing more intuitive and visually coherent image arrangements.",2024,10.3389/frai.2024.1382566
"Adapting emotional support in teams: productivity, emotional stability, and conscientiousness","Students' mental health has received increased attention in recent years: reports of worsened mental health among higher education students call for new ways to support them in their college years. Educational demands are among the concerns that students report, such as the stress of academic performance, the stress related to examinations and the pressure to succeed. One aspect often present in higher education is group work. Group work can be truly beneficial for learning, but it often causes additional stress to students. The present research contributes to the design of a peer assessment tool to support students during group work. In this tool, each student is asked to rate their teammates on several aspects of group work, and a virtual agent delivers support statements in response to such ratings. For the support statements to be appropriate, the virtual agent should adapt them to the recipient and the group work situation they are experiencing. We investigate the adaptation of emotional support statements to the student's personality trait of Conscientiousness and the score assigned to a teammate on one aspect of teamwork, Productivity. The resulting algorithm is then combined with related work on Emotional Stability, and a final algorithm considering both dimensions is created.",2025,10.3389/frai.2025.1449176
"ICT Enabled Disease Diagnosis, Treatment and Management—A Holistic Cost-Effective Approach Through Data Management and Analysis in UAE and India","This concept paper addresses specific challenges identified in the UN 2030 Agenda Sustainable Development Goals (SDG) as well as the National Health Policy of India (NHP-India) and the Ministry of Health Policy of UAE (MHP-UAE). This policy calls for a digital health technology ecosystem. SDG Goal 1 and its related objectives are conceptualized which serves as the foundation for Virtual Consultations, Tele-pharmacy, Virtual Storage, and Virtual Community (VCom). SDG Goals 2 and 3 are conceptualized as Data Management &amp; Analytical (DMA) Architecture. Individual researchers and health care professionals in India and the UAE can use DMA to uncover and harness PHC and POC data into practical insights. In addition, the DMA would provide a set of core tools for cross-network initiatives, allowing researchers and other users to compare their data with DMA data. In rural, urban, and remote populations of the UAE and India, the concept augments the PHC system with ICT-based interventions. The ICT-based interventions may improve patient health outcomes. The open and flexible design allows users to access various digital materials. Extendable data/metadata format, scalable architecture for petabyte-scale federated discovery. The modular DMA is designed using existing technology and resources. Public health functions include population health assessment, policy development, and monitoring policy implementation. PHC and POC periodically conduct syndromic surveillance to identify population risk patterns. In addition, the PHC and POC deploy medical and non-medical preventive measures to prevent disease outbreaks. To assess the impact of social and economic factors on health, epidemiologists must first understand diseases. Improved health due to compliance with holistic disease treatment plans and access to scientific health information.",2022,10.3389/frai.2022.909101
Three-dimensional visualization and navigation for micro-noninvasive uterine fibroid surgery based on MRI and ultrasound image fusion,"ObjectiveTo address the challenges of low surgical precision and poor consistency in focused ultrasound ablation surgery (FUAS) for uterine fibroids, which are often caused by variations in clinical experience and operator fatigue, this study aims to develop an intelligent three-dimensional (3D) visualization and navigation system by integrating magnetic resonance imaging (MRI) with real-time ultrasound (US) imaging, thereby improving the accuracy and efficiency of uterine fibroid surgery.MethodsMRI and US images from 638 patients were annotated by experienced clinicians. The nnU-Net algorithm was used for preoperative segmentation and 3D reconstruction of MRI images to provide detailed visualization of fibroid morphology. The YOLACT model was applied to achieve rapid delineation of the uterus and key anatomical structures in real-time US images. To enhance the accuracy of lesion localization and navigation, the Iterative Closest Point (ICP) algorithm was employed for the registration of preoperative MRI with intraoperative US images.Results and discussionExperimental results demonstrated that the system achieved a Dice Similarity Coefficient (DSC) exceeding 90% for the segmentation and identification of anatomical structures such as the uterus and fibroids. The YOLACT model achieved an accuracy greater than 95% in identifying key structures in real-time US images. In 90% of the cases, the system enabled efficient and precise tracking; however, approximately 5% of the cases required manual adjustment due to discrepancies between patient anatomy and preoperative MRI data. The proposed intelligent navigation system, based on MRI–US image fusion, offers an efficient and automated solution for FUAS in treating uterine fibroids, significantly improving surgical precision and operational efficiency. This system demonstrates strong clinical applicability. Future research will focus on enhancing the adaptability of the system, particularly in addressing challenges such as significant tissue deformation and occlusion, to improve its robustness and applicability in complex clinical scenarios.",2025,10.3389/frai.2025.1613960
Perceptions of health data commodification in AI-driven healthcare systems in Saudi Arabia,"Introduction
                    Artificial Intelligence (AI) is transforming healthcare service delivery through predictive analytics, precision medicine, and advanced diagnostics. However, the commodification of health data introduces complex ethical and social challenges related to privacy, ownership, and consent. This study explores perceptions of health data commodification within AI-driven healthcare systems, focusing on Saudi Arabia’s rapidly evolving digital healthcare landscape.
                  
                  
                    Methods
                    A mixed-methods approach was employed, combining quantitative surveys and in-depth qualitative interviews. The study included 42 patients, 8 healthcare professionals, 3 insurance representatives, and 4 AI experts. Data were collected across three main themes: data privacy, perceived benefits of AI, and attitudes toward data commodification. Quantitative data were analyzed descriptively, while qualitative responses were examined thematically.
                  
                  
                    Results
                    Findings reveal that 61.9% of patients consider health data a form of personal property, while 59.5% feel they have limited control over how their data are used. A significant trust deficit was observed, with 50% expressing low confidence in AI systems’ ability to protect privacy, particularly among older participants. Financial incentives strongly influenced willingness to share data, with 81% agreeing to share their data if compensated. Furthermore, 64.3% supported the sale of anonymized data by healthcare providers to technology companies, provided adequate safeguards are in place.
                  
                  
                    Discussion
                    These insights underscore the urgent need for robust regulatory frameworks emphasizing informed consent, transparency, and ethical governance in AI healthcare systems. The study highlights the importance of patient-centered policies, equitable compensation mechanisms, and enhanced training and awareness programs to build public trust and ensure responsible AI adoption. By addressing these ethical and governance challenges, policymakers can align technological innovation with equity, privacy, and the principles of ethical healthcare delivery.",2025,10.3389/frai.2025.1559302
Deception detection in educational AI: challenges for Japanese middle school students in interacting with generative AI robots,"Educational materials that utilize generative AI (e.g., ChatGPT) have been developed, thus, allowing students to learn through conversations with robots or agents. However, if these artificial entities provide incorrect information (hallucinating), it could lead to confusion among students. To investigate whether students can detect lies from these artificial entities, we conducted an experiment using the social robot Furhat and we make it engage in various types of deceptive interactions. Twenty-two Japanese middle school students participated in ten teaching sessions with Furhat using a human and an anime facial appearances while employing different types of deception: Lying, Paltering, Pandering, and Bullshit. The results revealed that the majority of students were deceived by those lies. Additionally, the robot's facial appearance (i.e., social agency) affected both the learning effectiveness and the likelihood of being deceived. We conclude that an anime robot face is recommended to be used as it excelled in learning effectiveness as it attracts students attention. An anime face also provided protection against deceptive techniques due to its low social agency which leads to ineffectiveness in persuasion and deception. This study underscores the importance of preparing AI-based educational tools and scripts carefully to prevent the dissemination of false information produced through generative AI hallucinations to students.",2024,10.3389/frai.2024.1493348
Stochastic Learning in Kolkata Paise Restaurant Problem: Classical and Quantum Strategies,"We review the results for stochastic learning strategies, both classical (one-shot and iterative) and quantum (one-shot only), for optimizing the available many-choice resources among a large number of competing agents, developed over the last decade in the context of the Kolkata Paise Restaurant (KPR) Problem. Apart from few rigorous and approximate analytical results, both for classical and quantum strategies, most of the interesting results on the phase transition behavior (obtained so far for the classical model) uses classical Monte Carlo simulations. All these including the applications to computer science [job or resource allotments in Internet-of-Things (IoT)], transport engineering (online vehicle hire problems), operation research (optimizing efforts for delegated search problem, efficient solution of Traveling Salesman problem) will be discussed.",2022,10.3389/frai.2022.874061
Enhancing breast cancer treatment selection through 2TLIVq-ROFS-based multi-attribute group decision making,"IntroductionBreast cancer is an extremely common and potentially fatal illness that impacts millions of women worldwide. Multiple criteria and inclinations must be taken into account when selecting the optimal treatment option for each patient.MethodsThe selection of breast cancer treatments can be modeled as a multi-attribute group decision-making (MAGDM) problem, in which a group of experts evaluate and rank alternative treatments based on multiple attributes. MAGDM methods can aid in enhancing the quality and efficacy of breast cancer treatment selection decisions. For this purpose, we introduce the concept of a 2-tuple linguistic interval-valued q-rung orthopair fuzzy set (2TLIVq-ROFS), a new development in fuzzy set theory that incorporates the characteristics of interval-valued q-rung orthopair fuzzy set (IVq-ROFS) and 2-tuple linguistic terms. It can express the quantitative and qualitative aspects of uncertain information, as well as the decision-makers' level of satisfaction and dissatisfaction.ResultsThen, the 2TLIVq-ROF weighted average (2TLIVq-ROFWA) operator and the 2TLIVq-ROF weighted geometric (2TLIVq-ROFWJ) operator are introduced as two new aggregation operators. In addition, the multi-attribute border approximation area comparison (MABAC) method is extended to solve the MAGDM problem with 2TLIVq-ROF information.DiscussionTo demonstrate the efficacy and applicability of the suggested model, a case study of selecting the optimal breast cancer treatment is presented. The results of the computations show that the suggested MAGDM model is able to handle imprecision and subjectivity in complicated decision-making scenarios and opens new research scenarios for scholars.",2024,10.3389/frai.2024.1402719
Stochastic Learning in Kolkata Paise Restaurant Problem: Classical and Quantum Strategies,"We review the results for stochastic learning strategies, both classical (one-shot and iterative) and quantum (one-shot only), for optimizing the available many-choice resources among a large number of competing agents, developed over the last decade in the context of the Kolkata Paise Restaurant (KPR) Problem. Apart from few rigorous and approximate analytical results, both for classical and quantum strategies, most of the interesting results on the phase transition behavior (obtained so far for the classical model) uses classical Monte Carlo simulations. All these including the applications to computer science [job or resource allotments in Internet-of-Things (IoT)], transport engineering (online vehicle hire problems), operation research (optimizing efforts for delegated search problem, efficient solution of Traveling Salesman problem) will be discussed.",2022,10.3389/frai.2022.874061
Personalized bundle recommendation using preference elicitation and the Choquet integral,"Bundle recommendation aims to generate bundles of associated products that users tend to consume as a whole under certain circumstances. Modeling the bundle utility for users is a non-trivial task, as it requires to account for the potential interdependencies between bundle attributes. To address this challenge, we introduce a new preference-based approach for bundle recommendation exploiting the Choquet integral. This allows us to formalize preferences for coalitions of environmental-related attributes, thus recommending product bundles accounting for synergies among product attributes. An experimental evaluation of a dataset of local food products in Northern Italy shows how the Choquet integral allows the natural formalization of a sensible notion of environmental friendliness and that standard approaches based on weighted sums of attributes end up recommending bundles with lower environmental friendliness even if weights are explicitly learned to maximize it. We further show how preference elicitation strategies can be leveraged to acquire weights of the Choquet integral from user feedback in terms of preferences over candidate bundles, and show how a handful of queries allow to recommend optimal bundles for a diverse set of user prototypes.",2024,10.3389/frai.2024.1346684
Twitter data emotion analysis using Hadoop and metaheuristic optimized Graphical Neural Network,"This study applies the Hive framework within the Hadoop ecosystem for sentiment classification, focusing on emotion analysis of X data. After outlining Hadoop’s core advantages in large-scale unstructured data processing, the study focuses on using a Graphical Neural Network (GNN) for sentiment categorization of Twitter comments. To address the suboptimal performance of traditional GNNs due to trial-and-error hyperparameter tuning, the study introduces the Modified Elephant Herd Optimization (MEHO) algorithm—improved version of the standard EHO, to optimize the network’s weight parameters, hyperparameters, and feature subsets, ensuring a balance between exploration and exploitation. An automated dataset construction system has also been developed to reduce manual labeling effort and ensure consistency. Preprocessing techniques, including information entropy–based phrase ranking, further enhance data quality. To capture both semantic and statistical features of tweets, feature extraction methods such as Term Frequency–Inverse Document Frequency (TF–IDF) and Bag of Words (BoW) are integrated. Experimental results demonstrate that MEHO reduces premature convergence by 40% and improves classification accuracy by 6.1% compared with the standard EHO algorithm. The automated labeling system decreases manual effort by 80%, while entropy-based preprocessing increases phrase difficulty classification accuracy by 7%. This study provides an effective solution for social media emotion analysis; future research will explore multi-modal data fusion and optimize MEHO’s convergence speed for ultra-large feature sets.",2025,10.3389/frai.2025.1672252
Three-dimensional visualization and navigation for micro-noninvasive uterine fibroid surgery based on MRI and ultrasound image fusion,"ObjectiveTo address the challenges of low surgical precision and poor consistency in focused ultrasound ablation surgery (FUAS) for uterine fibroids, which are often caused by variations in clinical experience and operator fatigue, this study aims to develop an intelligent three-dimensional (3D) visualization and navigation system by integrating magnetic resonance imaging (MRI) with real-time ultrasound (US) imaging, thereby improving the accuracy and efficiency of uterine fibroid surgery.MethodsMRI and US images from 638 patients were annotated by experienced clinicians. The nnU-Net algorithm was used for preoperative segmentation and 3D reconstruction of MRI images to provide detailed visualization of fibroid morphology. The YOLACT model was applied to achieve rapid delineation of the uterus and key anatomical structures in real-time US images. To enhance the accuracy of lesion localization and navigation, the Iterative Closest Point (ICP) algorithm was employed for the registration of preoperative MRI with intraoperative US images.Results and discussionExperimental results demonstrated that the system achieved a Dice Similarity Coefficient (DSC) exceeding 90% for the segmentation and identification of anatomical structures such as the uterus and fibroids. The YOLACT model achieved an accuracy greater than 95% in identifying key structures in real-time US images. In 90% of the cases, the system enabled efficient and precise tracking; however, approximately 5% of the cases required manual adjustment due to discrepancies between patient anatomy and preoperative MRI data. The proposed intelligent navigation system, based on MRI–US image fusion, offers an efficient and automated solution for FUAS in treating uterine fibroids, significantly improving surgical precision and operational efficiency. This system demonstrates strong clinical applicability. Future research will focus on enhancing the adaptability of the system, particularly in addressing challenges such as significant tissue deformation and occlusion, to improve its robustness and applicability in complex clinical scenarios.",2025,10.3389/frai.2025.1613960
Perceptions of health data commodification in AI-driven healthcare systems in Saudi Arabia,"Introduction
                    Artificial Intelligence (AI) is transforming healthcare service delivery through predictive analytics, precision medicine, and advanced diagnostics. However, the commodification of health data introduces complex ethical and social challenges related to privacy, ownership, and consent. This study explores perceptions of health data commodification within AI-driven healthcare systems, focusing on Saudi Arabia’s rapidly evolving digital healthcare landscape.
                  
                  
                    Methods
                    A mixed-methods approach was employed, combining quantitative surveys and in-depth qualitative interviews. The study included 42 patients, 8 healthcare professionals, 3 insurance representatives, and 4 AI experts. Data were collected across three main themes: data privacy, perceived benefits of AI, and attitudes toward data commodification. Quantitative data were analyzed descriptively, while qualitative responses were examined thematically.
                  
                  
                    Results
                    Findings reveal that 61.9% of patients consider health data a form of personal property, while 59.5% feel they have limited control over how their data are used. A significant trust deficit was observed, with 50% expressing low confidence in AI systems’ ability to protect privacy, particularly among older participants. Financial incentives strongly influenced willingness to share data, with 81% agreeing to share their data if compensated. Furthermore, 64.3% supported the sale of anonymized data by healthcare providers to technology companies, provided adequate safeguards are in place.
                  
                  
                    Discussion
                    These insights underscore the urgent need for robust regulatory frameworks emphasizing informed consent, transparency, and ethical governance in AI healthcare systems. The study highlights the importance of patient-centered policies, equitable compensation mechanisms, and enhanced training and awareness programs to build public trust and ensure responsible AI adoption. By addressing these ethical and governance challenges, policymakers can align technological innovation with equity, privacy, and the principles of ethical healthcare delivery.",2025,10.3389/frai.2025.1559302
"ICT Enabled Disease Diagnosis, Treatment and Management—A Holistic Cost-Effective Approach Through Data Management and Analysis in UAE and India","This concept paper addresses specific challenges identified in the UN 2030 Agenda Sustainable Development Goals (SDG) as well as the National Health Policy of India (NHP-India) and the Ministry of Health Policy of UAE (MHP-UAE). This policy calls for a digital health technology ecosystem. SDG Goal 1 and its related objectives are conceptualized which serves as the foundation for Virtual Consultations, Tele-pharmacy, Virtual Storage, and Virtual Community (VCom). SDG Goals 2 and 3 are conceptualized as Data Management &amp; Analytical (DMA) Architecture. Individual researchers and health care professionals in India and the UAE can use DMA to uncover and harness PHC and POC data into practical insights. In addition, the DMA would provide a set of core tools for cross-network initiatives, allowing researchers and other users to compare their data with DMA data. In rural, urban, and remote populations of the UAE and India, the concept augments the PHC system with ICT-based interventions. The ICT-based interventions may improve patient health outcomes. The open and flexible design allows users to access various digital materials. Extendable data/metadata format, scalable architecture for petabyte-scale federated discovery. The modular DMA is designed using existing technology and resources. Public health functions include population health assessment, policy development, and monitoring policy implementation. PHC and POC periodically conduct syndromic surveillance to identify population risk patterns. In addition, the PHC and POC deploy medical and non-medical preventive measures to prevent disease outbreaks. To assess the impact of social and economic factors on health, epidemiologists must first understand diseases. Improved health due to compliance with holistic disease treatment plans and access to scientific health information.",2022,10.3389/frai.2022.909101
Quantum pathways for charged track finding in high-energy collisions,"In high-energy particle collisions, charged track finding is a complex yet crucial endeavor. We propose a quantum algorithm, specifically quantum template matching, to enhance the accuracy and efficiency of track finding. Abstracting the Quantum Amplitude Amplification routine by introducing a data register, and utilizing a novel oracle construction, allows data to be parsed to the circuit and matched with a hit-pattern template, without prior knowledge of the input data. Furthermore, we address the challenges posed by missing hit data, demonstrating the ability of the quantum template matching algorithm to successfully identify charged-particle tracks from hit patterns with missing hits. Our findings therefore propose quantum methodologies tailored for real-world applications and underline the potential of quantum computing in collider physics.",2024,10.3389/frai.2024.1339785
Arabic speech recognition model using Baidu's deep and cluster learning,"This study involves extracting the spectrum from the Arabic raw, unlabeled audio signal and producing Mel-frequency cepstral coefficients (MFCCs). The clustering algorithm groups the retrieved MFCCs with analogous features. The K-means clustering technique played a crucial role in our research, enabling the unsupervised categorization of unlabeled Arabic audio data. Employing K-means on the extracted MFCC features allowed us to classify acoustically similar segments into distinct groups without prior knowledge of their characteristics. This initial phase was crucial for understanding the inherent diversity in our diverse sampled dataset. Dynamic Time Warping (DTW) and Euclidean Distance are utilized for illustration. Classification algorithms such as Decision Tree, eXtreme Gradient Boosting (XGBoost), K-Nearest Neighbors (KNN), and Random Forest are used to classify the various classes obtained based on clustering. This study also demonstrates the efficacy of Mozilla's Deep Speech framework for Arabic speech recognition. The core component of deep speech is its neural network architecture, which consists of multiple layers of Recurrent Neural Networks (RNNs). It strives to comprehend the intricate patterns and interactions between spoken sounds and their corresponding textual representations. The clustered labeled Arabic audio dataset, along with transcripts and Arabic Alphabets, is used as input to Baidu's Deep Speech model for training and testing purposes. PyCharm, in conjunction with Python 3.6, is used to build a Dockerfile. Creating, editing, and managing Dockerfiles within PyCharm's IDE is simplified by its functionality and integrated environment. Deep speech provides an eminent Arabic speech recognition quality with reduced loss, word error rate (WER), and character error rate (CER). Baidu's Deep Speech intends to achieve high performance in both end-to-end and isolated speech recognition with good precision and a low word rate and character error rate in a reasonable amount of time. The suggested strategy yielded a loss of 276.147, a word error rate of 0.3720, and a character error rate of 0.0568. This technique increases the accuracy of Arabic automatic speech recognition (ASR).",2025,10.3389/frai.2025.1639147
"Adapting emotional support in teams: productivity, emotional stability, and conscientiousness","Students' mental health has received increased attention in recent years: reports of worsened mental health among higher education students call for new ways to support them in their college years. Educational demands are among the concerns that students report, such as the stress of academic performance, the stress related to examinations and the pressure to succeed. One aspect often present in higher education is group work. Group work can be truly beneficial for learning, but it often causes additional stress to students. The present research contributes to the design of a peer assessment tool to support students during group work. In this tool, each student is asked to rate their teammates on several aspects of group work, and a virtual agent delivers support statements in response to such ratings. For the support statements to be appropriate, the virtual agent should adapt them to the recipient and the group work situation they are experiencing. We investigate the adaptation of emotional support statements to the student's personality trait of Conscientiousness and the score assigned to a teammate on one aspect of teamwork, Productivity. The resulting algorithm is then combined with related work on Emotional Stability, and a final algorithm considering both dimensions is created.",2025,10.3389/frai.2025.1449176
Machine learning-based infant crying interpretation,"Crying is an inevitable character trait that occurs throughout the growth of infants, under conditions where the caregiver may have difficulty interpreting the underlying cause of the cry. Crying can be treated as an audio signal that carries a message about the infant's state, such as discomfort, hunger, and sickness. The primary infant caregiver requires traditional ways of understanding these feelings. Failing to understand them correctly can cause severe problems. Several methods attempt to solve this problem; however, proper audio feature representation and classifiers are necessary for better results. This study uses time-, frequency-, and time-frequency-domain feature representations to gain in-depth information from the data. The time-domain features include zero-crossing rate (ZCR) and root mean square (RMS), the frequency-domain feature includes the Mel-spectrogram, and the time-frequency-domain feature includes Mel-frequency cepstral coefficients (MFCCs). Moreover, time-series imaging algorithms are applied to transform 20 MFCC features into images using different algorithms: Gramian angular difference fields, Gramian angular summation fields, Markov transition fields, recurrence plots, and RGB GAF. Then, these features are provided to different machine learning classifiers, such as decision tree, random forest, K nearest neighbors, and bagging. The use of MFCCs, ZCR, and RMS as features achieved high performance, outperforming state of the art (SOTA). Optimal parameters are found via the grid search method using 10-fold cross-validation. Our MFCC-based random forest (RF) classifier approach achieved an accuracy of 96.39%, outperforming SOTA, the scalogram-based shuffleNet classifier, which had an accuracy of 95.17%.",2024,10.3389/frai.2024.1337356
Data-Driven Prediction of Fatigue in Parkinson’s Disease Patients,"Introduction: Numerous non-motor symptoms are associated with Parkinson’s disease (PD) including fatigue. The challenge in the clinic is to detect relevant non-motor symptoms while keeping patient-burden of questionnaires low and to take potential subgroups such as sex differences into account. The Fatigue Severity Scale (FSS) effectively detects clinically significant fatigue in PD patients. Machine learning techniques can determine which FSS items best predict clinically significant fatigue yet the choice of technique is crucial as it determines the stability of results.Methods: 182 records of PD patients were analyzed with two machine learning algorithms: random forest (RF) and Boruta. RF and Boruta calculated feature importance scores, which measured how much impact an FSS item had in predicting clinically significant fatigue. Items with the highest feature importance scores were the best predictors. Principal components analysis (PCA) grouped highly related FSS items together.Results: RF, Boruta and PCA demonstrated that items 8 (“Fatigue is among my three most disabling symptoms”) and 9 (“Fatigue interferes with my work, family or social life”) were the most important predictors. Item 5 (“Fatigue causes frequent problems for me”) was an important predictor for females, and item 6 (“My fatigue prevents sustained physical functioning”) was important for males. Feature importance scores’ standard deviations were large for RF (14–66%) but small for Boruta (0–5%).Conclusion: The clinically most informative questions may be how disabling fatigue is compared to other symptoms and interference with work, family and friends. There may be some sex-related differences with frequency of fatigue-related complaints in females and endurance-related complaints in males yielding significant information. Boruta but not RF yielded stable results and might be a better tool to determine the most relevant components of abbreviated questionnaires. Further research in this area would be beneficial in order to replicate these findings with other machine learning algorithms, and using a more representative sample of PD patients.",2021,10.3389/frai.2021.678678
Leveraging multi-scale feature integration in UNet and FPN for semantic segmentation of lung nodules,"Introduction
                    Lung cancer remains as an important source of cancer-related mortality worldwide, demonstrating a substantial challenge to public health systems. The absence of evident symptoms in the early stages makes timely diagnosis of lung cancer challenging. Early identification and treatment will reduce the mortality rate caused by lung cancer. Abnormal growths identified as lung or pulmonary nodules can be found in the lungs and some of these could be malignant. A Computer-Aided Detection (CAD) framework can aid in identifying pulmonary nodules by investigating medical images. Automated CAD systems assist radiologists by reducing the diagnostic workload and increasing the possibility of early lung cancer identification. Finding and accurately outlining lung nodules is the specific task of lung nodule segmentation in medical image analysis.
                  
                  
                    Methods
                    Multi-scale UNet, Feature Pyramid Network (FPN) with Linear Attention Mechanism and UNet with Asynchronous Convolution Blocks (ACB) and Channel Attention Mechanism were used to segment lung nodules. Multi-scale UNet improvises the traditional UNet architecture by incorporating multi-scale convolutional operations, which improves feature extraction and boosts segmentation accuracy. The UNet with ACB and Channel Attention Mechanism employs a cross-like receptive field that can reduce the impact of redundant information in obtaining representative characteristics. FPN with Linear Attention mechanism uses a multi-scale feature pyramid to identify nodules of different sizes and a linear attention mechanism is employed to improve feature extraction. FPN with Linear Attention mechanism attains a linear time and spatial complexity while effectively segmenting pulmonary nodules.
                  
                  
                    Results and discussion
                    Employing the FPN with Linear Attention mechanism yielded the highest performance in the experiments. The highest results in the study using FPN with Linear Attention were achieved using GELU on the LIDC-IDRI dataset with a DSC of 71.59% and IoU of 58.57%. The smooth, probabilistic weighting of GeLU complements the model's attention mechanisms.",2025,10.3389/frai.2025.1682171
Explainable correlation-based anomaly detection for Industrial Control Systems,"Anomaly detection is vital for enhancing the safety of Industrial Control Systems (ICS). However, the complicated structure of ICS creates complex temporal correlations among devices with many parameters. Current methods often ignore these correlations and poorly select parameters, missing valuable insights. Additionally, they lack interpretability, operating efficiently with limited resources, and root cause identification. This study proposes an explainable correlation-based anomaly detection method for ICS. The optimal window size of the data is determined using Long Short-Term Memory Networks—Autoencoder (LSTM-AE) and the correlation parameter set is extracted using the Pearson correlation. A Latent Correlation Matrix (LCM) is created from the correlation parameter set and a Latent Correlation Vector (LCV) is derived from LCM. Based on the LCV, the method utilizes a Multivariate Gaussian Distribution (MGD) to identify anomalies. This is achieved through an anomaly detection module that incorporates a threshold mechanism, utilizing alpha and epsilon values. The proposed method utilizes a novel set of input features extracted using the Shapley Additive explanation (SHAP) framework to train and evaluate the MGD model. The method is evaluated on the Secure Water Treatment (SWaT), Hardware-in-the-loop-based augmented ICS security (HIL-HAI), and Internet of Things Modbus dataset using precision, recall, and F-1 score metrics. Additionally, SHAP is used to gain insights into the anomalies and identify their root causes. Comparative experiments demonstrate the method's effectiveness, achieving a better 0.96% precision and 0.84% F1-score. This enhanced performance aids ICS engineers and decision-makers in identifying the root causes of anomalies. Our code is publicly available at a GitHub repository: https://github.com/Ermiyas21/Explainable-correlation-AD.",2025,10.3389/frai.2024.1508821
Exploring the utilization and deficiencies of Generative Artificial Intelligence in students’ cognitive and emotional needs: a systematic mini-review,"Despite advances in educational technology, the specific ways in which Generative Artificial Intelligence (GAI) and Large Language Models cater to learners’ nuanced cognitive and emotional needs are not fully understood. This mini-review methodically describes GAI’s practical implementations and limitations in meeting these needs. It included journal and conference papers from 2019 to 2024, focusing on empirical studies that employ GAI tools in educational contexts while addressing their practical utility and ethical considerations. The selection criteria excluded non-English studies, non-empirical research, and works published before 2019. From the dataset obtained from Scopus and Web of Science as of June 18, 2024, four significant studies were reviewed. These studies involved tools like ChatGPT and emphasized their effectiveness in boosting student engagement and emotional regulation through interactive learning environments with instant feedback. Nonetheless, the review reveals substantial deficiencies in GAI’s capacity to promote critical thinking and maintain response accuracy, potentially leading to learner confusion. Moreover, the ability of these tools to tailor learning experiences and offer emotional support remains limited, often not satisfying individual learner requirements. The findings from the included studies suggest limited generalizability beyond specific GAI versions, with studies being cross-sectional and involving small participant pools. Practical implications underscore the need to develop teaching strategies leveraging GAI to enhance critical thinking. There is also a need to improve the accuracy of GAI tools’ responses. Lastly, deep analysis of intervention approval is needed in cases where GAI does not meet acceptable error margins to mitigate potential negative impacts on learning experiences.",2024,10.3389/frai.2024.1493566
Implementation of deep reinforcement learning models for emotion detection and personalization of learning in hybrid educational environments,"The integration of artificial intelligence in education has shown great potential to improve student’s learning experience through emotion detection and the personalization of learning. Many educational settings lack adequate mechanisms to dynamically adapt to students’ emotions, which can negatively impact their academic performance and engagement. This study addresses this problem by implementing a deep reinforcement learning model to detect emotions in real-time and personalize teaching strategies in a hybrid educational environment. Using data from 500 students, captured through cameras, microphones, and biometric sensors and pre-processed with advanced techniques such as histogram equalization and noise reduction, the deep reinforcement learning model was trained and validated to improve the detection accuracy of emotions and the personalization of learning. The results showed a significant improvement in the accuracy of emotion detection, going from 72.4% before the implementation of the system to 89.3% after. Real-time adaptability also increased from 68.5 to 87.6%, while learning personalization rose from 70.2 to 90.1%. K-fold cross-validation with k = 10 confirmed the robustness and generalization of the model, with consistently high scores in all evaluated metrics. This study demonstrates that integrating reinforcement learning models for emotion detection and learning personalization can transform education, providing a more adaptive and student-centered learning experience. These findings identify the potential of these technologies to improve academic performance and student engagement, offering a solid foundation for future research and implementation.",2024,10.3389/frai.2024.1458230
Accelerating Hyperparameter Tuning in Machine Learning for Alzheimer’s Disease With High Performance Computing,"Driven by massive datasets that comprise biomarkers from both blood and magnetic resonance imaging (MRI), the need for advanced learning algorithms and accelerator architectures, such as GPUs and FPGAs has increased. Machine learning (ML) methods have delivered remarkable prediction for the early diagnosis of Alzheimer’s disease (AD). Although ML has improved accuracy of AD prediction, the requirement for the complexity of algorithms in ML increases, for example, hyperparameters tuning, which in turn, increases its computational complexity. Thus, accelerating high performance ML for AD is an important research challenge facing these fields. This work reports a multicore high performance support vector machine (SVM) hyperparameter tuning workflow with 100 times repeated 5-fold cross-validation for speeding up ML for AD. For demonstration and evaluation purposes, the high performance hyperparameter tuning model was applied to public MRI data for AD and included demographic factors such as age, sex and education. Results showed that computational efficiency increased by 96%, which helped to shed light on future diagnostic AD biomarker applications. The high performance hyperparameter tuning model can also be applied to other ML algorithms such as random forest, logistic regression, xgboost, etc.",2021,10.3389/frai.2021.798962
Challenges of Developing Robust AI for Intrapartum Fetal Heart Rate Monitoring,"Background:CTG remains the only non-invasive tool available to the maternity team for continuous monitoring of fetal well-being during labour. Despite widespread use and investment in staff training, difficulty with CTG interpretation continues to be identified as a problem in cases of fetal hypoxia, which often results in permanent brain injury. Given the recent advances in AI, it is hoped that its application to CTG will offer a better, less subjective and more reliable method of CTG interpretation.Objectives:This mini-review examines the literature and discusses the impediments to the success of AI application to CTG thus far. Prior randomised control trials (RCTs) of CTG decision support systems are reviewed from technical and clinical perspectives. A selection of novel engineering approaches, not yet validated in RCTs, are also reviewed. The review presents the key challenges that need to be addressed in order to develop a robust AI tool to identify fetal distress in a timely manner so that appropriate intervention can be made.Results:The decision support systems used in three RCTs were reviewed, summarising the algorithms, the outcomes of the trials and the limitations. Preliminary work suggests that the inclusion of clinical data can improve the performance of AI-assisted CTG. Combined with newer approaches to the classification of traces, this offers promise for rewarding future development.",2021,10.3389/frai.2021.765210
Investigation of independent reinforcement learning algorithms in multi-agent environments,"Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on seven PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. For the cooperative setting, we show that independent algorithms can perform on par with multi-agent algorithms in fully-observable environments, while adding recurrence improves the learning of independent algorithms in partially-observable environments. In the competitive setting, independent algorithms can perform on par or better than multi-agent algorithms, even in more challenging environments. We also show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies in mixed environments.",2022,10.3389/frai.2022.805823
Poultry diseases diagnostics models using deep learning,"Coccidiosis, Salmonella, and Newcastle are the common poultry diseases that curtail poultry production if they are not detected early. In Tanzania, these diseases are not detected early due to limited access to agricultural support services by poultry farmers. Deep learning techniques have the potential for early diagnosis of these poultry diseases. In this study, a deep Convolutional Neural Network (CNN) model was developed to diagnose poultry diseases by classifying healthy and unhealthy fecal images. Unhealthy fecal images may be symptomatic of Coccidiosis, Salmonella, and Newcastle diseases. We collected 1,255 laboratory-labeled fecal images and fecal samples used in Polymerase Chain Reaction diagnostics to annotate the laboratory-labeled fecal images. We took 6,812 poultry fecal photos using an Open Data Kit. Agricultural support experts annotated the farm-labeled fecal images. Then we used a baseline CNN model, VGG16, InceptionV3, MobileNetV2, and Xception models. We trained models using farm and laboratory-labeled fecal images and then fine-tuned them. The test set used farm-labeled images. The test accuracies results without fine-tuning were 83.06% for the baseline CNN, 85.85% for VGG16, 94.79% for InceptionV3, 87.46% for MobileNetV2, and 88.27% for Xception. Finetuning while freezing the batch normalization layer improved model accuracies, resulting in 95.01% for VGG16, 95.45% for InceptionV3, 98.02% for MobileNetV2, and 98.24% for Xception, with F1 scores for all classifiers above 75% in all four classes. Given the lighter weight of the trained MobileNetV2 and its better ability to generalize, we recommend deploying this model for the early detection of poultry diseases at the farm level.",2022,10.3389/frai.2022.733345
Automated detection of dolphin whistles with convolutional networks and transfer learning,"Effective conservation of maritime environments and wildlife management of endangered species require the implementation of efficient, accurate and scalable solutions for environmental monitoring. Ecoacoustics offers the advantages of non-invasive, long-duration sampling of environmental sounds and has the potential to become the reference tool for biodiversity surveying. However, the analysis and interpretation of acoustic data is a time-consuming process that often requires a great amount of human supervision. This issue might be tackled by exploiting modern techniques for automatic audio signal analysis, which have recently achieved impressive performance thanks to the advances in deep learning research. In this paper we show that convolutional neural networks can indeed significantly outperform traditional automatic methods in a challenging detection task: identification of dolphin whistles from underwater audio recordings. The proposed system can detect signals even in the presence of ambient noise, at the same time consistently reducing the likelihood of producing false positives and false negatives. Our results further support the adoption of artificial intelligence technology to improve the automatic monitoring of marine ecosystems.",2023,10.3389/frai.2023.1099022
Image–text coherence and its implications for multimodal AI,"Human communication often combines imagery and text into integrated presentations, especially online. In this paper, we show how image–text coherence relations can be used to model the pragmatics of image–text presentations in AI systems. In contrast to alternative frameworks that characterize image–text presentations in terms of the priority, relevance, or overlap of information across modalities, coherence theory postulates that each unit of a discourse stands in specific pragmatic relations to other parts of the discourse, with each relation involving its own information goals and inferential connections. Text accompanying an image may, for example, characterize what's visible in the image, explain how the image was obtained, offer the author's appraisal of or reaction to the depicted situation, and so forth. The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications. To argue this, we review case studies describing coherence in image–text data sets, predicting coherence from few-shot annotations, and coherence models of image–text tasks such as caption generation and caption evaluation.",2023,10.3389/frai.2023.1048874
Gaussian process latent variable models-ANN based method for automatic features selection and dimensionality reduction for control of EMG-driven systems,"Electromyography (EMG) signals have gained significant attention due to their potential applications in prosthetics, rehabilitation, and human-computer interfaces. However, the dimensionality of EMG signal features poses challenges in achieving accurate classification and reducing computational complexity. To overcome such issues, this paper proposes a novel approach that integrates feature reduction techniques with an artificial neural network (ANN) classifier to enhance the accuracy of high-dimensional EMG classification. This approach aims to improve the classification accuracy of EMG signals while substantially reducing computational costs, offering valuable implications for all EMG-related processes on such data. The proposed methodology involves extracting time and frequency domain features from twelve channels of EMG signals, followed by dimensionality reduction using techniques such as PCA, LDA, PPCA, Lasso and GPLVM, and classification using an ANN. Our investigation revealed that LDA is not appropriate for this dataset. The dimensionality reduction models did not have any significant effect on the accuracy, but the computational cost decreased significantly. In individual comparisons, GPLVM had the shortest computational time (29 s), which was significantly less than that of all the other models (p &lt; 0.05), with PCA following at approximately 35 s and Relief at approximately 57 s, while PPCA took approximately 69 s, and Lasso exhibited higher computational costs than all the models but lower computational costs than did the original set. Using the best-performing features, all possible sets of 2, 3, 4 and 5 features were tested, and the 5-feature set exhibited the best performance. This research demonstrates the effectiveness of dimensionality reduction and feature selection in improving the accuracy of movement recognition in myoelectric control.",2025,10.3389/frai.2025.1506042
Cutting-edge communication and learning assistive technologies for disabled children: An artificial intelligence perspective,"In this study we provide an in-depth review and analysis of the impact of artificial intelligence (AI) components and solutions that support the development of cutting-edge assistive technologies for children with special needs. Various disabilities are addressed and the most recent assistive technologies that enhance communication and education of disabled children, as well as the AI technologies that have enabled their development, are presented. The paper summarizes with an AI perspective on future assistive technologies and ethical concerns arising from the use of such cutting-edge communication and learning technologies for children with disabilities.",2022,10.3389/frai.2022.970430
Revisiting the role of HR in the age of AI: bringing humans and machines closer together in the workplace,"The functions of human resource management (HRM) have changed radically in the past 20 years due to market and technological forces, becoming more cross-functional and data-driven. In the age of AI, the role of HRM professionals in organizations continues to evolve. Artificial intelligence (AI) is transforming many HRM functions and practices throughout organizations creating system and process efficiencies, performing advanced data analysis, and contributing to the value creation process of the organization. A growing body of evidence highlights the benefits AI brings to the field of HRM. Despite the increased interest in AI-HRM scholarship, focus on human-AI interaction at work and AI-based technologies for HRM is limited and fragmented. Moreover, the lack of human considerations in HRM tech design and deployment can hamper AI digital transformation efforts. This paper provides a contemporary and forward-looking perspective to the strategic and human-centric role HRM plays within organizations as AI becomes more integrated in the workplace. Spanning three distinct phases of AI-HRM integration (technocratic, integrated, and fully-embedded), it examines the technical, human, and ethical challenges at each phase and provides suggestions on how to overcome them using a human-centric approach. Our paper highlights the importance of the evolving role of HRM in the AI-driven organization and provides a roadmap on how to bring humans and machines closer together in the workplace.",2024,10.3389/frai.2023.1272823
Exploring security threats and solutions Techniques for Internet of Things (IoT): from vulnerabilities to vigilance,"The rapid proliferation of Internet of Things (IoT) devices across various industries has revolutionized the way we interact with technology. However, this widespread adoption has also brought about significant security challenges that must be addressed to ensure the integrity and confidentiality of data transmitted and processed by IoT systems. This survey paper delves into the diverse array of security threats faced by IoT devices and networks, ranging from data breaches and unauthorized access to physical tampering and denial-of-service attacks. By examining the vulnerabilities inherent in IoT ecosystems, we highlight the importance of implementing robust security measures to safeguard sensitive information and ensure the reliable operation of connected devices. Furthermore, we explore cutting-edge technologies such as blockchain, edge computing, and machine learning as potential solutions to enhance the security posture of IoT deployments. Through a comprehensive analysis of existing security frameworks and best practices, this paper aims to provide valuable insights for researchers, practitioners, and policymakers seeking to fortify the resilience of IoT systems in an increasingly interconnected world.",2024,10.3389/frai.2024.1397480
Benchmarking the influence of pre-training on explanation performance in MR image classification,"Convolutional Neural Networks (CNNs) are frequently and successfully used in medical prediction tasks. They are often used in combination with transfer learning, leading to improved performance when training data for the task are scarce. The resulting models are highly complex and typically do not provide any insight into their predictive mechanisms, motivating the field of “explainable” artificial intelligence (XAI). However, previous studies have rarely quantitatively evaluated the “explanation performance” of XAI methods against ground-truth data, and transfer learning and its influence on objective measures of explanation performance has not been investigated. Here, we propose a benchmark dataset that allows for quantifying explanation performance in a realistic magnetic resonance imaging (MRI) classification task. We employ this benchmark to understand the influence of transfer learning on the quality of explanations. Experimental results show that popular XAI methods applied to the same underlying model differ vastly in performance, even when considering only correctly classified examples. We further observe that explanation performance strongly depends on the task used for pre-training and the number of CNN layers pre-trained. These results hold after correcting for a substantial correlation between explanation and classification performance.",2024,10.3389/frai.2024.1330919
PSO-XnB: a proposed model for predicting hospital stay of CAD patients,"Coronary artery disease poses a significant challenge in decision-making when predicting the length of stay for a hospitalized patient. This study presents a predictive model—a Particle Swarm Optimized-Enhanced NeuroBoost—that combines the deep autoencoder with an eXtreme gradient boosting model optimized using particle swarm optimization. The model uses a fuzzy set of rules to categorize the length of stay into four distinct classes, followed by data preparation and preprocessing. In this study, the dimensionality of the data is reduced using deep neural autoencoders. The reconstructed data obtained from autoencoders is given as input to an eXtreme gradient boosting model. Finally, the model is tuned with particle swarm optimization to obtain optimal hyperparameters. With the proposed technique, the model achieved superior performance with an overall accuracy of 98.8% compared to traditional ensemble models and past research works. The model also scored highest in other metrics such as precision, recall, and particularly F1 scores for all categories of hospital stay. These scores validate the suitability of our proposed model in medical healthcare applications.",2024,10.3389/frai.2024.1381430
Development of a knowledge graph framework to ease and empower translational approaches in plant research: a use-case on grain legumes,"While the continuing decline in genotyping and sequencing costs has largely benefited plant research, some key species for meeting the challenges of agriculture remain mostly understudied. As a result, heterogeneous datasets for different traits are available for a significant number of these species. As gene structures and functions are to some extent conserved through evolution, comparative genomics can be used to transfer available knowledge from one species to another. However, such a translational research approach is complex due to the multiplicity of data sources and the non-harmonized description of the data. Here, we provide two pipelines, referred to as structural and functional pipelines, to create a framework for a NoSQL graph-database (Neo4j) to integrate and query heterogeneous data from multiple species. We call this framework Orthology-driven knowledge base framework for translational research (Ortho_KB). The structural pipeline builds bridges across species based on orthology. The functional pipeline integrates biological information, including QTL, and RNA-sequencing datasets, and uses the backbone from the structural pipeline to connect orthologs in the database. Queries can be written using the Neo4j Cypher language and can, for instance, lead to identify genes controlling a common trait across species. To explore the possibilities offered by such a framework, we populated Ortho_KB to obtain OrthoLegKB, an instance dedicated to legumes. The proposed model was evaluated by studying the conservation of a flowering-promoting gene. Through a series of queries, we have demonstrated that our knowledge graph base provides an intuitive and powerful platform to support research and development programmes.",2023,10.3389/frai.2023.1191122
Artificial intelligence skills and their impact on the employability of university graduates,"Artificial intelligence (AI) has emerged as a transformative technology in multiple areas, including the labor market. Its incorporation into organizations redefines professional profiles, required skills, and employability conditions. In this context, it is essential to understand how university graduates are preparing to face these changes and what role their AI skills play in their integration into the workforce. The study aimed to analyze the level of AI skills and their impact on the employability of university graduates through a quantitative and descriptive design. A survey was conducted with a sample of 148 undergraduate and graduate graduates. The data were analyzed using descriptive statistics and visualized using graphs. The results indicated that graduates who report greater knowledge and more frequent use of AI tools, especially generative ones such as ChatGPT, are more likely to be employed in areas related to their majors and to perceive higher productivity and better professional alignment. However, a generational gap in digital skills was also identified, as well as a widespread feeling of insufficient preparation for the challenges of the current labor market. The conclusion is that AI skills are consolidating as a key differentiating factor in employability and that their formal incorporation into university curricula is urgently needed. The implications of the study point to the need for an educational transformation that integrates AI as a transversal skill, promotes ongoing teacher training, and fosters policies that guarantee inclusive education aligned with the challenges of the digital age.",2025,10.3389/frai.2025.1629320
"A multidimensional comparison of ChatGPT, Google Translate, and DeepL in Chinese tourism texts translation: fidelity, fluency, cultural sensitivity, and persuasiveness","This study systematically compares the translation performance of ChatGPT, Google Translate, and DeepL on Chinese tourism texts, focusing on two prompt-engineering strategies. Using a mixed-methods approach that combines quantitative expert assessments with qualitative analysis, the evaluation centers on fidelity, fluency, cultural sensitivity, and persuasiveness. ChatGPT outperformed its counterparts across all metrics, especially when culturally tailored prompts were used. However, it occasionally introduced semantic shifts, highlighting a trade-off between accuracy and rhetorical adaptation. Despite its strong performance, human post-editing remains necessary to ensure semantic precision and professional standards. The study demonstrates ChatGPT’s potential in domain-specific translation tasks while calling for continued oversight in culturally nuanced content.",2025,10.3389/frai.2025.1619489
The history of the semantic hacking project and the lessons it teaches for modern cognitive security,"The Semantic Hacking Project ran from 2001 to 2003. It focused on how information systems (and the human decisions shaped by them) could be exploited through attacks not on code or infrastructure, but on meaning. This work is relevant to contemporary cognitive security concerns in the face of today’s information space. The work provides insight into the key question of how people come to hold the beliefs which they do. The project anticipated many of today’s challenges (disinformation campaigns, social media manipulation, AI-generated narratives) not just in technical terms, but in philosophical and linguistic terms. At the heart of its concern was a simple but powerful question: What happens when you can manipulate the inputs to a person’s belief system without the person knowing it? This question has only grown more urgent in an era of generative AI, large language models (LLMs), and algorithmically amplified influence.",2025,10.3389/frai.2025.1616447
Optimal blending of multiple independent prediction models,"We derive blending coefficients for the optimal blend of multiple independent prediction models with normal (Gaussian) distribution as well as the variance of the final blend. We also provide lower and upper bound estimation for the final variance and we compare these results with machine learning with counts, where only binary information (feature says yes or no only) is used for every feature and the majority of features agreeing together make the decision.",2023,10.3389/frai.2023.1144886
Lipschitz-based robustness estimation for hyperdimensional learning,"With the adoption of machine learning models in various practical domains, there is a growing need for evaluating and increasing model robustness. Hyperdimensional computing (HDC) is a neurosymbolic computational paradigm that represents symbols as high dimensional vectors and symbolic operations as vector operations, seamlessly interfacing between neuro- and symbolic components of a model. However, there is a notable gap in HDC research regarding the robustness of HDC models to input perturbations. This study presents a novel theoretical framework tailored to evaluate the robustness of hyperdimensional classifiers against perturbations in the input space. In particular, our proposed measure of robustness gives a theoretical upper bound for the magnitude of noise a model can tolerate without changing its prediction for any given data point. We also propose a method to enhance the robustness of the model based on our proposed measure of robustness. Our approach introduces several methods to calculate model robustness as a function of the specific dataset and type of hyperdimensional encoding used. The results show that the average robustness of HDC models increases under the proposed optimization scheme while maintaining accuracy by varying the variance of the Gaussian distribution used to encode hypervectors. The practical effectiveness of our proposed measure of robustness is also demonstrated.",2025,10.3389/frai.2025.1637105
Differences between remote and analog design thinking through the lens of distributed cognition,"Due to the huge surge in remote work all over the world caused by the COVID-19 pandemic, today's work is largely defined by tools for information exchange as well as new complex problems that must be solved. Design Thinking offers a well-known and established methodological approach for iterative, collaborative and interdisciplinary problem solving. Still, recent circumstances shed a new light on how to facilitate Design Thinking activities in a remote rather than an analog way. Due to Design Thinking's high production of artifacts and its focus on communication and interaction between team members, the theory of Distributed Cognition, specifically the Distributed Cognition for Teamwork (DiCoT) framework, provides an interesting perspective on the recent going-remote of Design Thinking activities. For this, we first highlight differences of analog vs. remote Design Thinking by analyzing corresponding literature from the recent years. Next, we apply the DiCoT framework to those findings, pointing out implications for practical facilitation of Design Thinking activities in an analog and remote setting. Finally, we discuss opportunities through artificial intelligence-based technologies and methods.",2022,10.3389/frai.2022.915922
Does business news sentiment matter in the energy stock market? Adopting sentiment analysis for short-term stock market prediction in the energy industry,"Characterized by high volatility the energy stock market provides ample research potential for stock market prediction using machine learning models. This paper investigates using business news as an indicator of market sentiment in Recurrent Neural Networks. The authors adopt a finance-specific Transformer-based model, FinBERT, for news sentiment analysis and use a Long Short-Term Memory (LSTM) model for stock prediction. As prior research indicates that sentiment may vary for different news elements, they specifically explore differences between news headlines and content. Results show that (1) transformer-based sentiment analysis of business news can improve stock market prediction in the energy industry and that (2) sentiment of news content is more effective than sentiment of news headlines.",2025,10.3389/frai.2025.1559900
Dawn of the dialogue: AI's leap from lab to living room,"Prior to the advent of mainstream Large Language Models, e.g., ChatGPT, there were two contexts of AI use: theoretical and technical. The former involves the mathematics behind AI constructs, as well as new AI research; the latter encompasses the substance of AI use, i.e., programming, training, execution, etc. With the recent proliferation of Large Language Models for content generation, such as texts, images, and videos, there arises a new context of AI use: practical. This aspect of AI use is unique, in that practical users do not need theoretical or technical AI knowledge to prosper: they need only know how to prompt. In effect, the practical context of AI use is a black-box approach. These three contexts of AI converge in a unique intersection of AI knowledge. This emerging AI perspective is important to consider, as most AI users, now and in the future, will possess no deep knowledge of AI.",2024,10.3389/frai.2024.1308156
A nnU-Net-based automatic segmentation of FCD type II lesions in 3D FLAIR MRI images,"Focal cortical dysplasia (FCD) type II is a common cause of epilepsy and is challenging to detect due to its similarities with other brain conditions. Finding these lesions accurately is essential for successful surgery and seizure control. Manual detection is slow and challenging because the MRI features are subtle. Deep learning, especially convolutional neural networks, has shown great potential in automating image classification and segmentation by learning and extracting features. The nnU-Net framework is known for its ability to adapt its settings, including preprocessing, network design, training, and post-processing, to any new medical imaging task. This study employs an automated slice selection approach that ranks axial FLAIR slices by their peak voxel intensity and retains the five highest-ranked slices per scan, thereby focusing the network on lesion-rich slices and uses nnU-Net to automate the segmentation of FCD type II lesions on 3D FLAIR MRI images. The study was conducted on 85 FCD type II subjects and results are evaluated through 5-fold cross-validation. Using nnU-Net’s flexible and robust design, this study aims to improve the accuracy and speed of lesion detection, helping with better presurgical evaluations and outcomes for epilepsy patients.",2025,10.3389/frai.2025.1601815
Beyond the Failure of Direct-Matching in Keyword Evaluation: A Sketch of a Graph Based Solution,"The starting point of this paper is the observation that methods based on the direct match of keywords are inadequate because they do not consider the cognitive ability of concept formation and abstraction. We argue that keyword evaluation needs to be based on a semantic model of language capturing the semantic relatedness of words to satisfy the claim of the human-like ability of concept formation and abstraction and achieve better evaluation results. Evaluation of keywords is difficult since semantic informedness is required for this purpose. This model must be capable of identifying semantic relationships such as synonymy, hypernymy, hyponymy, and location-based abstraction. For example, when gathering texts from online sources, one usually finds a few keywords with each text. Still, these keyword sets are neither complete for the text nor are they in themselves closed, i.e., in most cases, the keywords are a random subset of all possible keywords and not that informative w.r.t. the complete keyword set. Therefore all algorithms based on this cannot achieve good evaluation results and provide good/better keywords or even a complete keyword set for a text. As a solution, we propose a word graph that captures all these semantic relationships for a given language. The problem with the hyponym/hyperonym relationship is that, unlike synonyms, it is not bidirectional. Thus the space of keyword sets requires a metric that is non-symmetric, in other words, aquasi-metric. We sketch such a metric that works on our graph. Since it is nearly impossible to obtain such a complete word graph for a language, we propose for the keyword task a simpler graph based on the base text upon which the keyword sets should be evaluated. This reduction is usually sufficient for evaluating keyword sets.",2022,10.3389/frai.2022.801564
She adapts to her student: An expert pragmatic speaker tailoring her referring expressions to the Layman listener,"Communication is a dynamic process through which interlocutors adapt to each other. In the development of conversational agents, this core aspect has been put aside for several years since the main challenge was to obtain conversational neural models able to produce utterances and dialogues that at least at the surface level are human-like. Now that this milestone has been achieved, the importance of paying attention to the dynamic and adaptive interactive aspects of language has been advocated in several position papers. In this paper, we focus on how a Speaker adapts to an interlocutor with different background knowledge. Our models undergo a pre-training phase, through which they acquire grounded knowledge by learning to describe an image, and an adaptive phase through which a Speaker and a Listener play a repeated reference game. Using a similar setting, previous studies focus on how conversational models create new conventions; we are interested, instead, in studying whether the Speaker learns from the Listener's mistakes to adapt to his background knowledge. We evaluate models based on Rational Speech Act (RSA), a likelihood loss, and a combination of the two. We show that RSA could indeed work as a backbone to drive the Speaker toward the Listener: in the combined model, apart from the improved Listener's accuracy, the language generated by the Speaker features the changes that signal adaptation to the Listener's background knowledge. Specifically, captions to unknown object categories contain more adjectives and less direct reference to the unknown objects.",2023,10.3389/frai.2023.1017204
Neuronal Sequence Models for Bayesian Online Inference,"Various imaging and electrophysiological studies in a number of different species and brain regions have revealed that neuronal dynamics associated with diverse behavioral patterns and cognitive tasks take on a sequence-like structure, even when encoding stationary concepts. These neuronal sequences are characterized by robust and reproducible spatiotemporal activation patterns. This suggests that the role of neuronal sequences may be much more fundamental for brain function than is commonly believed. Furthermore, the idea that the brain is not simply a passive observer but an active predictor of its sensory input, is supported by an enormous amount of evidence in fields as diverse as human ethology and physiology, besides neuroscience. Hence, a central aspect of this review is to illustrate how neuronal sequences can be understood as critical for probabilistic predictive information processing, and what dynamical principles can be used as generators of neuronal sequences. Moreover, since different lines of evidence from neuroscience and computational modeling suggest that the brain is organized in a functional hierarchy of time scales, we will also review how models based on sequence-generating principles can be embedded in such a hierarchy, to form a generative model for recognition and prediction of sensory input. We shortly introduce the Bayesian brain hypothesis as a prominent mathematical description of how online, i.e., fast, recognition, and predictions may be computed by the brain. Finally, we briefly discuss some recent advances in machine learning, where spatiotemporally structured methods (akin to neuronal sequences) and hierarchical networks have independently been developed for a wide range of tasks. We conclude that the investigation of specific dynamical and structural principles of sequential brain activity not only helps us understand how the brain processes information and generates predictions, but also informs us about neuroscientific principles potentially useful for designing more efficient artificial neuronal networks for machine learning tasks.",2021,10.3389/frai.2021.530937
An Exploration of Stress: Leveraging Online Data from Crowdsourcing Platforms,"Background:Early detection of community health risk factors such as stress is of great interest to health policymakers, but representative data collection is often expensive and time-consuming. It is important to investigate the use of alternative means of data collection such as crowdsourcing platforms.Methods:An online sample of Amazon Mechanical Turk (MTurk) workers (N = 500) filled out, for themselves and their child, demographic information and the 10-item Perceived Stress Scale (PSS-10), designed to measure the degree to which situations in one’s life are appraised as stressful. Internal consistency reliability of the PSS-10 was examined via Cronbach’s alpha. Analysis of variance (ANOVA) was utilized to explore trends in the average perceived stress of both adults and their children. Last, Rasch trees were utilized to detect differential item functioning (DIF) in the set of PSS-10 items.Results:The PSS-10 showed adequate internal consistency reliability (Cronbach’s alpha = 0.73). ANOVA results suggested that stress scores significantly differed by education (p= 0.024), employment status (p= 0.0004), and social media usage (p= 0.015). Rasch trees, a recursive partitioning technique based on the Rasch model, indicated that items on the PSS-10 displayed DIF attributable to physical health for adults and social media usage for children.Conclusion:The key conclusion is that this data collection scheme shows promise, allowing public health officials to examine health risk factors such as perceived stress quickly and cost effectively.",2021,10.3389/frai.2021.591529
NLP-enhanced inflation measurement using BERT and web scraping,"In this research note, we explore the integration of natural language processing (NLP) and web scraping techniques to develop a custom price index for measuring inflation. Using the Harmonized Index of Consumer Prices (HICP) as a benchmark, we created a database of consumer electronics product data through web scraping. Using the BERT model for classification, we achieved a high-performance classification of approximately 10,000 items into COICOP categories, with an accuracy of 94.56 %, macro precision of 79.41 %, and weighted precision of 94.07 % on validation data. Our custom index, particularly with weighted and median methodologies, demonstrated closer alignment with the official HICP while capturing more detailed price fluctuations within the market. Monthly inflation trends revealed variability that reflects price changes in the COICOP 091 category, contrasting with the relative stability of the official HICP. This work provides an alternative perspective on inflation measurement, highlighting the potential of computational approaches to enhance economic analysis.",2025,10.3389/frai.2025.1520659
Accuracy improvement in financial sanction screening: is natural language processing the solution?,"Sanction screening is a crucial banking compliance process that protects financial institutions from inadvertently engaging with internationally sanctioned individuals or organizations. Given the severe consequences, including financial crime risks and potential loss of banking licenses, effective execution is essential. One of the major challenges in this process is balancing the high rate of false positives, which exceed 90% and lead to inefficiencies due to increased human oversight, with the more critical issue of false negatives, which pose severe regulatory and financial risks by allowing sanctioned entities to go undetected. This study explores the use of Natural Language Processing (NLP) to enhance the accuracy of sanction screening, with a particular focus on reducing false negatives. Using an experimental approach, we evaluated a prototype NLP program on a dataset of sanctioned entities and transactions, assessing its performance in minimising false negatives and understanding its effect on false positives. Our findings demonstrate that while NLP significantly improves sensitivity by detecting more true positives, it also increases false positives, resulting in a trade-off between improved detection and reduced overall accuracy. Given the heightened risks associated with false negatives, this research emphasizes the importance of prioritizing their reduction. The study provides practical insights into how NLP can enhance sanction screening, while recognizing the need for ongoing adaptation to the dynamic nature of the field.",2024,10.3389/frai.2024.1374323
Fluorescent marker prediction for non-invasive optical imaging in bovine satellite cells using deep learning,"Assessing the quality of bovine satellite cells (BSCs) is vital for advancing tissue engineered muscle constructs with applications in sustainable protein research. In this study, we present a non-invasive deep learning approach for optical imaging that predicts fluorescent markers directly from brightfield microscopy images of BSC cultures. Using a convolutional neural network based on the U-Net architecture, our method simultaneously predicts two key fluorescent signals, specifically DAPI and Pax7, which serve as biomarkers for cell abundance and differentiation status. An image preprocessing pipeline featuring fluorescent signal denoising was implemented to enhance prediction performance and consistency. A dataset comprising 48 biological replicates was evaluated using statistical metrics such as the Pearson r (correlation coefficient), the mean squared error (MSE), and the structural similarity Index (SSIM). For DAPI, denoising improved the Pearson r from 0.065 to 0.212 and SSIM from 0.047 to 0.761 (with MSE increasing from 9.507 to 41.571). For Pax7, the Pearson r increased from 0.020 to 0.124 and MSE decreased from 44.753 to 18.793, while SSIM remained low, reflecting inherent biological heterogeneity. Furthermore, enhanced visualization techniques, including color mapping and image overlay, improved the interpretability of the predicted outputs. These findings underscore the importance of optimized data preprocessing and demonstrate the potential of AI to advance non-invasive optical imaging for cellular quality assessment in tissue biology. This work also contributes to the broader integration of machine learning and computer vision methods in biological and agricultural applications.",2025,10.3389/frai.2025.1577027
"Predicting pediatric diagnostic imaging patient no-show and extended wait-times using LLMs, regression, and tree based models","IntroductionPatients missing their appointments (no-shows) are a persistent issue that results in idle resources while delaying critical patient prognosis. Likewise, long waiting times increase frustration for patients, leaving a negative impression on the appointment. In this paper, we explore 3 modalities of diagnostic and interventional radiology appointments for pediatric patients at the Hospital for Sick Children (SickKids), Toronto, ON, Canada. Our goal was to survey machine learning methods that best predict the risk of patient no-shows and long wait-times exceeding 1 hour for scheduling teams to propose targeted downstream accommodations.MethodsWe experimented with 6 predictive model types separately trained on both tasks which included extreme gradient boosting (XGBoost), Random Forest (RF), Support Vector Machine, Logistic Regression, Artificial Neural Network, and a pre-trained large language model (LLM). Utilizing 20 features containing a mixture of patient demographics and appointment related data, we experimented with different data balancing methods including instance hardness threshold (IHT) and class weighting to reduce bias in prediction. We then conducted a comparative study of the improvements made by utilizing continuous contextual data in our LLM which boasted a 51% improvement in F1 score for the wait-time model.ResultsOur XGBoost model had the best combination of AUC and F1 scores (0.96 and 0.62, respectively) for predicting no-show while RF had the best AUC and F1 scores (0.83 and 0.61, respectively) for wait-time prediction. The LLMs also performed well for 90% probability thresholds (high risk patients) while being robustly calibrated on unseen test data.DiscussionOur results surveyed multiple algorithms and data balancing methods to propose the greatest performing models on our tasks, implemented a unique methodology to use LLMs on heterogeneous data within this domain, and demonstrated the greater importance of contextual appointment data over patient demographic features for a more equitable prediction algorithm. Going forward, the predictive output (calibrated probabilities of events) can be used as stochastic input for risk-based optimized scheduling to provide accommodation for patients less likely to receive quality access to healthcare.",2025,10.3389/frai.2025.1652397
Comparative analysis of multimodal architectures for effective skin lesion detection using clinical and image data,"Background/IntroductionSkin lesion classification poses a critical diagnostic challenge in dermatology, where early and accurate identification has a direct impact on patient outcomes. While deep learning approaches have shown promise using dermatoscopic images alone, the integration of clinical metadata remains underexplored despite its potential to enhance diagnostic accuracy.MethodsWe developed a novel multimodal data fusion framework that systematically integrates dermatoscopic images with clinical metadata for the classification of skin lesions. Using the HAM10000 dataset, we evaluated multiple fusion strategies, including simple concatenation, weighted concatenation, self-attention mechanisms, and cross-attention fusion. Clinical features were processed through a customized Multi-Layer Perceptron (MLP), while images were analyzed using a modified Residual Networks (ResNet) architecture. Model interpretability was enhanced using Gradient-weighted Class Activation Mapping (Grad-CAM) visualization to identify the contribution of clinical attributes to classification decisions.ResultsCross-attention fusion achieved the highest classification accuracy, demonstrating superior performance compared to unimodal approaches and simpler fusion techniques. The multimodal framework significantly outperformed image-only baselines, with cross-attention effectively capturing inter-modal dependencies and contextual relationships between visual and clinical data modalities.Discussion/ConclusionsOur findings demonstrate that integrating clinical metadata with dermatoscopic images substantially improves the accuracy of skin lesion classification. However, challenges, including class imbalance and the computational complexity of advanced fusion methods, require further investigation.",2025,10.3389/frai.2025.1608837
Machine learning enhanced acute heart failure phenotype prediction using natural language processing and random forest,"BackgroundHeart failure (HF), with its distinct phenotypes, poses significant public health challenges. Early diagnosis of specific HF phenotypes is crucial for timely therapeutic intervention.ObjectivesWe employed random forests to predict acute HF (AHF) phenotypes (HFrEF, HFmrEF, and HFpEF) during admission, using structured and unstructured data types while blinded to left ventricular ejection fraction (LVEF) information.MethodsWe investigated the predictive performance of integrated natural language processing (NLP) and machine learning (ML)-based models in AHF phenotype classification by random forests, leveraging clinical text and laboratory data from the MIMIC-III database. Feature selection for unstructured textual data and biochemical test data was performed using the LASSO method, with selected textual features converted into structured data using one-hot encoding. The areas under the ROC and PRC curves (AUROC and AUPRC) assessed overall performance.ResultsOur final study cohort comprised 1,192 training datasets and 513 independent validating datasets with primary data types and LVEF information available. The overall model from the training dataset showed the best performance with combined datasets (accuracy: 0.70 ± 0.03, AUROC: 0.76 ± 0.02) compared to the textual or laboratory dataset alone, which was replicated in the independent validating dataset. Our model achieved optimal performance by selecting up to 100 combined features from both textual and laboratory data. Reducing features to 20 did not substantially attenuate the overall model performance until only 10 features were selected.ConclusionOur study enhances HF phenotype classification and underscores the value of multifaceted data analysis in clinical informatics, enabling more personalized heart failure treatment. Early identification of AHF phenotypes may support timely, phenotype-specific management and inform treatment decisions.",2025,10.3389/frai.2025.1664627
Early-fusion hybrid CNN-transformer models for multiclass ovarian tumor ultrasound classification,"Ovarian cancer remains the deadliest gynecologic malignancy, and transvaginal ultrasound (TVS), the first-line test, still suffers from limited specificity and operator dependence. We introduce a learned early-fusion (joint projection) hybrid that couples EfficientNet-B7 (local descriptors) with a Swin Transformer (hierarchical global context) to classify eight ovarian tumor categories from 2D TVS. Using the public, de-identified OTU-2D dataset (n = 1,469 images across eight histopathologic classes), we conducted patient-level, stratified 5-fold cross-validation repeated 10×. To address class imbalance while preventing leakage, training used train-only oversampling, ultrasound-aware augmentations, and strong regularization; validation/test folds were never resampled. The hybrid achieved AUC 0.9904, accuracy 92.13%, sensitivity 92.38%, and specificity 98.90%, outperforming single CNN or ViT baselines. A soft ensemble of the top hybrids further improved performance to AUC 0.991, accuracy 93.3%, sensitivity 93.6%, and specificity 99.0%. Beyond discrimination, we provide deployment-oriented evaluation: isotonic calibration yielded reliable probabilities, decision-curve analysis showed net clinical benefit across 5–20% risk thresholds, entropy-based uncertainty supported confidence-based triage, and Grad-CAM highlighted clinically salient regions. All metrics are reported with 95% bootstrap confidence intervals, and the evaluation protocol preserves real-world data distributions. Taken together, this work advances ovarian ultrasound AI from accuracy-only reporting to calibrated, explainable, and uncertainty-aware decision support, offering a reproducible reference framework for multiclass ovarian ultrasound and a clear path toward clinical integration and prospective validation.",2025,10.3389/frai.2025.1679310
An Attempt to Boost Posterior Population Expansion Using Fast Machine Learning Algorithms,"In hydrogeology, inverse techniques have become indispensable to characterize subsurface parameters and their uncertainty. When modeling heterogeneous, geologically realistic discrete model spaces, such as categorical fields, Monte Carlo methods are needed to properly sample the solution space. Inversion algorithms use a forward operator, such as a numerical groundwater solver. The forward operator often represents the bottleneck for the high computational cost of the Monte Carlo sampling schemes. Even if efficient sampling methods (for example Posterior Population Expansion, PoPEx) have been developed, they need significant computing resources. It is therefore desirable to speed up such methods. As only a few models generated by the sampler have a significant likelihood, we propose to predict the significance of generated models by means of machine learning. Only models labeled as significant are passed to the forward solver, otherwise, they are rejected. This work compares the performance of AdaBoost, Random Forest, and convolutional neural network as classifiers integrated with the PoPEx framework. During initial iterations of the algorithm, the forward solver is always executed and subsurface models along with the likelihoods are stored. Then, the machine learning schemes are trained on the available data. We demonstrate the technique using a simulation of a tracer test in a fluvial aquifer. The geology is modeled by the multiple-point statistical approach, the field contains four geological facies, with associated permeability, porosity, and specific storage values. MODFLOW is used for groundwater flow and transport simulation. The solution of the inverse problem is used to estimate the 10 days protection zone around the pumping well. The estimated speed-ups with Random Forest and AdaBoost were higher than with the convolutional neural network. To validate the approach, computing times of inversion without and with machine learning schemes were computed and the error against the reference solution was calculated. For the same mean error, accelerated PoPEx achieved a speed-up rate of up to 2 with respect to the standard PoPEx.",2021,10.3389/frai.2021.624629
Dissemination Dynamics of Receding Words: A Diachronic Case Study of Whom,"We explore the relationship between word dissemination and frequency change for a rapidly receding feature, the relativizer whom. The success of newly emerging words has been shown to correlate with high dissemination scores. However, the reverse—a correlation of lower dissemination scores with receding features—has not been investigated. Based on two established and two newly developed measures of word dissemination—across texts, linguistic environments, registers, and topics—we show that a general correlation between dissemination and frequency does not obtain in the case of whom. Different dissemination measures diverge from each other and show internally variable developments. These can, however, be explained with reference to the specific sociolinguistic history of whom over the past 300 years. Our findings suggest that the relationship between dissemination and word success is not static, but needs to be contextualized against different stages in individual words’ life-cycles. Our study demonstrates the applicability of large-scale, quantitative measures to qualitatively informed sociolinguistic research.",2021,10.3389/frai.2021.654154
Toward a new AI winter? How diffusion of technological innovation on networks leads to chaotic boom-bust cycles,"Technological developments and the impact of artificial intelligence (AI) are omnipresent themes and concerns of the present day. Much has been written on these topics but applications of quantitative models to understand the techno-social landscape have been much more limited. We propose a mathematical model that can help understand in a unified manner the patterns underlying technological development and also identify the different regimes in which the technological landscape evolves. First, we develop a model of innovation diffusion between different technologies, the growth of each reinforcing the development of the others. The model has a variable that quantifies the level of development (or innovation, discovery) potential for a given technology. The potential, or market capacity, increases via diffusion from related technologies, reflecting the fact that a technology does not develop in isolation. Hence, the growth of each technology is influenced by how developed its neighboring (related) technologies are. This allows us to reproduce long-term trends seen in computing technology and large language models (LLMs). We then present a three-dimensional system of supply, demand, and investment which shows oscillations (business cycles) emerging if investment is too high into a given technology, product, or market. We finally combine the two models through a common variable and show that if investment or diffusion is too high in the network context, chaotic boom-bust cycles can emerge. These quantitative considerations allow us to reproduce the boom-bust patterns seen in non-fungible token (NFT) transaction data and also have deep implications for the development of AI which we highlight, such as the arrival of a new AI winter.",2025,10.3389/frai.2025.1671917
Fibrosis-Net: A Tailored Deep Convolutional Neural Network Design for Prediction of Pulmonary Fibrosis Progression From Chest CT Images,"Pulmonary fibrosis is a devastating chronic lung disease that causes irreparable lung tissue scarring and damage, resulting in progressive loss in lung capacity and has no known cure. A critical step in the treatment and management of pulmonary fibrosis is the assessment of lung function decline, with computed tomography (CT) imaging being a particularly effective method for determining the extent of lung damage caused by pulmonary fibrosis. Motivated by this, we introduce Fibrosis-Net, a deep convolutional neural network design tailored for the prediction of pulmonary fibrosis progression from chest CT images. More specifically, machine-driven design exploration was leveraged to determine a strong architectural design for CT lung analysis, upon which we build a customized network design tailored for predicting forced vital capacity (FVC) based on a patient’s CT scan, initial spirometry measurement, and clinical metadata. Finally, we leverage an explainability-driven performance validation strategy to study the decision-making behavior of Fibrosis-Net as to verify that predictions are based on relevant visual indicators in CT images. Experiments using a patient cohort from the OSIC Pulmonary Fibrosis Progression Challenge showed that the proposed Fibrosis-Net is able to achieve a significantly higher modified Laplace Log Likelihood score than the winning solutions on the challenge. Furthermore, explainability-driven performance validation demonstrated that the proposed Fibrosis-Net exhibits correct decision-making behavior by leveraging clinically-relevant visual indicators in CT images when making predictions on pulmonary fibrosis progress. Fibrosis-Net is able to achieve a significantly higher modified Laplace Log Likelihood score than the winning solutions on the OSIC Pulmonary Fibrosis Progression Challenge, and has been shown to exhibit correct decision-making behavior when making predictions. Fibrosis-Net is available to the general public in an open-source and open access manner as part of the OpenMedAI initiative. While Fibrosis-Net is not yet a production-ready clinical assessment solution, we hope that its release will encourage researchers, clinicians, and citizen data scientists alike to leverage and build upon it.",2021,10.3389/frai.2021.764047
Role of artificial intelligence in smart grid – a mini review,"A smart grid is a structure that regulates, operates, and utilizes energy sources that are incorporated into the smart grid using smart communications techniques and computerized techniques. The running and maintenance of Smart Grids now depend on artificial intelligence methods quite extensively. Artificial intelligence is enabling more dependable, efficient, and sustainable energy systems from improving load forecasting accuracy to optimizing power distribution and guaranteeing issue identification. An intelligent smart grid will be created by substituting artificial intelligence for manual tasks and achieving high efficiency, dependability, and affordability across the energy supply chain from production to consumption. Collection of a large diversity of data is vital to make effective decisions. Artificial intelligence application operates by processing abundant data samples, advanced computing, and strong communication collaboration. The development of appropriate infrastructure resources, including big data, cloud computing, and other collaboration platforms, must be enhanced for this type of operation. In this paper, an attempt has been made to summarize the artificial intelligence techniques used in various aspects of smart grid system.",2025,10.3389/frai.2025.1551661
The role of artificial intelligence in preoperative planning for Total Hip Arthroplasty: a systematic review,"BackgroundTotal Hip Arthroplasty (THA) is a transformative surgical intervention for hip joint disorders, necessitating meticulous preoperative planning for optimal outcomes. With the emergence of Artificial Intelligence (AI), preoperative planning paradigms have evolved, leveraging AI algorithms for enhanced decision support and imaging analysis. This systematic review aims to comprehensively evaluate the role of AI in THA preoperative planning, synthesizing evidence from studies exploring various AI techniques and their applications.MethodsA systematic search of PubMed, Scopus, and Web of Science databases was conducted to identify relevant articles. Inclusion criteria encompassed studies focusing on AI in THA preoperative planning, including randomized controlled trials (RCTs), observational studies, and comparative studies.ResultsSix studies from China met the inclusion criteria, collectively analyzing 831 patients. AI-assisted planning demonstrated superior accuracy in estimating prosthesis size and positioning compared to traditional methods. However, limitations such as geographic bias and language constraints were noted.ConclusionAI-assisted preoperative planning significantly enhances femoral positioning accuracy, providing superior outcomes compared to traditional methods. This improvement in precision, particularly in the placement of femoral and acetabular components, has been consistently observed across studies, making AI an indispensable tool in improving the overall success of Total Hip Arthroplasty. Despite promising findings, further research is warranted to address limitations and optimize the integration of AI technologies into routine clinical practice.",2024,10.3389/frai.2024.1417729
CMDMamba: dual-layer Mamba architecture with dual convolutional feed-forward networks for efficient financial time series forecasting,"IntroductionTransformer models have demonstrated remarkable performance in financial time series forecasting. However, they suffer from inefficiencies in computational efficiency, high operational costs, and limitations in capturing temporal dependencies.MethodsTo address these challenges, we propose the CMDMamba model, which is based on the Mamba architecture of state-space models (SSMs) and achieves near-linear time complexity. This significantly enhances the real-time data processing capability and reduces the deployment costs for risk management systems. The CMDMamba model employs a dual-layer Mamba structure that effectively captures price fluctuations at both the micro- and macrolevels in financial markets and integrates an innovative Dual Convolutional Feedforward Network (DconvFFN) module. This module is able to effectively capture the correlations between multiple variables in financial markets. By doing so, it provides more accurate time series modeling, optimizes algorithmic trading strategies, and facilitates investment portfolio risk warnings.ResultsExperiments conducted on four real-world financial datasets demonstrate that CMDMamba achieves a 10.4% improvement in prediction accuracy for multivariate forecasting tasks compared to state-of-the-art models.DiscussionMoreover, CMDMamba excels in both predictive accuracy and computational efficiency, setting a new benchmark in the field of financial time series forecasting.",2025,10.3389/frai.2025.1599799
Low-rank human-like agents are trusted more and blamed less in human-autonomy teaming,"If humans are to team with artificial teammates, factors that influence trust and shared accountability must be considered when designing agents. This study investigates the influence of anthropomorphism, rank, decision cost, and task difficulty on trust in human-autonomous teams (HAT) and how blame is apportioned if shared tasks fail. Participants (N = 31) completed repeated trials with an artificial teammate using a low-fidelity variation of an air-traffic control game. We manipulated anthropomorphism (human-like or machine-like), military rank of artificial teammates using three-star (superiors), two-star (peers), or one-star (subordinate) agents, the perceived payload of vehicles with people or supplies onboard, and task difficulty with easy or hard missions using a within-subject design. A behavioural measure of trust was inferred when participants accepted agent recommendations, and a measure of no trust when recommendations were rejected or ignored. We analysed the data for trust using binomial logistic regression. After each trial, blame was apportioned using a 2-item scale and analysed using a one-way repeated measures ANOVA. A post-experiment questionnaire obtained participants’ power distance orientation using a seven-item scale. Possible power-related effects on trust and blame apportioning are discussed. Our findings suggest that artificial agents with higher levels of anthropomorphism and lower levels of rank increased trust and shared accountability, with human team members accepting more blame for team failures.",2024,10.3389/frai.2024.1273350
Artificial intelligence as the new frontier in chemical risk assessment,"The rapid progress of AI impacts various areas of life, including toxicology, and promises a major role for AI in future risk assessments. Toxicology has shifted from a purely empirical science focused on observing chemical exposure outcomes to a data-rich field ripe for AI integration. AI methods are well-suited to handling and integrating large, diverse data volumes - a key challenge in modern toxicology. Additionally, AI enables Predictive Toxicology, as demonstrated by the automated read-across tool RASAR that achieved 87% balanced accuracy across nine OECD tests and 190,000 chemicals, outperforming animal test reproducibility. AI’s ability to handle big data and provide probabilistic outputs facilitates probabilistic risk assessment. Rather than just replicating human skills at larger scales, AI should be viewed as a transformative technology. Despite potential challenges, like model black-boxing and dataset biases, explainable AI (xAI) is emerging to address these issues.",2023,10.3389/frai.2023.1269932
"Artificial intelligence, complexity, and systemic resilience in global governance","Artificial Intelligence (AI) is reshaping international governance, presenting opportunities to enhance systemic resilience while posing significant ethical, social, and geopolitical challenges. This paper argues that complexity science offers a valuable framework for navigating AI's integration into global governance systems. We analyze AI's dual capacity as both a transformative tool for improving decision-making, resource allocation, and crisis management, and as a disruptive force introducing risks like data bias, exacerbated inequalities, and governance gaps. By framing resilience as a crucial, boundary concept bridging disciplines and practice, we advocate for adaptive, inclusive governance models capable of managing the inherent uncertainties of AI-driven complex socio-technical systems. Integrating complexity insights with principles like institutional modularity and robust stakeholder collaboration is vital for fostering equity, accountability, and sustainability. This study proposes a conceptual approach aiming to align technological innovation with societal values, ensuring AI deployment contributes to a more resilient and equitable global future, while at the same time it proposes complexity as a boundary concept to bridge the gap between governance literature and philosophy of science and technology.",2025,10.3389/frai.2025.1562095
What you see is not what you get anymore: a mixed-methods approach on human perception of AI-generated images,"The rapid development of text-to-image (TTI) models has made it increasingly difficult to distinguish between AI-generated and authentic photographs. This study explores human perception and detection capabilities regarding AI-generated images of landscapes, architecture, and interiors using a mixed-methods approach. A total of 104 participants took part in an online survey, classifying 50 images (25 real, 25 AI-generated) from five leading TTI models. Alongside their classifications, participants rated their level of confidence and provided optional justifications for their choices. A quantitative analysis revealed that participants correctly identified AI-generated images in 63.7% of cases overall and notably in only 29% of cases when FLUX.1-dev was used. The hierarchical model estimated lower odds of correct detection with increasing age, while education, gender, AI-tool use, media work, and editing experience showed no significant effects. Respective confidence scores highlight calibration issues and suggest potential overconfidence in more experienced groups. The qualitative analysis of 511 textual justifications uncovered several classic visual flaws such as geometric inconsistencies, unrealistic lighting, and semantic anomalies, while simultaneously showing a shift toward tacit judgments. Participants often characterized newer outputs as ‘too perfect’ or faintly uncanny. Therefore, this study emphasizes the need for visual literacy and regulatory mechanisms, especially in contexts susceptible to disinformation. The findings provide insights into vulnerable groups and raise awareness of the social risks posed by hyper-realistic synthetic media.",2025,10.3389/frai.2025.1707336
Comparative diagnostic accuracy of artificial intelligence-derived risk stratification versus conventional risk stratification methods in pulmonary hypertension patients: a systematic review and meta-analysis,"Background
                    Accurate risk stratification in pulmonary hypertension (PH) is integral for optimizing therapeutic strategies and improving patient outcomes. Recent artificial intelligence (AI) models have demonstrated notable efficacy in risk stratification of PH, achieving area under the curve (AUC) values of 0.94 and 0.81 in internal and external validation cohorts, respectively. This meta-analysis aims to demonstrate the effectiveness of AI models in the risk stratification of PH by comparing their performance to conventional risk stratification methods.
                  
                  
                    Methods
                    A systematic search of five databases (PubMed, Embase, ScienceDirect, Scopus, and the Cochrane Library) was conducted from inception to March 2025. Statistical analysis was performed in R (version 2024.12.1 + 563) using 2 × 2 contingency data. Sensitivity, specificity, and diagnostic odds ratio (DOR) were pooled using a bivariate random-effects model (reitsma from the mada package), while the AUC was meta-analyzed using logit-transformed values via the metagen() function from the meta package.
                  
                  
                    Results
                    
                      Six studies were included in the final synthesis, comprising 14,095 patients: 4,481 in internal test datasets and 4,948 in external datasets. AI risk stratification models showed significant performance with a logit mean difference of 0.26 (95% CI 0.09–0.43;
                      p
                       = 0.31), having low heterogeneity (
                      I
                      2
                       = 14.3%) as compared to conventional methods. Furthermore, pooled sensitivity and specificity were 0.77 (95% CI 0.74–0.79) and 0.72 (95% CI 0.70–0.75) in favor of AI methods, respectively. The heterogeneities for pooled sensitivity and specificity were 57.1% (
                      p
                       = 0.04) and 91.8% (
                      p
                       &lt; 0.0001), underscoring high variability across all studies. Finally, DOR was substantially high, 8.53 (6.59–11.04) in favor of AI models with a high heterogeneity of 73.6% (
                      p
                       = 0.002). Heterogeneity (I2) for pooled sensitivity went to 25.9% after excluding a major outlier, but it remained high for pooled specificity and DOR upon leave-one-out sensitivity analysis.
                    
                  
                  
                    Conclusion
                    Artificial intelligence-based risk stratification demonstrates significantly higher diagnostic performance compared to conventional methods in pulmonary hypertension. The higher pooled AUC, sensitivity, specificity, and DOR highlight AI’s potential to enhance predictive accuracy, guiding better treatment strategies. Nonetheless, more superior quality studies are needed to validate AI models for clinical integration.",2025,10.3389/frai.2025.1692829
Analysis of article screening and data extraction performance by an AI systematic literature review platform,"Background
                    Systematic literature reviews (SLRs) are critical to health research and decision-making but are often time- and labor-intensive. Artificial intelligence (AI) tools like large language models (LLMs) provide a promising way to automate these processes.
                  
                  
                    Methods
                    We conducted a systematic literature review on the cost-effectiveness of adult pneumococcal vaccination and prospectively assessed the performance of our AI-assisted review platform, Intelligent Systematic Literature Review (ISLaR) 2.0, compared to expert researchers.
                  
                  
                    Results
                    ISLaR demonstrated high accuracy (0.87 full-text screening; 0.86 data extraction), precision (0.88; 0.86), and sensitivity (0.91; 0.98) in article screening and data extraction tasks, but lower specificity (0.79; 0.42), especially when extracting data from tables. The platform reduced abstract and full-text screening time by over 90% compared to human reviewers.
                  
                  
                    Conclusion
                    The platform has strong potential to reduce reviewer workload but requires further development.",2025,10.3389/frai.2025.1662202
Leveraging artificial intelligence to optimize COVID-19 robust spread and vaccination roll-out strategies in Southern Africa,"The outbreak of coronavirus in the year 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) prompted widespread illness, death, and extended economic devastation worldwide. In response, numerous countries, including Botswana and South Africa, instituted various clinical public health (CPH) strategies to mitigate and control the disease. However, the emergence of variants of concern (VOC), vaccine hesitancy, morbidity, inadequate and inequitable vaccine supply, and ineffective vaccine roll-out strategies caused continuous disruption of essential services. Based on Botswana and South Africa hospitalization and mortality data, we studied the impact of age and gender on disease severity. Comparative analysis was performed between the two countries to establish a vaccination strategy that could complement the existing CPH strategies. To optimize the vaccination roll-out strategy, artificial intelligence was used to identify the population groups in need of insufficient vaccines. We found that COVID-19 was associated with several comorbidities. However, hypertension and diabetes were more severe and common in both countries. The elderly population aged ≥60 years had 70% of major COVID-19 comorbidities; thus, they should be prioritized for vaccination. Moreover, we found that the Botswana and South Africa populations had similar COVID-19 mortality rates. Hence, our findings should be extended to the rest of Southern African countries since the population in this region have similar demographic and disease characteristics.",2022,10.3389/frai.2022.1013010
Streamlining event extraction with a simplified annotation framework,"Event extraction, grounded in semantic relationships, can serve as a simplified relation extraction. In this study, we propose an efficient open-domain event annotation framework tailored for subsequent information extraction, with a specific focus on its applicability to low-resource languages. The proposed event annotation method, which is based on event semantic elements, demonstrates substantial time-efficiency gains over traditional Universal Dependencies (UD) tagging. We show how language-specific pretraining outperforms multilingual counterparts in entity and relation extraction tasks and emphasize the importance of task- and language-specific fine-tuning for optimal model performance. Furthermore, we demonstrate the improvement of model performance upon integrating UD information during pre-training, achieving the F1 score of 71.16 and 60.43% for entity and relation extraction respectively. In addition, we showcase the usage of our extracted event graph for improving node classification in a retail banking domain. This work provides valuable guidance on improving information extraction and outlines a methodology for developing training datasets, particularly for low-resource languages.",2024,10.3389/frai.2024.1361483
An empirical assessment of the use of an algorithm factory for video delivery operations,"IntroductionVideo service providers are moving from focusing on Quality of Service (QoS) to Quality of Experience (QoE) in their video networks since the users’ demand for high-quality video content is continually growing. By focusing on QoE, video service providers can provide their subscribers with a more personalized and engaging experience, which can help increase viewer satisfaction and retention. This focus shift requires not only a more sophisticated approach to network management and new tools and technologies to measure and optimize QoE in their networks but also a novel approach to video delivery operations.MethodsThis paper describes the components, interactions, and relationships of an algorithm factory for video delivery operation that assures high QoE for video streaming services. The paper also showcases the results of gradually implementing an algorithm factory in the video industry. Using a dataset from 2016 to 2022, we present the case of a European PayTV service provider that achieved improved performance measured by both objective and subjective metrics.ResultsThe use of an algorithm factory significantly improved the PayTV service provider’s performance. The study found a fivefold increase in the speed of critical incident resolution and a 59% reduction in the number of critical incidents, all while expanding the customer base and maintaining the same level of labor resources. The case also demonstrates a strong positive relation between the productivity measures of the PayTV operator and their survey-based quality ratings. These results underscore the importance of flawless QoS and operational excellence in delivering QoE to meet the evolving demands of viewers.DiscussionThe paper adds to the existing literature on relationships between operational efficiency, innovation, and subjective quality. The paper further offers empirical evidence from the PayTV industry. The insights provided are expected to benefit both traditional and over-the-top (OTT) video service providers in their quest to stay ahead in the rapidly evolving video industry. It may also translate to other service providers in similar industries committed to supporting high-quality service delivery.",2024,10.3389/frai.2024.1281110
Deep learning in ultrasound tongue imaging: a systematic review toward automated detection of speech sound disorders,"BackgroundSpeech sound disorders (SSD) in children can significantly impact communication and development. Ultrasound tongue imaging (UTI) is a non-invasive method for visualising tongue motion during speech, offering a promising alternative for diagnosis and therapy. Deep learning (DL) techniques have shown great promise in automating the analysis of UTI data, although their clinical application for SSD remains underexplored.ObjectiveThis review aims to synthesise how DL has been utilised in UTI to support automated SSD detection, highlighting the advancement of techniques, key challenges, and future directions.MethodsA comprehensive search of IEEE Xplore, PubMed, ScienceDirect, Scopus, Taylor &amp; Francis, and arXiv identified studies from 2010 through 2025. Inclusion criteria focused on studies using DL to analyse UTI data with relevance to SSD classification, feature extraction, or speech assessment. Eleven studies met the criteria: three directly tackled disordered speech classification tasks, while four addressed supporting tasks like tongue contour segmentation and tongue motion modelling. Promising results were reported in each category, but limitations such as small datasets, inconsistent evaluation, and limited generalisability were common.ResultsDL models demonstrate effectiveness in analysing UTI for articulatory assessment and show early potential in identifying SSD-related patterns. The included studies collectively outline a developmental pipeline, from foundational pre-processing to phoneme-level classification in typically developing speakers, and finally to preliminary attempts at classifying speech errors in children with SSD. This progression illustrates significant technological advances; however, it also emphasises gaps such as the lack of large, disorder-focused datasets and the need for integrated end-to-end systems.ConclusionThe field of DL-driven UTI assessment for speech disorders is developing. Current studies provide a strong technical foundation and proof-of-concept for automatic SSD detection using ultrasound, but clinical translation remains limited. Future research should prioritise the creation of larger annotated UTI datasets of disordered speech, developing generalisable and interpretable models, and validating fully integrated DL-UTI pipelines in real-world speech therapy settings. With these advances, DL-based UTI systems have the potential to transform SSD diagnosis and treatment by providing objective, real-time articulatory feedback in a child-friendly manner.",2025,10.3389/frai.2025.1631134
Synchronizing LLM-based semantic knowledge bases via secure federated fine-tuning in semantic communication,"Semantic communication (SemCom) has seen substantial growth in recent years, largely due to its potential to support future intelligent industries. This advancement hinges on the construction and synchronization of robust semantic knowledge bases (SKBs) across multiple endpoints, which can be achieved through large language models (LLMs). However, existing methods for constructing and synchronizing LLM-based SKBs often face numerous security threats, such as privacy leakage and poisoning attacks, particularly when federated fine-tuning is employed to update LLM knowledge bases. To address these challenges, we propose a novel Secure Federated Fine-Tuning (SecFFT) scheme for synchronizing LLM-based SKBs in semantic communication. First, we incorporate homomorphic encryption into SecFFT to ensure the secure synchronization of model parameters. Second, to enhance the trustworthiness of participants against poisoning attacks, we introduce a residual-based access control mechanism, where only participants with low residuals are authenticated to participate in updating the knowledge base. This mechanism is combined with a hash-based message authentication code. Third, we design a self-adaptive local updating strategy to minimize the impact of poisoned model parameters on benign participants, which is crucial for strengthening the robustness of LLM-based knowledge bases against poisoning attacks. Extensive experiments, conducted using four different datasets from the GLUE benchmark, demonstrate that SecFFT can securely synchronize distributed LLM-based SKBs while maintaining high accuracy (98.4% of the performance of the original federated LoRA), with an acceptable additional cost.",2025,10.3389/frai.2025.1690950
Is synthetic data generation effective in maintaining clinical biomarkers? Investigating diffusion models across diverse imaging modalities,"IntroductionThe integration of recent technologies in medical imaging has become a cornerstone of modern healthcare, facilitating detailed analysis of internal anatomy and pathology. Traditional methods, however, often grapple with data-sharing restrictions due to privacy concerns. Emerging techniques in artificial intelligence offer innovative solutions to overcome these constraints, with synthetic data generation enabling the creation of realistic medical imaging datasets, but the preservation of critical hidden medical biomarkers is an open question.MethodsThis study employs state-of-the-art Denoising Diffusion Probabilistic Models integrated with a Swin-transformer-based network to generate synthetic medical data. Three distinct areas of medical imaging - radiology, ophthalmology, and histopathology - are explored. The quality of synthetic images is evaluated through a classifier trained to identify the preservation of medical biomarkers.ResultsThe diffusion model effectively preserves key medical features, such as lung markings and retinal abnormalities, producing synthetic images closely resembling real data. Classifier performance demonstrates the reliability of synthetic data for downstream tasks, with F1 and AUC reaching 0.8–0.99.DiscussionThis work provides valuable insights into the potential of diffusion-based models for generating realistic, biomarker-preserving synthetic images across various medical imaging modalities. These findings highlight the potential of synthetic data to address challenges such as data scarcity and privacy concerns in clinical practice, research, and education.",2025,10.3389/frai.2024.1454441
A multimodal deep learning architecture for smoking detection with a small data approach,"Covert tobacco advertisements often raise regulatory measures. This paper presents that artificial intelligence, particularly deep learning, has great potential for detecting hidden advertising and allows unbiased, reproducible, and fair quantification of tobacco-related media content. We propose an integrated text and image processing model based on deep learning, generative methods, and human reinforcement, which can detect smoking cases in both textual and visual formats, even with little available training data. Our model can achieve 74% accuracy for images and 98% for text. Furthermore, our system integrates the possibility of expert intervention in the form of human reinforcement. Using the pre-trained multimodal, image, and text processing models available through deep learning makes it possible to detect smoking in different media even with few training data.",2024,10.3389/frai.2024.1326050
Explainable machine learning to predict postoperative ileus after radical cystectomy: an 11-year real-world cohort,"Background
                    Post-operative ileus (POI) is a frequent complication after radical cystectomy (RC). Conventional scores capture only linear relations and have limited accuracy. Interpretable machine learning (ML) may improve early risk stratification.
                  
                  
                    Methods
                    
                      In a single-centre real-world cohort (
                      n
                       = 1,062, 2013–2023), POI was defined by ≥2 standard clinical–radiological criteria. We extracted pre-operative comorbidities/medications, operative factors (approach, urinary diversion, lymph-node dissection, fluids, blood loss, nasogastric-tube placement) and first-day laboratory indices. After LASSO selection, five ML models were trained/validated on a stratified split; discrimination (AUC), accuracy, precision, recall and Brier score were compared. SHAP delivered global and patient-level explanations.
                    
                  
                  
                    Results
                    POI occurred in 28.9%. The back-propagation neural network performed best (AUC 0.828; accuracy 78.4%; Brier 0.143). Intra-operative nasogastric-tube placement and surgical approach dominated feature attribution, followed by medication history, lymph-node dissection, lymphocyte count and C-reactive protein. SHAP clarified feature effects and enabled interpretable, case-level risk summaries.
                  
                  
                    Conclusion
                    An interpretable ML model based on routinely captured peri-operative variables accurately stratifies RC patients at risk for POI as early as postoperative day 0, outperforming existing nomograms and highlighting modifiable factors. Embedding this tool into electronic-health-record workflows could enable real-time alerts and risk-adapted management. Prospective multicentre validation is warranted.",2025,10.3389/frai.2025.1678292
Affective Response Categories—Toward Personalized Reactions in Affect-Adaptive Tutoring Systems,"Affect-adaptive tutoring systems detect the current emotional state of the learner and are capable of adequately responding by adapting the learning experience. Adaptations could be employed to manipulate the emotional state in a direction favorable to the learning process; for example, contextual help can be offered to mitigate frustration, or lesson plans can be accelerated to avoid boredom. Safety-critical situations, in which wrong decisions and behaviors can have fatal consequences, may particularly benefit from affect-adaptive tutoring systems, because accounting for affecting responses during training may help develop coping strategies and improve resilience. Effective adaptation, however, can only be accomplished when knowing which emotions benefit high learning performance in such systems. The results of preliminary studies indicate interindividual differences in the relationship between emotion and performance that require consideration by an affect-adaptive system. To that end, this article introduces the concept of Affective Response Categories (ARCs) that can be used to categorize learners based on their emotion-performance relationship. In an experimental study,N= 50 subjects (33% female, 19–57 years,M= 32.75,SD= 9.8) performed a simulated airspace surveillance task. Emotional valence was detected using facial expression analysis, and pupil diameters were used to indicate emotional arousal. A cluster analysis was performed to group subjects into ARCs based on their individual correlations of valence and performance as well as arousal and performance. Three different clusters were identified, one of which showed no correlations between emotion and performance. The performance of subjects in the other two clusters benefitted from negative arousal and differed only in the valence-performance correlation, which was positive or negative. Based on the identified clusters, the initial ARC model was revised. We then discuss the resulting model, outline future research, and derive implications for the larger context of the field of adaptive tutoring systems. Furthermore, potential benefits of the proposed concept are discussed and ethical issues are identified and addressed.",2022,10.3389/frai.2022.873056
Predictive keywords: Using machine learning to explain document characteristics,"When exploring the characteristics of a discourse domain associated with texts, keyword analysis is widely used in corpus linguistics. However, one of the challenges facing this method is the evaluation of the quality of the keywords. Here, we propose casting keyword analysis as a prediction problem with the goal of discriminating the texts associated with the target corpus from the reference corpus. We demonstrate that, when using linear support vector machines, this approach can be used not only to quantify the discrimination between the two corpora, but also extract keywords. To evaluate the keywords, we develop a systematic and rigorous approach anchored to the concepts of usefulness and relevance used in machine learning. The extracted keywords are compared with the recently proposed text dispersion keyness measure. We demonstrate that that our approach extracts keywords that are highly useful and linguistically relevant, capturing the characteristics of their discourse domain.",2023,10.3389/frai.2022.975729
"Stakeholder-specific adoption of AI in HRM: workers’ representatives’ perspective on concerns, requirements, and measures","IntroductionAI regulations aim to balance AI’s potential and risks in general and human resource management (HRM) in particular. However, regulations are not finally defined and the perspectives of key stakeholders of HRM applications are not clear yet. Research on AI in HRM contributes only to a limited extent to the understanding of key HRM stakeholders, and the perspective of workers’ representatives is especially lacking so far.MethodsThis paper presents a study of three focus group workshops investigating workers’ representatives’ perspectives, to determine which concerns they perceive when using AI in HRM, which resulting requirements they have for adopting AI in HRM, and which measures they perceive as most suitable to fulfill them.ResultsOur results revealed that workers’ representatives were critical of using AI across all HRM phases, particularly in personnel selection. We identified requirements and measures for adopting AI in HRM from the perspective of workers’ representatives. These were summarized in a catalog including six dimensions: control, human oversight, responsibilities, transparency and explainability, lawful AI, and data security.DiscussionOur findings shed a nuanced light on workers’ representatives’ needs, providing relevant insights for research on stakeholder-oriented adoption of AI in HRM and for specifying current AI regulations.",2025,10.3389/frai.2025.1561322
Credit Risk Modeling Using Transfer Learning and Domain Adaptation,"In the domain of credit risk assessment lenders may have limited or no data on the historical lending outcomes of credit applicants. Typically this disproportionately affects Micro, Small, and Medium Enterprises (MSMEs), for which credit may be restricted or too costly, due to the difficulty of predicting the Probability of Default (PD). However, if data from other related credit risk domains is available Transfer Learning may be applied to successfully train models, e.g., from the credit card lending and debt consolidation (CD) domains to predict in the small business lending domain. In this article, we report successful results from an approach using transfer learning to predict the probability of default based on the novel concept of Progressive Shift Contribution (PSC) from source to target domain. Toward real-world application by lenders of this approach, we further address two key questions. The first is to explain transfer learning models, and the second is to adjust features when the source and target domains differ. To address the first question, we apply Shapley values to investigate how and why transfer learning improves model accuracy, and also propose and test a domain adaptation approach to address the second. These results show that adaptation improves model accuracy in addition to the improvement from transfer learning. We extend this by proposing and testing a combined strategy of feature selection and adaptation to convert values of source domain features to better approximate values of target domain features. Our approach includes a strategy to choose features for adaptation and an algorithm to adapt the values of these features. In this setting, transfer learning appears to improve model accuracy by increasing the contribution of less predictive features. Although the percentage improvements are small, such improvements in real world lending could be of significant economic importance.",2022,10.3389/frai.2022.868232
Supporting Artificial Social Intelligence With Theory of Mind,"In this paper, we discuss the development of artificial theory of mind as foundational to an agent's ability to collaborate with human team members. Agents imbued with artificial social intelligence will require various capabilities to gather the social data needed to inform an artificial theory of mind of their human counterparts. We draw from social signals theorizing and discuss a framework to guide consideration of core features of artificial social intelligence. We discuss how human social intelligence, and the development of theory of mind, can contribute to the development of artificial social intelligence by forming a foundation on which to help agents model, interpret and predict the behaviors and mental states of humans to support human-agent interaction. Artificial social intelligence will need the processing capabilities to perceive, interpret, and generate combinations of social cues to operate within a human-agent team. Artificial Theory of Mind affords a structure by which a socially intelligent agent could be imbued with the ability to model their human counterparts and engage in effective human-agent interaction. Further, modeling Artificial Theory of Mind can be used by an ASI to support transparent communication with humans, improving trust in agents, so that they may better predict future system behavior based on their understanding of and support trust in artificial socially intelligent agents.",2022,10.3389/frai.2022.750763
PED: a novel predictor-encoder-decoder model for Alzheimer drug molecular generation,"Alzheimer's disease (AD) is a gradually advancing neurodegenerative disorder characterized by a concealed onset. Acetylcholinesterase (AChE) is an efficient hydrolase that catalyzes the hydrolysis of acetylcholine (ACh), which regulates the concentration of ACh at synapses and then terminates ACh-mediated neurotransmission. There are inhibitors to inhibit the activity of AChE currently, but its side effects are inevitable. In various application fields where Al have gained prominence, neural network-based models for molecular design have recently emerged and demonstrate encouraging outcomes. However, in the conditional molecular generation task, most of the current generation models need additional optimization algorithms to generate molecules with intended properties which make molecular generation inefficient. Consequently, we introduce a cognitive-conditional molecular design model, termed PED, which leverages the variational auto-encoder. Its primary function is to adeptly produce a molecular library tailored for specific properties. From this library, we can then identify molecules that inhibit AChE activity without adverse effects. These molecules serve as lead compounds, hastening AD treatment and concurrently enhancing the AI's cognitive abilities. In this study, we aim to fine-tune a VAE model pre-trained on the ZINC database using active compounds of AChE collected from Binding DB. Different from other molecular generation models, the PED can simultaneously perform both property prediction and molecule generation, consequently, it can generate molecules with intended properties without additional optimization process. Experiments of evaluation show that proposed model performs better than other methods benchmarked on the same data sets. The results indicated that the model learns a good representation of potential chemical space, it can well generate molecules with intended properties. Extensive experiments on benchmark datasets confirmed PED's efficiency and efficacy. Furthermore, we also verified the binding ability of molecules to AChE through molecular docking. The results showed that our molecular generation system for AD shows excellent cognitive capacities, the molecules within the molecular library could bind well to AChE and inhibit its activity, thus preventing the hydrolysis of ACh.",2024,10.3389/frai.2024.1374148
C3PO: a crop planning and production process ontology and knowledge graph,"Vegetable crop farmers diversify their production by growing a range of crops during the season on the same plot. Crop diversification and rotation enables farmers to increase their income and crop yields while enhancing their farm sustainability against climatic events and pest attacks. Farmers must plan their agricultural work per year and over successive years. Planning decisions are made on the basis of their experience regarding previous plans. For the purpose of assisting farmers in planning decisions and monitoring, we developed the Crop Planning and Production Process Ontology (C3PO), i.e., a representation of agricultural knowledge and data for diversified crop production. C3PO is composed of eight modules to capture all crop production dimensions and complexity for representing farming practices and constraints. It encodes agricultural processes and farm plot organization and captures common agricultural knowledge. C3PO introduces a representation of technical itineraries, i.e., sequences of technical farming tasks to grow vegetables, from soil identification and seed selection to harvest and storage. C3PO is the backbone of a knowledge graph which aggregates data from heterogeneous related semantic resources, e.g., organism taxonomies, chemicals, reference crop listings, or development stages. C3PO and its knowledge graph are used by the Elzeard enterprise to develop knowledge-based decision support systems for farmers. This article describes how we built C3PO and its knowledge graph—which are both publicly available—and briefly outlines their applications.",2023,10.3389/frai.2023.1187090
Beyond the stereotypes: Artificial Intelligence image generation and diversity in anesthesiology,"IntroductionArtificial Intelligence (AI) is increasingly being integrated into anesthesiology to enhance patient safety, improve efficiency, and streamline various aspects of practice.ObjectiveThis study aims to evaluate whether AI-generated images accurately depict the demographic racial and ethnic diversity observed in the Anesthesia workforce and to identify inherent social biases in these images.MethodsThis cross-sectional analysis was conducted from January to February 2024. Demographic data were collected from the American Society of Anesthesiologists (ASA) and the European Society of Anesthesiology and Intensive Care (ESAIC). Two AI text-to-image models, ChatGPT DALL-E 2 and Midjourney, generated images of anesthesiologists across various subspecialties. Three independent reviewers assessed and categorized each image based on sex, race/ethnicity, age, and emotional traits.ResultsA total of 1,200 images were analyzed. We found significant discrepancies between AI-generated images and actual demographic data. The models predominantly portrayed anesthesiologists as White, with ChatGPT DALL-E2 at 64.2% and Midjourney at 83.0%. Moreover, male gender was highly associated with White ethnicity by ChatGPT DALL-E2 (79.1%) and with non-White ethnicity by Midjourney (87%). Age distribution also varied significantly, with younger anesthesiologists underrepresented. The analysis also revealed predominant traits such as “masculine, ““attractive, “and “trustworthy” across various subspecialties.ConclusionAI models exhibited notable biases in gender, race/ethnicity, and age representation, failing to reflect the actual diversity within the anesthesiologist workforce. These biases highlight the need for more diverse training datasets and strategies to mitigate bias in AI-generated images to ensure accurate and inclusive representations in the medical field.",2024,10.3389/frai.2024.1462819
Targeted generative data augmentation for automatic metastases detection from free-text radiology reports,"Automatic identification of metastatic sites in cancer patients from electronic health records is a challenging yet crucial task with significant implications for diagnosis and treatment. In this study, we demonstrate how advancements in natural language processing, namely the instruction-following capability of recent large language models and extensive model pretraining, made it possible to automate metastases detection from radiology reports texts with a limited amount of gold-labeled data. Specifically, we prompt Llama3, an open-source instruction-tuned large language model, to generate synthetic training data to expand our limited labeled data and adapt BERT, a small pretrained language model, to the task. We further investigate three targeted data augmentation techniques which selectively expand the original training samples, leading to comparable or superior performance compared to vanilla data augmentation, in most cases, while being substantially more computationally efficient. In our experiments, data augmentation improved the average F1-score by 2.3, 3.5, and 3.9 points for lung, liver, and adrenal glands, the organs for which we had access to expert-annotated data. This observation suggests that Llama3, which has not been specifically tailored to this task or clinical data in general, can generate high-quality synthetic data through paraphrasing in the clinical context. We also compare metastasis identification accuracy between models utilizing institutionally standardized reports vs. non-structured reports, which complicate the extraction of relevant information, and show how including patient history with a customized model architecture narrows the gap between those two setups from 7.3 to 4.5 points on F1-score under LoRA tuning. Our work delivers a broadly applicable solution with remarkable performance that does not require model customization for each institution, making large-scale, low-cost spatio-temporal cancer progression pattern extraction possible.",2025,10.3389/frai.2025.1513674
The assessment list for trustworthy artificial intelligence: A review and recommendations,"In July 2020, the European Commission's High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as Environmental Sustainability, Social Justice, and Corporate Governance (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry.",2023,10.3389/frai.2023.1020592
ChatGPT: perspectives from human–computer interaction and psychology,"The release of GPT-4 has garnered widespread attention across various fields, signaling the impending widespread adoption and application of Large Language Models (LLMs). However, previous research has predominantly focused on the technical principles of ChatGPT and its social impact, overlooking its effects on human–computer interaction and user psychology. This paper explores the multifaceted impacts of ChatGPT on human–computer interaction, psychology, and society through a literature review. The author investigates ChatGPT’s technical foundation, including its Transformer architecture and RLHF (Reinforcement Learning from Human Feedback) process, enabling it to generate human-like responses. In terms of human–computer interaction, the author studies the significant improvements GPT models bring to conversational interfaces. The analysis extends to psychological impacts, weighing the potential of ChatGPT to mimic human empathy and support learning against the risks of reduced interpersonal connections. In the commercial and social domains, the paper discusses the applications of ChatGPT in customer service and social services, highlighting the improvements in efficiency and challenges such as privacy issues. Finally, the author offers predictions and recommendations for ChatGPT’s future development directions and its impact on social relationships.",2024,10.3389/frai.2024.1418869
Evaluating a retrieval-augmented pregnancy chatbot: a comprehensibility–accuracy-readability study of the DIAN AI assistant,"IntroductionPatient education materials (PEMs) often exceed common health literacy levels. Retrieval-augmented conversational AI may deliver interactive, evidence-grounded explanations tailored to user needs. We evaluated DIAN, a RAG-enabled pregnancy chatbot grounded in the NHS Pregnancy Book, using a comprehensibility–accuracy–readability (CAR) framework to compare perceptions between women and clinicians across key perinatal domains.MethodsWe conducted a cross-sectional evaluation with standardized prompts and blinded scoring. Participants were 119 women (18–55 years) and 29 clinicians. After brief CAR training and calibration, all evaluators independently rated the same DIAN responses on 4-point Likert scales across postpartum care, pregnancy health and complications, diet and nutrition, and mental and emotional wellbeing. Between-group differences were tested using the Mann–Whitney U test with Bonferroni adjustment across domains per outcome; effect sizes were summarized with r = |Z|/√N and Cliff’s delta. Inter-rater reliability was not estimated, given the independent-rater design.ResultsDifferences concentrated in postpartum care. Comprehensibility favored women (U = 1206.50, Z = −2.524, p = 0.012; r = 0.207; Δ = 0.301). Accuracy also favored women (U = 1239.00, Z = −2.370, p = 0.018; r = 0.195; Δ = 0.282). Readability favored clinicians (U = 1181.50, Z = −2.639, p = 0.008; r = 0.217; Δ = 0.315). Other domains showed no significant between-group differences after correction. Radar visualizations mirrored these patterns, with women showing larger comprehensibility/accuracy profiles and clinicians showing larger readability profiles in postpartum care.DiscussionGrounded in an authoritative national guide, DIAN achieved broadly comparable CAR perceptions across groups, with clinically relevant divergence limited to postpartum care. Women perceived higher comprehensibility and accuracy, while clinicians judged language more readable, suggesting a gap between experiential clarity and professional textual ease. Targeted postpartum refinement, lexical simplification, role-tailored summaries, and actionable checklists may align perceptions without compromising fidelity. More broadly, RAG-grounded chatbots can support equitable digital health education when content is vetted, updated, and evaluated with stakeholder-centered metrics. Future work should examine free-form interactions, longitudinal behavioral outcomes, and ethical safeguards (scope-of-use messaging, escalation pathways, and bias audits).",2025,10.3389/frai.2025.1640994
Air pollution particulate matter (PM2.5) prediction in South African cities using machine learning techniques,"BackgroundAir pollution contributes to the most severe environmental and health problems due to industrial emissions and atmosphere contamination, produced by climate and traffic factors, fossil fuel combustion, and industrial characteristics. Because this is a global issue, several nations have established control of air pollution stations in various cities to monitor pollutants like Nitrogen Dioxide (NO2), Ozone (O3), Sulfur Dioxide (SO2), Carbon Monoxide (CO), Particulate Matter (PM2.5, PM10), to notify inhabitants when pollution levels surpass the quality threshold. With the rise in air pollution, it is necessary to construct models to capture data on air pollutant concentrations. Compared to other parts of the world, Africa has a scarcity of reliable air quality sensors for monitoring and predicting Particulate Matter (PM2.5). This demonstrates the possibility of extending research in air pollution control.MethodsMachine learning techniques were utilized in this study to identify air pollution in terms of time, cost, and efficiency so that different scenarios and systems may select the optimal way for their needs. To assess and forecast the behavior of Particulate Matter (PM2.5), this study presented a Machine Learning approach that includes Cat Boost Regressor, Extreme Gradient Boosting Regressor, Random Forest Classifier, Logistic Regression, Support Vector Machine, K-Nearest Neighbor, and Decision Tree.ResultsCat Boost Regressor and Extreme Gradient Boosting Regressor were implemented to predict the latest PM2.5 concentrations for South African Cities with recording stations using past dated recordings, then the best performing model between the two is used to predict PM2.5 concentrations for South African Cities with no recording stations and also to predict future PM2.5 concentrations for South African Cities. K-Nearest Neighbor, Logistic Regression, Support Vector Machine, Decision Tree, and Random Forest Classifier were implemented to create a system predicting the Air Quality Index (AQI) Status.ConclusionThis study investigated various machine learning techniques for air pollution to analyze and predict air pollution behavior regarding air quality and air pollutants, detecting which areas are most affected in South African cities.",2023,10.3389/frai.2023.1230087
Conversational AI agent for precision oncology: AI-HOPE-WNT integrates clinical and genomic data to investigate WNT pathway dysregulation in colorectal cancer,"IntroductionThe WNT signaling pathway is a key driver of colorectal cancer (CRC) initiation and progression, particularly in early-onset CRC (EOCRC) among underserved populations. However, interrogating WNT pathway dysregulation across clinical and genomic dimensions remains technically challenging, limiting both translational insight and personalized intervention strategies. To address this gap, we developed AI-HOPE-WNT, the first conversational artificial intelligence (AI) agent purpose-built to investigate WNT signaling in CRC using natural language–driven, integrative bioinformatics.MethodsAI-HOPE-WNT employs a modular architecture combining large language models (LLMs), a natural language-to-code engine, and a backend statistical workflow interfaced with harmonized data from cBioPortal. Unlike general-purpose platforms, AI-HOPE-WNT is uniquely optimized for WNT-specific precision oncology. The tool supports mutation frequency analysis, odds ratio testing, survival modeling, and subgroup stratification by genomic, clinical, and demographic variables. To validate the platform, we recapitulated findings from two previous studies examining WNT pathway alterations in high-risk CRC populations, including mutation prevalence in RNF43 and AXIN2 and survival outcomes associated with WNT pathway status across ethnic and age subgroups. Exploratory queries further assessed treatment response, co-mutation patterns, and population-specific trends.ResultsIn recapitulation analyses, AI-HOPE-WNT reproduced key trends from prior work, including improved survival in WNT-altered EOCRC and higher RNF43 mutation rates in Hispanic/Latino (H/L) populations compared to non-Hispanic White (NHW) people. Exploratory analyses revealed several novel findings. Among FOLFOX-treated EOCRC patients, APC mutations were associated with significantly different survival outcomes (p = 0.043). RNF43-mutant tumors showed worse survival in metastatic versus primary cases (p = 0.028). AXIN1 and APC co-mutations demonstrated location-specific enrichment between colon and rectal tumors. Gender-based differences in AXIN2-mutant cases under varying MSI status yielded significant survival variation (p = 0.036). Additionally, patients under 50 with APC-mutant primary tumors showed worse survival (p = 0.031) and increased mutation prevalence.ConclusionAI-HOPE-WNT is the first dedicated AI platform for WNT pathway analysis in CRC. By combining natural language interaction with automated, high-throughput bioinformatics, it democratizes access to pathway-specific precision oncology research. The platform is freely available at: https://github.com/Velazquez-Villarreal-Lab/AI-HOPE-WNT.",2025,10.3389/frai.2025.1624797
Detection and classification of ChatGPT-generated content using deep transformer models,"IntroductionThe rapid advancement of AI, particularly artificial neural networks, has led to revolutionary breakthroughs and applications, such as text-generating tools and chatbots. However, this potent technology also introduces potential misuse and societal implications, including privacy violations, misinformation, and challenges to integrity and originality in academia. Several studies have attempted to distinguish and classify AI-generated textual content from human-authored work, but their performance remains questionable, particularly for AI models utilizing large language models like ChatGPT.MethodsTo address this issue, we compiled a dataset consisting of both human-written and AI-generated (ChatGPT) content. This dataset was then used to train and evaluate a range of machine learning and deep learning models under various training conditions. We assessed the efficacy of different models in detecting and classifying AI-generated content, with a particular focus on transformer-based architectures.ResultsExperimental results demonstrate that the proposed RoBERTa-based custom deep learning model achieved an F1-score of 0.992 and an accuracy of 0.991, followed by DistilBERT, which yielded an F1-score of 0.988 and an accuracy of 0.988. These results indicate exceptional performance in detecting and classifying AI-generated content.DiscussionOur findings establish a robust baseline for the detection and classification of AI-generated textual content. This work marks a significant step toward mitigating the potential misuse of AI-powered text generation tools by providing a reliable approach for distinguishing between human and AI-generated text. Future research could explore the generalizability of these models across different AI-generated content sources and address evolving challenges in AI text detection.",2025,10.3389/frai.2025.1458707
Explainable multilingual and multimodal fake-news detection: toward robust and trustworthy AI for combating misinformation,"Fake-news detection requires systems that are multilingual, multimodal, and explainable—yet the majority of the existing models are English-centric, text-only, and opaque. This study introduces two key innovations: (i) a new multilingual–multimodal dataset of 74,000 news articles in Hindi, Gujarati, Marathi, Telugu, and English with paired images, and (ii) Hybrid Explainable Multimodal Transformer Fake (HEMT-Fake) that integrates text, image, and relational signals with hierarchical explainability. The architecture combines transformer embeddings, a convolutional neural network–bidirectional long short-term memory (CNN–BiLSTM) text encoder, residual network (ResNet) image features, and graph sample and aggregate (GraphSAGE) metadata, all of which are fused via multi-head attention. Its explainability module unites attention, Shapley Additive exPlanations (SHAP), and local interpretable model-agnostic explanations (LIME) to provide token-, sentence-, and modality-level transparency. Across four languages, HEMT-Fake delivers a ~ 5% Macro-F1 improvement over Cross-Lingual Language Model with RoBERTa (XLM-R) architecture and Multilingual Bidirectional Encoder Representations From Transformers (mBERT), with gains of 7–8% in low-resource languages. The model achieves 85% accuracy under adversarial paraphrasing and 80% on artificial intelligence (AI)-generated fake news, halving robustness losses compared to baselines. Human evaluation reveals that 82% of explanations are judged to be meaningful, confirming transparency and trust for fact-checkers.",2025,10.3389/frai.2025.1690616
Application of Video-to-Video Translation Networks to Computational Fluid Dynamics,"In recent years, the evolution of artificial intelligence, especially deep learning, has been remarkable, and its application to various fields has been growing rapidly. In this paper, I report the results of the application of generative adversarial networks (GANs), specifically video-to-video translation networks, to computational fluid dynamics (CFD) simulations. The purpose of this research is to reduce the computational cost of CFD simulations with GANs. The architecture of GANs in this research is a combination of the image-to-image translation networks (the so-called “pix2pix”) and Long Short-Term Memory (LSTM). It is shown that the results of high-cost and high-accuracy simulations (with high-resolution computational grids) can be estimated from those of low-cost and low-accuracy simulations (with low-resolution grids). In particular, the time evolution of density distributions in the cases of a high-resolution grid is reproduced from that in the cases of a low-resolution grid through GANs, and the density inhomogeneity estimated from the image generated by GANs recovers the ground truth with good accuracy. Qualitative and quantitative comparisons of the results of the proposed method with those of several super-resolution algorithms are also presented.",2021,10.3389/frai.2021.670208
Feature alignment as a generative process,"Reversibility in artificial neural networks allows us to retrieve the input given an output. We present feature alignment, a method for approximating reversibility in arbitrary neural networks. We train a network by minimizing the distance between the output of a data point and the random output with respect to a random input. We applied the technique to the MNIST, CIFAR-10, CelebA, and STL-10 image datasets. We demonstrate that this method can roughly recover images from just their latent representation without the need of a decoder. By utilizing the formulation of variational autoencoders, we demonstrate that it is possible to produce new images that are statistically comparable to the training data. Furthermore, we demonstrate that the quality of the images can be improved by coupling a generator and a discriminator together. In addition, we show how this method, with a few minor modifications, can be used to train networks locally, which has the potential to save computational memory resources.",2023,10.3389/frai.2022.1025148
Utility of Crowdsourced User Experiments for Measuring the Central Tendency of User Performance: A Case of Error-Rate Model Evaluation in a Pointing Task,"The usage of crowdsourcing to recruit numerous participants has been recognized as beneficial in the human-computer interaction (HCI) field, such as for designing user interfaces and validating user performance models. In this work, we investigate its effectiveness for evaluating an error-rate prediction model in target pointing tasks. In contrast to models for operational times, a clicking error (i.e., missing a target) occurs by chance at a certain probability, e.g., 5%. Therefore, in traditional laboratory-based experiments, a lot of repetitions are needed to measure the central tendency of error rates. We hypothesize that recruiting many workers would enable us to keep the number of repetitions per worker much smaller. We collected data from 384 workers and found that existing models on operational time and error rate showed good fits (both R2 &gt; 0.95). A simulation where we changed the number of participants NP and the number of repetitions Nrepeat showed that the time prediction model was robust against small NP and Nrepeat, although the error-rate model fitness was considerably degraded. These findings empirically demonstrate a new utility of crowdsourced user experiments for collecting numerous participants, which should be of great use to HCI researchers for their evaluation studies.",2022,10.3389/frai.2022.798892
Imagining the city in lockdown: Place in the COVID-19 self-recordings of the Lothian Diary Project,"The COVID-19 pandemic brought about a profound change to the organization of space and time in our daily lives. In this paper we analyze the self-recorded audio/video diaries made by residents of Edinburgh and the Lothian counties during the first national lockdown. We identify three ways in which diarists describe a shift in place-time, or “chronotope”, in lockdown. We argue that the act of making a diary for an audience of the future prompts diarists to contrast different chronotopes, and each of these orientations illuminates the differential impact of the COVID-19 lockdowns across the community.",2022,10.3389/frai.2022.945643
AlphaZe∗∗: AlphaZero-like baselines for imperfect information games are surprisingly strong,"In recent years, deep neural networks for strategy games have made significant progress. AlphaZero-like frameworks which combine Monte-Carlo tree search with reinforcement learning have been successfully applied to numerous games with perfect information. However, they have not been developed for domains where uncertainty and unknowns abound, and are therefore often considered unsuitable due to imperfect observations. Here, we challenge this view and argue that they are a viable alternative for games with imperfect information—a domain currently dominated by heuristic approaches or methods explicitly designed for hidden information, such as oracle-based techniques. To this end, we introduce a novel algorithm based solely on reinforcement learning, called AlphaZe∗∗, which is an AlphaZero-based framework for games with imperfect information. We examine its learning convergence on the games Stratego and DarkHex and show that it is a surprisingly strong baseline, while using a model-based approach: it achieves similar win rates against other Stratego bots like Pipeline Policy Space Response Oracle (P2SRO), while not winning in direct comparison against P2SRO or reaching the much stronger numbers of DeepNash. Compared to heuristics and oracle-based approaches, AlphaZe∗∗ can easily deal with rule changes, e.g., when more information than usual is given, and drastically outperforms other approaches in this respect.",2023,10.3389/frai.2023.1014561
Toward explainable deep learning in healthcare through transition matrix and user-friendly features,"Modern artificial intelligence (AI) solutions often face challenges due to the “black box” nature of deep learning (DL) models, which limits their transparency and trustworthiness in critical medical applications. In this study, we propose and evaluate a scalable approach based on a transition matrix to enhance the interpretability of DL models in medical signal and image processing by translating complex model decisions into user-friendly and justifiable features for healthcare professionals. The criteria for choosing interpretable features were clearly defined, incorporating clinical guidelines and expert rules to align model outputs with established medical standards. The proposed approach was tested on two medical datasets: electrocardiography (ECG) for arrhythmia detection and magnetic resonance imaging (MRI) for heart disease classification. The performance of the DL models was compared with expert annotations using Cohen’s Kappa coefficient to assess agreement, achieving coefficients of 0.89 for the ECG dataset and 0.80 for the MRI dataset. These results demonstrate strong agreement, underscoring the reliability of the approach in providing accurate, understandable, and justifiable explanations of DL model decisions. The scalability of the approach suggests its potential applicability across various medical domains, enhancing the generalizability and utility of DL models in healthcare while addressing practical challenges and ethical considerations.",2024,10.3389/frai.2024.1482141
Parallel joint encoding for drone-view object detection under low-light conditions,"Under low-light conditions, the accuracy of drone-view object detection algorithms is frequently compromised by noise and insufficient illumination. Herein, we propose a parallel neural network that concurrently performs image enhancement and object detection for drone-view object detection in nighttime environments. Our innovative coevolutionary framework establishes bidirectional gradient propagation pathways between network modules, improving the robustness of feature representations through the joint optimization of the photometric correction and detection objectives. The illumination enhancement network employs Zero-DCE++, which adaptively adjusts the brightness distribution without requiring paired training data. In our model, object detection is performed using a lightweight YOLOv5 architecture that exhibits good detection accuracy while maintaining real-time performance. To further optimize feature extraction, we introduce a spatially adaptive feature modulation module and a high- and low-frequency adaptive feature enhancement block. The former dynamically modulates the input features through multiscale feature fusion, enhancing the ability of the model to perceive local and global information. The latter module enhances semantic representation and edge details through the parallel processing of spatial contextual information and feature refinement. Experiments on the two data sets of VisDrone2019 (Night) and Drone Vehicle (Night) show that the proposed method improves 3.13 and 3.1% compared with the traditional YOLOv5 method mAP@0.5:0.95, and improves 6.3 and 2% in mAP@0.5, especially in the extreme low light and high noise environment.Thus, the proposed parallel model is an efficient and reliable solution for drone-based nighttime visual monitoring.",2025,10.3389/frai.2025.1622100
Enhancing pre-trained language model by answering natural questions for event extraction,"IntroductionEvent extraction is the task of identifying and extracting structured information about events from unstructured text. However, event extraction remains challenging due to the complexity and diversity of event expressions, as well as the ambiguity and context dependency of language.MethodsIn this paper, we propose a new method to improve the precision and recall of event extraction by including topic words related to events and their contexts, directing the model to focus on the relevant information, and filtering the noise.ResultsThis method was evaluated on the ACE 2005 dataset, achieving an F1-score of 77.27% with significant improvements in both precision and recall.DiscussionOur results show that the use of topic words and question answering techniques can effectively address the challenges faced by event extraction and pave the way for the development of more accurate and robust event extraction systems.",2025,10.3389/frai.2025.1520290
Domain-Informed Neural Networks for Interaction Localization Within Astroparticle Experiments,"This work proposes a domain-informed neural network architecture for experimental particle physics, using particle interaction localization with the time-projection chamber (TPC) technology for dark matter research as an example application. A key feature of the signals generated within the TPC is that they allow localization of particle interactions through a process called reconstruction (i.e., inverse-problem regression). While multilayer perceptrons (MLPs) have emerged as a leading contender for reconstruction in TPCs, such a black-box approach does not reflect prior knowledge of the underlying scientific processes. This paper looks anew at neural network-based interaction localization and encodes prior detector knowledge, in terms of both signal characteristics and detector geometry, into the feature encoding and the output layers of a multilayer (deep) neural network. The resulting neural network, termed Domain-informed Neural Network (DiNN), limits the receptive fields of the neurons in the initial feature encoding layers in order to account for the spatially localized nature of the signals produced within the TPC. This aspect of the DiNN, which has similarities with the emerging area of graph neural networks in that the neurons in the initial layers only connect to a handful of neurons in their succeeding layer, significantly reduces the number of parameters in the network in comparison to an MLP. In addition, in order to account for the detector geometry, the output layers of the network are modified using two geometric transformations to ensure the DiNN produces localizations within the interior of the detector. The end result is a neural network architecture that has 60% fewer parameters than an MLP, but that still achieves similar localization performance and provides a path to future architectural developments with improved performance because of their ability to encode additional domain knowledge into the architecture.",2022,10.3389/frai.2022.832909
Explainable detection: a transformer-based language modeling approach for Bengali news title classification with comparative explainability analysis using ML and DL,"Classifying scattered Bengali text is the primary focus of this study, with an emphasis on explainability in Natural Language Processing (NLP) for low-resource languages. We employed supervised Machine Learning (ML) models as a baseline and compared their performance with Long Short-Term Memory (LSTM) networks from the deep learning domain. Subsequently, we implemented transformer models designed for sequential learning. To prepare the dataset, we collected recent Bengali news articles online and performed extensive feature engineering. Given the inherent noise in Bengali datasets, significant preprocessing was required. Among the models tested, XLM-RoBERTa Base achieved the highest accuracy 0.91. Furthermore, we integrated explainable AI techniques to interpret the model’s predictions, enhancing transparency and fostering trust in the classification outcomes. Additionally, we employed LIME (Local Interpretable Model-agnostic Explanations) to identify key features and the most weighted words responsible for classifying news titles, which validated the accuracy of Bengali news classification results. This study underscores the potential of deep learning models in advancing text classification for the Bengali language and emphasizes the critical role of explainability in AI-driven solutions.",2025,10.3389/frai.2025.1537432
A systematic review of deep learning methods for community detection in social networks,"IntroductionThe rapid expansion of generated data through social networks has introduced significant challenges, which underscores the need for advanced methods to analyze and interpret these complex systems. Deep learning has emerged as an effective approach, offering robust capabilities to process large datasets, and uncover intricate relationships and patterns.MethodsIn this systematic literature review, we explore research conducted over the past decade, focusing on the use of deep learning techniques for community detection in social networks. A total of 19 studies were carefully selected from reputable databases, including the ACM Library, Springer Link, Scopus, Science Direct, and IEEE Xplore. This review investigates the employed methodologies, evaluates their effectiveness, and discusses the challenges identified in these works.ResultsOur review shows that models like graph neural networks (GNNs), autoencoders, and convolutional neural networks (CNNs) are some of the most commonly used approaches for community detection. It also examines the variety of social networks, datasets, evaluation metrics, and employed frameworks in these studies.DiscussionHowever, the analysis highlights several challenges, such as scalability, understanding how the models work (interpretability), and the need for solutions that can adapt to different types of networks. These issues stand out as important areas that need further attention and deeper research. This review provides meaningful insights for researchers working in social network analysis. It offers a detailed summary of recent developments, showcases the most impactful deep learning methods, and identifies key challenges that remain to be explored.",2025,10.3389/frai.2025.1572645
Analyzing handwriting legibility through hand kinematics,"IntroductionHandwriting is a complex skill that requires coordination between human motor system, sensory perception, cognitive processing, memory retrieval, and linguistic proficiency. Various aspects of hand and stylus kinematics can affect the legibility of a handwritten text. Assessing handwriting legibility is challenging due to variations in experts' cultural and academic backgrounds, which introduce subjectivity biases in evaluations.MethodsIn this paper, we utilize a deep-learning model to analyze kinematic features influencing the legibility of handwriting based on temporal convolutional networks (TCN). Fifty subjects are recruited to complete a 26-word paragraph handwriting task, designed to include all possible orthographic combinations of Arabic characters, during which the hand and stylus movements are recorded. A total of 117 different spatiotemporal features are recorded, and the data collected are used to train the model. Shapley values are used to determine the important hand and stylus kinematics features toward evaluating legibility. Three experts are recruited to label the produced text into different legibility scores. Statistical analysis of the top 6 features is conducted to investigate the differences between features associated with high and low legibility scores.ResultsAlthough the model trained on stylus kinematics features demonstrates relatively high accuracy (around 76%), where the number of legibility classes can vary between 7 and 8 depending on the expert, the addition of hand kinematics features significantly increases the model accuracy by approximately 10%. Explainability analysis revealed that pressure variability, pen slant (altitude, azimuth), and hand speed components are the most prominent for evaluating legibility across the three experts.DiscussionThe model learns meaningful stylus and hand kinematics features associated with the legibility of handwriting. The hand kinematics features are important for accurate assessment of handwriting legibility. The proposed approach can be used in handwriting learning tools for personalized handwriting skill acquisition as well as for pathology detection and rehabilitation.",2025,10.3389/frai.2025.1426455
"Heart rates, facial expressions and self-reports: a multimodal longitudinal approach of learners' emotions in the foreign language classroom","Emotions in educational settings are often studied through self-reports or lab experiments, limiting insights into their real-world dynamics. This study examines learner emotions in authentic foreign language classrooms using a multimodal longitudinal approach. Over 16 consecutive sessions, we collected heart rate (HR) signals, emotional facial expressions (EFE), classroom observations, and self-reports on enjoyment, anxiety, and boredom to capture both physiological and self-perceived emotional responses. Rather than aggregating data across students, we focused on individualized emotional patterns to understand variations in emotional experiences. Each dataset included extensive video recordings, continuous HR monitoring, detailed observational notes, and post-session questionnaires, providing a high-resolution picture of emotional dynamics. Using unsupervised clustering techniques, we identified key emotional episodes—peaks and drops in physiological arousal (heart rate variation) and facial expression—relative to individual emotional baselines. These moments were cross-referenced with classroom observations and self-reports for validation. Findings highlight moments of positive emotional contagion during peer interactions, emphasizing the social dimension of language learning. This multimodal approach captures the interplay of physiological, behavioral, and subjective responses, offering a scalable method for studying classroom emotions. Methodologically, it demonstrates how multimodal analytics can uncover transient emotional states in real-world settings, while practically informing adaptive teaching strategies, such as leveraging peer interactions to enhance engagement or reduce anxiety. By integrating physiological, behavioral, and subjective data, this study provides a comprehensive framework for understanding the affective dimensions of learning.",2025,10.3389/frai.2025.1604110
Image restoration and key field alignment for misaligned overlapping text in secondary printing document images,"With the advancement of information technology, the demand for efficient recognition and information extraction from paper documents in industrial scenarios has grown rapidly. In practice, business information is often secondarily printed onto pre-designed templates, which frequently leads to text misalignment or overlap with backgrounds and tables, thereby significantly impairing the accuracy of subsequent Optical Character Recognition (OCR). To address this issue, this paper proposes a preprocessing method for OCR recognition of secondary printed documents, specifically targeting the problems of text misalignment and overlap. In particular, we design a Text Overlap Restoration Network (TORNet) to restore document images affected by text overlap. Experimental results demonstrate that, compared to the latest image restoration models, TORNet achieves PSNR improvements of 0.17 dB and 0.12 dB in foreground and background text restoration, respectively. Furthermore, to resolve residual misalignment issues after image restoration, a key-field alignment method is introduced. This method accurately locates the positional deviations of critical fields in the reconstructed image, enabling precise field-level alignment and structural correction. Based on the proposed preprocessing framework, the recognition accuracy and field-matching accuracy are improved by 23% and 31%, respectively, compared to existing commercial OCR models, significantly enhancing the recognition performance on misaligned and overlapping documents. This study provides an effective solution for recognizing secondary printed documents with text overlap in industrial environments.",2025,10.3389/frai.2025.1616007
Improving text mining in plant health domain with GAN and/or pre-trained language model,"The Bidirectional Encoder Representations from Transformers (BERT) architecture offers a cutting-edge approach to Natural Language Processing. It involves two steps: 1) pre-training a language model to extract contextualized features and 2) fine-tuning for specific downstream tasks. Although pre-trained language models (PLMs) have been successful in various text-mining applications, challenges remain, particularly in areas with limited labeled data such as plant health hazard detection from individuals' observations. To address this challenge, we propose to combine GAN-BERT, a model that extends the fine-tuning process with unlabeled data through a Generative Adversarial Network (GAN), with ChouBERT, a domain-specific PLM. Our results show that GAN-BERT outperforms traditional fine-tuning in multiple text classification tasks. In this paper, we examine the impact of further pre-training on the GAN-BERT model. We experiment with different hyper parameters to determine the best combination of models and fine-tuning parameters. Our findings suggest that the combination of GAN and ChouBERT can enhance the generalizability of the text classifier but may also lead to increased instability during training. Finally, we provide recommendations to mitigate these instabilities.",2023,10.3389/frai.2023.1072329
Inclusive Growth in the Era of Automation and AI: How Can Taxation Help?,"In the last decades, the world economy is facing a massive rise in automation, robotics and Artificial Intelligence (AI) which, according to some analysts, could lead to significant job losses or job polarization and hence widen income and wealth disparities. This scenario may impede the achievement of the Sustainable Development Goal 8 (SDG 8). In this context, the role of government and regulation becomes crucial in order to prevent an undesirable scenario, where technological change, namely automation and AI, comes at the cost of mass unemployment and growing inequality. This paper focuses on the role of taxation as a possible tool for sharing the gains from automation and AI. Nowadays, advances in technology may have a direct impact on tax systems, which should be re-adapted to take into account new forms of jobs and new business models. The paper discusses pros and cons of several possible solutions and then compares progresses achieved in different countries. Concerning robot tax and digital taxes there are already some concrete steps undertaken both at national and international level, while other proposals remain still nebulous. Of course, taxationper se, and any single policy in general, is not sufficient to achieve a more inclusive and equal growth. It is instead crucial to create synergies across policies and a strong link between employment creation strategies, redistributive policies, skill development and social protection systems.",2022,10.3389/frai.2022.867832
Schrödinger's tree—On syntax and neural language models,"In the last half-decade, the field of natural language processing (NLP) has undergone two major transitions: the switch to neural networks as the primary modeling paradigm and the homogenization of the training regime (pre-train, then fine-tune). Amidst this process, language models have emerged as NLP's workhorse, displaying increasingly fluent generation capabilities and proving to be an indispensable means of knowledge transfer downstream. Due to the otherwise opaque, black-box nature of such models, researchers have employed aspects of linguistic theory in order to characterize their behavior. Questions central to syntax—the study of the hierarchical structure of language—have factored heavily into such work, shedding invaluable insights about models' inherent biases and their ability to make human-like generalizations. In this paper, we attempt to take stock of this growing body of literature. In doing so, we observe a lack of clarity across numerous dimensions, which influences the hypotheses that researchers form, as well as the conclusions they draw from their findings. To remedy this, we urge researchers to make careful considerations when investigating coding properties, selecting representations, and evaluatingviadownstream tasks. Furthermore, we outline the implications of the different types of research questions exhibited in studies on syntax, as well as the inherent pitfalls of aggregate metrics. Ultimately, we hope that our discussion adds nuance to the prospect of studying language models and paves the way for a less monolithic perspective on syntax in this context.",2022,10.3389/frai.2022.796788
A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement,"Virtual Mental Health Assistants (VMHAs) continuously evolve to support the overloaded global healthcare system, which receives approximately 60 million primary care visits and 6 million emergency room visits annually. These systems, developed by clinical psychologists, psychiatrists, and AI researchers, are designed to aid in Cognitive Behavioral Therapy (CBT). The main focus of VMHAs is to provide relevant information to mental health professionals (MHPs) and engage in meaningful conversations to support individuals with mental health conditions. However, certain gaps prevent VMHAs from fully delivering on their promise during active communications. One of the gaps is their inability to explain their decisions to patients and MHPs, making conversations less trustworthy. Additionally, VMHAs can be vulnerable in providing unsafe responses to patient queries, further undermining their reliability. In this review, we assess the current state of VMHAs on the grounds of user-level explainability and safety, a set of desired properties for the broader adoption of VMHAs. This includes the examination of ChatGPT, a conversation agent developed on AI-driven models: GPT3.5 and GPT-4, that has been proposed for use in providing mental health services. By harnessing the collaborative and impactful contributions of AI, natural language processing, and the mental health professionals (MHPs) community, the review identifies opportunities for technological progress in VMHAs to ensure their capabilities include explainable and safe behaviors. It also emphasizes the importance of measures to guarantee that these advancements align with the promise of fostering trustworthy conversations.",2023,10.3389/frai.2023.1229805
Advancements and challenges of artificial intelligence in climate modeling for sustainable urban planning,"Artificial Intelligence (AI) is revolutionizing climate modeling by enhancing predictive accuracy, computational efficiency, and multi-source data integration, playing a crucial role in sustainable urban planning. This Mini Review examines recent advancements in machine learning (ML) and deep learning (DL) techniques that improve climate risk assessment, resource optimization, and infrastructure resilience. Despite these innovations, significant challenges persist, including data quality inconsistencies, model interpretability limitations, ethical concerns, and the scalability of AI models across diverse urban contexts. To bridge these gaps, this review highlights key research directions, emphasizing the development of interpretable AI models, robust data governance frameworks, and scalable AI-driven solutions that help climate adaptation. By addressing these challenges, AI-based climate modeling can provide actionable insights for policymakers, urban planners, and researchers fostering climate-resilient and sustainable urban environments.",2025,10.3389/frai.2025.1517986
A Machine Learning Approach to Monitor the Emergence of Late Intrauterine Growth Restriction,"Late intrauterine growth restriction (IUGR) is a fetal pathological condition characterized by chronic hypoxia secondary to placental insufficiency, resulting in an abnormal rate of fetal growth. This pathology has been associated with increased fetal and neonatal morbidity and mortality. In standard clinical practice, late IUGR diagnosis can only be suspected in the third trimester and ultimately confirmed at birth. This study presents a radial basis function support vector machine (RBF-SVM) classification based on quantitative features extracted from fetal heart rate (FHR) signals acquired using routine cardiotocography (CTG) in a population of 160 healthy and 102 late IUGR fetuses. First, the individual performance of each time, frequency, and nonlinear feature was tested. To improve the unsatisfactory results of univariate analysis we firstly adopted a Recursive Feature Elimination approach to select the best subset of FHR-based parameters contributing to the discrimination of healthy vs. late IUGR fetuses. A fine tuning of the RBF-SVM model parameters resulted in a satisfactory classification performance in the training set (accuracy 0.93, sensitivity 0.93, specificity 0.84). Comparable results were obtained when applying the model on a totally independent testing set. This investigation supports the use of a multivariate approach for the in utero identification of late IUGR condition based on quantitative FHR features encompassing different domains. The proposed model allows describing the relationships among features beyond the traditional linear approaches, thus improving the classification performance. This framework has the potential to be proposed as a screening tool for the identification of late IUGR fetuses.",2021,10.3389/frai.2021.622616
Virtual Cohorts and Synthetic Data in Dementia: An Illustration of Their Potential to Advance Research,"When attempting to answer questions of interest, scientists often encounter hurdles that may stem from limited access to existing adequate datasets as a consequence of poor data sharing practices, constraining administrative practices. Further, when attempting to integrate data, differences in existing datasets also impose challenges that limit opportunities for data integration. As a result, the pace of scientific advancements is suboptimal. Synthetic data and virtual cohorts generated using innovative computational techniques represent an opportunity to overcome some of these limitations and consequently, to advance scientific developments. In this paper, we demonstrate the use of virtual cohorts techniques to generate a synthetic dataset that mirrors a deeply phenotyped sample of preclinical dementia research participants.",2021,10.3389/frai.2021.613956
SNPAAMapper-Python: A highly efficient genome-wide SNP variant analysis pipeline for Next-Generation Sequencing data,"Currently, there are many publicly available Next Generation Sequencing tools developed for variant annotation and classification. However, as modern sequencing technology produces more and more sequencing data, a more efficient analysis program is desired, especially for variant analysis. In this study, we updated SNPAAMapper, a variant annotation pipeline by converting perl codes to python for generating annotation output with an improved computational efficiency and updated information for broader applicability. The new pipeline written in Python can classify variants by region (Coding Sequence, Untranslated Regions, upstream, downstream, intron), predict amino acid change type (missense, nonsense, etc.), and prioritize mutation effects (e.g., synonymous &gt; non-synonymous) while being faster and more efficient. Our new pipeline works in five steps. First, exon annotation files are generated. Next, the exon annotation files are processed, and gene mapping and feature information files are produced. Afterward, the python scrips classify the variants based on genomic regions and predict the amino acid change category. Lastly, another python script prioritizes and ranks the mutation effects of variants to output the result file. The Python version of SNPAAMapper accomplished the overall speed by running most annotation steps in a substantially shorter time. The Python script can classify variants by region in 53 s compared to 166 s for the Perl script in a test sample run on a Latitude 7480 Desktop computer with 8GB RAM and an Intel Core i5-6300 CPU @ 2.4Ghz. Steps of predicting amino acid change type and prioritizing mutation effects of variants were executed within 1 s for both pipelines. SNPAAMapper-Python was developed and tested on the ClinVar database, a NCBI database of information on genomic variation and its relationship to human health. We believe our developed Python version of SNPAAMapper variant annotation pipeline will benefit the community by elucidating the variant consequence and speed up the discovery of causative genetic variants through whole genome/exome sequencing. Source codes, test data files, instructions, and further explanations are available on the web at https://github.com/BaiLab/SNPAAMapper-Python.",2022,10.3389/frai.2022.991733
Human reconstruction using 3D Gaussian Splatting: a brief survey,"Reconstructing high-fidelity and animatable 3D human avatars from visual data is a core task for immersive applications such as virtual reality (VR) and digital content creation. While traditional approaches often suffer from high computational costs, slow inference, and visual artifacts, recent advances leverage 3D Gaussian Splatting (3DGS) to enable rapid training and real-time rendering (up to 361 FPS). A common framework leverages parametric models to establish a canonical human representation, followed by deformation of 3D Gaussians into target poses using learnable skinning and novel regularization techniques. Key advances include deformation mechanisms for motion generalization, hybrid Gaussian-mesh representations for complex clothing and geometry, efficient compression and acceleration strategies, and specialized modules for handling occlusions and fine details. This article briefly reviews recent progress in 3DGS-based human reconstruction, we organize methods by input type: single-view and multi-view reconstruction. We discuss the strengths and limitations of each category and highlight promising future directions.",2025,10.3389/frai.2025.1709229
Exploring ChatGPT's potential for augmenting post-editing in machine translation across multiple domains: challenges and opportunities,"Introduction
                    Post-editing plays a crucial role in enhancing the quality of machine-generated translation (MGT) by correcting errors and ensuring cohesion and coherence. With advancements in artificial intelligence, Large Language Models (LLMs) like ChatGPT-4o offer promising capabilities for post-editing tasks. This study investigates the effectiveness of ChatGPT-4o as a natural language processing tool in post-editing Arabic translations across various domains, aiming to evaluate its performance in improving productivity, accuracy, consistency, and overall translation quality.
                  
                  
                    Methods
                    
                      The study involved a comparative analysis of Arabic translations generated by Google Translate. These texts, drawn from multiple domains, were post-edited by two professional human translators and ChatGPT-4o. Subsequently, three additional professional human post-editors evaluated both sets of post-edited outputs. To statistically assess the differences in quality between humans and ChatGPT-4o post-edits, a paired
                      t
                      -test was employed, focusing on metrics such as fluency, accuracy, coherence, and efficiency.
                    
                  
                  
                    Results
                    
                      The findings indicated that human post-editors outperformed ChatGPT-4o in most quality metrics. However, ChatGPT-4o demonstrated superior efficiency, yielding a positive
                      t
                      -statistic of 8.00 and a
                      p
                      -value of 0.015, indicating a statistically significant difference. Regarding fluency, no significant difference was observed between the two methods (
                      t
                      -statistic = −3.5,
                      p
                      -value = 0.074), suggesting comparable performance in ensuring the natural flow of text.
                    
                  
                  
                    Discussion
                    ChatGPT-4o showed competitive performance in English-to-Arabic post-editing, particularly in producing fluent, coherent, and stylistically consistent text. Its conversational design enables efficient and consistent editing across various domains. Nonetheless, the model faced challenges in handling grammatical and syntactic nuances, domain-specific idioms, and complex terminology, especially in medical and sports contexts. Overall, the study highlights the potential of ChatGPT-4o as a supportive tool in translation post-editing workflows, complementing human translators by enhancing productivity and maintaining acceptable quality standards.",2025,10.3389/frai.2025.1526293
"Comparative analysis of frequentist, Bayesian, and machine learning models for predicting SARS-CoV-2 PCR positivity","Background
                    Prediction of infection status is critical for effective disease management and timely intervention. Traditional diagnostic methods for Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) are challenged by varying sensitivities and specificities, necessitating the evaluation of advanced statistical approaches. This study evaluated the predictive performance of frequentist logistic regression, Bayesian logistic regression, and a random forest classifier using clinical and demographic predictors to predict PCR positivity.
                  
                  
                    Methodology
                    A total of 950 participants were analyzed using three modeling approaches. To address class imbalance, the data were balanced using the Synthetic Minority Oversampling Technique (SMOTE) before training the random forest classifier. Predictors include IgG serostatus, travel history (international and domestic), self-reported symptoms (such as loss of smell, fatigue, sore throat), sex, and age. Three models were developed: (1) frequentist logistic regression; (2) Bayesian logistic regression with a moderately informative Normal (mean = 1, SD = 2) prior and a weakly informative Cauchy (0, 2.5) prior; and (3) machine learning (ML) using a random forest classifier. Missing data were minimal (&lt;2%) and handled through imputation, with sensitivity analyses confirming no material impact on model performance. Performance was evaluated using odds ratios, posterior means with credible intervals, and area under the ROC curve (AUC).
                  
                  
                    Results
                    Of the 950 participants, 74.8% tested positive for SARS-CoV-2. The frequentist logistic regression identified recent international travel (Odds Ratio = 4.8), loss of smell (OR = 2.3), and domestic travel (OR = 1.5) as the strongest predictors of PCR positivity. The Bayesian model yielded similar posterior estimates, confirming the robustness of these associations across prior assumptions. The random forest classifier achieved the highest discriminative performance (AUC = 0.947–0.963). Notably, age and sex were not significant in the regression models but emerged as influential predictors in the random forest model, suggesting possible nonlinear or interaction effects.
                  
                  
                    Conclusion
                    The machine learning approach (random forest) outperformed the logistic regression models in predictive accuracy. Bayesian regression confirmed the reliability of key predictors and allowed quantification of uncertainty. These findings highlight that simple, routinely collected symptom and exposure data can support rapid, resource-conscious screening for SARS-CoV-2, particularly when laboratory testing capacity is limited.",2025,10.3389/frai.2025.1668477
Toward standardization of GenAI-driven agentic architectures for radio access networks,"The adoption of Generative Artificial Intelligence (GenAI) in Radio Access Networks (RAN) presents new opportunities for automation and intelligence across network operations. GenAI-powered agents, leveraging Large Language Models (LLMs), can enhance planning, execution, and decision-making for orchestration and real-time optimisation of 6G networks. Standardizing the implementation of the Agentic architecture for RAN is now essential to establish a unified framework for RANOps and AgentOps. One of the key challenges is to develop a blueprint that incorporates best practices for memory integration, tool generation, multi-agent orchestration, and performance benchmarking. This study highlights key areas requiring standardization, including agent tool specifications, RAN-specific LLM fine-tuning, validation frameworks, and AI-friendly documentation. We propose a dedicated research initiative on GenAI-for-RAN and GenAI-on-RAN to address these gaps and advance AI-driven network automation.",2025,10.3389/frai.2025.1621963
Automated Disengagement Tracking Within an Intelligent Tutoring System,"This paper describes a new automated disengagement tracking system (DTS) that detects learners’ maladaptive behaviors, e.g. mind-wandering and impetuous responding, in an intelligent tutoring system (ITS), called AutoTutor. AutoTutor is a conversation-based intelligent tutoring system designed to help adult literacy learners improve their reading comprehension skills. Learners interact with two computer agents in natural language in 30 lessons focusing on word knowledge, sentence processing, text comprehension, and digital literacy. Each lesson has one to three dozen questions to assess and enhance learning. DTS automatically retrieves and aggregates a learner's response accuracies and time on the first three to five questions in a lesson, as a baseline performance for the lesson when they are presumably engaged, and then detects disengagement by observing if the learner's following performance significantly deviates from the baseline. DTS is computed with an unsupervised learning method and thus does not rely on any self-reports of disengagement. We analyzed the response time and accuracy of 252 adult literacy learners who completed lessons in AutoTutor. Our results show that items that the detector identified as the learner being disengaged had a performance accuracy of 18.5%, in contrast to 71.8% for engaged items. Moreover, the three post-test reading comprehension scores from Woodcock Johnson III, RISE, and RAPID had a significant association with the accuracy of engaged items, but not disengaged items.",2021,10.3389/frai.2020.595627
The relevance of lead prioritization: a B2B lead scoring model based on machine learning,"In business-to-business (B2B) companies, marketing and sales teams face significant challenges in identifying, qualifying, and prioritizing a large number of leads. Lead prioritization is a critical task for B2B organizations because it allows them to allocate resources more effectively, focus their sales force on the most viable and valuable opportunities, optimize their time spent qualifying leads, and maximize their B2B digital marketing strategies. This article addresses the topic by presenting a case study of a B2B software company's development of a lead scoring model based on data analytics and machine learning under the consumer theory approach. The model was developed using real lead data generated between January 2020 and April 2024, extracted from the company's CRM, which were analyzed and evaluated by fifteen classification algorithms, where the results in terms of accuracy and ROC AUC showed a superior performance of the Gradient Boosting Classifier over the other classifiers. At the same time, the feature importance analysis allowed the identification of features such as “source” and “lead status,” which increased the accuracy of the conversion prediction. The developed model significantly improved the company's ability to identify high quality leads compared to the traditional methods used. This research confirms and complements existing theories related to understanding the application of consumer behavior theory and the application of machine learning in the development of B2B lead scoring models. This study also contributes to bridging the gap between marketers and data scientists in jointly understanding lead scoring as a critical activity because of its impact on overall marketing strategy performance and sales revenue performance in B2B organizations.",2025,10.3389/frai.2025.1554325
Introducing DynaPTI–constructing a dynamic patent technology indicator using text mining and machine learning,"Patent data is an established source of information for both scientific research and corporate intelligence. Yet, most patent-based technology indicators fail to consider firm-level dynamics regarding their technological quality and technological activity. Accordingly, these indicators are unlikely to deliver an unbiased view on the current state of firm-level innovation and are thus incomplete tools for researchers and corporate intelligence practitioners. In this paper, we develop DynaPTI, an indicator that tackles this particular shortcoming of existing patent-based measures. Our proposed framework extends the literature by incorporating a dynamic component and is built upon an index-based comparison of firms. Furthermore, we use machine-learning techniques to enrich our indicator with textual information from patent texts. Together, these features allow our proposed framework to provide precise and up-to-date assessments about firm-level innovation activities. To present an exemplary implementation of the framework, we provide an empirical application to companies from the wind energy sector and compare our results to alternatives. Our corresponding findings suggest that our approach can generate valuable insights that are complementary to existing approaches, particularly regarding the identification of recently emerging, innovation-overperformers in a particular technological field.",2023,10.3389/frai.2023.1136846
The perils and promises of fact-checking with large language models,"Automated fact-checking, using machine learning to verify claims, has grown vital as misinformation spreads beyond human fact-checking capacity. Large language models (LLMs) like GPT-4 are increasingly trusted to write academic papers, lawsuits, and news articles and to verify information, emphasizing their role in discerning truth from falsehood and the importance of being able to verify their outputs. Understanding the capacities and limitations of LLMs in fact-checking tasks is therefore essential for ensuring the health of our information ecosystem. Here, we evaluate the use of LLM agents in fact-checking by having them phrase queries, retrieve contextual data, and make decisions. Importantly, in our framework, agents explain their reasoning and cite the relevant sources from the retrieved context. Our results show the enhanced prowess of LLMs when equipped with contextual information. GPT-4 outperforms GPT-3, but accuracy varies based on query language and claim veracity. While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy. Our investigation calls for further research, fostering a deeper comprehension of when agents succeed and when they fail.",2024,10.3389/frai.2024.1341697
Assessing the quality of AI-generated clinical notes: validated evaluation of a large language model ambient scribe,"Background
                    Generative artificial intelligence (AI) tools are increasingly being used as “ambient scribes” to generate drafts for clinical notes from patient encounters. Despite rapid adoption, few studies have systematically evaluated the quality of AI-generated documentation against physician standards using validated frameworks.
                  
                  
                    Objective
                    This study aimed to compare the quality of large language model (LLM)-generated clinical notes (“Ambient”) with physician-authored reference (“Gold”) notes across five clinical specialties using the Physician Documentation Quality Instrument (PDQI-9) as a validated framework to assess document quality.
                  
                  
                    Methods
                    
                      We pooled 97 de-identified audio recordings of outpatient clinical encounters across general medicine, pediatrics, obstetrics/gynecology, orthopedics, and adult cardiology. For each encounter, clinical notes were generated using both LLM-optimized “Ambient” and blinded physician-drafted “Gold” notes, based solely on audio recording and corresponding transcripts. Two blinded specialty reviewers independently evaluated each note using the modified PDQI-9, which includes 11 criteria rated on a Likert-scale, along with binary hallucination detection. Interrater reliability was assessed using within-group interrater agreement coefficient (RWG) statistics. Paired comparisons were performed using
                      t
                      -tests or Mann–Whitney tests.
                    
                  
                  
                    Results
                    
                      Paired analysis of 97 clinical encounters yielded 194 notes (2 per encounter) and 388 paired reviews. Overall, high interrater agreement was observed (RWG &gt; 0.7), with moderate concordance noted in pediatrics and cardiology. Gold notes achieved higher overall quality scores (4.25/5 vs. 4.20/5,
                      p
                       = 0.04), as well as superior accuracy (
                      p
                       = 0.05), succinctness (
                      p
                       &lt; 0.001), and internal consistency (
                      p
                       = 0.004) compared to ambient notes. In contrast, ambient notes scored higher in thoroughness (
                      p
                       &lt; 0.001) and organization (
                      p
                       = 0.03). Hallucinations were detected in 20% of gold notes and 31% of ambient notes (
                      p
                       = 0.01). Despite these limitations, reviewers overall preferred ambient notes (47% vs. 39% for gold).
                    
                  
                  
                    Conclusion
                    LLM-generated Ambient notes demonstrated quality comparable to physician-authored notes across multiple specialties. While Ambient notes were more thorough and better organized, they were also less succinct and more prone to hallucination. The PDQI-9 provides a validated, practical framework for evaluating AI-generated clinical documentation. This quality assessment methodology can inform iterative quality optimization and support the standardization of ambient AI scribes in clinical practice.",2025,10.3389/frai.2025.1691499
Impact of hypertension on coronary artery plaques and FFR-CT in type 2 diabetes mellitus patients: evaluation utilizing artificial intelligence processed coronary computed tomography angiography,"ObjectiveThis study utilized artificial intelligence (AI) to quantify coronary computed tomography angiography (CCTA) images, aiming to compare plaque characteristics and CT-derived fractional flow reserve (FFR-CT) in type 2 diabetes mellitus (T2DM) patients with or without hypertension (HTN).MethodsA retrospective analysis was conducted on 1,151 patients with suspected coronary artery disease who underwent CCTA at a single center. Patients were grouped into T2DM (n = 133), HTN (n = 442), T2DM (HTN+) (n = 256), and control (n = 320). AI assessed various CCTA parameters, including plaque components, high-risk plaques (HRPs), FFR-CT, severity of coronary stenosis using Coronary Artery Disease Reporting and Data System 2.0 (CAD-RADS 2.0), segment involvement score (SIS), and segment stenosis score (SSS). Statistical analysis compared these parameters among groups.ResultsThe T2DM (HTN+) group had the highest plaque volume and length, SIS, SSS, and CAD-RADS 2.0 classification. In the T2DM group, 54.0% of the plaque volume was noncalcified and 46.0% was calcified, while in the HTN group, these values were 24.0 and 76.0%, respectively. The T2DM (HTN+) group had more calcified plaques (35.7% noncalcified, 64.3% calcified) than the T2DM group. The average necrotic core volume was 4.25 mm3 in the T2DM group and 5.23 mm3 in the T2DM (HTN+) group, with no significant difference (p &gt; 0.05). HRPs were more prevalent in both T2DM and T2DM (HTN+) compared to HTN and control groups (p &lt; 0.05). The T2DM (HTN+) group had a higher likelihood (26.1%) of FFR-CT ≤0.75 compared to the T2DM group (13.8%). FFR-CT ≤0.75 correlated with CAD-RADS 2.0 (OR = 7.986, 95% CI = 5.466–11.667, cutoff = 3, p &lt; 0.001) and noncalcified plaque volume (OR = 1.006, 95% CI = 1.003–1.009, cutoff = 29.65 mm3, p &lt; 0.001). HRPs were associated with HbA1c levels (OR = 1.631, 95% CI = 1.387–1.918).ConclusionAI analysis of CCTA identifies patterns in quantitative plaque characteristics and FFR-CT values. Comorbid HTN exacerbates partially calcified plaques, leading to more severe coronary artery stenosis in patients with T2DM. T2DM is associated with partially noncalcified plaques, whereas HTN is linked to partially calcified plaques.",2024,10.3389/frai.2024.1446640
Handling missing data of using the XGBoost-based multiple imputation by chained equations regression method,"This study introduces an XGBoost-MICE (Multiple Imputation by Chained Equations) method for addressing missing data in mine ventilation parameters. Using historical ventilation system data from Shangwan Coal Mine, scenarios with different missing rates (5, 10, and 15%) and iteration numbers (30 and 50) were simulated to validate the accuracy and effectiveness of the approach. The results demonstrate that as the missing rate increased from 5 to 15%, the Mean Squared Error (MSE) rose from 0.0445 to 0.3254, while the Explained Variance decreased from 0.988309 to 0.943267. Additionally, the Mean Absolute Error (MAE) increased by 0.29. Iteration experiments on the “frictional resistance per 100 meters” attribute showed convergence of MSE and MAE after six iterations. Overall, the XGBoost-MICE method exhibited high imputation accuracy and stable convergence across various missing data scenarios, providing robust technical support for optimizing intelligent mine ventilation systems.",2025,10.3389/frai.2025.1553220
Stock Price Forecasting by a Deep Convolutional Generative Adversarial Network,"Stock market prices are known to be very volatile and noisy, and their accurate forecasting is a challenging problem. Traditionally, both linear and non-linear methods (such as ARIMA and LSTM) have been proposed and successfully applied to stock market prediction, but there is room to develop models that further reduce the forecast error. In this paper, we introduce a Deep Convolutional Generative Adversarial Network (DCGAN) architecture to deal with the problem of forecasting the closing price of stocks. To test the empirical performance of our proposed model we use the FTSE MIB (Financial Times Stock Exchange Milano Indice di Borsa), the benchmark stock market index for the Italian national stock exchange. By conducting both single-step and multi-step forecasting, we observe that our proposed model performs better than standard widely used tools, suggesting that Deep Learning (and in particular GANs) is a promising field for financial time series forecasting.",2022,10.3389/frai.2022.837596
Hybrid morphological-convolutional neural networks for computer-aided diagnosis,"Training deep Convolutional Neural Networks (CNNs) presents challenges in terms of memory requirements and computational resources, often resulting in issues such as model overfitting and lack of generalization. These challenges can only be mitigated by using an excessive number of training images. However, medical image datasets commonly suffer from data scarcity due to the complexities involved in their acquisition, preparation, and curation. To address this issue, we propose a compact and hybrid machine learning architecture based on the Morphological and Convolutional Neural Network (MCNN), followed by a Random Forest classifier. Unlike deep CNN architectures, the MCNN was specifically designed to achieve effective performance with medical image datasets limited to a few hundred samples. It incorporates various morphological operations into a single layer and uses independent neural networks to extract information from each signal channel. The final classification is obtained by utilizing a Random Forest classifier on the outputs of the last neural network layer. We compare the classification performance of our proposed method with three popular deep CNN architectures (ResNet-18, ShuffleNet-V2, and MobileNet-V2) using two training approaches: full training and transfer learning. The evaluation was conducted on two distinct medical image datasets: the ISIC dataset for melanoma classification and the ORIGA dataset for glaucoma classification. Results demonstrate that the MCNN method exhibits reliable performance in melanoma classification, achieving an AUC of 0.94 (95% CI: 0.91 to 0.97), outperforming the popular CNN architectures. For the glaucoma dataset, the MCNN achieved an AUC of 0.65 (95% CI: 0.53 to 0.74), which was similar to the performance of the popular CNN architectures. This study contributes to the understanding of mathematical morphology in shallow neural networks for medical image classification and highlights the potential of hybrid architectures in effectively learning from medical image datasets that are limited by a small number of case samples.",2023,10.3389/frai.2023.1253183
Exploring gender biases in ML and AI academic research through systematic literature review,"Automated systems that implement Machine learning (ML) and Artificial Intelligence (AI) algorithms present promising solutions to a variety of technological and non-technological issues. Although, industry leaders are rapidly adopting these systems for anything from marketing to national defense operations, these systems are not without flaws. Recently, many of these systems are found to inherit and propagate gender and racial biases that disadvantages the minority population. In this paper, we analyze academic publications in the area of gender biases in ML and AI algorithms thus outlining different themes, mitigation and detection methods explored through research in this topic. Through a detailed analysis of N = 120 papers, we map the current research landscape on gender specific biases present in ML and AI assisted automated systems. We further point out the aspects of ML/AI gender biases research that are less explored and require more attention. Mainly we focus on the lack of user studies and inclusivity in this field of study. We also shed some light into the gender bias issue as experienced by the algorithm designers. In conclusion, in this paper we provide a holistic view of the breadth of studies conducted in the field of exploring, detecting and mitigating gender biases in ML and AI systems and, a future direction for the studies to take in order to provide a fair and accessible ML and AI systems to all users.",2022,10.3389/frai.2022.976838
Avoiding Conflict: When Speaker Coordination Does Not Require Conceptual Agreement,"In this paper we discuss thesocialization hypothesis—the idea that speakers of the same (linguistic) community should share similar concepts given that they are exposed to similar environments and operate in highly-coordinated social contexts—and challenge the fact that it is assumed to constitute a prerequisite to successful communication. We do so usingdistributional semantic modelsof meaning (DSMs) which create lexical representations via latent aggregation of co-occurrence information between words and contexts. We argue that DSMs constitute particularly adequate tools for exploring the socialization hypothesis given that 1) they provide full control over the notion of background environment, formally characterized as the training corpus from which distributional information is aggregated; and 2) their geometric structure allows for exploiting alignment-based similarity metrics to measure inter-subject alignment over an entire semantic space, rather than a set of limited entries. We propose to modelcoordinationbetween two different DSMs trained on two distinct corpora asdimensionality selectionover a dense matrix obtained via Singular Value Decomposition This approximates an ad-hoc coordination scenario between two speakers as the attempt to align their similarity ratings on a set of word pairs. Our results underline the specific way in which linguistic information is spread across singular vectors, and highlight the need to distinguishagreementfrom merecompatibilityin alignment-based notions of conceptual similarity. Indeed, we show thatcompatibility emerges from idiosyncrasyso that the unique and distinctive aspects of speakers’ background experiences can actually facilitate—rather than impede—coordination and communication between them. We conclude that the socialization hypothesis may constitute an unnecessary prerequisite to successful communication and that, all things considered, communication is probably best formalized as the cooperative act ofavoiding conflict, rather than maximizing agreement.",2021,10.3389/frai.2020.523920
Survey and analysis of hallucinations in large language models: attribution to prompting strategies or model behavior,"Hallucination in Large Language Models (LLMs) refers to outputs that appear fluent and coherent but are factually incorrect, logically inconsistent, or entirely fabricated. As LLMs are increasingly deployed in education, healthcare, law, and scientific research, understanding and mitigating hallucinations has become critical. In this work, we present a comprehensive survey and empirical analysis of hallucination attribution in LLMs. Introducing a novel framework to determine whether a given hallucination stems from not optimize prompting or the model's intrinsic behavior. We evaluate state-of-the-art LLMs—including GPT-4, LLaMA 2, DeepSeek, and others—under various controlled prompting conditions, using established benchmarks (TruthfulQA, HallucinationEval) to judge factuality. Our attribution framework defines metrics for Prompt Sensitivity (PS) and Model Variability (MV), which together quantify the contribution of prompts vs. model-internal factors to hallucinations. Through extensive experiments and comparative analyses, we identify distinct patterns in hallucination occurrence, severity, and mitigation across models. Notably, structured prompt strategies such as chain-of-thought (CoT) prompting significantly reduce hallucinations in prompt-sensitive scenarios, though intrinsic model limitations persist in some cases. These findings contribute to a deeper understanding of LLM reliability and provide insights for prompt engineers, model developers, and AI practitioners. We further propose best practices and future directions to reduce hallucinations in both prompt design and model development pipelines.",2025,10.3389/frai.2025.1622292
Bringing multi-modal multi-task federated foundation models to education domain: prospects and challenges,"Multi-modal multi-task (M3T) foundation models (FMs) have recently shown transformative potential in artificial intelligence, with emerging applications in education. However, their deployment in real-world educational settings is hindered by privacy regulations, data silos, and limited domain-specific data availability. We introduce M3T Federated Foundation Models (FedFMs) for education: a paradigm that integrates federated learning (FL) with M3T FMs to enable collaborative, privacy-preserving training across decentralized institutions while accommodating diverse modalities and tasks. Subsequently, this perspective paper aims to unveil M3T FedFMs as a promising yet underexplored approach to the education community, explore its potentials, and reveal its related future research directions. We outline how M3T FedFMs can advance three critical pillars of next-generation intelligent education systems:
                    (i) privacy preservation
                    , by keeping sensitive multi-modal student and institutional data local;
                    (ii) personalization
                    , through modular architectures enabling tailored models for students, instructors, and institutions; and
                    (iii) equity and inclusivity
                    , by facilitating participation from underrepresented and resource-constrained entities. We finally identify various open research challenges, including studying of (i) inter-institution heterogeneous privacy regulations, (ii) the non-uniformity of data modalities' characteristics, (iii) the unlearning approaches for M3T FedFMs, (iv) the continual learning frameworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must be collectively addressed for practical deployment.",2025,10.3389/frai.2025.1683960
tachAId—An interactive tool supporting the design of human-centered AI solutions,"In an era where Artificial Intelligence (AI) integration into business processes is crucial for maintaining competitiveness, there is a growing need for structured guidance on designing AI solutions that align with human needs. To this end, we present “technical assistance concerning human-centered AI development” (tachAId), an interactive advisory tool which comprehensively guides AI developers and decision makers in navigating the machine learning lifecycle with a focus on human-centered design. tachAId motivates and presents concrete technical advice to ensure human-centeredness across the phases of AI development. The tool's effectiveness is evaluated through a catalog of criteria for human-centered AI in the form of relevant challenges and goals, derived from existing methodologies and guidelines. Lastly, tachAId and one other comparable advisory tool were examined to determine their adherence to these criteria in order to provide an overview of the human-centered aspects covered by these tools and to allow interested parties to quickly assess whether the tools meet their needs.",2024,10.3389/frai.2024.1354114
Instance Segmentation to Estimate Consumption of Corn Ears by Wild Animals for GMO Preference Tests,"The Genetically Modified (GMO) Corn Experiment was performed to test the hypothesis that wild animals prefer Non-GMO corn and avoid eating GMO corn, which resulted in the collection of complex image data of consumed corn ears. This study develops a deep learning-based image processing pipeline that aims to estimate the consumption of corn by identifying corn and its bare cob from these images, which will aid in testing the hypothesis in the GMO Corn Experiment. Ablation uses mask regional convolutional neural network (Mask R-CNN) for instance segmentation. Based on image data annotation, two approaches for segmentation were discussed: identifying whole corn ears and bare cob parts with and without corn kernels. The Mask R-CNN model was trained for both approaches and segmentation results were compared. Out of the two, the latter approach, i.e., without the kernel, was chosen to estimate the corn consumption because of its superior segmentation performance and estimation accuracy. Ablation experiments were performed with the latter approach to obtain the best model with the available data. The estimation results of these models were included and compared with manually labeled test data with R2 = 0.99 which showed that use of the Mask R-CNN model to estimate corn consumption provides highly accurate results, thus, allowing it to be used further on all collected data and help test the hypothesis of the GMO Corn Experiment. These approaches may also be applied to other plant phenotyping tasks (e.g., yield estimation and plant stress quantification) that require instance segmentation.",2021,10.3389/frai.2020.593622
A human-centered automated machine learning agent with large language models for multimodal data management and analysis,"Automated Machine Learning (AutoML) aims to streamline the end-to-end process of ML models, yet current approaches remain constrained by rigid rule-based frameworks and structured input requirements that create barriers for non-expert users. Despite advances in Large Language Models (LLMs) demonstrating capabilities in code generation and natural language understanding, their potential to improve AutoML accessibility has not been fully realized. We present an innovative LLM-driven AI agent that enables natural language interaction throughout the entire ML workflow while maintaining high performance standards, reducing the need for predefined rules and minimizing technical expertise requirements. The proposed agent implements an end-to-end ML pipeline, incorporating automatic data loading and pre-processing, task identification, neural architecture selection, hyperparameter optimization, and training automation. Additionally, we propose a novel data processing approach that leverages LLMs to automatically interpret and handle diverse data formats without requiring manual pre-processing or format conversion. Moreover, we propose an adaptive hyperparameter optimization strategy that combines LLMs' knowledge of ML best practices with dynamic performance feedback to intelligently adjust search spaces. Extensive evaluation on 10 diverse datasets spanning classification and regression tasks across multiple data modalities demonstrates that our approach consistently achieves superior performance compared to traditional rule-based AutoML frameworks. By bridging the gap between human intent and ML implementation, our approach contributes to the development of a more accessible AutoML framework.",2025,10.3389/frai.2025.1680845
FMEA based prescriptive model for equipment repair guidance,"Introduction
                    Accurate prediction of steps required to address machine faults is critical for minimizing downtime and enhancing production efficiency in modern manufacturing. This study utilizes machine failure data and Failure Mode and Effects Analysis to demonstrate how machine learning supports maintenance teams in selecting optimal repair methods.
                  
                  
                    Methods
                    The research adopts the Design Science Research paradigm, which emphasizes the creation of artifacts to address practical challenges. For the practical component, quality assurance and control frameworks in data science projects were implemented by integrating two widely used methodologies: CRISP-DM and PDCA, to ensure rigorous quality assurance and control in data science initiatives.
                  
                  
                    Results
                    Repair actions serve as the target variables, while the input comprises ten multivariate time-series machine parameters. The prediction task is formulated as a classification problem. Two modeling approaches are evaluated. The first approach merges multiple time series into a single sequence, facilitating the application of Multi-Layer Perceptron, Convolutional Neural Networks, and Fully Convolutional Networks. The second approach preserves the time series as three-dimensional arrays, enabling advanced applications of MLP, CNN, Multi-Head CNN, and FCN models.
                  
                  
                    Discussion
                    The models are assessed based on their capacity to predict repair actions, with particular emphasis on the impact of time-series processing and model architecture on classification accuracy. The findings highlight effective strategies for predicting machine repairs and advancing prescriptive maintenance in manufacturing environments.",2025,10.3389/frai.2025.1630907
Quantitative evaluation of meibomian gland dysfunction via deep learning-based infrared image segmentation,"In recent years, numerous advanced image segmentation algorithms have been employed in the analysis of meibomian glands (MG). However, their clinical utility remains limited due to insufficient integration with the diagnostic and grading processes of meibomian gland dysfunction (MGD). To bridge this gap, the present study leverages three state-of-the-art deep learning models—DeepLabV3+, U-Net, and U-Net++—to segment infrared MG images and extract quantitative features for MGD diagnosis and severity assessment. A comprehensive set of morphological (e.g., gland area, width, length, and distortion) and distributional (e.g., gland density, count, inter-gland distance, disorder degree, and loss ratio) indicators were derived from the segmentation outcomes. Spearman correlation analysis revealed significant positive associations between most indicators and MGD severity (correlation coefficients ranging from 0.26 to 0.58;
                    p
                     &lt; 0.001), indicating their potential diagnostic value. Furthermore, Box plot analysis highlighted clear distribution differences in the majority of indicators across all grades, with medians shifting progressively, interquartile ranges widening, and an increase in outliers, reflecting morphological changes associated with disease progression. Logistic regression models trained on these quantitative features yielded area under the receiver operating characteristic curve (AUC) values of 0.89 ± 0.02, 0.76 ± 0.03, 0.85 ± 0.02, and 0.94 ± 0.01 for MGD grades 0, 1, 2, and 3, respectively. The models demonstrated strong classification performance, with micro-average and macro-average AUCs of 0.87 ± 0.02 and 0.86 ± 0.03, respectively. Model stability and generalizability were validated through 5-fold cross-validation. Collectively, these findings underscore the clinical relevance and robustness of deep learning-assisted quantitative analysis for the objective diagnosis and grading of MGD, offering a promising framework for automated medical image interpretation in ophthalmology.",2025,10.3389/frai.2025.1642361
"Scaling and Disagreements: Bias, Noise, and Ambiguity","Crowdsourced data are often rife with disagreement, either because of genuine item ambiguity, overlapping labels, subjectivity, or annotator error. Hence, a variety of methods have been developed for learning from data containing disagreement. One of the observations emerging from this work is that different methods appear to work best depending on characteristics of the dataset such as the level of noise. In this paper, we investigate the use of an approach developed to estimate noise, temperature scaling, in learning from data containing disagreements. We find that temperature scaling works with data in which the disagreements are the result of label overlap, but not with data in which the disagreements are due to annotator bias, as in, e.g., subjective tasks such as labeling an item as offensive or not. We also find that disagreements due to ambiguity do not fit perfectly either category.",2022,10.3389/frai.2022.818451
A systematic literature review on the use of multicriteria decision making methods for small and medium-sized enterprises innovation assessment,"Multi-criteria decision making (MCDM) methods are essential tools for assessing multiple factors in various contexts, including innovation in small and medium-sized enterprises (SMEs). In this study, a systematic literature review (SLR) was conducted based on a literature search in Web of Science, Scopus and Google Scholar, covering the period 2018–2024, taking as a basis the general guidelines and main phases of an SLR, in addition, the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) method was used, which allowed the selection of 25 relevant articles. From the analysis, four main trends in innovation assessment were identified: Innovation Capacity and Business Strategies, Open Innovation, Evaluation and Management, Technological and Digital Innovation, and Green Innovation and Sustainability. The results indicate that India and China are the countries with the highest volume of publications on this topic, while the business and academic sectors are the most studied, followed by the social sector. In addition, other key factors assessed in SMEs using MCDM methods were identified, grouped into five main themes including industry 4.0 and digital transformation, sustainability and green manufacturing, risk management and business resilience, decision making in trade and markets, and business management strategies and technology selection, broken down into 11 specific approaches. The review shows that assessing innovation in SMEs requires a multidisciplinary and collaborative approach tailored to business needs. It also shows a preference for fuzzy tools and the combination of different MCDM methods. This article provides an updated diagnosis on the use of multiple criteria in the innovation assessment in SMEs, providing a basis for future research and applications in this field.",2025,10.3389/frai.2025.1605756
Identification of Scams in Initial Coin Offerings With Machine Learning,"Following the emergence of cryptocurrencies, the field of digital assets experienced a sudden explosion of interest among institutional investors. However, regarding ICOs, there were a lot of scams involving the disappearance of firms after they had collected significant amounts of funds. We study how well one can predict if an offering will turn out to be a scam, doing so based on the characteristics known ex-ante. We therefore examine which of these characteristics are the most important predictors of a scam, and how they influence the probability of a scam. We use detailed data with 160 features from about 300 ICOs that took place before March 2018 and succeeded in raising most of their required capital. Various machine learning algorithms are applied together with novel XAI tools in order to identify the most important predictors of an offering’s failure and understand the shape of relationships. It turns out that based on the features known ex-ante, one can predict a scam with an accuracy of about 65–70%, and that nonlinear machine learning models perform better than traditional logistic regression and its regularized extensions.",2021,10.3389/frai.2021.718450
Targeted Screening for Alzheimer's Disease Clinical Trials Using Data-Driven Disease Progression Models,"Heterogeneity in Alzheimer's disease progression contributes to the ongoing failure to demonstrate efficacy of putative disease-modifying therapeutics that have been trialed over the past two decades. Any treatment effect present in a subgroup of trial participants (responders) can be diluted by non-responders who ideally should have been screened out of the trial. How to identify (screen-in) the most likely potential responders is an important question that is still without an answer. Here, we pilot a computational screening tool that leverages recent advances in data-driven disease progression modeling to improve stratification. This aims to increase the sensitivity to treatment effect by screening out non-responders, which will ultimately reduce the size, duration, and cost of a clinical trial. We demonstrate the concept of such a computational screening tool by retrospectively analyzing a completed double-blind clinical trial of donepezil in people with amnestic mild cognitive impairment (clinicaltrials.gov: NCT00000173), identifying a data-driven subgroup having more severe cognitive impairment who showed clearer treatment response than observed for the full cohort.",2022,10.3389/frai.2022.660581
Modeling Users' Cognitive Performance Using Digital Pen Features,"Digital pen features model characteristics of sketches and user behavior, and can be used for various supervised machine learning (ML) applications, such as multi-stroke sketch recognition and user modeling. In this work, we use a state-of-the-art set of more than 170 digital pen features, which we implement and make publicly available. The feature set is evaluated in the use case of analyzing paper-pencil-based neurocognitive assessments in the medical domain. Most cognitive assessments, for dementia screening for example, are conducted with a pen on normal paper. We record these tests with a digital pen as part of a new interactive cognitive assessment tool with automatic analysis of pen input. The physician can, first, observe the sketching process in real-time on a mobile tablet, e.g., in telemedicine settings or to follow Covid-19 distancing regulations. Second, the results of an automatic test analysis are presented to the physician in real-time, thereby reducing manual scoring effort and producing objective reports. As part of our evaluation we examine how accurately different feature-based, supervised ML models can automatically score cognitive tests, with and without semantic content analysis. A series of ML-based sketch recognition experiments is conducted, evaluating 10 modern off-the-shelf ML classifiers (i.e., SVMs, Deep Learning, etc.) on a sketch data set which we recorded with 40 subjects from a geriatrics daycare clinic. In addition, an automated ML approach (AutoML) is explored for fine-tuning and optimizing classification performance on the data set, achieving superior recognition accuracies. Using standard ML techniques our feature set outperforms all previous approaches on the cognitive tests considered, i.e., the Clock Drawing Test, the Rey-Osterrieth Complex Figure Test, and the Trail Making Test, by automatically scoring cognitive tests with up to 87.5% accuracy in a binary classification task.",2022,10.3389/frai.2022.787179
Application of Artificial Intelligence to Plasma Metabolomics Profiles to Predict Response to Neoadjuvant Chemotherapy in Triple-Negative Breast Cancer,"There is a need to identify biomarkers predictive of response to neoadjuvant chemotherapy (NACT) in triple-negative breast cancer (TNBC). We previously obtained evidence that a polyamine signature in the blood is associated with TNBC development and progression. In this study, we evaluated whether plasma polyamines and other metabolites may identify TNBC patients who are less likely to respond to NACT. Pre-treatment plasma levels of acetylated polyamines were elevated in TNBC patients that had moderate to extensive tumor burden (RCB-II/III) following NACT compared to those that achieved a complete pathological response (pCR/RCB-0) or had minimal residual disease (RCB-I). We further applied artificial intelligence to comprehensive metabolic profiles to identify additional metabolites associated with treatment response. Using a deep learning model (DLM), a metabolite panel consisting of two polyamines as well as nine additional metabolites was developed for improved prediction of RCB-II/III. The DLM has potential clinical value for identifying TNBC patients who are unlikely to respond to NACT and who may benefit from other treatment modalities.",2022,10.3389/frai.2022.876100
Assessment of a Spatiotemporal Deep Learning Approach for Soil Moisture Prediction and Filling the Gaps in Between Soil Moisture Observations,"Soil moisture (SM) plays a significant role in determining the probability of flooding in a given area. Currently, SM is most commonly modeled using physically-based numerical hydrologic models. Modeling the natural processes that take place in the soil is difficult and requires assumptions. Besides, hydrologic model runtime is highly impacted by the extent and resolution of the study domain. In this study, we propose a data-driven modeling approach using Deep Learning (DL) models. There are different types of DL algorithms that serve different purposes. For example, the Convolutional Neural Network (CNN) algorithm is well suited for capturing and learning spatial patterns, while the Long Short-Term Memory (LSTM) algorithm is designed to utilize time-series information and to learn from past observations. A DL algorithm that combines the capabilities of CNN and LSTM called ConvLSTM was recently developed. In this study, we investigate the applicability of the ConvLSTM algorithm in predicting SM in a study area located in south Louisiana in the United States. This study reveals that ConvLSTM significantly outperformed CNN in predicting SM. We tested the performance of ConvLSTM based models by using a combination of different sets of predictors and different LSTM sequence lengths. The study results show that ConvLSTM models can predict SM with a mean areal Root Mean Squared Error (RMSE) of 2.5% and mean areal correlation coefficients of 0.9 for our study area. ConvLSTM models can also provide predictions between discrete SM observations, making them potentially useful for applications such as filling observational gaps between satellite overpasses.",2021,10.3389/frai.2021.636234
Breaking the gatekeepers: how AI will revolutionize scientific funding,"As artificial intelligence (AI) transforms nearly every domain of human endeavor, one of its most consequential impacts may be on science itself. This analysis explores how AI technologies could disrupt the power structures that govern research funding—structures that privilege senior investigators while sidelining early-career scientists and genuinely novel ideas. By juxtaposing the youth-driven innovation behind AI with the increasingly gerontocratic funding patterns in biomedical sciences, we highlight how institutional mechanisms shape not only who gets to do science but also when. Evidence suggests that conventional grant peer review has become a self-reinforcing system—more effective at preserving consensus than fostering discovery. AI presents a compelling alternative: evaluation frameworks that could reduce bias, broaden participation, and open more meritocratic pathways to research independence. The implications extend far beyond individual careers. At stake is society's ability to mobilize scientific creativity against its most urgent challenges. By rethinking outdated practices—especially the gatekeeping role of study sections—and exploring algorithmic approaches to assessment, we may be able to reverse troubling trends and unleash a broader, more diverse wave of discovery. AI will not fix science on its own, but it could help build a system where innovation is no longer an accident of privilege and timing.",2025,10.3389/frai.2025.1667752
Enhancing detection of common bean diseases using Fast Gradient Sign Method–trained Vision Transformers,"Common bean production in Tanzania is threatened by diseases such as bean rust and bean anthracnose, with early detection critical for effective management. This study presents a Vision Transformer (ViT)-based deep learning model enhanced with adversarial training to improve disease detection robustness under real-world farm conditions. A dataset of 100,000 annotated images augmented with geometric, color, and FGSM-based perturbations, simulating field variability. FGSM was selected for its computational efficiency in low-resource settings. The model, fine-tuned using transfer learning and validated through cross-validation, achieved an accuracy of 99.4%. Results highlight the effectiveness of integrating adversarial robustness to enhance model reliability for mobile-based plant disease detection in resource-constrained environments.",2025,10.3389/frai.2025.1643582
Addressing Label Sparsity With Class-Level Common Sense for Google Maps,"Successful knowledge graphs (KGs) solved the historical knowledge acquisition bottleneck by supplanting the previous expert focus with a simple, crowd-friendly one: KG nodes represent popular people, places, organizations, etc., and the graph arcs represent common sense relations like affiliations, locations, etc. Techniques for more general, categorical, KG curation do not seem to have made the same transition: the KG research community is still largely focused on logic-based methods that belie the common-sense characteristics of successful KGs. In this paper, we propose a simple yet novel three-tier crowd approach to acquiringclass-level attributesthat represent broad common sense associations between categories, and can be used with the classic knowledge-base default &amp; override technique, to address the earlylabel sparsity problemfaced by machine learning systems for problems that lack data for training. We demonstrate the effectiveness of our acquisition and reasoning approach on a pair of very real industrial-scale problems: how to augment an existing KG of places and offerings (e.g. stores and products, restaurants and dishes) with associations between them indicating the availability of the offerings at those places. Label sparsity is a general problem, and not specific to these use cases, that prevents modern AI and machine learning techniques from applying to many applications for which labeled data is not readily available. As a result, the study of how to acquire the knowledge and data needed for AI to work is as much a problem today as it was in the 1970s and 80s during the advent of expert systems. Our approach was a critical part of enabling a worldwidelocal searchcapability on Google Maps, with which users can find products and dishes that are available in most places on earth.",2022,10.3389/frai.2022.830299
A computational model for the cancer field effect,"IntroductionThe Cancer Field Effect describes an area of pre-cancerous cells that results from continued exposure to carcinogens. Cells in the cancer field can easily develop into cancer. Removal of the main tumor mass might leave the cancer field behind, increasing risk of recurrence.MethodsThe model we propose for the cancer field effect is a hybrid cellular automaton (CA), which includes a multi-layer perceptron (MLP) to compute the effects of the carcinogens on the gene expression of the genes related to cancer development. We use carcinogen interactions that are typically associated with smoking and alcohol consumption and their effect on cancer fields of the tongue.ResultsUsing simulations we support the understanding that tobacco smoking is a potent carcinogen, which can be reinforced by alcohol consumption. The effect of alcohol alone is significantly less than the effect of tobacco. We further observe that pairing tumor excision with field removal delays recurrence compared to tumor excision alone. We track cell lineages and find that, in most cases, a polyclonal field develops, where the number of distinct cell lineages decreases over time as some lineages become dominant over others. Finally, we find tumor masses rarely form via monoclonal origin.",2023,10.3389/frai.2023.1060879
A model for representing the semantics of MWEs: From lexical semantics to the semantic annotation of complex predicates,"Multiword expressions (MWEs) are sequences of words that pose a challenge to the computational processing of human languages due to their idiosyncrasies and the mismatch between their phrasal structure and their semantics. These idiosyncrasies are of lexical, morphosyntactic and semantic 11 nature, namely: non-compositionality, i.e., the meaning of the expression cannot be computed from the meanings of its constituents; discontinuity, i.e., alien elements may intervene; non-13 substitutability, i.e., at least one of the expression constituents is lexicalized and therefore, does not enter in alternations at the paradigmatic axis; and non-modifiability, in that they enter in syntactically 15 rigid structures, posing further constraints over modification, transformations, etc. The paper presents a model for representing MWEs at the level of semantics by taking into account all these inherent idiosyncrasies. The model assumes the form of a linguistic ontology and is applied to Greek verbal multi-word expressions (VMWEs); moreover, the semantics of the lexical entries under scrutiny is also represented via the semantics of their arguments based on corpus evidence. In this regard, modeling the semantics of VMWEs is placed in the lexicon-corpus interface.",2023,10.3389/frai.2023.802218
SciLinker: a large-scale text mining framework for mapping associations among biological entities,"IntroductionThe biomedical literature is the go-to source of information regarding relationships between biological entities, including genes, diseases, cell types, and drugs, but the rapid pace of publication makes an exhaustive manual exploration impossible. In order to efficiently explore an up-to-date repository of millions of abstracts, we constructed an efficient and modular natural language processing pipeline and applied it to the entire PubMed abstract corpora.MethodsWe developed SciLinker using open-source libraries and pre-trained named entity recognition models to identify human genes, diseases, cell types and drugs, normalizing these biological entities to the Unified Medical Language System (UMLS). We implemented a scoring schema to quantify the statistical significance of entity co-occurrences and applied a fine-tuned PubMedBERT model for gene-disease relationship extraction.ResultsWe identified and analyzed over 30 million association sentences, including more than 11 million gene-disease co-occurrence sentences, revealing more than 1.25 million unique gene-disease associations. We demonstrate SciLinker’s ability to extract specific gene-disease relationships using osteoporosis as a case study. We show how such an analysis benefits target identification as clinically validated targets are enriched in SciLinker-derived disease-associated genes. Moreover, this co-occurrence data can be used to construct disease-specific networks, providing insights into significant relationships among biological entities from scientific literature.ConclusionSciLinker represents a novel text mining approach that extracts and quantifies associations between biomedical entities through co-occurrence analysis and relationship extraction from PubMed abstracts. Its modular design enables expansion to additional entities and text corpora, making it a versatile tool for transforming unstructured biomedical data into actionable insights for drug discovery.",2025,10.3389/frai.2025.1528562
Benefits of Adaptive Learning Transfer From Typing-Based Learning to Speech-Based Learning,"Memorising vocabulary is an important aspect of formal foreign-language learning. Advances in cognitive psychology have led to the development of adaptive learning systems that make vocabulary learning more efficient. One way these computer-based systems optimize learning is by measuring learning performance in real time to create optimal repetition schedules for individual learners. While such adaptive learning systems have been successfully applied to word learning using keyboard-based input, they have thus far seen little application in word learning where spoken instead of typed input is used. Here we present a framework for speech-based word learning using an adaptive model that was developed for and tested with typing-based word learning. We show that typing- and speech-based learning result in similar behavioral patterns that can be used to reliably estimate individual memory processes. We extend earlier findings demonstrating that a response-time based adaptive learning approach outperforms an accuracy-based, Leitner flashcard approach in learning efficiency (demonstrated by higher average accuracy and lower response times after a learning session). In short, we show that adaptive learning benefits transfer from typing-based learning, to speech based learning. Our work provides a basis for the development of language learning applications that use real-time pronunciation assessment software to score the accuracy of the learner’s pronunciations. We discuss the implications for our approach for the development of educationally relevant, adaptive speech-based learning applications.",2021,10.3389/frai.2021.780131
Cross-validated tree-based models for multi-target learning,"Multi-target learning (MTL) is a popular machine learning technique which considers simultaneous prediction of multiple targets. MTL schemes utilize a variety of methods, from traditional linear models to more contemporary deep neural networks. In this work we introduce a novel, highly interpretable, tree-based MTL scheme which exploits the correlation between the targets to obtain improved prediction accuracy. Our suggested scheme applies cross-validated splitting criterion to identify correlated targets at every node of the tree. This allows us to benefit from the correlation among the targets while avoiding overfitting. We demonstrate the performance of our proposed scheme in a variety of synthetic and real-world experiments, showing a significant improvement over alternative methods. An implementation of the proposed method is publicly available at the first author's webpage.",2024,10.3389/frai.2024.1302860
David vs. Goliath: comparing conventional machine learning and a large language model for assessing students' concept use in a physics problem,"Large language models have been shown to excel in many different tasks across disciplines and research sites. They provide novel opportunities to enhance educational research and instruction in different ways such as assessment. However, these methods have also been shown to have fundamental limitations. These relate, among others, to hallucinating knowledge, explainability of model decisions, and resource expenditure. As such, more conventional machine learning algorithms might be more convenient for specific research problems because they allow researchers more control over their research. Yet, the circumstances in which either conventional machine learning or large language models are preferable choices are not well understood. This study seeks to answer the question to what extent either conventional machine learning algorithms or a recently advanced large language model performs better in assessing students' concept use in a physics problem-solving task. We found that conventional machine learning algorithms in combination outperformed the large language model. Model decisions were then analyzed via closer examination of the models' classifications. We conclude that in specific contexts, conventional machine learning can supplement large language models, especially when labeled data is available.",2024,10.3389/frai.2024.1408817
FinFakeBERT: financial fake news detection,"The intentional use of fake news for financial manipulation or the disruption of financial markets is a serious concern, particularly with the rise of generative artificial intelligence, which is expected to significantly increase its dissemination. A lack of open-access, labeled
                    financial
                    fake news data poses challenges when training effective models for financial fake news detection. To address these challenges, we present FinFakeBERT, a family of models trained using newly curated fake news data. We demonstrate that fine-tuning BERT with a small set of actual fake financial news, following fine-tuning with a large cross-domain fake news dataset and accurate financial news articles, leads to high fake news detection accuracy and significantly reduces the false positive rate (FPR) when tested on several large sets of real financial news articles. Our best model achieves a 2.1% false positive rate (FPR) on real financial news, whereas available benchmark fake-news detectors exhibit FPRs that are more than three to ten times higher.",2025,10.3389/frai.2025.1604272
Transparency and precision in the age of AI: evaluation of explainability-enhanced recommendation systems,"In today’s information age, recommender systems have become an essential tool to filter and personalize the massive data flow to users. However, these systems’ increasing complexity and opaque nature have raised concerns about transparency and user trust. Lack of explainability in recommendations can lead to ill-informed decisions and decreased confidence in these advanced systems. Our study addresses this problem by integrating explainability techniques into recommendation systems to improve both the precision of the recommendations and their transparency. We implemented and evaluated recommendation models on the MovieLens and Amazon datasets, applying explainability methods like LIME and SHAP to disentangle the model decisions. The results indicated significant improvements in the precision of the recommendations, with a notable increase in the user’s ability to understand and trust the suggestions provided by the system. For example, we saw a 3% increase in recommendation precision when incorporating these explainability techniques, demonstrating their added value in performance and improving the user experience.",2024,10.3389/frai.2024.1410790
AI-driven disinformation: policy recommendations for democratic resilience,"The increasing integration of artificial intelligence (AI) into digital communication platforms has significantly transformed the landscape of information dissemination. Recent evidence indicates that AI-enabled tools, particularly generative models and engagement-optimization algorithms, play a central role in the production and amplification of disinformation. This phenomenon poses a direct challenge to democratic processes, as algorithmically amplified falsehoods systematically distort political information environments, erode public trust in institutions, and foster polarization – conditions that degrade democratic decision-making. The regulatory asymmetry between traditional media – historically subject to public oversight – and digital platforms exacerbates these vulnerabilities. This policy and practice review has three primary aims: (1) to document and analyze the role of AI in recent disinformation campaigns, (2) to assess the effectiveness and limitations of existing AI governance frameworks in mitigating disinformation risks, and (3) to formulate evidence-informed policy recommendations to strengthen institutional resilience. Drawing on qualitative analysis of case studies and regulatory trends, we argue for the urgent need to embed AI-specific oversight mechanisms within democratic governance systems. We recommend a multi-stakeholder approach involving platform accountability, enforceable regulatory harmonization across jurisdictions, and sustained civic education to foster digital literacy and cognitive resilience as defenses against malign information. Without such interventions, democratic processes risk becoming increasingly susceptible to manipulation, delegitimization, and systemic erosion.",2025,10.3389/frai.2025.1569115
Evaluation of MRI Denoising Methods Using Unsupervised Learning,"In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein’s Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network’s receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods.",2021,10.3389/frai.2021.642731
MLR-predictor: a versatile and efficient computational framework for multi-label requirements classification,"IntroductionRequirements classification is an essential task for development of a successful software by incorporating all relevant aspects of users' needs. Additionally, it aids in the identification of project failure risks and facilitates to achieve project milestones in more comprehensive way. Several machine learning predictors are developed for binary or multi-class requirements classification. However, a few predictors are designed for multi-label classification and they are not practically useful due to less predictive performance.MethodMLR-Predictor makes use of innovative OkapiBM25 model to transforms requirements text into statistical vectors by computing words informative patterns. Moreover, predictor transforms multi-label requirements classification data into multi-class classification problem and utilize logistic regression classifier for categorization of requirements. The performance of the proposed predictor is evaluated and compared with 123 machine learning and 9 deep learning-based predictive pipelines across three public benchmark requirements classification datasets using eight different evaluation measures.ResultsThe large-scale experimental results demonstrate that proposed MLR-Predictor outperforms 123 adopted machine learning and 9 deep learning predictive pipelines, as well as the state-of-the-art requirements classification predictor. Specifically, in comparison to state-of-the-art predictor, it achieves a 13% improvement in macro F1-measure on the PROMISE dataset, a 1% improvement on the EHR-binary dataset, and a 2.5% improvement on the EHR-multiclass dataset.DiscussionAs a case study, the generalizability of proposed predictor is evaluated on softwares customer reviews classification data. In this context, the proposed predictor outperformed the state-of-the-art BERT language model by F-1 score of 1.4%. These findings underscore the robustness and effectiveness of the proposed MLR-Predictor in various contexts, establishing its utility as a promising solution for requirements classification task.",2024,10.3389/frai.2024.1481581
Generating high-fidelity privacy-conscious synthetic patient data for causal effect estimation with multiple treatments,"In the past decade, there has been exponentially growing interest in the use of observational data collected as a part of routine healthcare practice to determine the effect of a treatment with causal inference models. Validation of these models, however, has been a challenge because the ground truth is unknown: only one treatment-outcome pair for each person can be observed. There have been multiple efforts to fill this void using synthetic data where the ground truth can be generated. However, to date, these datasets have been severely limited in their utility either by being modeled after small non-representative patient populations, being dissimilar to real target populations, or only providing known effects for two cohorts (treated vs. control). In this work, we produced a large-scale and realistic synthetic dataset that provides ground truth effects for over 10 hypertension treatments on blood pressure outcomes. The synthetic dataset was created by modeling a nationwide cohort of more than 580, 000 hypertension patient data including each person's multi-year history of diagnoses, medications, and laboratory values. We designed a data generation process by combining an adapted ADS-GAN model for fictitious patient information generation and a neural network for treatment outcome generation. Wasserstein distance of 0.35 demonstrates that our synthetic data follows a nearly identical joint distribution to the patient cohort used to generate the data. Patient privacy was a primary concern for this study; the ϵ-identifiability metric, which estimates the probability of actual patients being identified, is 0.008%, ensuring that our synthetic data cannot be used to identify any actual patients. To demonstrate its usage, we tested the bias in causal effect estimation of four well-established models using this dataset. The approach we used can be readily extended to other types of diseases in the clinical domain, and to datasets in other domains as well.",2022,10.3389/frai.2022.918813
"Predicting Cervical Cancer Outcomes: Statistics, Images, and Machine Learning","Cervical cancer is a very common and severe disease in women worldwide. Accurate prediction of its clinical outcomes will help adjust or optimize the treatment of cervical cancer and benefit the patients. Statistical models, various types of medical images, and machine learning have been used for outcome prediction and obtained promising results. Compared to conventional statistical models, machine learning has demonstrated advantages in dealing with the complexity in large-scale data and discovering prognostic factors. It has great potential in clinical application and improving cervical cancer management. However, the limitations of prediction studies and prediction models including simplification, insufficient data, overfitting and lack of interpretability, indicate that more work is needed to make clinical outcome prediction more accurate, more reliable, and more practical for clinical use.",2021,10.3389/frai.2021.627369
The interactive reading task: Transformer-based automatic item generation,"Automatic item generation (AIG) has the potential to greatly expand the number of items for educational assessments, while simultaneously allowing for a more construct-driven approach to item development. However, the traditional item modeling approach in AIG is limited in scope to content areas that are relatively easy to model (such as math problems), and depends on highly skilled content experts to create each model. In this paper we describe the interactive reading task, a transformer-based deep language modeling approach for creating reading comprehension assessments. This approach allows a fully automated process for the creation of source passages together with a wide range of comprehension questions about the passages. The format of the questions allows automatic scoring of responses with high fidelity (e.g., selected response questions). We present the results of a large-scale pilot of the interactive reading task, with hundreds of passages and thousands of questions. These passages were administered as part of the practice test of the Duolingo English Test. Human review of the materials and psychometric analyses of test taker results demonstrate the feasibility of this approach for automatic creation of complex educational assessments.",2022,10.3389/frai.2022.903077
The evaluation of performance for agroecological greenhouse tomato strategies by the CRITIC-OWA model,"IntroductionModern agriculture must begin to use production strategies that are increasingly sustainable. To help in decision-making, the present work analyzes the sustainability of greenhouse tomato production with different agroecological strategies: shading (conventional fixed mesh and mobile photovoltaic shading), grafting and deficit irrigation, based on economic, social, and environmental criteria.MethodsFor the ranking of the different strategies, the use of an extension of the CRiteria Importance Through Inter-criteria Correlation (CRITIC) is proposed, in which the correlation between the criteria is obtained through the Pearson-OWA, where the aggregation of the quadratic differences between criteria is carried out considering the attitudinal character of the decision-maker, that is, using Ordered Weighted Averaging (OWA), in addition to induced variables, with the Induced Probabilistic OWA CRITIC (IPOWA CRITIC). Three extensions are considered based on this model depending on the way the multicriteria score is calculated: i) the ranking is carried out on the relative score (S) of each alternative (IPOWA-S-CRITIC), ii) on the weighting vector (W) (IPOWA-W-CRITIC), or iii) on both (IPOWA-S-W-CRITIC).ResultsThe results of the classifications conducted indicate that the use of mobile photovoltaic mesh is a sustainable production strategy, due to its effect on production and quality of the crop, CO2 fixation, and irrigation water savings.DiscussionThe use of mobile photovoltaic shades is compatible with tomato cultivation in a greenhouse if the management of the installation is performed considering the needs of the plants in most of the rankings.",2025,10.3389/frai.2025.1599334
ChatGPT in society: emerging issues,"We review and critically assess several issues arising from the potential -large-scale- implementation or deployment of Large Language Models (LLMs) in society. These include security, political, economic, cultural, and educational issues as well as issues concerning social biases, creativity, copyright, and freedom of speech. We argue, without a preconceived pessimism toward these tools, that they may bring about many benefits. However, we also call for a balance assessment of their downsides. While our work is only preliminary and certainly partial it nevertheless holds some value as one of the first exploratory attempts in the literature.",2023,10.3389/frai.2023.1130913
A comparative study of bone density in elderly people measured with AI and QCT,"BackgroundOsteoporosis, a systemic skeletal disorder characterized by deteriorated bone microarchitecture and low bone mass, poses substantial fracture risks to aging populations globally. Early detection of reduced bone mineral density (BMD) through opportunistic screening is critical for preventing fragility fractures. Although dual-energy X-ray absorptiometry (DXA) is the gold standard for diagnosing osteoporosis, many patients have not undergone screening with this technique. Therefore, developing an automated tool that can diagnose bone density through routine chest and abdominal CT examinations is highly important. With advancements in technology and the accumulation of clinical data, the role of bone density artificial intelligence (AI) in the diagnosis and management of osteoporosis is becoming increasingly significant.ObjectiveFirst to validate the diagnostic equivalence of AI-based BMD prediction against quantitative CT (QCT) reference standards, second to assess inter-device measurement consistency across multi-vendor CT systems (Siemens, GE, Philips). Ultimately, the objective is to determine the clinical utility of AI-derived BMD for osteoporosis classification.MethodsIn this retrospective multicenter study, paired CT/QCT datasets from 702 patients (2019–2022) were analyzed. The accuracy, sensitivity, and specificity of an Bone Density AI model were evaluated by comparing the predicted bone mineral density values from bone density AI with the measured values from QCT. Moreover, the consistency of lumbar spine BMD measurements between QCT and Bone Density AI on different devices was compared.ResultsThe AUC of Bone Density AI model in diagnosing osteoporosis was 0.822 (95% CI: 0.787–0.867, p &lt; 0.001), with an accuracy of 0.9456, sensitivity of 0.9601, and specificity of 0.9270, indicating good performance in predicting bone density. The consistency study between Bone Density AI and QCT for the vertebral BMD measurements revealed no statistically significant difference in R2 values, suggesting no significant difference in performance between the two methods in measuring BMD. The linear regression fit between the R2 values of QCT and Bone Density AI for measuring lumbar spine BMD with different equipment ranged from 0.88 to 0.96, indicating a high degree of consistency between the two measurement methods across devices.ConclusionThis multicenter study pioneers a dual-validation framework to establish the clinical validity of deep learning-based BMD prediction algorithms using routine thoracic/abdominal CT scans. Our data suggest that AI-driven BMD quantification demonstrates non-inferior diagnostic accuracy to QCT while overcoming DXA’s accessibility limitations. This technology enables cost-effective, radiation-free osteoporosis screening through routine CT repurposing, particularly beneficial for resource-constrained settings.",2025,10.3389/frai.2025.1582960
Machine learning-based detection of cognitive decline using SSWTRT: classification performance and decision analysis,"Introduction
                    
                      Early detection of cognitive decline is essential for preventing dementia progression, yet conventional screening tools such as the Mini-Mental State Examination (MMSE) require trained examiners and substantial time. Building on evidence that dementia is associated with tactile and visual perceptual deficits, this study examined whether the
                      Sound Symbolic Word Texture Recognition Test
                      (SSWTRT)—a rapid, self-administered task using Japanese sound-symbolic words (SSWs)—could identify individuals with suspected cognitive decline through machine learning analysis.
                    
                  
                  
                    Methods
                    A total of 233 participants diagnosed with idiopathic normal pressure hydrocephalus (mean age = 77.1 ± 7.3 years) completed the SSWTRT, which presents 12 close-up images of material surfaces and requires selecting one of eight SSWs to describe perceived texture. Each response was scored by its concordance with normative data from healthy young adults. Using these 12 item scores, together with participants’ age and education, several machine learning classifiers were trained to predict MMSE-based groups (≤27 vs. ≥28). Model performance was evaluated via five-fold cross-validation, and interpretability was examined using SHapley Additive exPlanations (SHAP).
                  
                  
                    Results
                    Among the tested models—K-Nearest Neighbors, Random Forest, and Support Vector Machine (SVM)—the balanced SVM achieved the highest performance (accuracy = 0.71, precision = 0.72, recall = 0.72, F1 = 0.72, AUC = 0.72). SHAP analysis revealed that responses to specific images, especially those depicting soft or coarse textures, strongly influenced classification outcomes. Some image items showed effects opposite to the intended scoring direction, indicating possible interference from age-related sensory decline rather than cognitive factors.
                  
                  
                    Discussion
                    These findings demonstrate that machine learning applied to SSWTRT responses can moderately classify individuals with potential cognitive decline using a non-invasive, resource-efficient approach. The model’s interpretability analysis highlighted key image features and response tendencies associated with cognitive status, providing guidance for test refinement. Although the current cohort consisted solely of iNPH patients, limiting generalizability, the proposed framework offers a promising foundation for scalable, language-specific cognitive screening tools.",2025,10.3389/frai.2025.1689182
Stylistic variation across English translations of Chinese science fiction: Ken Liu versus ChatGPT,"Advancements in computational tools, including neural machine translation (NMT) and large language models (LLMs), have revolutionized literary stylistics and opened new avenues in corpus-based translation studies (CBTS). Yet, the style of LLM-produced translations, especially in science fiction (SF) literature, remain understudied. This study examines stylistic variation across English translations of Chinese SF by translator Ken Liu and ChatGPT-4o. Thirteen works translated by both were compared using Multi-Dimensional analysis on key dimensions. Stylometric tests assessed within-translator and between-translator variations, and functional analysis interpreted the subordinate linguistic features. Findings reveal that Ken Liu adapts his style to each story’s depth, exhibiting greater variation, while GPT maintains a more consistent style. Ken Liu’s less narrative style enhances resonance through a minimalist approach, whereas GPT’s more narrative style offers clarity but may undermine thematic impact. The study contributes to CBTS by providing a methodological framework for comparing human and LLM translations in terms of style. It highlights a collaborative model that combines human creativity with LLM efficiency, necessitating continuous upskilling among students, educators, and practitioners to adapt to LLMs’ growing presence in translation. Ultimately, by exploring the intersection of linguistics, literature, and artificial intelligence, the study pushes the boundaries of translation studies and practices.",2025,10.3389/frai.2025.1576750
Artificial intelligence-enhanced assessment of fundamental motor skills: validity and reliability of the FUS test for jumping rope performance,"Introduction
                    Widespread concerns about children’s low fundamental motor skill (FMS) proficiency highlight the need for accurate assessment tools to support structured instruction. This study examined the validity and reliability of an AI-enhanced methodology for assessing jumping rope performance within the Fundamental Motor Skills in Sport (FUS) test.
                  
                  
                    Methods
                    A total of 236 participants (126 primary school students aged 7–14; 110 university sports students aged 20–21) completed jumping rope tasks recorded via the FUS mobile app integrated with an AI model evaluating five process-oriented performance criteria. Concurrent validity and inter-rater reliability were examined by comparing AIgenerated assessments with scores from two expert evaluators. Intra-rater reliability was also assessed through reassessment of video trials after a 3-week interval.
                  
                  
                    Results
                    Results revealed excellent concurrent validity and inter-rater reliability for the AI model compared with expert ratings (ICC = 0.96; weighted kappa = 0.87). Agreement on individual criteria was similarly high (Cohen’s kappa = 0.83–0.87). Expertadjusted AI scores further improved reliability (ICC = 0.98). Intrarater reliability was also excellent, with perfect agreement for AIgenerated scores (ICC = 1.00; kappa = 1.00).
                  
                  
                    Conclusions
                    These findings demonstrate that AI-based assessment offers objective, reliable, and scalable evaluation, enhancing accuracy and efficiency of FMS assessment in education and research.",2025,10.3389/frai.2025.1611534
Requirements and challenges for hybrid intelligence: A case-study in education,"The potential for Artificial Intelligence is widely proclaimed. Yet, in everyday educational settings the use of this technology is limited. Particularly, if we consider smart systems that actually interact with learners in a knowledgeable way and as such support the learning process. It illustrates the fact that teaching professionally is a complex challenge that is beyond the capabilities of current autonomous robots. On the other hand, dedicated forms of Artificial Intelligence can be very good at certain things. For example, computers are excellent chess players and automated route planners easily outperform humans. To deploy this potential, experts argue for a hybrid approach in which humans and smart systems collaboratively accomplish goals. How to realize this for education? What does it entail in practice? In this contribution, we investigate the idea of a hybrid approach in secondary education. As a case-study, we focus on learners acquiring systems thinking skills and our recently for this purpose developed pedagogical approach. Particularly, we discuss the kind of Artificial Intelligence that is needed in this situation, as well as which tasks the software can perform well and which tasks are better, or necessarily, left with the teacher.",2022,10.3389/frai.2022.891630
Opportunities for synthetic data in nature and climate finance,"This paper delves into the intricacies of synthetic data, emphasizing its growing significance in the realm of finance and more notably, sustainable finance. Synthetic data, artificially generated to simulate real-world data, is being recognized for its potential to address risk management, regulatory compliance, and the innovation of financial products. Especially in sustainable finance, synthetic data offers insights into modeling environmental uncertainties, assessing volatile social and governance scenarios, enhancing data availability, and protecting data confidentiality. This critical review attempts first ever classification of synthetic data production methods, when applied to sustainable finance data gaps, elucidates the methodologies behind its creation, and examines its assurance and controls. Further, it identifies the unique data needs of green finance going forward and breaks down potential risks tied to synthetic data utilization, including challenges from generative AI, input quality, and critical ethical considerations like bias and discrimination.",2024,10.3389/frai.2023.1168749
MPAR-RCNN: a multi-task network for multiple person detection with attribute recognition,"Multi-label attribute recognition is a critical task in computer vision, with applications ranging across diverse fields. This problem often involves detecting objects with multiple attributes, necessitating sophisticated models capable of both high-level differentiation and fine-grained feature extraction. The integration of object detection and attribute recognition typically relies on approaches such as dual-stage networks, where accurate predictions depend on advanced feature extraction techniques, such as Region of Interest (RoI) pooling. To meet these demands, an efficient method that achieves both reliable detection and attribute classification in a unified framework is essential. This study introduces an innovative MTL framework designed to incorporate Multi-Person Attribute Recognition (MPAR) within a single-model architecture. Named MPAR-RCNN, this framework unifies object detection and attribute recognition tasks through a spatially aware, shared backbone, facilitating efficient and accurate multi-label prediction. Unlike the traditional Fast Region-based Convolutional Neural Network (R-CNN), which separately manages person detection and attribute classification with a dual-stage network, the MPAR-RCNN architecture optimizes both tasks within a single structure. Validated on the WIDER (Web Image Dataset for Event Recognition) dataset, the proposed model demonstrates an improvement over current state-of-the-art (SOTA) architectures, showcasing its potential in advancing multi-label attribute recognition.",2025,10.3389/frai.2025.1454488
Anomaly detection via Gumbel Noise Score Matching,"We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method to detect anomalies in categorical data. GNSM accomplishes this by estimating the scores, i.e., the gradients of log likelihoods w.r.t. inputs, of continuously relaxed categorical distributions. We test our method on a suite of anomaly detection tabular datasets. GNSM achieves a consistently high performance across all experiments. We further demonstrate the flexibility of GNSM by applying it to image data where the model is tasked to detect poor segmentation predictions. Images ranked anomalous by GNSM show clear segmentation failures, with the anomaly scores strongly correlating with segmentation metrics computed on ground-truth. We outline the score matching training objective utilized by GNSM and provide an open-source implementation of our work.",2024,10.3389/frai.2024.1441205
Missing data in multi-omics integration: Recent advances through artificial intelligence,"Biological systems function through complex interactions between various ‘omics (biomolecules), and a more complete understanding of these systems is only possible through an integrated, multi-omic perspective. This has presented the need for the development of integration approaches that are able to capture the complex, often non-linear, interactions that define these biological systems and are adapted to the challenges of combining the heterogenous data across ‘omic views. A principal challenge to multi-omic integration is missing data because all biomolecules are not measured in all samples. Due to either cost, instrument sensitivity, or other experimental factors, data for a biological sample may be missing for one or more ‘omic techologies. Recent methodological developments in artificial intelligence and statistical learning have greatly facilitated the analyses of multi-omics data, however many of these techniques assume access to completely observed data. A subset of these methods incorporate mechanisms for handling partially observed samples, and these methods are the focus of this review. We describe recently developed approaches, noting their primary use cases and highlighting each method's approach to handling missing data. We additionally provide an overview of the more traditional missing data workflows and their limitations; and we discuss potential avenues for further developments as well as how the missing data issue and its current solutions may generalize beyond the multi-omics context.",2023,10.3389/frai.2023.1098308
On the construction of artificial general intelligence based on the correspondence between goals and means,"Humans are goal-directed agents and intelligence is suggested to be a characteristic of such agents. AGI can be achieved following the principle of the goals-means correspondence that posits the necessary condition for achieving a goal is the correspondence between the goal and the means. The goals-means correspondence is used in all architectures underlying intelligent systems. There are two conventional architectures regarding how the correspondence can be established. One conventional architecture that is based on observations of animals, is intelligent agents whose goals, means, or criteria for its construction are determined jointly at the moment of the birth of an agent. The other conventional architecture that is based on the analysis of human actions, defines intelligent agents whose goals and means are constructed arbitrarily and independently from each other. The conventional architectures cannot explain human actions and thinking. Since the conventional architectures underlie all artificial intelligent systems these systems are insufficient to construct AGI. The formal analysis of architectures demonstrates that there is another architecture in that arbitrary goals and means are constructed jointly on the basis of the criterion of minimal construction costs. This architecture is suggested to underlie human goal-directed processes. The view on humans as goal-directed agents constructing goals and means jointly allows creating an AGI agent that is capable of functioning in real situations. Unlike conventional AI agents that have an unaltered structure, the structure of agents in the new architecture is alterable. The development of an AGI agent may be similar to human growth from an infant to an adult. A model including a simple agent based on the new architecture, is considered. In the model the agent wanders in a quadrangular field filled with various objects that stimulate the agent to move in several directions simultaneously, thus trapping the agent. However, changing its structure the agent constructs goal-directed processes; therefore it is capable of leaving traps.",2025,10.3389/frai.2025.1588726
AttentionTTE: a deep learning model for estimated time of arrival,"Estimating travel time (ETA) for arbitrary paths is crucial in urban intelligent transportation systems. Previous studies primarily focus on constructing complex feature systems for individual road segments or sub-segments, which fail to effectively model the influence of each road segment on others. To address this issue, we propose an end-to-end model, AttentionTTE. It utilizes a self-attention mechanism to capture global spatial correlations and a recurrent neural network to capture temporal dependencies from local spatial correlations. Additionally, a multi-task learning module integrates global spatial correlations and temporal dependencies to estimate the travel time for both the entire path and each local path. We evaluate our model on a large trajectory dataset, and extensive experimental results demonstrate that AttentionTTE achieves state-of-the-art performance compared to other methods.",2024,10.3389/frai.2024.1258086
Integrating 4E cognition with science and technology studies: a framework for understanding AI applications,"The paper brings together two different theoretical strands of research, one from cognitive science, the other from Science and Technology Studies. The purpose in so doing is to uncover how cognition interrelates with socio-material practices and AI technology. An integrative framework is presented as a possible way for connecting the two strands while theorizing on their interrelations with AI.",2025,10.3389/frai.2025.1545014
Investigating the contribution of image time series observations to cauliflower harvest-readiness prediction,"Cauliflower cultivation is subject to high-quality control criteria during sales, which underlines the importance of accurate harvest timing. Using time series data for plant phenotyping can provide insights into the dynamic development of cauliflower and allow more accurate predictions of when the crop is ready for harvest than single-time observations. However, data acquisition on a daily or weekly basis is resource-intensive, making selection of acquisition days highly important. We investigate which data acquisition days and development stages positively affect the model accuracy to get insights into prediction-relevant observation days and aid future data acquisition planning. We analyze harvest-readiness using the cauliflower image time series of the GrowliFlower dataset. We use an adjusted ResNet18 classification model, including positional encoding of the data acquisition dates to add implicit information about development. The explainable machine learning approach GroupSHAP analyzes time points' contributions. Time points with the lowest mean absolute contribution are excluded from the time series to determine their effect on model accuracy. Using image time series rather than single time points, we achieve an increase in accuracy of 4%. GroupSHAP allows the selection of time points that positively affect the model accuracy. By using seven selected time points instead of all 11 ones, the accuracy improves by an additional 4%, resulting in an overall accuracy of 89.3%. The selection of time points may therefore lead to a reduction in data collection in the future.",2024,10.3389/frai.2024.1416323
MLGCN: an ultra efficient graph convolutional neural model for 3D point cloud analysis,"With the rapid advancement of 3D acquisition technologies, 3D sensors such as LiDARs, 3D scanners, and RGB-D cameras have become increasingly accessible and cost-effective. These sensors generate 3D point cloud data that require efficient algorithms for tasks such as 3D model classification and segmentation. While deep learning techniques have proven effective in these areas, existing models often rely on complex architectures, leading to high computational costs that are impractical for real-time applications like augmented reality and robotics. In this work, we propose the Multi-level Graph Convolutional Neural Network (MLGCN), an ultra-efficient model for 3D point cloud analysis. The MLGCN model utilizes shallow Graph Neural Network (GNN) blocks to extract features at various spatial locality levels, leveraging precomputed KNN graphs shared across GCN blocks. This approach significantly reduces computational overhead and memory usage, making the model well-suited for deployment on low-memory and low-CPU devices. Despite its efficiency, MLGCN achieves competitive performance in object classification and part segmentation tasks, demonstrating results comparable to state-of-the-art models while requiring up to a thousand times fewer floating-point operations and significantly less storage. The contributions of this paper include the introduction of a lightweight, multi-branch graph-based network for 3D shape analysis, the demonstration of the model's efficiency in both computation and storage, and a thorough theoretical and experimental evaluation of the model's performance. We also conduct ablation studies to assess the impact of different branches within the model, providing valuable insights into the role of specific components.",2024,10.3389/frai.2024.1439340
"Lexical simplification benchmarks for English, Portuguese, and Spanish","Even in highly-developed countries, as many as 15–30% of the population can only understand texts written using a basic vocabulary. Their understanding of everyday texts is limited, which prevents them from taking an active role in society and making informed decisions regarding healthcare, legal representation, or democratic choice. Lexical simplification is a natural language processing task that aims to make text understandable to everyone by replacing complex vocabulary and expressions with simpler ones, while preserving the original meaning. It has attracted considerable attention in the last 20 years, and fully automatic lexical simplification systems have been proposed for various languages. The main obstacle for the progress of the field is the absence of high-quality datasets for building and evaluating lexical simplification systems. In this study, we present a new benchmark dataset for lexical simplification in English, Spanish, and (Brazilian) Portuguese, and provide details about data selection and annotation procedures, to enable compilation of comparable datasets in other languages and domains. As the first multilingual lexical simplification dataset, where instances in all three languages were selected and annotated using comparable procedures, this is the first dataset that offers a direct comparison of lexical simplification systems for three languages. To showcase the usability of the dataset, we adapt two state-of-the-art lexical simplification systems with differing architectures (neural vs. non-neural) to all three languages (English, Spanish, and Brazilian Portuguese) and evaluate their performances on our new dataset. For a fairer comparison, we use several evaluation measures which capture varied aspects of the systems' efficacy, and discuss their strengths and weaknesses. We find that a state-of-the-art neural lexical simplification system outperforms a state-of-the-art non-neural lexical simplification system in all three languages, according to all evaluation measures. More importantly, we find that the state-of-the-art neural lexical simplification systems perform significantly better for English than for Spanish and Portuguese, thus posing a question if such an architecture can be used for successful lexical simplification in other languages, especially the low-resourced ones.",2022,10.3389/frai.2022.991242
Cracking the genetic code with neural networks,"The genetic code is textbook scientific knowledge that was soundly established without resorting to Artificial Intelligence (AI). The goal of our study was to check whether a neural network could re-discover, on its own, the mapping links between codons and amino acids and build the complete deciphering dictionary upon presentation of transcripts proteins data training pairs. We compared different Deep Learning neural network architectures and estimated quantitatively the size of the required human transcriptomic training set to achieve the best possible accuracy in the codon-to-amino-acid mapping. We also investigated the effect of a codon embedding layer assessing the semantic similarity between codons on the rate of increase of the training accuracy. We further investigated the benefit of quantifying and using the unbalanced representations of amino acids within real human proteins for a faster deciphering of rare amino acids codons. Deep neural networks require huge amount of data to train them. Deciphering the genetic code by a neural network is no exception. A test accuracy of 100% and the unequivocal deciphering of rare codons such as the tryptophan codon or the stop codons require a training dataset of the order of 4–22 millions cumulated pairs of codons with their associated amino acids presented to the neural network over around 7–40 training epochs, depending on the architecture and settings. We confirm that the wide generic capacities and modularity of deep neural networks allow them to be customized easily to learn the deciphering task of the genetic code efficiently.",2023,10.3389/frai.2023.1128153
A review of data abstraction,"It is well-known that Artificial Intelligence (AI), and in particular Machine Learning (ML), is not effective without good data preparation, as also pointed out by the recent wave of data-centric AI. Data preparation is the process of gathering, transforming and cleaning raw data prior to processing and analysis. Since nowadays data often reside in distributed and heterogeneous data sources, the first activity of data preparation requires collecting data from suitable data sources and data services, often distributed and heterogeneous. It is thus essential that providers describe their data services in a way to make them compliant with the FAIR guiding principles, i.e., make them automatically Findable, Accessible, Interoperable, and Reusable (FAIR). The notion of data abstraction has been introduced exactly to meet this need. Abstraction is a kind of reverse engineering task that automatically provides a semantic characterization of a data service made available by a provider. The goal of this paper is to review the results obtained so far in data abstraction, by presenting the formal framework for its definition, reporting about the decidability and complexity of the main theoretical problems concerning abstraction, and discuss open issues and interesting directions for future research.",2023,10.3389/frai.2023.1085754
Comparing Plan Recognition Algorithms Through Standard Plan Libraries,"Plan recognition deals with reasoning about the goals and execution process of an actor, given observations of its actions. It is one of the fundamental problems of AI, applicable to many domains, from user interfaces to cyber-security. Despite the prevalence of these approaches, they lack a standard representation, and have not been compared using a common testbed. This paper provides a first step towards bridging this gap by providing a standard plan library representation that can be used by hierarchical, discrete-space plan recognition and evaluation criteria to consider when comparing plan recognition algorithms. This representation is comprehensive enough to describe a variety of known plan recognition problems and can be easily used by existing algorithms in this class. We use this common representation to thoroughly compare two known approaches, represented by two algorithms, SBR and Probabilistic Hostile Agent Task Tracker (PHATT). We provide meaningful insights about the differences and abilities of these algorithms, and evaluate these insights both theoretically and empirically. We show a tradeoff between expressiveness and efficiency: SBR is usually superior to PHATT in terms of computation time and space, but at the expense of functionality and representational compactness. We also show how different properties of the plan library affect the complexity of the recognition process, regardless of the concrete algorithm used. Lastly, we show how these insights can be used to form a new algorithm that outperforms existing approaches both in terms of expressiveness and efficiency.",2022,10.3389/frai.2021.732177
Models of Intervention: Helping Agents and Human Users Avoid Undesirable Outcomes,"When working in an unfamiliar online environment, it can be helpful to have an observer that can intervene and guide a user toward a desirable outcome while avoiding undesirable outcomes or frustration. The Intervention Problem is deciding when to intervene in order to help a user. The Intervention Problem is similar to, but distinct from, Plan Recognition because the observer must not only recognize the intended goals of a user but also when to intervene to help the user when necessary. We formalize a family of Intervention Problems and show that how these problems can be solved using a combination of Plan Recognition methods and classification algorithms to decide whether to intervene. For our benchmarks, the classification algorithms dominate three recent Plan Recognition approaches. We then generalize these results to Human-Aware Intervention, where the observer must decide in real time whether to intervene human users solving a cognitively engaging puzzle. Using a revised feature set more appropriate to human behavior, we produce a learned model to recognize when a human user is about to trigger an undesirable outcome. We perform a human-subject study to evaluate the Human-Aware Intervention. We find that the revised model also dominates existing Plan Recognition algorithms in predicting Human-Aware Intervention.",2022,10.3389/frai.2021.723936
Classification of user queries according to a hierarchical medical procedure encoding system using an ensemble classifier,"The Swiss classification of surgical interventions (CHOP) has to be used in daily practice by physicians to classify clinical procedures. Its purpose is to encode the delivered healthcare services for the sake of quality assurance and billing. For encoding a procedure, a code of a maximal of 6-digits has to be selected from the classification system, which is currently realized by a rule-based system composed of encoding experts and a manual search in the CHOP catalog. In this paper, we will investigate the possibility of automatic CHOP code generation based on a short query to enable automatic support of manual classification. The wide and deep hierarchy of CHOP and the differences between text used in queries and catalog descriptions are two apparent obstacles for training and deploying a learning-based algorithm. Because of these challenges, there is a need for an appropriate classification approach. We evaluate different strategies (multi-class non-terminal and per-node classifications) with different configurations so that a flexible modular solution with high accuracy and efficiency can be provided. The results clearly show that the per-node binary classification outperforms the non-terminal multi-class classification with an F1-micro measure between 92.6 and 94%. The hierarchical prediction based on per-node binary classifiers achieved a high exact match by the single code assignment on the 5-fold cross-validation. In conclusion, the hierarchical context from the CHOP encoding can be employed by both classifier training and representation learning. The hierarchical features have all shown improvement in the classification performances under different configurations, respectively: the stacked autoencoder and training examples aggregation using true path rules as well as the unified vocabulary space have largely increased the utility of hierarchical features. Additionally, the threshold adaption through Bayesian aggregation has largely increased the vertical reachability of the per node classification. All the trainable nodes can be triggered after the threshold adaption, while the F1 measures at code levels 3–6 have been increased from 6 to 89% after the threshold adaption.",2022,10.3389/frai.2022.1000283
Domain Generalization for Language-Independent Automatic Speech Recognition,"A language-independent automatic speech recognizer (ASR) is one that can be used for phonetic transcription in languages other than the languages in which it was trained. Language-independent ASR is difficult to train, because different languages implement phones differently: even when phonemes in two different languages are written using the same symbols in the international phonetic alphabet, they are differentiated by different distributions of language-dependent redundant articulatory features. This article demonstrates that the goal of language-independence may be approximated in different ways, depending on the size of the training set, the presence vs. absence of familial relationships between the training and test languages, and the method used to implement phone recognition or classification. When the training set contains many languages, and when every language in the test set is related (shares the same language family with) a language in the training set, then language-independent ASR may be trained using an empirical risk minimization strategy (e.g., using connectionist temporal classification without extra regularizers). When the training set is limited to a small number of languages from one language family, however, and the test languages are not from the same language family, then the best performance is achieved by using domain-invariant representation learning strategies. Two different representation learning strategies are tested in this article: invariant risk minimization, and regret minimization. We find that invariant risk minimization is better at the task of phone token classification (given known segment boundary times), while regret minimization is better at the task of phone token recognition.",2022,10.3389/frai.2022.806274
"Evaluation of the accuracy and repeatability of Deepseek V3, Doubao, and Kimi1.5 in answering knowledge-related queries about chronic non-bacterial osteitis","BackgroundThere are significant differences in the diagnosis and treatment of chronic non-bacterial osteitis (CNO), and there is an urgent need for health education efforts to enhance awareness of this condition. Deepseek V3, Doubao, and Kimi1.5 are highly popular language models in China that can provide knowledge related to diseases. This article aims to investigate the accuracy and reproducibility of the responses provided by these three artificial intelligence (AI) language models in answering questions about CNO.MethodsAccording to the latest expert consensus, 16 questions related to CNO were collected. The three AI language models were separately asked these questions at three different times. The answers were independently evaluated by two orthopedic experts.ResultsAmong the responses of the three AI models to 16 CNO-related questions across three rounds of testing, only Doubao received “Completely incorrect” ratings (accounting for 6.25%) in the third round of scoring by Reviewer 2. During the answering process, Doubao had the shortest response time and provided the most words in its answers. In the first and third rounds of scoring by the first expert, Kimi scored the highest (3.938 ± 0.342, 3.875 ± 0.873), while in the second round, Doubao scored the highest (3.875 ± 0.5). In the second round of scoring by the second expert, Doubao received the highest score (3.812 ± 0.403). In the first and third rounds, Kimi1.5 received the highest score (3.812 ± 0.602, 3.812 ± 0.704).ConclusionDeepseek V3, Doubao, and Kimi1.5 are capable of answering most questions related to CNO with good accuracy and reproducibility, showing no significant differences.",2025,10.3389/frai.2025.1629149
Deep multimodal learning for domain-level cognitive decline prediction in Alzheimer's disease,"Introduction
                    Alzheimer's disease (AD) is characterized by significant variability in clinical progression; however, few studies have focused on developing models to predict cognitive decline. Anticipating these trajectories is essential for patient management, care planning, and developing new treatments. This study explores the potential of artificial intelligence (AI) techniques to model neurocognitive trajectories from multimodal neuroimaging data and further investigates different data representation frameworks.
                  
                  
                    Methods
                    
                      Using information from 653 participants from the Alzheimer's Disease Neuroimaging Initiative (ADNI), we developed models to predict future clinical diagnoses and cognitive decline, both quantitatively (rate of decline) and qualitatively (presence or absence of decline). Input features included structural T1-weighted magnetic resonance imaging (MRI), [
                      18
                      F]-fluorodeoxyglucose positron emission tomography (FDG-PET), [
                      18
                      F]-florbetapir PET (AV45-PET), neuropsychological assessments, and demographic variables. Several information representation strategies were explored, including tabular data models, convolutional neural networks (CNNs), and graph neural networks (GNNs). Furthermore, to maximize the use of all available information, we proposed a modeling framework that performed modality-specific pre-training to learn feature embeddings, which were then integrated through a late-fusion layer to produce a unified representation for downstream prediction.
                    
                  
                  
                    Results
                    The modeling strategies demonstrated good predictive performance for future clinical diagnoses, consistent with previous studies (F1 = 0.779). Quantitative models explained approximately 29.4%–36.0% of the variance in cognitive decline. In the qualitative analysis, the models achieved AUC values above 0.83 when predicting cognitive deterioration in the memory, language, and executive function domains. Architecturally, CNN- and GNN-based models yielded the best performance, and the proposed pre-training strategy consistently improved predictive accuracy.
                  
                  
                    Conclusions
                    This study demonstrates that AI techniques can capture patterns of cognitive decline by exploiting multimodal neuroimaging data. These findings contribute to the development of more precise phenotyping approaches for neurodegenerative patterns in AD.",2025,10.3389/frai.2025.1731062
Artificial intelligence and machine learning applications for cultured meat,"Cultured meat has the potential to provide a complementary meat industry with reduced environmental, ethical, and health impacts. However, major technological challenges remain which require time-and resource-intensive research and development efforts. Machine learning has the potential to accelerate cultured meat technology by streamlining experiments, predicting optimal results, and reducing experimentation time and resources. However, the use of machine learning in cultured meat is in its infancy. This review covers the work available to date on the use of machine learning in cultured meat and explores future possibilities. We address four major areas of cultured meat research and development: establishing cell lines, cell culture media design, microscopy and image analysis, and bioprocessing and food processing optimization. In addition, we have included a survey of datasets relevant to CM research. This review aims to provide the foundation necessary for both cultured meat and machine learning scientists to identify research opportunities at the intersection between cultured meat and machine learning.",2024,10.3389/frai.2024.1424012
"An overview of model uncertainty and variability in LLM-based sentiment analysis: challenges, mitigation strategies, and the role of explainability","Large Language Models (LLMs) have significantly advanced sentiment analysis, yet their inherent uncertainty and variability pose critical challenges to achieving reliable and consistent outcomes. This paper systematically explores the Model Variability Problem (MVP) in LLM-based sentiment analysis, characterized by inconsistent sentiment classification, polarization, and uncertainty arising from stochastic inference mechanisms, prompt sensitivity, and biases in training data. We present illustrative examples and two case studies to highlight its impact and analyze the core causes of MVP, discussing a dozen fundamental reasons for model variability. We pay especial atenttion to explainabily, with an analysis of its importance in LLMs from the MVP perspective. In addition, we investigate key challenges and mitigation strategies, paying particular attention to the role of temperature as a driver of output randomness and highlighting the crucial role of explainability in improving transparency and user trust. By providing a structured perspective on stability, reproducibility, and trustworthiness, this study helps develop more reliable, explainable, and robust sentiment analysis models, facilitating their deployment in high-risk domains such as finance, healthcare and policy making, among others.",2025,10.3389/frai.2025.1609097
Does splitting make sentence easier?,"In this study, we focus on sentence splitting, a subfield of text simplification, motivated largely by an unproven idea that if you divide a sentence in pieces, it should become easier to understand. Our primary goal in this study is to find out whether this is true. In particular, we ask, does it matter whether we break a sentence into two, three, or more? We report on our findings based on Amazon Mechanical Turk. More specifically, we introduce a Bayesian modeling framework to further investigate to what degree a particular way of splitting the complex sentence affects readability, along with a number of other parameters adopted from diverse perspectives, including clinical linguistics, and cognitive linguistics. The Bayesian modeling experiment provides clear evidence that bisecting the sentence leads to enhanced readability to a degree greater than when we create simplification with more splits.",2023,10.3389/frai.2023.1208451
Disembodied creativity in generative AI: prima facie challenges and limitations of prompting in creative practice,"This paper examines some prima facie challenges of using natural language prompting in Generative AI (GenAI) for creative practices in design and the arts. While GenAI is purported to “democratize” creativity by offering a new mode of creation, we argue that it comes with a significant mortgage—particularly one in relation to expert performance, skill acquisition, and embodied engagement. Drawing from Dreyfus and Dreyfus, we show that creativity grounded in internalized expert knowledge cannot be reduced to rule-following or meaningfully externalized in instructions, i.e., prompts. Building on Polanyi, Simon, and Sennett, we posit that much of what makes creative work meaningful is tacit and intuitive, and therefore cannot be fully articulated through prompts. From the perspective of embodied and enactive cognition (Thompson, Noë, Pallasmaa), we argue that even “traditional” digital tools retain a material, bodily interface—something entirely absent from prompt-centered creation. While it may be tempting to treat GenAI systems as mere instruments, the mode of interaction they afford introduces a discontinuity: unlike analog tools or conventional software, they offer the creator significantly less control and disrupt and even erode the feedback loop between mind, hand, and expressive material. Rather than supporting skill development, prompting risks sequestering the user in novice-level engagement. By addressing these challenges, our analysis offers a clearer view of what is at stake when generative systems are integrated into creative disciplines, and why human creators, integrating multiple creative and epistemic faculties as they see fit, must remain at the center of that process.",2025,10.3389/frai.2025.1651354
Divide and summarize: improve SLM text summarization,"IntroductionText summarization is a longstanding challenge in natural language processing, with recent advancements driven by the adoption of Large Language Models (LLMs) and Small Language Models (SLMs). Despite these developments, issues such as the “Lost in the Middle” problem—where LLMs tend to overlook information in the middle of lengthy prompts—persist. Traditional summarization, often termed the “Stuff” method, processes an entire text in a single pass. In contrast, the “Map” method divides the text into segments, summarizes each independently, and then synthesizes these partial summaries into a final output, potentially mitigating the “Lost in the Middle” issue. This study investigates whether the Map method outperforms the Stuff method for texts that fit within the context window of SLMs and assesses its effectiveness in addressing the “Lost in the Middle” problem.MethodsWe conducted a two-part investigation: first, a simulation study using generated texts, paired with an automated fact-retrieval evaluation to eliminate the need for human assessment; second, a practical study summarizing scientific papers.ResultsResults from both studies demonstrate that the Map method produces summaries that are at least as accurate as those from the Stuff method. Notably, the Map method excels at retaining key facts from the beginning and middle of texts, unlike the Stuff method, suggesting its superiority for SLM-based summarization of smaller texts. Additionally, SLMs using the Map method achieved performance comparable to LLMs using the Stuff method, highlighting its practical utility.DiscussionBoth theoretical and practical studies suggest that using Map method for summarization with SLM allowed to address the “Lost in the Middle” problem and outperform Stuff method.",2025,10.3389/frai.2025.1604034
What Does a Language-And-Vision Transformer See: The Impact of Semantic Information on Visual Representations,"Neural networks have proven to be very successful in automatically capturing the composition of language and different structures across a range of multi-modal tasks. Thus, an important question to investigate is how neural networks learn and organise such structures. Numerous studies have examined the knowledge captured by language models (LSTMs, transformers) and vision architectures (CNNs, vision transformers) for respective uni-modal tasks. However, very few have explored what structures are acquired by multi-modal transformers where linguistic and visual features are combined. It is critical to understand the representations learned by each modality, their respective interplay, and the task’s effect on these representations in large-scale architectures. In this paper, we take a multi-modal transformer trained for image captioning and examine the structure of the self-attention patterns extracted from the visual stream. Our results indicate that the information about different relations between objects in the visual stream is hierarchical and varies from local to a global object-level understanding of the image. In particular, while visual representations in the first layers encode the knowledge of relations between semantically similar object detections, often constituting neighbouring objects, deeper layers expand their attention across more distant objects and learn global relations between them. We also show that globally attended objects in deeper layers can be linked with entities described in image descriptions, indicating a critical finding - the indirect effect of language on visual representations. In addition, we highlight how object-based input representations affect the structure of learned visual knowledge and guide the model towards more accurate image descriptions. A parallel question that we investigate is whether the insights from cognitive science echo the structure of representations that the current neural architecture learns. The proposed analysis of the inner workings of multi-modal transformers can be used to better understand and improve on such problems as pre-training of large-scale multi-modal architectures, multi-modal information fusion and probing of attention weights. In general, we contribute to the explainable multi-modal natural language processing and currently shallow understanding of how the input representations and the structure of the multi-modal transformer affect visual representations.",2021,10.3389/frai.2021.767971
"Clear, easy, plain, and simple as keywords for text simplification","In this paper, we distinguish between four interconnected notions that recur in the literature on text simplification:clarity, easiness, plainness, andsimplicity. Whileplain languageandeasy languagehave both been the subject of standardization efforts, there are few attempts to definetext clarityandtext simplicity. Indeed, in the definition ofplain language, clarityhas been favored at the expense ofsimplicitybut is employed as a self-evident notion. Meanwhile,text simplicitysuffers from a negative connotation and is more likely to be defined by its antonym,text complexity. In our analysis, we examine the current definitions ofplain languageandeasy languageand discuss common definitions oftext clarityandtext complexity. We propose a model oftext simplificationthat can clarify the transition from specialized texts to plain language texts, and easy language texts. It is our contention that text simplification should be placed in a more general framework ofdiscursive ergonomics.",2022,10.3389/frai.2022.1042258
Artificial intelligence in the tourism business: a systematic review,"In the tourism sector, AI has been gradually integrated to optimize operations, personalize customer experiences, and improve resource management, thereby transforming the way companies operate and connect with travelers. The aim of this re-search is to explore the application of AI in the tourism industry, identifying the main AI technologies used in the business, the specific areas or processes, their benefits, and challenges. For this purpose, a systematic literature review methodology was used, following PRISMA guidelines, from which 112 primary studies were obtained that contributed to answering the research questions. The main findings indicate that, in the tourism industry, the most commonly used AI technologies include Natural Language Processing (NLP) and deep learning with Neural Networks, with chatbots and models such as CNNs and LSTMs being particularly prominent. These technologies facilitate everything from the automation of interactions (such as bookings and customer service) to advanced data analysis for the personalization of services and strategic decisions, demonstrating their broad applicability and benefit in the sector. However, multiple challenges are also identified, ranging from high costs and advanced technological infrastructure to ethical and privacy concerns. Therefore, for proper implementation of AI in the tourism sector, it is crucial to carefully manage both the benefits and challenges to ensure its success.",2025,10.3389/frai.2025.1599391
Digital twin-enabled interactive cockpits for smart products management and testing,"Digitalization is influencing the design, development, and management of products across myriad industries, transforming traditional products into smart ones. Among digital technologies and models, the digital twin (DT) is regarded as an important contribution to the advancement of physical entity management. DTs are virtual representations of physical objects or systems, which are continuously updated with real-time data collected from their physical counterparts. Surprisingly, DT has yet to be applied in marketing. This study aims, accordingly, first, to introduce the DT concept and, second, to explore the human factor (human-in-the-loop) in DT. Third, elaborate on the DT cockpit (the DT’s interactive element) in the product management paradigm. Specifically, the authors use vehicles as a case study to show how interactive digital twins (IDTs) can be employed to predict and optimize vehicle performance, reliability, sustainability, and customer satisfaction. To conceptualize IDT for smart products and marketing analytics, the customer-centric Technology Acceptance Model (TAM) is employed. As this is the first study to explore DT technology in marketing, the DT concept’s main attributes are discussed, significant contributions are suggested, and avenues for future research are delineated.",2025,10.3389/frai.2025.1685702
Emotional characteristic analysis of human gait while real-time movie viewing,"Emotion recognition is useful in many applications such as preventing crime or improving customer satisfaction. Most of current methods are performed using facial features, which require close-up face information. Such information is difficult to capture with normal security cameras. The advantage of using gait and posture over conventional biometrics such as facial features is that gaits and postures can be obtained unobtrusively from faraway, even in a noisy environment. This study aims to investigate and analyze the relationship between human emotions and their gaits or postures. We collected a dataset made from the input of 49 participants for our experiments. Subjects were instructed to walk naturally in a circular walking path, while watching emotion-inducing videos on Microsoft HoloLens 2 smart glasses. An OptiTrack motion-capturing system was used for recording the gaits and postures of participants. The angles between body parts and walking straightness were calculated as features for comparison of body-part movements while walking under different emotions. Results of statistical analyses show that the subjects' arm swings are significantly different among emotions. And the arm swings on one side of the body could reveal subjects' emotions more obviously than those on the other side. Our results suggest that the arm movements together with information of arm side and walking straightness can reveal the subjects' current emotions while walking. That is, emotions of humans are unconsciously expressed by their arm swings, especially by the left arm, when they are walking in a non-straight walking path. We found that arm swings in happy emotion are larger than arm swings in sad emotion. To the best of our knowledge, this study is the first to perform emotion induction by showing emotion-inducing videos to the participants using smart glasses during walking instead of showing videos before walking. This induction method is expected to be more consistent and more realistic than conventional methods. Our study will be useful for implementation of emotion recognition applications in real-world scenarios, since our emotion induction method and the walking direction we used are designed to mimic the real-time emotions of humans as they walk in a non-straight walking direction.",2022,10.3389/frai.2022.989860
A review on deep learning methods for heart sound signal analysis,"IntroductionApplication of Deep Learning (DL) methods is being increasingly appreciated by researchers from the biomedical engineering domain in which heart sound analysis is an important topic of study. Diversity in methodology, results, and complexity causes uncertainties in obtaining a realistic picture of the methodological performance from the reported methods.MethodsThis survey paper provides the results of a broad retrospective study on the recent advances in heart sound analysis using DL methods. Representation of the results is performed according to both methodological and applicative taxonomies. The study method covers a wide span of related keywords using well-known search engines. Implementation of the observed methods along with the related results is pervasively represented and compared.Results and discussionIt is observed that convolutional neural networks and recurrent neural networks are the most commonly used ones for discriminating abnormal heart sounds and localization of heart sounds with 67.97% and 33.33% of the related papers, respectively. The convolutional neural network and the autoencoder network show a perfect accuracy of 100% in the case studies on the classification of abnormal from normal heart sounds. Nevertheless, this superiority against other methods with lower accuracy is not conclusive due to the inconsistency in evaluation.",2024,10.3389/frai.2024.1434022
Predicting overall survival from tumor dynamics metrics using parametric statistical and machine learning models: application to patients with RET-altered solid tumors,"In oncology drug development, tumor dynamics modeling is widely applied to predict patients' overall survival (OS) via parametric models. However, the current modeling paradigm, which assumes a disease-specific link between tumor dynamics and survival, has its limitations. This is particularly evident in drug development scenarios where the clinical trial under consideration contains patients with tumor types for which there is little to no prior institutional data. In this work, we propose the use of a pan-indication solid tumor machine learning (ML) approach whereby all three tumor metrics (tumor shrinkage rate, tumor regrowth rate and time to tumor growth) are simultaneously used to predict patients' OS in a tumor type independent manner. We demonstrate the utility of this approach in a clinical trial of cancer patients treated with the tyrosine kinase inhibitor, pralsetinib. We compared the parametric and ML models and the results showed that the proposed ML approach is able to adequately predict patient OS across RET-altered solid tumors, including non-small cell lung cancer, medullary thyroid cancer as well as other solid tumors. While the findings of this study are promising, further research is needed for evaluating the generalizability of the ML model to other solid tumor types.",2024,10.3389/frai.2024.1412865
A sentiment analysis approach to the prediction of market volatility,"Prediction and quantification of future volatility and returns play an important role in financial modeling, both in portfolio optimisation and risk management. Natural language processing today allows one to process news and social media comments to detect signals of investors' confidence. We have explored the relationship between sentiment extracted from financial news and tweets and FTSE100 movements. We investigated the strength of the correlation between sentiment measures on a given day and market volatility and returns observed the next day. We found that there is evidence of correlation between sentiment and stock market movements. Moreover, the sentiment captured from news headlines could be used as a signal to predict market returns; we also found that the same does not apply for volatility. However, for the sentiment found in Twitter comments we obtained, in a surprising finding, a correlation coefficient of –0.7 (p &lt; 0.05), which indicates a strong negative correlation between negative sentiment captured from the tweets on a given day and the volatility observed the next day. It is important to keep in mind that stock volatility rises greatly when the market collapses but not symmetrically so when it goes up (the so-called leverage effect). We developed an accurate classifier for the prediction of market volatility in response to the arrival of new information by deploying topic modeling, based on Latent Dirichlet Allocation, in order to extract feature vectors from a collection of tweets and financial news. The obtained features were used as additional input to the classifier. Thanks to the combination of sentiment and topic modeling even on modest (essentially personal) architecture our classifier achieved a directional prediction accuracy for volatility of 63%.",2022,10.3389/frai.2022.836809
Quantum Prisoner’s Dilemma and High Frequency Trading on the Quantum Cloud,"High-frequency trading (HFT) offers an excellent use case and a potential killer application of the commercially available, first generation quasi-quantum computers. To this end, we offer here a simple game-theoretic model of HFT as the famous two player game, Prisoner’s Dilemma. We explore the implementation of HFT as an instance of Prisoner’s Dilemma on the (quasi) quantum cloud using the Eisert, Wilkens, and Lewenstein quantum mediated communication protocol, and how this implementation can not only increase transaction speed but also improve the lot of the players in HFT. Using cooperative game-theoretic reasoning, we also note that in the near future when the internet is properly quantum, players will be able to achieve Pareto-optimality in HFT as an instance of reinforced machine learning.",2021,10.3389/frai.2021.769392
An artificial intelligence algorithm to select most viable embryos considering current process in IVF labs,"BackgroundThe most common Assisted Reproductive Technology is In-Vitro Fertilization (IVF). During IVF, embryologists commonly perform a morphological assessment to evaluate embryo quality and choose the best embryo for transferring to the uterus. However, embryo selection through morphological assessment is subjective, so various embryologists obtain different conclusions. Furthermore, humans can consider only a limited number of visual parameters resulting in a poor IVF success rate. Artificial intelligence (AI) for embryo selection is objective and can include many parameters, leading to better IVF outcomes.ObjectivesThis study sought to use AI to (1) predict pregnancy results based on embryo images, (2) assess using more than one image of the embryo in the prediction of pregnancy but based on the current process in IVF labs, and (3) compare results of AI-Based methods and embryologist experts in predicting pregnancy.MethodsA data set including 252 Time-lapse Videos of embryos related to IVF performed between 2017 and 2020 was collected. Frames related to 19 ± 1, 43 ± 1, and 67 ± 1 h post-insemination were extracted. Well-Known CNN architectures with transfer learning have been applied to these images. The results have been compared with an algorithm that only uses the final image of embryos. Furthermore, the results have been compared with five experienced embryologists.ResultsTo predict the pregnancy outcome, we applied five well-known CNN architectures (AlexNet, ResNet18, ResNet34, Inception V3, and DenseNet121). DeepEmbryo, using three images, predicts pregnancy better than the algorithm that only uses one final image. It also can predict pregnancy better than all embryologists. Different well-known architectures can successfully predict pregnancy chances with up to 75.0% accuracy using Transfer Learning.ConclusionWe have developed DeepEmbryo, an AI-based tool that uses three static images to predict pregnancy. Additionally, DeepEmbryo uses images that can be obtained in the current IVF process in almost all IVF labs. AI-based tools have great potential for predicting pregnancy and can be used as a proper tool in the future.",2024,10.3389/frai.2024.1375474
Explainable AI for Data-Driven Feedback and Intelligent Action Recommendations to Support Students Self-Regulation,"Formative feedback has long been recognised as an effective tool for student learning, and researchers have investigated the subject for decades. However, the actual implementation of formative feedback practices is associated with significant challenges because it is highly time-consuming for teachers to analyse students’ behaviours and to formulate and deliver effective feedback and action recommendations to support students’ regulation of learning. This paper proposes a novel approach that employs learning analytics techniques combined with explainable machine learning to provide automatic and intelligent feedback and action recommendations that support student’s self-regulation in a data-driven manner, aiming to improve their performance in courses. Prior studies within the field of learning analytics have predicted students’ performance and have used the prediction status as feedback without explaining the reasons behind the prediction. Our proposed method, which has been developed based on LMS data from a university course, extends this approach by explaining the root causes of the predictions and by automatically providing data-driven intelligent recommendations for action. Based on the proposed explainable machine learning-based approach, a dashboard that provides data-driven feedback and intelligent course action recommendations to students is developed, tested and evaluated. Based on such an evaluation, we identify and discuss the utility and limitations of the developed dashboard. According to the findings of the conducted evaluation, the dashboard improved students’ learning outcomes, assisted them in self-regulation and had a positive effect on their motivation.",2021,10.3389/frai.2021.723447
Balancing accuracy and user satisfaction: the role of prompt engineering in AI-driven healthcare solutions,"IntroductionThe rapid evolution of the Internet of Things (IoT) and Artificial Intelligence (AI) has opened new possibilities for public healthcare. Effective integration of these technologies is essential to ensure precise and efficient healthcare delivery. This study explores the application of IoT-enabled, AI-driven systems for detecting and managing Dry Eye Disease (DED), emphasizing the use of prompt engineering to enhance system performance.MethodsA specialized prompt mechanism was developed utilizing OpenAI GPT-4.0 and ERNIE Bot-4.0 APIs to assess the urgency of medical attention based on 5,747 simulated patient complaints. A Bidirectional Encoder Representations from Transformers (BERT) machine learning model was employed for text classification to differentiate urgent from non-urgent cases. User satisfaction was evaluated through composite scores derived from Service Experiences (SE) and Medical Quality (MQ) assessments.ResultsThe comparison between prompted and non-prompted queries revealed a significant accuracy increase from 80.1% to 99.6%. However, this improvement was accompanied by a notable rise in response time, resulting in a decrease in SE scores (95.5 to 84.7) but a substantial increase in MQ satisfaction (73.4 to 96.7). These findings indicate a trade-off between accuracy and user satisfaction.DiscussionThe study highlights the critical role of prompt engineering in improving AI-based healthcare services. While enhanced accuracy is achievable, careful attention must be given to balancing response time and user satisfaction. Future research should optimize prompt structures, explore dynamic prompting approaches, and prioritize real-time evaluations to address the identified challenges and maximize the potential of IoT-integrated AI systems in medical applications.",2025,10.3389/frai.2025.1517918
A hybrid AI approach for predicting academic performance in RBE students,"Machine learning has advanced significantly in recent years and is being used in higher education to perform various types of data analysis. While the literature demonstrates the application of machine learning algorithms to predict performance in university education, no such applications are found in EBR, let alone in private institutions of a denominational nature, which presents an opportunity to study prediction in these institutions. To address this gap, this research aims to propose a predictive approach as a decision-support tool for regular basic education, using machine learning techniques. Among the techniques utilized, three machine learning models (Logistic Regression, Support Vector Machine, and Random Forest), along with deep learning models (AlexNet, Gated Recurrent Unit, and Bidirectional Gated Recurrent Unit), were analyzed, as well as ensemble models. Nonetheless, the Ensemble model, which combines deep learning and machine learning techniques, is preferred due to its superior accuracy, precision, and sensitivity performance metrics.",2025,10.3389/frai.2025.1651100
Federated Learning for Privacy-Aware Human Mobility Modeling,"Human mobility modeling is a complex yet essential subject of study related to modeling important spatiotemporal events, including traffic, disease spreading, and customized directions and recommendations. While spatiotemporal data can be collected easily via smartphones, current state-of-the-art deep learning methods require vast amounts of such privacy-sensitive data to generate useful models. This work investigates the creation of spatiotemporal models using a Federated Learning (FL) approach—a machine learning technique that avoids sharing personal data with centralized servers. More specifically, we examine three centralized models for next-place prediction: a simple Gated Recurrent Unit (GRU) model, as well as two state-of-the-art centralized approaches, Flashback and DeepMove. Flashback is a Recurrent Neural Network (RNN) that utilizes historical hidden states with similar context as the current spatiotemporal context to improve performance. DeepMove is an attentional RNN that aims to capture human mobility's regularity while coping with data sparsity. We then implemented models based on FL for the two best-performing centralized models. We compared the performance of all models using two large public datasets: Foursquare (9,450 million check-ins, February 2009 to October 2010) and Gowalla (3,300 million check-ins, April 2012 to January 2014). We first replicated the performance of both Flashback and DeepMove, as reported in the original studies, and compared them to the simple GRU model. Flashback and GRU proved to be the best performing centralized models, so we further explored both in FL scenarios, including several parameters such as the number of clients, rounds, and epochs. Our results indicated that the training process of the federated models was less stable, i.e., the FL versions of both Flashback and GRU tended to have higher variability in the loss curves. The higher variability led to a slower convergence and thus a poorer performance when compared to the corresponding centralized models. Model performance was also highly influenced by the number of federated clients and the sparsity of the evaluation dataset. We additionally provide insights into the technical challenges of applying FL to state-of-the-art deep learning methods for human mobility.",2022,10.3389/frai.2022.867046
A modified U-Net to detect real sperms in videos of human sperm cell,"BackgroundThis study delves into the crucial domain of sperm segmentation, a pivotal component of male infertility diagnosis. It explores the efficacy of diverse architectural configurations coupled with various encoders, leveraging frames from the VISEM dataset for evaluation.MethodsThe pursuit of automated sperm segmentation led to the examination of multiple deep learning architectures, each paired with distinct encoders. Extensive experimentation was conducted on the VISEM dataset to assess their performance.ResultsOur study evaluated various deep learning architectures with different encoders for sperm segmentation using the VISEM dataset. While each model configuration exhibited distinct strengths and weaknesses, UNet++ with ResNet34 emerged as a top-performing model, demonstrating exceptional accuracy in distinguishing sperm cells from non-sperm cells. However, challenges persist in accurately identifying closely adjacent sperm cells. These findings provide valuable insights for improving automated sperm segmentation in male infertility diagnosis.DiscussionThe study underscores the significance of selecting appropriate model combinations based on specific diagnostic requirements. It also highlights the challenges related to distinguishing closely adjacent sperm cells.ConclusionThis research advances the field of automated sperm segmentation for male infertility diagnosis, showcasing the potential of deep learning techniques. Future work should aim to enhance accuracy in scenarios involving close proximity between sperm cells, ultimately improving clinical sperm analysis.",2024,10.3389/frai.2024.1376546
Are We There Yet? - A Systematic Literature Review on Chatbots in Education,"Chatbots are a promising technology with the potential to enhance workplaces and everyday life. In terms of scalability and accessibility, they also offer unique possibilities as communication and information tools for digital learning. In this paper, we present a systematic literature review investigating the areas of education where chatbots have already been applied, explore the pedagogical roles of chatbots, the use of chatbots for mentoring purposes, and their potential to personalize education. We conducted a preliminary analysis of 2,678 publications to perform this literature review, which allowed us to identify 74 relevant publications for chatbots’ application in education. Through this, we address five research questions that, together, allow us to explore the current state-of-the-art of this educational technology. We conclude our systematic review by pointing to three main research challenges: 1) Aligning chatbot evaluations with implementation objectives, 2) Exploring the potential of chatbots for mentoring students, and 3) Exploring and leveraging adaptation capabilities of chatbots. For all three challenges, we discuss opportunities for future research.",2021,10.3389/frai.2021.654924
Exploring the potential of AI-driven food waste management strategies used in the hospitality industry for application in household settings,"This study explores the potential for adapting AI-driven food waste management strategies from the hospitality industry for application in household settings. The hospitality industry, particularly hotels and restaurants, has implemented AI technologies through companies like Leanpath, Winnow, and Kitro, which use real-time data and predictive analytics to monitor, categorize, and reduce food waste. These AI-driven systems have demonstrated significant reductions in food waste, offering economic savings and environmental benefits. This study employs an instrumental case study approach, utilizing semi-structured interviews with representatives from these companies to gain insights into the technologies and strategies that have proven effective in hospitality. The findings suggest that with modifications for scale, cost, and user engagement, AI-driven solutions could enhance household food management by providing insights into consumption patterns, offering expiration reminders, and supporting sustainable practices. Highlighted are key considerations for household adaptation, including policy support, educational strategies, economic incentives, and integration with smart home systems. Ultimately, this study identifies a promising avenue for reducing household food waste through AI, underscoring the need for continued research and policy initiatives to facilitate the transition of these technologies from commercial kitchens to everyday homes.",2025,10.3389/frai.2024.1429477
Defining human-AI teaming the human-centered way: a scoping review and network analysis,"IntroductionWith the advancement of technology and the increasing utilization of AI, the nature of human work is evolving, requiring individuals to collaborate not only with other humans but also with AI technologies to accomplish complex goals. This requires a shift in perspective from technology-driven questions to a human-centered research and design agenda putting people and evolving teams in the center of attention. A socio-technical approach is needed to view AI as more than just a technological tool, but as a team member, leading to the emergence of human-AI teaming (HAIT). In this new form of work, humans and AI synergistically combine their respective capabilities to accomplish shared goals.MethodsThe aim of our work is to uncover current research streams on HAIT and derive a unified understanding of the construct through a bibliometric network analysis, a scoping review and synthetization of a definition from a socio-technical point of view. In addition, antecedents and outcomes examined in the literature are extracted to guide future research in this field.ResultsThrough network analysis, five clusters with different research focuses on HAIT were identified. These clusters revolve around (1) human and (2) task-dependent variables, (3) AI explainability, (4) AI-driven robotic systems, and (5) the effects of AI performance on human perception. Despite these diverse research focuses, the current body of literature is predominantly driven by a technology-centric and engineering perspective, with no consistent definition or terminology of HAIT emerging to date.DiscussionWe propose a unifying definition combining a human-centered and team-oriented perspective as well as summarize what is still needed in future research regarding HAIT. Thus, this work contributes to support the idea of the Frontiers Research Topic of a theoretical and conceptual basis for human work with AI systems.",2023,10.3389/frai.2023.1250725
Prediction of outpatient rehabilitation patient preferences and optimization of graded diagnosis and treatment based on XGBoost machine learning algorithm,"BackgroundThe Department of Rehabilitation Medicine is key to improving patients’ quality of life. Driven by chronic diseases and an aging population, there is a need to enhance the efficiency and resource allocation of outpatient facilities. This study aims to analyze the treatment preferences of outpatient rehabilitation patients by using data and a grading tool to establish predictive models. The goal is to improve patient visit efficiency and optimize resource allocation through these predictive models.MethodsData were collected from 38 Chinese institutions, including 4,244 patients visiting outpatient rehabilitation clinics. Data processing was conducted using Python software. The pandas library was used for data cleaning and preprocessing, involving 68 categorical and 12 continuous variables. The steps included handling missing values, data normalization, and encoding conversion. The data were divided into 80% training and 20% test sets using the Scikit-learn library to ensure model independence and prevent overfitting. Performance comparisons among XGBoost, random forest, and logistic regression were conducted using metrics, including accuracy and receiver operating characteristic (ROC) curves. The imbalanced learning library’s SMOTE technique was used to address the sample imbalance during model training. The model was optimized using a confusion matrix and feature importance analysis, and partial dependence plots (PDP) were used to analyze the key influencing factors.ResultsXGBoost achieved the highest overall accuracy of 80.21% with high precision and recall in Category 1. random forest showed a similar overall accuracy. Logistic Regression had a significantly lower accuracy, indicating difficulties with nonlinear data. The key influencing factors identified include distance to medical institutions, arrival time, length of hospital stay, and specific diseases, such as cardiovascular, pulmonary, oncological, and orthopedic conditions. The tiered diagnosis and treatment tool effectively helped doctors assess patients’ conditions and recommend suitable medical institutions based on rehabilitation grading.ConclusionThis study confirmed that ensemble learning methods, particularly XGBoost, outperform single models in classification tasks involving complex datasets. Addressing class imbalance and enhancing feature engineering can further improve model performance. Understanding patient preferences and the factors influencing medical institution selection can guide healthcare policies to optimize resource allocation, improve service quality, and enhance patient satisfaction. Tiered diagnosis and treatment tools play a crucial role in helping doctors evaluate patient conditions and make informed recommendations for appropriate medical care.",2025,10.3389/frai.2024.1473837
Opportunities and challenges of using generative AI to personalize educational assessment,"In line with the positive effects of personalized learning, personalized assessments are expected to maximize learner motivation and engagement, allowing learners to show what they truly know and can do. Considering the advances in Generative Artificial Intelligence (GenAI), in this perspective article, we elaborate on the opportunities of integrating GenAI into personalized educational assessments to maximize learner engagement, performance, and access. We also draw attention to the challenges of integrating GenAI into personalized educational assessments regarding its potential risks to the assessment’s core values of validity, reliability, and fairness. Finally, we discuss possible solutions and future directions.",2024,10.3389/frai.2024.1460651
"The current state, challenges, and future directions of artificial intelligence in healthcare in Saudi Arabia: systematic review","BackgroundThe use of artificial intelligence has been part of the healthcare technologies used in managing various aspects of healthcare processes. In Saudi Arabia, the use of artificial intelligence for managing healthcare has been influenced by the increasing use of healthcare technologies within the healthcare system. The aim of this study is to systematically review the current state, challenges, and future directions of artificial intelligence in healthcare in Saudi Arabia.MethodsThe study used a systematic review methodology, which used the critical appraisal of articles on the use of artificial intelligence in healthcare. The critical appraisal used the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) and Joanna Briggs Institute (JBI) to implement the inclusion and exclusion criteria. The initial search for articles led to 88 articles, which were screened to 13, based on the inclusion and exclusion criteria.ResultsThe current state of the use of artificial intelligence in Saudi’s healthcare system has been slowed down by the gradual uptake of healthcare technologies and the investments required. The main challenges identified included lack of policies to support artificial intelligence, lack of adequate capital for infrastructure and human resources and lack of cultures to accommodate the artificial intelligence in Saudi Arabia. With the current privatization and increased use of the artificial intelligence, the future of artificial intelligence in Saudi’s healthcare system would see an increase in their utilization. Specific findings indicate the potential of artificial intelligence in improving clinical practice through blockchain, and that investments in artificial intelligence have encompasses various applications, including radiology. Skills gaps expected among healthcare professionals and the adoption of new technology are difficulties impacting the utilization of artificial intelligence in the healthcare sector.ConclusionThe use of artificial intelligence in Saudi’s healthcare system requires the investments into infrastructure, human resource development and gradual commitments towards the healthcare technologies. The use of artificial intelligence would have benefits such as effectiveness in access to care and ability to meet the healthcare outcomes.",2025,10.3389/frai.2025.1518440
CowMesh: a data-mesh architecture to unify dairy industry data for prediction and monitoring,"Dairy is an economically significant industry that caters to the huge demand for food products in people's lives. To remain profitable, farmers need to manage their farms and the health of the dairy cows in their herds. There are, however, many risks to cow health that can lead to significant challenges to dairy farm management and have the potential to lead to significant losses. Such risks include cow udder infections (i.e., mastitis) and cow lameness. As automation and data recording become more common in the agricultural sector, dairy farms are generating increasing amounts of data. Recently, these data are being used to generate insights into farm and cow health, where the objective is to help farmers manage the health and welfare of dairy cows and reduce losses from cow health issues. Despite the level of data generation on dairy farms, this information is often difficult to access due to a lack of a single, central organization to collect data from individual farms. The prospect of such an organization, however, raises questions about data ownership, with some farmers reluctant to share their farm data for privacy reasons. In this study, we describe a newdata mesharchitecture designed for the dairy industry that focuses on facilitating access to data from farms in a decentralized fashion. This has the benefit of keeping the ownership of data with dairy farmers while bringing data together by providing a common and uniform set of protocols. Furthermore, this architecture will allow secure access to the data by research groups and product development groups, who can plug in new projects and applications built across the data. No similar framework currently exists in the dairy industry, and such a data mesh can help industry stakeholders by bringing the dairy farms of a country together in a decentralized fashion. This not only helps farmers, dairy researchers, and product builders but also facilitates an overview of all dairy farms which can help governments to decide on regulations to improve the dairy industry at a national level.",2023,10.3389/frai.2023.1209507
"Morphology in a Parallel, Distributed, Interactive Architecture of Language Production","How do speakers produce novel words? This programmatic paper synthesizes research in linguistics and neuroscience to argue for a parallel distributed architecture of the language system, in which distributed semantic representations activate competing form chunks in parallel. This process accounts for both the synchronic phenomenon of paradigm uniformity and the diachronic process of paradigm leveling; i.e., the shaping or reshaping of relatively infrequent forms by semantically-related forms of higher frequency. However, it also raises the question of how leveling is avoided. A negative feedback cycle is argued to be responsible. The negative feedback cycle suppresses activated form chunks with unintended semantics or connotations and allows the speaker to decide when to begin speaking. The negative feedback cycle explains away much of the evidence for paradigmatic mappings, allowing more of the grammar to be described with only direct form-meaning mappings/constructions. However, there remains an important residue of cases for which paradigmatic mappings are necessary. I show that these cases can be accounted for by spreading activation down paradigmatic associations as the source of the activation is being inhibited by negative feedback. The negative feedback cycle provides a mechanistic explanation for several phenomena in language change that have so far eluded usage-based accounts. In particular, it provides a mechanism for degrammaticalization and affix liberation (e.g., the detachment of-holicfrom the context(s) in which it occurs), explaining how chunks can gain productivity despite occurring in a single fixed context. It also provides a novel perspective on paradigm gaps. Directions for future work are outlined.",2022,10.3389/frai.2022.803259
The ReIMAGINE Multimodal Warehouse: Using Artificial Intelligence for Accurate Risk Stratification of Prostate Cancer,"Introduction. Prostate cancer (PCa) is the most frequent cancer diagnosis in men worldwide. Our ability to identify those men whose cancer will decrease their lifespan and/or quality of life remains poor. The ReIMAGINE Consortium has been established to improve PCa diagnosis.Materials and methods. MRI will likely become the future cornerstone of the risk-stratification process for men at risk of early prostate cancer. We will, for the first time, be able to combine the underlying molecular changes in PCa with the state-of-the-art imaging. ReIMAGINE Screening invites men for MRI and PSA evaluation. ReIMAGINE Risk includes men at risk of prostate cancer based on MRI, and includes biomarker testing.Results. Baseline clinical information, genomics, blood, urine, fresh prostate tissue samples, digital pathology and radiomics data will be analysed. Data will be de-identified, stored with correlated mpMRI disease endotypes and linked with long term follow-up outcomes in an instance of the Philips Clinical Data Lake, consisting of cloud-based software. The ReIMAGINE platform includes application programming interfaces and a user interface that allows users to browse data, select cohorts, manage users and access rights, query data, and more. Connection to analytics tools such as Python allows statistical and stratification method pipelines to run profiling regression analyses. Discussion. The ReIMAGINE Multimodal Warehouse comprises a unique data source for PCa research, to improve risk stratification for PCa and inform clinical practice. The de-identified dataset characterized by clinical, imaging, genomics and digital pathology PCa patient phenotypes will be a valuable resource for the scientific and medical community.",2021,10.3389/frai.2021.769582
Rejected by an AI? Comparing job applicants’ fairness perceptions of artificial intelligence and humans in personnel selection,"Introduction
                    Artificial intelligence (AI) transforms personnel selection, but the application of AI raises fairness concerns and aversion towards AI. Although job applicants may perceive the selection process as fairer when they receive an explanation for the decision, scientific knowledge about AI-related fairness perceptions in this setting is limited. This paper investigates how job applicants perceive fairness of an AI-based personnel selection process considering explanations provided.
                  
                  
                    Methods
                    
                      The hypotheses are based on a theoretical framework about fairness and literature on algorithm aversion. Data were collected through a vignette-style method focusing on four personnel selection scenarios (
                      n
                      = 921).
                    
                  
                  
                    Results
                    We show that provided explanations increase job applicants’ perceptions of outcome fairness, process fairness, interpersonal treatment, and recommendation intention, irrespective of the decision being made by an AI or human.
                  
                  
                    Discussion
                    We provide conclusions for algorithmic decision-making and discuss factors that need to be considered when adopting and designing AI so that AI is perceived as fair.",2025,10.3389/frai.2025.1671997
Crowdsourcing lexical diversity,"Lexical-semantic resources (LSRs), such as online lexicons and wordnets, are fundamental to natural language processing applications as well as to fields such as linguistic anthropology and language preservation. In many languages, however, such resources suffer from quality issues: incorrect entries, incompleteness, but also the rarely addressed issue of bias toward the English language and Anglo-Saxon culture. Such bias manifests itself in the absence of concepts specific to the language or culture at hand, the presence of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit indication of untranslatability, also known as cross-lingual
                    lexical gaps
                    , when a term has no equivalent in another language. This paper proposes a novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers compare lexemes from two languages, focusing on domains rich in lexical diversity, such as kinship or food. Our LingoGap crowdsourcing platform facilitates comparisons through microtasks identifying equivalent terms, language-specific terms, and lexical gaps across languages. We validated our method by applying it to two case studies focused on food-related terminology: (1) English and Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified 2,140 lexical gaps in the first case study and 951 in the second. The success of these experiments confirmed the usability of our method and tool for future large-scale lexicon enrichment tasks.",2025,10.3389/frai.2025.1648073
ALL classification using neural ensemble and memetic deep feature optimization,"Acute lymphoblastic leukemia (ALL) is a fatal blood disorder characterized by the excessive proliferation of immature white blood cells, originating in the bone marrow. An effective prognosis and treatment of ALL calls for its accurate and timely detection. Deep convolutional neural networks (CNNs) have shown promising results in digital pathology. However, they face challenges in classifying different subtypes of leukemia due to their subtle morphological differences. This study proposes an improved pipeline for binary detection and sub-type classification of ALL from blood smear images. At first, a customized, 88 layers deep CNN is proposed and trained using transfer learning along with GoogleNet CNN to create an ensemble of features. Furthermore, this study models the feature selection problem as a combinatorial optimization problem and proposes a memetic version of binary whale optimization algorithm, incorporating Differential Evolution-based local search method to enhance the exploration and exploitation of feature search space. The proposed approach is validated using publicly available standard datasets containing peripheral blood smear images of various classes of ALL. An overall best average accuracy of 99.15% is achieved for binary classification of ALL with an 85% decrease in the feature vector, together with 99% precision and 98.8% sensitivity. For B-ALL sub-type classification, the best accuracy of 98.69% is attained with 98.7% precision and 99.57% specificity. The proposed methodology shows better performance metrics as compared with several existing studies.",2024,10.3389/frai.2024.1351942
Forecasting Stock Price Trends by Analyzing Economic Reports With Analyst Profiles,"This article proposes a methodology to forecast the movements of analysts' estimated net income and stock prices using analyst profiles. Our methodology is based on applying natural language processing and neural networks in the context of analyst reports. First, we apply the proposed method to extract opinion sentences from the analyst report while classifying the remaining parts as non-opinion sentences. Then, we employ the proposed method to forecast the movements of analysts' estimated net income and stock price by inputting the opinion and non-opinion sentences into separate neural networks. In addition to analyst reports, we input analyst profiles to the networks. As analyst profiles, we used the name of an analyst, the securities company to which the analyst belongs, the sector which the analyst covers, and the analyst ranking. Consequently, we obtain an indication that the analyst profile effectively improves the model forecasts. However, classifying analyst reports into opinion and non-opinion sentences is insignificant for the forecasts.",2022,10.3389/frai.2022.866723
Development and evaluation of a java-based deep neural network method for drug response predictions,"Accurate prediction of drug response is a crucial step in personalized medicine. Recently, deep learning techniques have been witnessed with significant breakthroughs in a variety of areas including biomedical research and chemogenomic applications. This motivated us to develop a novel deep learning platform to accurately and reliably predict the response of cancer cells to different drug treatments. In the present work, we describe a Java-based implementation of deep neural network method, termed JavaDL, to predict cancer responses to drugs solely based on their chemical features. To this end, we devised a novel cost function and added a regularization term which suppresses overfitting. We also adopted an early stopping strategy to further reduce overfit and improve the accuracy and robustness of our models. To evaluate our method, we compared with several popular machine learning and deep neural network programs and observed that JavaDL either outperformed those methods in model building or obtained comparable predictions. Finally, JavaDL was employed to predict drug responses of several aggressive breast cancer cell lines, and the results showed robust and accurate predictions with r2 as high as 0.81.",2023,10.3389/frai.2023.1069353
Statistical inference for dependence networks in topological data analysis,"Topological data analysis (TDA) provide tools that are becoming increasingly popular for analyzing multivariate time series data. One key aspect in analyzing multivariate time series is dependence between components. One application is on brain signal analysis. In particular, various dependence patterns in brain networks may be linked to specific tasks and cognitive processes. These dependence patterns may be altered by various neurological and cognitive impairments such as Alzheimer's and Parkinson's diseases, as well as attention deficit hyperactivity disorder (ADHD). Because there is no ground-truth with known dependence patterns in real brain signals, testing new TDA methods on multivariate time series is still a challenge. Our goal here is to develop novel statistical inference procedures via simulations. Simulations are useful for generating some null distributions of a test statistic (for hypothesis testing), forming confidence regions, and for evaluating the performance of proposed TDA methods. To the best of our knowledge, there are no methods that simulate multivariate time series data with potentially complex user-specified connectivity patterns. In this paper we present a novel approach to simulate multivariate time series with specific number of cycles/holes in its dependence network. Furthermore, we also provide a procedure for generating higher dimensional topological features.",2023,10.3389/frai.2023.1293504
Digital Articulation: Examining Text-Based Linguistic Performances in Mobile Communication Through Keystroke-Logging Analysis,"This study examines how text-based mobile communication practices are performatively constructed as individuals compose messages key-by-key on virtual keyboards, and how thesesynchronous performances(Mobile interface theory: embodied space and locative media. New York, NY: Routledge) reflect the iterative process of constructing and maintaining interpersonal relationships. In doing so, this study reports on keystroke-logging analysis (see Writ. Commun. 30, 358–392) in order to observe how participants (N =10) composed text as part of everyday mobile communication for the period of one week, subsequently producing 179,996 individual keystroke log-file records. Participants used LogKey, a virtual keyboard application made exclusively for this study to run on the Android mobile operating system. Analysis of keystroke log-file data suggest that timing processes of composing text-messages may differ as participants messaged with different categories of interlocutors, composed on different communication applications, and composed paralinguistic features—such as variants ofLolandHahaThurlow and Brown, (Discourse Anal. Online, 2003, 1, 1); Tagg, (Discourse of text messaging. 2012, Bloomsbury, UK)—at different turn-taking positions. This evidence suggests that keystroke-logging methods may contribute to understanding of how individuals manage interpersonal relationships in real-time (Please reply! the replying norm in adolescent SMS communication,” in The inside text: social, cultural and design perspectives on SMS. (Norwell, MA: Springer), 53–73); (Beyond genre: closings and relational work in texting,” in Digital discourse: language in the new media. (Oxford: Oxford University Press), 67–85), and suggests future direction for methodologically studying linguistic performances as part of text-based mobile communication.",2021,10.3389/frai.2020.539920
Analysis and correcting pronunciation disorders based on artificial intelligence approach,"The main aim of this study is to employ artificial intelligence and machine learning methods to assess and correct pronunciation disorders in post-traumatic military patients, acknowledging the critical need for effective communication rehabilitation in individuals who have experienced trauma, such as head injuries or war-related incidents. Tasks include reviewing existing research, selecting appropriate machine learning methods, generating relevant training data, and implementing a software architecture tailored to analyze and correct pronunciation defects in this specific population. The analysis of machine learning methods led to the selection of two experimental models: a Convolutional Neural Network (CNN) utilizing mel-spectrograms for image-based sound representation and a Long Short-Term Memory (LSTM) network combined with mel-frequency cepstral coefficients, aiming to explore the effectiveness of sequential data processing in the context of pronunciation disorder classification in post-traumatic military patients. The results of the two models were compared based on the loss and accuracy functions of the training and validation data, error matrices, and such key metrics as precision, recall, and F1-score. Both models showed promising results in classifying dysarthria stages, but the CNN model performed slightly better in predicting all classes than the LSTM.",2025,10.3389/frai.2025.1388180
Outliers and anomalies in training and testing datasets for AI-powered morphometry—evidence from CT scans of the spleen,"IntroductionCreating training and testing datasets for machine learning algorithms to measure linear dimensions of organs is a tedious task. There are no universally accepted methods for evaluating outliers or anomalies in such datasets. This can cause errors in machine learning and compromise the quality of end products. The goal of this study is to identify optimal methods for detecting organ anomalies and outliers in medical datasets designed to train and test neural networks in morphometrics.MethodsA dataset was created containing linear measurements of the spleen obtained from CT scans. Labelling was performed by three radiologists. The total number of studies included in the sample was N = 197 patients. Using visual methods (1.5 interquartile range; heat map; boxplot; histogram; scatter plot), machine learning algorithms (Isolation forest; Density-Based Spatial Clustering of Applications with Noise; K-nearest neighbors algorithm; Local outlier factor; One-class support vector machines; EllipticEnvelope; Autoencoders), and mathematical statistics (z-score, Grubb’s test; Rosner’s test).ResultsWe identified measurement errors, input errors, abnormal size values and non-standard shapes of the organ (sickle-shaped, round, triangular, additional lobules). The most effective methods included visual techniques (including boxplots and histograms) and machine learning algorithms such is OSVM, KNN and autoencoders. A total of 32 outlier anomalies were found.DiscussionCuration of complex morphometric datasets must involve thorough mathematical and clinical analyses. Relying solely on mathematical statistics or machine learning methods appears inadequate.",2025,10.3389/frai.2025.1607348
StaBle-MambaNet: structure-aware and blur-guided lane detection with Mamba,"The perception system constitutes a critical component of autonomous driving, due to factors such as high-speed motion and complex illumination, camera-captured images often exhibit local blurring, leading to the degradation of lane structure clarity and even temporary disappearance of lane markings, which severely compromises the accuracy and robustness of lane detection. Traditional approaches typically adopt a two-stage strategy of “image enhancement followed by structural recognition” Initially, the entire image undergoes deblurring or super-resolution reconstruction, followed by lane detection. However, such methods rely on the quality of full-image restoration, exhibit low processing efficiency, and struggle to determine whether the disappearance of lane markings is genuinely caused by image blurring. To address these challenges, this paper proposes an Inter-frame Stability-Aware Blur-enhanced Mamba Network (StaBle-MambaNet), which identifies blurred regions and assesses the presence of potential lane structures without relying on full-image restoration. The method first localizes blurred areas and employs a Structure-Aware Restoration Module to perform directional extrapolation and completion for potential lane line regions. Subsequently, the Blur-Guided Consistency Reasoning Module evaluates structural stability to identify genuine lane regions. Finally, enhanced features are constructed into a spatially continuous token sequence, which is fed into a lightweight state-space model, Mamba, to model the dynamic feature variations in blurred regions while preserving the vertical structural evolution of the image. Experimental results demonstrate that StaBle-MambaNet significantly outperforms existing mainstream methods across multiple public lane datasets (e.g., CULane and CurveLanes), particularly under challenging conditions such as nighttime, occlusion, and curved lanes, exhibiting clear advantages in both detection accuracy and structural stability.",2025,10.3389/frai.2025.1687983
Yes we care!-Certification for machine learning methods through the care label framework,"Machine learning applications have become ubiquitous. Their applications range from embedded control in production machines over process optimization in diverse areas (e.g., traffic, finance, sciences) to direct user interactions like advertising and recommendations. This has led to an increased effort of making machine learning trustworthy. Explainable and fair AI have already matured. They address the knowledgeable user and the application engineer. However, there are users that want to deploy a learned model in a similar way as their washing machine. These stakeholders do not want to spend time in understanding the model, but want to rely on guaranteed properties. What are the relevant properties? How can they be expressed to the stake- holder without presupposing machine learning knowledge? How can they be guaranteed for a certain implementation of a machine learning model? These questions move far beyond the current state of the art and we want to address them here. We propose a unified framework that certifies learning methodsviacare labels. They are easy to understand and draw inspiration from well-known certificates like textile labels or property cards of electronic devices. Our framework considers both, the machine learning theory and a given implementation. We test the implementation's compliance with theoretical properties and bounds.",2022,10.3389/frai.2022.975029
Exploring artificial intelligence techniques to research low energy nuclear reactions,"The world urgently needs new sources of clean energy due to a growing global population, rising energy use, and the effects of climate change. Nuclear energy is one of the most promising solutions for meeting the world’s energy needs now and in the future. One type of nuclear energy, Low Energy Nuclear Reactions (LENR), has gained interest as a potential clean energy source. Recent AI advancements create new ways to help research LENR and to comprehensively analyze the relationships between experimental parameters, materials, and outcomes across diverse LENR research endeavors worldwide. This study explores and investigates the effectiveness of modern AI capabilities leveraging embedding models and topic modeling techniques, including Latent Dirichlet Allocation (LDA), BERTopic, and Top2Vec, in elucidating the underlying structure and prevalent themes within a large LENR research corpus. These methodologies offer unique perspectives on understanding relationships and trends within the LENR research landscape, thereby facilitating advancements in this crucial energy research area. Furthermore, the study presents LENRsim, an experimental machine learning tool to identify similar LENR studies, along with a user-friendly web interface for widespread adoption and utilization. The findings contribute to the understanding and progression of LENR research through data-driven analysis and tool development, enabling more informed decision-making and strategic planning for future research in this field. The insights derived from this study, along with the experimental tools we developed and deployed, hold the potential to significantly aid researchers in advancing their studies of LENR.",2024,10.3389/frai.2024.1401782
A Chinese question and answer system for liver cancer based on knowledge graph and large language mode,"IntroductionThe liver cancer question-and-answer (Q&amp;A) system is primarily intended to help patients access disease-related information more conveniently. However, there is currently no Q&amp;A system specifically developed for liver cancer. Additionally, most existing Q&amp;A systems lack real clinical data and have limited capability in understanding Chinese questions.MethodsThis paper proposes a Chinese liver cancer question-answering system based on knowledge graphs and Large Language Models (LLMs). To unify information from diverse sources, the system employs a knowledge graph to store entities and inter-entity relationships extracted from patients' clinical electronic medical records and the professional medical website xywy.com, which serves as the foundation for the system's responses. Specifically, ChatGLM3.5 is utilized to extract entity information from questions, while BERT is applied to understand users' intent. Subsequently, the system retrieves corresponding information from the knowledge graph. Finally, the retrieved information is integrated, and a natural language response is generated as the answer to the question.ResultsThe experimental results indicate that in terms of intent classification, our system achieves a precision of 92.34%, representing an improvement of 1.38% over the BERT model and 4.32% over the GEBERT model. In terms of response relevance, the system's outputs are more aligned with patients' daily speech patterns and exhibit higher relevance to the target questions.DiscussionIn conclusion, the improved method significantly enhances the usefulness and reliability of the liver cancer Q&amp;A system.",2025,10.3389/frai.2025.1663891
Artificial Intelligence for Prognostic Scores in Oncology: a Benchmarking Study,"Introduction: Prognostic scores are important tools in oncology to facilitate clinical decision-making based on patient characteristics. To date, classic survival analysis using Cox proportional hazards regression has been employed in the development of these prognostic scores. With the advance of analytical models, this study aimed to determine if more complex machine-learning algorithms could outperform classical survival analysis methods.Methods: In this benchmarking study, two datasets were used to develop and compare different prognostic models for overall survival in pan-cancer populations: a nationwide EHR-derived de-identified database for training and in-sample testing and the OAK (phase III clinical trial) dataset for out-of-sample testing. A real-world database comprised 136K first-line treated cancer patients across multiple cancer types and was split into a 90% training and 10% testing dataset, respectively. The OAK dataset comprised 1,187 patients diagnosed with non-small cell lung cancer. To assess the effect of the covariate number on prognostic performance, we formed three feature sets with 27, 44 and 88 covariates. In terms of methods, we benchmarked ROPRO, a prognostic score based on the Cox model, against eight complex machine-learning models: regularized Cox, Random Survival Forests (RSF), Gradient Boosting (GB), DeepSurv (DS), Autoencoder (AE) and Super Learner (SL). The C-index was used as the performance metric to compare different models.Results: For in-sample testing on the real-world database the resulting C-index [95% CI] values for RSF 0.720 [0.716, 0.725], GB 0.722 [0.718, 0.727], DS 0.721 [0.717, 0.726] and lastly, SL 0.723 [0.718, 0.728] showed significantly better performance as compared to ROPRO 0.701 [0.696, 0.706]. Similar results were derived across all feature sets. However, for the out-of-sample validation on OAK, the stronger performance of the more complex models was not apparent anymore. Consistently, the increase in the number of prognostic covariates did not lead to an increase in model performance.Discussion: The stronger performance of the more complex models did not generalize when applied to an out-of-sample dataset. We hypothesize that future research may benefit by adding multimodal data to exploit advantages of more complex models.",2021,10.3389/frai.2021.625573
Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security,"IntroductionAs the number of Internet of Things (IoT) devices grows quickly, cyber threats are becoming more complex and increasingly sophisticated; thus, we need a more robust network security solutions. Traditional deep learning approaches often suffer in identifying effectively anomalies in IoT network. To tackle this evolving challenge, this research proposes a hybrid architecture of Neural Network (NN) models that combine Recurrent-NN (RNN) and Spiking-NN (SNN), referred to as HRSNN, to improve IoT the security.MethodsThe proposed HRSNN technique has five steps: preprocessing data, extracting features, equalization classes, features optimization and classification. Data processing step makes sure that input data is accurate and consistent and by employing normalization and the removal of outliers’ techniques. Feature extraction makes use of the RNN part to automatically detect abnormal patterns and high-level features, which are then turned into spike trains for the SNN to process over time. In class equalization step, the Synthetic Minority-Oversampling Technique (SMOTE) is being used resulting in balanced classes. Recursive Feature Elimination (RFE) is used to keep the important features for feature optimization. Then, the dataset is split into sets for testing and training so that the model can be tested properly.ResultsThe hybrid model integrates the spatial feature learning skills of RNNs with the temporal adaptability of SNNs, results in an improved accuracy and resilience in identifying IoT network abnormalities. The proposed HRSNN approach, which was tested on the CIC-IoT23 and TON_IoT data sets, achieved better performance compared to current deep learning (DL) models. In particular, experimental assessments show that the model attained an accuracy rate of 99.5% on the “CICIoT2023” dataset and 98.75% on the “TON_IoT” dataset.DiscussionThese results confirm demonstrate that the proposed architecture of RNN and SSN can achieve significant advancement to IoT security. By combining both spatial and temporal feature learning, HRSNN can improve accuracy detection against diverse security threats. The model is reliable, accurate, and adaptable for safeguarding IoT networks against diverse security threats. Thus, the model addresses the potential solutions in the challenging problem of secured IoT networks.",2025,10.3389/frai.2025.1651516
Quantifying training response in cycling based on cardiovascular drift using machine learning,"PurposeThe most important parameter influencing performance in endurance sports is aerobic fitness, the quality of the cardiovascular system for efficient oxygen supply of working muscles to produce mechanical work. Each individual athlete responds differently to training. However, for coaches it is not always easy to see improvement, accumulated fatigue, or overreaching. In the new era of technology, we propose an experimental method using machine learning (ML) to measure response quantified as aerobic fitness level based on cardiovascular drift and aerobic decoupling data.MethodsTwenty well-trained athletes in cycling-based sports performed monthly aerobic fitness tests over five months, riding at 75% of their functional threshold power for 60 min. Based on aerobic decoupling (power-to-heart rate ratio) and cardiovascular drift of each test ride, a prediction model was created using ML (Logistic regression, Variational Gaussian Process models and k-nearest neighbors algorithm) that indicated whether or not an athlete was responding to the training. Athletes were spitted as responders (i.e., those showing improvements in cardiovascular drift and aerobic decoupling) or non-responders.ResultsCardiovascular drift and aerobic decoupling demonstrated a significant strong linear correlation. All ML models achieved good predictive performance in classifying athletes as responders or non-responders, with cross-validation accuracy ranging from 0.87 to 0.9. Average predictive accuracy of 0.86 was for k-nearest neighbors, 0.91 for logistic regression, 0.93 for Variational Gaussian Process model. The Variational Gaussian Process model achieved the highest classification for training response.ConclusionCardiovascular drift and aerobic decoupling are reliable indicators of response to training stimulus. ML is a promising tool for monitoring training response in endurance sports, offering early and sensitive insights into fitness adaptations or fatigue that can support more personalized training decisions for coaches and athletes.",2025,10.3389/frai.2025.1623384
The Role of Self-Improving Tutoring Systems in Fostering Pre-Service Teacher Self-Regulated Learning,"Computer-based learning environments serve as a valuable asset to help strengthen teacher preparation and preservice teacher self-regulated learning. One of the most important advantages is the opportunity to collect ambient data unobtrusively as observable indicators of cognitive, affective, metacognitive, and motivational processes that mediate learning and performance. Ambient data refers to teacher interactions with the user interface that include but are not limited to timestamped clickstream data, keystroke and navigation events, as well as document views. We review the claim that computers designed as metacognitive tools can leverage the data to serve not only teachers in attaining the aims of instruction, but also researchers in gaining insights into teacher professional development. In our presentation of this claim, we review the current state of research and development of a network-based tutoring system called nBrowser, designed to support teacher instructional planning and technology integration. Network-based tutors are self-improving systems that continually adjust instructional decision-making based on the collective behaviors of communities of learners. A large part of the artificial intelligence resides in semantic web mining, natural language processing, and network algorithms. We discuss the implications of our findings to advance research into preservice teacher self-regulated learning.",2022,10.3389/frai.2021.769455
AI for Anglophone Africa: Unlocking its adoption for responsible solutions in academia-private sector,"In recent years, AI technologies have become indispensable in social and industrial development, yielding revolutionary results in improving labor efficiency, lowering labor costs, optimizing human resource structure, and creating new job demands. To reap the full benefits of responsible AI solutions in Africa, it is critical to investigate existing challenges and propose strategies, policies, and frameworks for overcoming and eliminating them. As a result, this study investigated the challenges of adopting responsible AI solutions in the Academia-Private sectors for Anglophone Africa through literature reviews, expert interviews, and then proposes solutions and framework for the sustainable and successful adoption of responsible AI.",2023,10.3389/frai.2023.1133677
Enhanced vehicle routing for medical waste management via hybrid deep reinforcement learning and optimization algorithms,"Modern technologies, particularly artificial intelligence, play a crucial role in improving medical waste management by developing intelligent systems that optimize the shortest routes for waste transport, from its generation to final disposal. Algorithms such as Q-learning and Deep Q Network enhance the efficiency of transport and disposal while reducing environmental pollution risks. In this study, artificial intelligence algorithms were trained using Homogeneous agent systems with a capacity of 3 tons to optimize routes between hospitals within the Closed Capacitated Vehicle Routing Problem framework. Integrating AI with pathfinding techniques, especially the hybrid A*-Deep Q Network approach, led to advanced results despite initial challenges. K-means clustering was used to divide hospitals into zones, allowing agents to navigate the shortest paths using the Deep Q Network. Analysis revealed that the agents’ capacity was not fully utilized. This led to the application of Fractional Knapsack dynamic programming with Deep Q Network to maximize capacity utilization while achieving optimal routes. Since the criteria used to compare the algorithms’ effectiveness are the number of vehicles and the utilization of the total vehicle capacity, it was found that the Fractional Knapsack with DQN stands out by requiring the fewest number of vehicles (4), achieving 0% loss in this metric as it matches the optimal value. Compared to other algorithms that require 5 or 7 vehicles, it reduces the fleet size by 20 and 42.86%, respectively. Additionally, it maximizes vehicle capacity utilization at 100%, unlike other methods, which utilize only 33 to 66% of vehicle capacity. However, this improvement comes at the cost of a 9% increase in distance, reflecting the longer routes needed to serve more hospitals per trip. Despite this trade-off, the algorithm’s ability to minimize fleet size while fully utilizing vehicle capacity makes it the optimal choice in scenarios where these factors are critical. This approach not only improved performance but also enhanced environmental sustainability, making it the most effective and challenging solution among all the algorithms used in the study.",2025,10.3389/frai.2025.1496653
Text-Graph Enhanced Knowledge Graph Representation Learning,"Knowledge Graphs (KGs) such as Freebase and YAGO have been widely adopted in a variety of NLP tasks. Representation learning of Knowledge Graphs (KGs) aims to map entities and relationships into a continuous low-dimensional vector space. Conventional KG embedding methods (such as TransE and ConvE) utilize only KG triplets and thus suffer from structure sparsity. Some recent works address this issue by incorporating auxiliary texts of entities, typically entity descriptions. However, these methods usually focus only on local consecutive word sequences, but seldom explicitly use global word co-occurrence information in a corpus. In this paper, we propose to model the whole auxiliary text corpus with a graph and present an end-to-end text-graph enhanced KG embedding model, named Teger. Specifically, we model the auxiliary texts with a heterogeneous entity-word graph (called text-graph), which entails both local and global semantic relationships among entities and words. We then apply graph convolutional networks to learn informative entity embeddings that aggregate high-order neighborhood information. These embeddings are further integrated with the KG triplet embeddings via a gating mechanism, thus enriching the KG representations and alleviating the inherent structure sparsity. Experiments on benchmark datasets show that our method significantly outperforms several state-of-the-art methods.",2021,10.3389/frai.2021.697856
That’s Cool. Computational Sociolinguistic Methods for Investigating Individual Lexico-grammatical Variation,"The present study deals with variation in the use of lexico-grammatical patterns and emphasizes the need to embrace individual variation. Targeting the patternthat’s adj(as inthat’s right,that’s niceorthat’s okay) as a case study, we use a tailor-made Python script to systematically retrieve grammatical and semantic information about all instances of this construction in BNC2014 as well as sociolinguistic information enabling us to study social and individual lexico-grammatical variation among speakers who have used this pattern. The dataset amounts to 4,394 tokens produced by 445 speakers using 159 adjective types in 931 conversations. Using detailed descriptive statistics and mixed-effects regression models, we show that while the choice of some adjectives is partly determined by social variables, situational and especially individual variation is rampant overall. Adopting a cognitive-linguistic perspective and relying on the notion of entrenchment, we interpret these findings as reflecting individual speakers' routines. We argue that computational sociolinguistics is in an ideal position to contribute to the data-driven investigation of individual lexico-grammatical variation and encourage computational sociolinguists to grab this opportunity. For the routines of individual speakers ultimately both underlie and compromise systematic social variation and trigger and steer well-known types of language change including grammaticalization, pragmaticalization and change by invited inference.",2021,10.3389/frai.2020.547531
Classification prediction of load losses in power stations using machine learning multilayer stack ensemble,"Load losses negatively impact the reliability of power stations, leading to plant failures. To support the decision-making of improving plant reliability, we experimented with six machine learning classifiers to find the model combination that produces the best prediction performance, called the Explainable Multilayer Stack Ensemble. We applied a five-year dataset from six power stations. Since the dataset is highly imbalanced with the positive class dominant, class weights are calculated and assigned to reduce bias toward the majority class. The best parameters are determined through a randomized search with cross-validation and applied to train the models. The Explainable Multilayer Stack Ensemble performed better than the individual models, with a further improvement by excluding the Gaussian Naïve Bayes in the second layer since it produced high false negatives. We demonstrate that when handling a highly imbalanced dataset, balanced accuracy, Receiver Operating Characteristics, and Precision-Recall Area Under the Curve provide a more reliable evaluation of model performance than focusing solely on standard evaluation metrics, such as accuracy, precision, and recall. Moreover, by excluding a poor-performing classifier from ensemble, we optimized the prediction process, and further enhanced overall performance.",2025,10.3389/frai.2025.1592492
Diversity in people's reluctance to use medical artificial intelligence: Identifying subgroups through latent profile analysis,"Medical artificial intelligence (AI) is important for future health care systems. Research on medical AI has examined people's reluctance to use medical AI from the knowledge, attitude, and behavioral levels in isolation using a variable-centered approach while overlooking the possibility that there are subpopulations of people who may differ in their combined level of knowledge, attitude and behavior. To address this gap in the literature, we adopt a person-centered approach employing latent profile analysis to consider people's medical AI objective knowledge, subjective knowledge, negative attitudes and behavioral intentions. Across two studies, we identified three distinct medical AI profiles that systemically varied according to people's trust in and perceived risk imposed by medical AI. Our results revealed new insights into the nature of people's reluctance to use medical AI and how individuals with different profiles may characteristically have distinct knowledge, attitudes and behaviors regarding medical AI.",2022,10.3389/frai.2022.1006173
Business analytics approach to artificial intelligence,"Artificial Intelligence has become an essential element for strengthening the business fabric. The advances obtained in recent years as a result of the incorporation of technology for the improvement of productive activities and the positioning of companies in the markets are remarkable. Hence, the purpose of this paper is to analyze the origin, evolution and development of business analytics (BA) and its relationship with Artificial Intelligence (AI); from the conceptualization, evolution and identification of the main characteristics and research areas of AI and BA, as well as research conducted and published in journals indexed in Scopus between 2002 and 2022. The aim is to define the incidence of BA in business activities and analyze scientific activity and advances of BA to define new research horizons in this field. For this purpose, a bibliometric and documentary analysis is applied, allowing to highlight the findings that provide recognition and comparison of the results. This will facilitate the understanding of the current dynamics, its importance for organizations, and its impact in the face of the new challenges generated by the requirements of world trade.",2022,10.3389/frai.2022.974180
Enhancing educational Q&amp;A systems using a Chaotic Fuzzy Logic-Augmented large language model,"IntroductionOnline question-and-answer (Q&amp;A) platforms are frequently replete with extensive human resource support. This study proposes a novel methodology of a customized large language model (LLM) called Chaotic LLM-based Educational Q&amp;A System (CHAQS) to navigate the complexities associated with intelligent Q&amp;A systems for the educational sector.MethodsIt uses an expansive dataset comprising over 383,000 educational data pairs, an intricate fine-tuning process encompassing p-tuning v2, low-rank adaptation (LRA), and strategies for parameter freezing at an open-source large language model ChatGLM as a baseline model. In addition, Fuzzy Logic is implemented to regulate parameters and the system's adaptability with the Lee Oscillator to refine the model's response variability and precision.ResultsExperiment results showed a 5.12% improvement in precision score, an 11% increase in recall metric, and an 8% improvement in the F1 score as compared to other models.DiscussionThese results suggest that the CHAQS methodology significantly enhances the performance of educational Q&amp;A systems, demonstrating the effectiveness of combining advanced tuning techniques and fuzzy logic for improved model precision and adaptability.",2024,10.3389/frai.2024.1404940
Augmenting Semantic Lexicons Using Word Embeddings and Transfer Learning,"Sentiment-aware intelligent systems are essential to a wide array of applications. These systems are driven by language models which broadly fall into two paradigms: Lexicon-based and contextual. Although recent contextual models are increasingly dominant, we still see demand for lexicon-based models because of their interpretability and ease of use. For example, lexicon-based models allow researchers to readily determine which words and phrases contribute most to a change in measured sentiment. A challenge for any lexicon-based approach is that the lexicon needs to be routinely expanded with new words and expressions. Here, we propose two models for automatic lexicon expansion. Our first model establishes a baseline employing a simple and shallow neural network initialized with pre-trained word embeddings using a non-contextual approach. Our second model improves upon our baseline, featuring a deep Transformer-based network that brings to bear word definitions to estimate their lexical polarity. Our evaluation shows that both models are able to score new words with a similar accuracy to reviewers from Amazon Mechanical Turk, but at a fraction of the cost.",2022,10.3389/frai.2021.783778
"Authority and solidarity on the Estonian COVID-19 signs: In line with the government's guidelines, we ask you to wear a mask","This article presents the results of a quantitative analysis of 900 Estonian COVID-19 door signs, which were studied to investigate the linguistic means of establishing and maintaining contact between the sign's author (institution) and the addressee (client). Malinowski's notion of “phatic communion” and Laver's notions of “self-oriented” and “other-oriented” utterances as means for expressing status relations—authority and solidarity—between the participants of the communication act were used to establish four types of grammatical person usage on the COVID-19 signs: (1) “neither 1st nor 2nd person”; (2) “1st person only”; (3) “2nd person only”, and (4) “both 1st and 2nd person”. Grammatical person of personal pronouns and verb forms were included. The presence and absence of two other means for expressing authority—the imperative mood and lexical expressions of authority—were analyzed within these four types of grammatical person usage. The most important difference emerged between the signs belonging to the types “2nd person only” (i.e., signs with only other-oriented 2nd person, without 1st person) and “both 1st and 2nd person” (i.e., signs with both self-oriented 1st person and other-oriented 2nd person). On the signs belonging to the type “2nd person only” that, relying on Laver, express the higher status of the sender of the message in relation to the receiver of the message, the authors of the signs use significantly more imperative mood and less refer to an authority outside the communication act, thus putting themselves in the role of authority. However, on the signs belonging to the type “both 1st and 2nd person” that, relying on Laver, express the solidarity of the sender of the message with the addressee, the authors of the signs seem less inclined to assume the role of authority (using less imperative mood) and rather call the reader of the sign to submit to some higher authority (using lexical expressions of authority, e.g., Vabariigi Valitsus “Government of the Republic”, Terviseamet “Health Board”, etc.) to which the author of the sign and the addressee are both in a subordinate position and, therefore, of equal status.",2023,10.3389/frai.2022.1000188
Novel machine learning models for the prediction of acute respiratory distress syndrome after liver transplantation,"Early prediction of acute respiratory distress syndrome (ARDS) after liver transplantation (LT) facilitates timely intervention. We aimed to develop a predictor of post-LT ARDS using machine learning (ML) methods. Data from 755 patients in the internal validation set and 115 patients in the external validation set were retrospectively reviewed, covering demographics, etiology, medical history, laboratory results, and perioperative data. According to the area under the receiver operating characteristic curve (AUROC), accuracy, specificity, sensitivity, and F1-value, the prediction performance of seven ML models, including logistic regression (LR), decision tree, random forest (RF), gradient boosting decision tree (GBDT), naïve bayes (NB), light gradient boosting machine (LGBM) and extreme gradient boosting (XGB) were evaluated and compared with acute lung injury prediction scores (LIPS). 234 (30.99%) ARDS patients were diagnosed. The RF model had the best performance, with an AUROC of 0.766 (accuracy: 0.722, sensitivity: 0.617) in the internal validation set and a comparable AUROC of 0.844 (accuracy: 0.809, sensitivity: 0.750) in the external validation set. The performance of all ML models was better than LIPS (AUROC 0.692, 0.776). The predictor variables included the age of the recipient, BMI, MELD score, total bilirubin, prothrombin time, operation time, standard urine volume, total intake volume, and red blood cell infusion volume. We firstly developed a risk predictor of post-LT ARDS based on RF model to ameliorate clinical practice.",2025,10.3389/frai.2025.1548131
"Ethical theories, governance models, and strategic frameworks for responsible AI adoption and organizational success","As artificial intelligence (AI) becomes integral to organizational transformation, ethical adoption has emerged as a strategic concern. This paper reviews ethical theories, governance models, and implementation strategies that enable responsible AI integration in business contexts. It explores how ethical theories such as utilitarianism, deontology, and virtue ethics inform practical models for AI deployment. Furthermore, the paper investigates governance structures and stakeholder roles in shaping accountability and transparency, and examines frameworks that guide strategic risk assessment and decision-making. Emphasizing real-world applicability, the study offers an integrated approach that aligns ethics with performance outcomes, contributing to organizational success. This synthesis aims to support firms in embedding responsible AI principles into innovation strategies that balance compliance, trust, and value creation.",2025,10.3389/frai.2025.1619029
Using Natural Language Processing and Artificial Intelligence to Explore the Nutrition and Sustainability of Recipes and Food,"In this paper, we discuss the use of natural language processing and artificial intelligence to analyze nutritional and sustainability aspects of recipes and food. We present the state-of-the-art and some use cases, followed by a discussion of challenges. Our perspective on addressing these is that while they typically have a technical nature, they nevertheless require an interdisciplinary approach combining natural language processing and artificial intelligence with expert domain knowledge to create practical tools and comprehensive analysis for the food domain.",2021,10.3389/frai.2020.621577
Users’ Responsiveness to Persuasive Techniques in Recommender Systems,"Understanding user’s behavior and their interactions with artificial-intelligent-based systems is as important as analyzing the performance of the algorithms used in these systems. For instance, in the Recommender Systems domain, the accuracy of the recommendation algorithm was the ultimate goal for most systems designers. However, researchers and practitioners have realized that providing accurate recommendations is insufficient to enhance users’ acceptance. A recommender system needs to focus on other factors that enhance its interactions with the users. Recent researches suggest augmenting these systems with persuasive capabilities. Persuasive features lead to increasing users’ acceptance of the recommendations, which, in turn, enhances users’ experience with these systems. Nonetheless, the literature still lacks a comprehensive view of the actual effect of persuasive principles on recommender users. To fill this gap, this study diagnoses how users of different characteristics get influenced by various persuasive principles that a recommender system uses. The study considers four users’ aspects: age, gender, culture (continent), and personality traits. The paper also investigates the impact of the context (or application domain) on the influence of the persuasive principles. Two application domains (namely eCommerce and Movie recommendations) are considered. A within-subject user study was conducted. The analysis of (279) responses revealed that persuasive principles have the potential to enhance users’ experience with recommender systems. The study also shows that, among the considered factors, culture, personality traits, and the domain of recommendations have a higher impact on the influence of persuasive principles than other factors. Based on the analysis of the results, the study provides insights and guidelines for recommender systems designers. These guidelines can be used as a reference for designing recommender systems with users’ experience in mind. We suggest that considering the results presented in this paper could help to improve recommender-users interaction.",2021,10.3389/frai.2021.679459
"Machine learning-based mortality prediction in critically ill patients with hypertension: comparative analysis, fairness, and interpretability","Background
                    Hypertension is a leading global health concern, significantly contributing to cardiovascular, cerebrovascular, and renal diseases. In critically ill patients, hypertension poses increased risks of complications and mortality. Early and accurate mortality prediction in this population is essential for timely intervention and improved outcomes. Machine learning (ML) and deep learning (DL) approaches offer promising solutions by leveraging high-dimensional electronic health record (EHR) data.
                  
                  
                    Objective
                    To develop and evaluate ML and DL models for predicting in-hospital mortality in hypertensive patients using the MIMIC-IV critical care dataset, and to assess the fairness and interpretability of the models.
                  
                  
                    Methods
                    We developed four ML models—gradient boosting machine (GBM), logistic regression, support vector machine (SVM), and random forest—and two DL models—multilayer perceptron (MLP) and long short-term memory (LSTM). A comprehensive set of features, including demographics, lab values, vital signs, comorbidities, and ICU-specific variables, were extracted or engineered. Models were trained using 5-fold cross-validation and evaluated on a separate test set. Feature importance was analyzed using SHapley Additive exPlanations (SHAP) values, and fairness was assessed using demographic parity difference (DPD) and equalized odds difference (EOD), with and without the application of debiasing techniques.
                  
                  
                    Results
                    The GBM model outperformed all other models, with an AUC-ROC score of 96.3%, accuracy of 89.4%, sensitivity of 87.8%, specificity of 90.7%, and F1 score of 89.2%. Key features contributing to mortality prediction included Glasgow Coma Scale (GCS) scores, Braden Scale scores, blood urea nitrogen, age, red cell distribution width (RDW), bicarbonate, and lactate levels. Fairness analysis revealed that models trained on the top 30 most important features demonstrated lower DPD and EOD, suggesting reduced bias. Debiasing methods improved fairness in models trained with all features but had limited effects on models using the top 30 features.
                  
                  
                    Conclusion
                    ML models show strong potential for mortality prediction in critically ill hypertensive patients. Feature selection not only enhances interpretability and reduces computational complexity but may also contribute to improved model fairness. These findings support the integration of interpretable and equitable AI tools in critical care settings to assist with clinical decision-making.",2025,10.3389/frai.2025.1686378
The impact of artificial intelligence on behavioral intentions to use mobile banking in the post-COVID-19 era,"IntroductionThis quantitative research investigates the determinants of behavioral intentions to use mobile banking in the post-COVID-19 era. The study extends the Unified Theory of Acceptance and Use of Technology (UTAUT) framework by incorporating two key characteristics of AI, i.e. perceived intelligence and perceived anthropomorphism.MethodsIt uses the UTAUT as a theoretical framework, and extends it by integrating core features of AI. Data has been collected from 412 respondents in Thailand, and structural equation modeling has been employed for the data analysis.ResultsThe findings reveal significant positive effects of performance expectancy, effort expectancy, social influence, facilitating conditions, trust, perceived privacy, perceived intelligence and anthropomorphism of AI on users’ behavioral intentions to use mobile banking. Price value, habits, and perceived security do not significantly influence behavioral intentions. The results highlight the transformative potential of AI technology in the mobile banking industry as consumers’ behaviors are greatly influenced by perceived intelligence and anthropomorphism.DiscussionThe positive impact of perceived intelligence and anthropomorphism indicates that consumers value advanced, human-like interactions with AI. M-banking platforms may focus on developing AI systems that offer intuitive, intelligent, and emotionally engaging experiences. Financial institutions may invest in AI that can analyze user data to offer personalized financial advice, predict future needs, and automate routine tasks effectively.",2025,10.3389/frai.2025.1649392
Humans and cyber-physical systems as teammates? Characteristics and applicability of the human-machine-teaming concept in intelligent manufacturing,"The paper explores and comments on the theoretical concept of human-machine-teaming in intelligent manufacturing. Industrial production is an important area of work applications and should be developed toward a more anthropocentric Industry 4.0/5.0. Teaming is used a design metaphor for human-centered integration of workers and complex cyber-physical-production systems using artificial intelligence. Concrete algorithmic solutions for technical processes should be based on theoretical concepts. A combination of literature scoping review and commentary was used to identify key characteristics for teaming applicable to the work environment addressed. From the body of literature, five criteria were selected and commented on. Two characteristics seemed particularly promising to guide the development of human-centered artificial intelligence and create tangible benefits in the mid-term: complementarity and shared knowledge/goals. These criteria are outlined with two industrial examples: human-robot-collaboration in assembly and intelligent decision support in thermal spraying. The main objective of the paper is to contribute to the discourse on human-centered artificial intelligence by exploring the theoretical concept of human-machine-teaming from a human-oriented perspective. Future research should focus on the empirical implementation and evaluation of teaming characteristics from different transdisciplinary viewpoints.",2023,10.3389/frai.2023.1247755
Combining large language models with enterprise knowledge graphs: a perspective on enhanced natural language understanding,"Knowledge Graphs (KGs) have revolutionized knowledge representation, enabling a graph-structured framework where entities and their interrelations are systematically organized. Since their inception, KGs have significantly enhanced various knowledge-aware applications, including recommendation systems and question-answering systems. Sensigrafo, an enterprise KG developed by Expert.AI, exemplifies this advancement by focusing on Natural Language Understanding through a machine-oriented lexicon representation. Despite the progress, maintaining and enriching KGs remains a challenge, often requiring manual efforts. Recent developments in Large Language Models (LLMs) offer promising solutions for KG enrichment (KGE) by leveraging their ability to understand natural language. In this article, we discuss the state-of-the-art LLM-based techniques for KGE and show the challenges associated with automating and deploying these processes in an industrial setup. We then propose our perspective on overcoming problems associated with data quality and scarcity, economic viability, privacy issues, language evolution, and the need to automate the KGE process while maintaining high accuracy.",2024,10.3389/frai.2024.1460065
On Topological Analysis of fs-LIMS Data. Implications for in Situ Planetary Mass Spectrometry,"In this contribution, we present results of non-linear dimensionality reduction and classification of the fs laser ablation ionization mass spectrometry (LIMS) imaging dataset acquired from the Precambrian Gunflint chert (1.88 Ga) using a miniature time-of-flight mass spectrometer developed for in situ space applications. We discuss the data generation, processing, and analysis pipeline for the classification of the recorded fs-LIMS mass spectra. Further, we define topological biosignatures identified for Precambrian Gunflint microfossils by projecting the recorded fs-LIMS intensity space into low dimensions. Two distinct subtypes of microfossil-related spectra, a layer of organic contamination and inorganic quartz matrix were identified using the fs-LIMS data. The topological analysis applied to the fs-LIMS data allows to gain additional knowledge from large datasets, formulate hypotheses and quickly generate insights from spectral data. Our contribution illustrates the utility of applying spatially resolved mass spectrometry in combination with topology-based analytics in detecting signatures of early (primitive) life. Our results indicate that fs-LIMS, in combination with topological methods, provides a powerful analytical framework and could be applied to the study of other complex mineralogical samples.",2021,10.3389/frai.2021.668163
"Large Language Models in equity markets: applications, techniques, and insights","Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.",2025,10.3389/frai.2025.1608365
Using large language models to support pre-service teachers mathematical reasoning—an exploratory study on ChatGPT as an instrument for creating mathematical proofs in geometry,"In this exploratory study, the potential of large language models (LLMs), specifically ChatGPT to support pre-service primary education mathematics teachers in constructing mathematical proofs in geometry is investigated. Utilizing the theoretical framework of instrumental genesis, the prior experiences of students with LLMs, their beliefs about the operating principle and their interactions with the chatbot are analyzed. Using qualitative content analysis, inductive categories for these aspects are formed. Results indicate that students had limited prior experiences with LLMs and used them predominantly for applications that are not mathematics specific. Regarding their beliefs, most show only superficial knowledge about the technology and misconceptions are common. The analysis of interactions showed multiple types of in parts mathematics-specific prompts and patterns on three different levels from single prompts to whole chat interactions.",2024,10.3389/frai.2024.1460337
Design Implications for Explanations: A Case Study on Supporting Reflective Assessment of Potentially Misleading Videos,"Online videos have become a prevalent means for people to acquire information. Videos, however, are often polarized, misleading, or contain topics on which people have different, contradictory views. In this work, we introducenatural language explanationsto stimulate more deliberate reasoning about videos and raise users’ awareness of potentially deceiving or biased information. With these explanations, we aim to support users in actively deciding and reflecting on theusefulnessof the videos. We generate the explanations through an end-to-end pipeline that extractsreflection triggersso users receive additional information to the video based on its source, covered topics, communicated emotions, and sentiment. In a between-subjects user study, we examine the effect of showing the explanations for videos on three controversial topics. Besides, we assess the users’ alignment with the video’s message and how strong their belief is about the topic. Our results indicate that respondents’ alignment with the video’s message is critical to evaluate the video’s usefulness. Overall, the explanations were found to be useful and of high quality. While the explanations do not influence the perceived usefulness of the videos compared to only seeing the video, people with anextreme negative alignmentwith a video’s message perceived it as less useful (with or without explanations) and felt more confident in their assessment. We relate our findings to cognitive dissonance since users seem to be less receptive to explanations when the video’s message strongly challenges their beliefs. Given these findings, we provide a set of design implications for explanations grounded in theories on reducing cognitive dissonance in light of raising awareness about online deception.",2021,10.3389/frai.2021.712072
Gender Bias in the News: A Scalable Topic Modelling and Visualization Framework,"We present a topic modelling and data visualization methodology to examine gender-based disparities in news articles by topic. Existing research in topic modelling is largely focused on the text mining ofclosedcorpora, i.e., those that include a fixed collection of composite texts. We showcase a methodology to discover topics via Latent Dirichlet Allocation, which can reliably produce human-interpretable topics over anopennews corpus that continually grows with time. Our system generates topics, or distributions of keywords, for news articles on a monthly basis, to consistently detect key events and trends aligned with events in the real world. Findings from 2 years worth of news articles in mainstream English-language Canadian media indicate that certain topics feature either women or men more prominently and exhibit different types of language. Perhaps unsurprisingly, topics such as lifestyle, entertainment, and healthcare tend to be prominent in articles that quote more women than men. Topics such as sports, politics, and business are characteristic of articles that quote more men than women. The data shows a self-reinforcing gendered division of duties and representation in society. Quoting female sources more frequently in a caregiving role and quoting male sources more frequently in political and business roles enshrines women’s status as caregivers and men’s status as leaders and breadwinners. Our results can help journalists and policy makers better understand the unequal gender representation of those quoted in the news and facilitate news organizations’ efforts to achieve gender parity in their sources. The proposed methodology is robust, reproducible, and scalable to very large corpora, and can be used for similar studies involving unsupervised topic modelling and language analyses.",2021,10.3389/frai.2021.664737
Predicting clinical trial success for Clostridium difficile infections based on preclinical data,"Preclinical models are ubiquitous and essential for drug discovery, yet our understanding of how well they translate to clinical outcomes is limited. In this study, we investigate the translational success of treatments for Clostridium difficile infection from animal models to human patients. Our analysis shows that only 36% of the preclinical and clinical experiment pairs result in translation success. Univariate analysis shows that the sustained response endpoint is correlated with translation failure (SRC = -0.20, p-value = 1.53 × 10−54), and explainability analysis of multi-variate random forest models shows that both sustained response endpoint and subject age are negative predictors of translation success. We have developed a recommendation system to help plan the right preclinical study given factors such as drug dosage, bacterial dosage, and preclinical/clinical endpoint. With an accuracy of 0.76 (F1 score of 0.71) and by using only 7 features (out of 68 total), the proposed system boosts translational efficiency by 25%. The method presented can extend to any disease and can serve as a preclinical to clinical translation decision support system to accelerate drug discovery and de-risk clinical outcomes.",2024,10.3389/frai.2024.1487335
Symptom Prediction and Mortality Risk Calculation for COVID-19 Using Machine Learning,"Background:
                    Early prediction of symptoms and mortality risks for COVID-19 patients would improve healthcare outcomes, allow for the appropriate distribution of healthcare resources, reduce healthcare costs, aid in vaccine prioritization and self-isolation strategies, and thus reduce the prevalence of the disease. Such publicly accessible prediction models are lacking, however.
                  
                  
                    Methods:
                    Based on a comprehensive evaluation of existing machine learning (ML) methods, we created two models based solely on the age, gender, and medical histories of 23,749 hospital-confirmed COVID-19 patients from February to September 2020: a symptom prediction model (SPM) and a mortality prediction model (MPM). The SPM predicts 12 symptom groups for each patient: respiratory distress, consciousness disorders, chest pain, paresis or paralysis, cough, fever or chill, gastrointestinal symptoms, sore throat, headache, vertigo, loss of smell or taste, and muscular pain or fatigue. The MPM predicts the death of COVID-19-positive individuals.
                  
                  
                    Results:
                    The SPM yielded ROC-AUCs of 0.53–0.78 for symptoms. The most accurate prediction was for consciousness disorders at a sensitivity of 74% and a specificity of 70%. 2,440 deaths were observed in the study population. MPM had a ROC-AUC of 0.79 and could predict mortality with a sensitivity of 75% and a specificity of 70%. About 90% of deaths occurred in the top 21 percentile of risk groups. To allow patients and clinicians to use these models easily, we created a freely accessible online interface at
                    www.aicovid.net
                    .
                  
                  
                    Conclusion:
                    The ML models predict COVID-19-related symptoms and mortality using information that is readily available to patients as well as clinicians. Thus, both can rapidly estimate the severity of the disease, allowing shared and better healthcare decisions with regard to hospitalization, self-isolation strategy, and COVID-19 vaccine prioritization in the coming months.",2021,10.3389/frai.2021.673527
Review of Multi-Criteria Decision-Making Methods in Finance Using Explainable Artificial Intelligence,"The influence of Artificial Intelligence is growing, as is the need to make it as explainable as possible. Explainability is one of the main obstacles that AI faces today on the way to more practical implementation. In practise, companies need to use models that balance interpretability and accuracy to make more effective decisions, especially in the field of finance. The main advantages of the multi-criteria decision-making principle (MCDM) in financial decision-making are the ability to structure complex evaluation tasks that allow for well-founded financial decisions, the application of quantitative and qualitative criteria in the analysis process, the possibility of transparency of evaluation and the introduction of improved, universal and practical academic methods to the financial decision-making process. This article presents a review and classification of multi-criteria decision-making methods that help to achieve the goal of forthcoming research: to create artificial intelligence-based methods that are explainable, transparent, and interpretable for most investment decision-makers.",2022,10.3389/frai.2022.827584
Probing for consciousness in machines,"This study explores the potential for artificial agents to develop core consciousness, as proposed by Antonio Damasio's theory of consciousness. According to Damasio, the emergence of core consciousness relies on the integration of a self model, informed by representations of emotions and feelings, and a world model. We hypothesize that an artificial agent, trained via reinforcement learning (RL) in a virtual environment, can develop preliminary forms of these models as a byproduct of its primary task. The agent's main objective is to learn to play a video game and explore the environment. To evaluate the emergence of world and self models, we employ probes–feedforward classifiers that use the activations of the trained agent's neural networks to predict the spatial positions of the agent itself. Our results demonstrate that the agent can form rudimentary world and self models, suggesting a pathway toward developing machine consciousness. This research provides foundational insights into the capabilities of artificial agents in mirroring aspects of human consciousness, with implications for future advancements in artificial intelligence.",2025,10.3389/frai.2025.1610225
Mobile robotics in smart farming: current trends and applications,"In recent years, precision agriculture and smart farming have been deployed by leaps and bounds as arable land has become increasingly scarce. According to the Food and Agriculture Organization (FAO), by the year 2050, farming in the world should grow by about one-third above current levels. Therefore, farmers have intensively used fertilizers to promote crop growth and yields, which has adversely affected the nutritional improvement of foodstuffs. To address challenges related to productivity, environmental impact, food safety, crop losses, and sustainability, mobile robots in agriculture have proliferated, integrating mainly path planning and crop information gathering processes. Current agricultural robotic systems are large in size and cost because they use a computer as a server and mobile robots as clients. This article reviews the use of mobile robotics in farming to reduce costs, reduce environmental impact, and optimize harvests. The current status of mobile robotics, the technologies employed, the algorithms applied, and the relevant results obtained in smart farming are established. Finally, challenges to be faced in new smart farming techniques are also presented: environmental conditions, implementation costs, technical requirements, process automation, connectivity, and processing potential. As part of the contributions of this article, it was possible to conclude that the leading technologies for the implementation of smart farming are as follows: the Internet of Things (IoT), mobile robotics, artificial intelligence, artificial vision, multi-objective control, and big data. One technological solution that could be implemented is developing a fully autonomous, low-cost agricultural mobile robotic system that does not depend on a server.",2023,10.3389/frai.2023.1213330
Medical reasoning in LLMs: an in-depth analysis of DeepSeek R1,"IntroductionThe integration of large language models (LLMs) into healthcare holds immense promise, but also raises critical challenges, particularly regarding the interpretability and reliability of their reasoning processes. While models like DeepSeek R1-which incorporates explicit reasoning steps-show promise in enhancing performance and explainability, their alignment with domain-specific expert reasoning remains understudied.MethodsThis paper evaluates the medical reasoning capabilities of DeepSeek R1, comparing its outputs to the reasoning patterns of medical domain experts.ResultsThrough qualitative and quantitative analyses of 100 diverse clinical cases from the MedQA dataset, we demonstrate that DeepSeek R1 achieves 93% diagnostic accuracy and shows patterns of medical reasoning. Analysis of the seven error cases revealed several recurring errors: anchoring bias, difficulty integrating conflicting data, limited consideration of alternative diagnoses, overthinking, incomplete knowledge, and prioritizing definitive treatment over crucial intermediate steps.DiscussionThese findings highlight areas for improvement in LLM reasoning for medical applications. Notably the length of reasoning was important with longer responses having a higher probability for error. The marked disparity in reasoning length suggests that extended explanations may signal uncertainty or reflect attempts to rationalize incorrect conclusions. Shorter responses (e.g., under 5,000 characters) were strongly associated with accuracy, providing a practical threshold for assessing confidence in model-generated answers. Beyond observed reasoning errors, the LLM demonstrated sound clinical judgment by systematically evaluating patient information, forming a differential diagnosis, and selecting appropriate treatment based on established guidelines, drug efficacy, resistance patterns, and patient-specific factors. This ability to integrate complex information and apply clinical knowledge highlights the potential of LLMs for supporting medical decision-making through artificial medical reasoning.",2025,10.3389/frai.2025.1616145
Gender and content bias in Large Language Models: a case study on Google Gemini 2.0 Flash Experimental,"This study evaluates the biases in Gemini 2.0 Flash Experimental, a state-of-the-art large language model (LLM) developed by Google, focusing on content moderation and gender disparities. By comparing its performance to ChatGPT-4o, examined in a previous work of the author, the analysis highlights some differences in ethical moderation practices. Gemini 2.0 demonstrates reduced gender bias, notably with female-specific prompts achieving a substantial rise in acceptance rates compared to results obtained by ChatGPT-4o. It adopts a more permissive stance toward sexual content and maintains relatively high acceptance rates for violent prompts (including gender-specific cases). Despite these changes, whether they constitute an improvement is debatable. While gender bias has been reduced, this reduction comes at the cost of permitting more violent content toward both males and females, potentially normalizing violence rather than mitigating harm. Male-specific prompts still generally receive higher acceptance rates than female-specific ones. These findings underscore the complexities of aligning AI systems with ethical standards, highlighting progress in reducing certain biases while raising concerns about the broader implications of the model's permissiveness. Ongoing refinements are essential to achieve moderation practices that ensure transparency, fairness, and inclusivity without amplifying harmful content.",2025,10.3389/frai.2025.1558696
Generative Models of Brain Dynamics,"This review article gives a high-level overview of the approaches across different scales of organization and levels of abstraction. The studies covered in this paper include fundamental models in computational neuroscience, nonlinear dynamics, data-driven methods, as well as emergent practices. While not all of these models span the intersection of neuroscience, AI, and system dynamics, all of them do or can work in tandem as generative models, which, as we argue, provide superior properties for the analysis of neuroscientific data. We discuss the limitations and unique dynamical traits of brain data and the complementary need for hypothesis- and data-driven modeling. By way of conclusion, we present several hybrid generative models from recent literature in scientific machine learning, which can be efficiently deployed to yield interpretable models of neural dynamics.",2022,10.3389/frai.2022.807406
Predicting the Bitcoin’s price using AI,"This study investigates the application of Artificial Intelligence (AI) and Machine Learning (ML) in predicting Bitcoin price movements and developing adaptive investment strategies. An analysis of Bitcoin performance from January 2018 to January 2024 revealed that the AI-driven strategy, leveraging an ensemble of neural networks, achieved a total return of 1640.32%, significantly surpassing the ML-based approach with a return of 304.77% and the traditional B&amp;H strategy at 223.40%. By incorporating predictive analytics and technical indicators, the AI strategy dynamically adjusted its market exposure, enabling it to mitigate losses during downturns and maximize gains during favorable market conditions. These findings underscore the transformative potential of AI in financial markets, particularly in emerging asset classes like cryptocurrencies. Using a broader spectrum of data and employing advanced analytical techniques, AI can provide a more nuanced understanding of market dynamics and investor behavior providing significant implications for portfolio management, risk assessment, and trading system design.",2025,10.3389/frai.2025.1519805
Enhancing COVID-19 classification of X-ray images with hybrid deep transfer learning models,"Deep learning, a subset of artificial intelligence, has made remarkable strides in computer vision, particularly in addressing challenges related to medical images. Deep transfer learning (DTL), one of the techniques of deep learning, has emerged as a pivotal technique in medical image analysis, including studies related to COVID-19 detection and classification. Our paper proposes an alternative DTL framework for classifying COVID-19 x-ray images in this context. Unlike prior studies, our approach integrates three distinct experimentation processes using pre-trained models: AlexNet, EfficientNetB1, ResNet18, and VGG16. Furthermore, we explore the application of YOLOV4, traditionally used in object detection tasks, to COVID-19 feature detection. Our methodology involves three different experiments: manual hyperparameter selection, k-fold retraining based on performance metrics, and the implementation of a genetic algorithm for hyperparameter optimization. The first involves training the models with manually selected hyperparameter sets (learning rate, batch size, and epoch). The second approach employs k-fold cross-validation to retrain the models based on the best-performing hyperparameter set. The third employed a genetic algorithm (GA) to automatically determine optimal hyperparameter values, selecting the model with the best performance on our dataset. We tested a Kaggle dataset with more than 5,000 samples and found ResNet18 to be the best model based on genetic algorithm-based hyperparameter selection. We also tested the proposed framework process on another separate public dataset and simulated adversarial attacks to ensure its robustness and dependability. The study outcomes had an accuracy of 99.57%, an F1-score of 99.50%, a precision of 99.44%, and an average AUC of 99.89 for each class. This study underscores the effectiveness of our proposed model, positioning it as a cutting-edge solution in COVID-19 x-ray image classification. Furthermore, the proposed study has the potential to achieve automatic predictions through the use of input images in a simulated web app. This would provide an essential supplement for imaging diagnosis in remote areas with scarce medical resources and help in training junior doctors to perform imaging diagnosis.",2025,10.3389/frai.2025.1646743
Blueprint2Code: a multi-agent pipeline for reliable code generation via blueprint planning and repair,"Automated programming has become a powerful tool for solving real-world problems. Code generation, in particular, plays a key role in improving developer productivity and reducing the entry barrier to software development. Recent advances in large language models (LLMs) have significantly improved program synthesis, enabling high-quality code generation from natural language. However, LLMs still struggle with complex tasks, especially in understanding problem intent, conducting multi-step reasoning, and producing code that passes all test cases. As task difficulty increases, existing models often fail to devise complete and reliable generation strategies, leading to reduced accuracy and robustness. To address these limitations, we propose Blueprint2Code, an innovative multi-agent framework for code generation. It emulates the human programming workflow through the coordinated interaction of four agents—Previewing, Blueprint, Coding, and Debugging—forming a closed-loop system from task comprehension to planning, implementation, and iterative refinement. Compared to existing methods, Blueprint2Code shows superior performance on complex programming tasks. Extensive experiments on benchmark datasets—HumanEval, MBPP, their extended versions (HumanEval-ET, MBPP-ET), and the APPS competition dataset—demonstrated its effectiveness, achieving strong pass@1 results: HumanEval 96.3%, MBPP 88.4%, HumanEval-ET 86.5%, MBPP-ET 59.4%, and APPS 24.6%. The related code is available at https://github.com/MKH99918/Blueprint2Code.",2025,10.3389/frai.2025.1660912
Integration between constrained optimization and deep networks: a survey,"Integration between constrained optimization and deep networks has garnered significant interest from both research and industrial laboratories. Optimization techniques can be employed to optimize the choice of network structure based not only on loss and accuracy but also on physical constraints. Additionally, constraints can be imposed during training to enhance the performance of networks in specific contexts. This study surveys the literature on the integration of constrained optimization with deep networks. Specifically, we examine the integration of hyper-parameter tuning with physical constraints, such as the number of FLOPS (FLoating point Operations Per Second), a measure of computational capacity, latency, and other factors. This study also considers the use of context-specific knowledge constraints to improve network performance. We discuss the integration of constraints in neural architecture search (NAS), considering the problem as both a multi-objective optimization (MOO) challenge and through the imposition of penalties in the loss function. Furthermore, we explore various approaches that integrate logic with deep neural networks (DNNs). In particular, we examine logic-neural integration through constrained optimization applied during the training of NNs and the use of semantic loss, which employs the probabilistic output of the networks to enforce constraints on the output.",2024,10.3389/frai.2024.1414707
Early Classification of Intent for Maritime Domains Using Multinomial Hidden Markov Models,"The need for increased maritime security has prompted research focus on intent recognition solutions for the naval domain. We consider the problem of early classification of the hostile behavior of agents in a dynamic maritime domain and propose our solution using multinomial hidden Markov models (HMMs). Our contribution stems from a novel encoding of observable symbols as the rate of change (instead of static values) for parameters relevant to the task, which enables the early classification of hostile behaviors, well before the behavior has been finalized. We discuss our implementation of a one-versus-all intent classifier using multinomial HMMs and present the performance of our system for three types of hostile behaviors (ram, herd, block) and a benign behavior.",2021,10.3389/frai.2021.702153
Implementation of a Commitment Machine for an Adaptive and Robust Expected Shortfall Estimation,"This study proposes a metaheuristic for the selection of models among different Expected Shortfall (ES) estimation methods. The proposed approach, denominated “Commitment Machine” (CM), has a strong focus on assets cross-correlation and allows to measure adaptively the ES, dynamically evaluating which is the most performing method through the minimization of a loss function. The CM algorithm compares four different ES estimation techniques which all take into account the interaction effects among assets: a Bayesian Vector autoregressive model, Stochastic Differential Equation (SDE) numerical schemes with Exponential Weighted Moving Average (EWMA), a Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) volatility model and a hybrid method that integrates Dynamic Recurrent Neural Networks together with a Monte Carlo approach. The integration of traditional Monte Carlo approaches with Machine Learning technologies and the heterogeneity of dynamically selected methodologies lead to an improved estimation of the ES. The study describes the techniques adopted by the CM and the logic behind model selection; moreover, it provides a market application case of the proposed metaheuristic, by simulating an equally weighted multi-asset portfolio.",2021,10.3389/frai.2021.732805
Large-scale Vietnamese point-of-interest classification using weak labeling,"Point-of-Interests (POIs) represent geographic location by different categories (e.g., touristic places, amenities, or shops) and play a prominent role in several location-based applications. However, the majority of POIs category labels are crowd-sourced by the community, thus often of low quality. In this paper, we introduce the first annotated dataset for the POIs categorical classification task in Vietnamese. A total of 750,000 POIs are collected from WeMap, a Vietnamese digital map. Large-scale hand-labeling is inherently time-consuming and labor-intensive, thus we have proposed a new approach using weak labeling. As a result, our dataset covers 15 categories with 275,000 weak-labeled POIs for training, and 30,000 gold-standard POIs for testing, making it the largest compared to the existing Vietnamese POIs dataset. We empirically conduct POI categorical classification experiments using a strong baseline (BERT-based fine-tuning) on our dataset and find that our approach shows high efficiency and is applicable on a large scale. The proposed baseline gives an F1 score of 90% on the test dataset, and significantly improves the accuracy of WeMap POI data by a margin of 37% (from 56 to 93%).",2022,10.3389/frai.2022.1020532
Critical Analysis of Deconfounded Pretraining to Improve Visio-Linguistic Models,"An important problem with many current visio-linguistic models is that they often depend on spurious correlations. A typical example of a spurious correlation between two variables is one that is due to a third variable causing both (a “confounder”). Recent work has addressed this by adjusting for spurious correlations using a technique of deconfounding with automatically found confounders. We will refer to this technique as AutoDeconfounding. This article dives more deeply into AutoDeconfounding, and surfaces a number of issues of the original technique. First, we evaluate whether its implementation is actually equivalent to deconfounding. We provide an explicit explanation of the relation between AutoDeconfounding and the underlying causal model on which it implicitly operates, and show that additional assumptions are needed before the implementation of AutoDeconfounding can be equated to correct deconfounding. Inspired by this result, we perform ablation studies to verify to what extent the improvement on downstream visio-linguistic tasks reported by the works that implement AutoDeconfounding is due to AutoDeconfounding, and to what extent it is specifically due to the deconfounding aspect of AutoDeconfounding. We evaluate AutoDeconfounding in a way that isolates its effect, and no longer see the same improvement. We also show that tweaking AutoDeconfounding to be less related to deconfounding does not negatively affect performance on downstream visio-linguistic tasks. Furthermore, we create a human-labeled ground truth causality dataset for objects in a scene to empirically verify whether and how well confounders are found. We show that some models do indeed find more confounders than a random baseline, but also that finding more confounders is not correlated with performing better on downstream visio-linguistic tasks. Finally, we summarize the current limitations of AutoDeconfounding to solve the issue of spurious correlations and provide directions for the design of novel AutoDeconfounding methods that are aimed at overcoming these limitations.",2022,10.3389/frai.2022.736791
Attention-based speech feature transfer between speakers,"In this study, we propose a simple yet effective method for incorporating the source speaker's characteristics in the target speaker's speech. This allows our model to generate the speech of the target speaker with the style of the source speaker. To achieve this, we focus on the attention model within the speech synthesis model, which learns various speaker features such as spectrogram, pitch, intensity, formant, pulse, and voice breaks. The model is trained separately using datasets specific to the source and target speakers. Subsequently, we replace the attention weights learned from the source speaker's dataset with the attention weights from the target speaker's model. Finally, by providing new input texts to the target model, we generate the speech of the target speaker with the styles of the source speaker. We validate the effectiveness of our model through similarity analysis utilizing five evaluation metrics and showcase real-world examples.",2024,10.3389/frai.2024.1259641
LRMP: Layer Replication with Mixed Precision for spatial in-memory DNN accelerators,"In-memory computing (IMC) with non-volatile memories (NVMs) has emerged as a promising approach to address the rapidly growing computational demands of Deep Neural Networks (DNNs). Mapping DNN layers spatially onto NVM-based IMC accelerators achieves high degrees of parallelism. However, two challenges that arise in this approach are the highly non-uniform distribution of layer processing times and high area requirements. We propose LRMP, a method to jointly apply layer replication and mixed precision quantization to improve the performance of DNNs when mapped to area-constrained IMC accelerators. LRMP uses a combination of reinforcement learning and mixed integer linear programming to search the replication-quantization design space using a model that is closely informed by the target hardware architecture. Across five DNN benchmarks, LRMP achieves 2.6–9.3× latency and 8–18× throughput improvement at minimal (&lt;1%) degradation in accuracy.",2024,10.3389/frai.2024.1268317
The three-step persuasion model on YouTube: A grounded theory study on persuasion in the protein supplements industry,"Persuasion can be defined as an active attempt by a person to change the behavior and attitudes of others. The purposive attempt to influence one's behavior can originate from different areas, and people who are able to do so are often referred to as influencers. Social media platforms such as Instagram or YouTube have become crucial platforms for influencers who generate their income by recommending products and services to their followers, including cosmetics, multimedia articles or clothing. Studies indicate that influencers actively try to persuade the viewer to adopt specific desirable behavior by strategically altering their displayed behavior on social media. Such strategies have mainly been explored in the context of beauty products, where lack of expertise and misinformation might have few negative consequences. Less is known about strategies used in a health-sensitive context, such as nutritional supplements. This research addresses this gap and aims to understand persuasive techniques used by health professionals on YouTube to promote the use of protein supplements. This study is based on an interpretive paradigm using interpretive grounded theory to analyze 60 YouTube videos. We developed a three-step model of persuasion for YouTube videos consisting of the steps: reaching the message, staying on the message, and performing the action that the persuader desires. Our analysis resulted in five core themes that contributed to the persuasiveness of the analyzed YouTube videos. These themes included: Quality, curiosity, engagement, concretization, and genuineness. We conclude the paper with reflections on our model's theoretical and practical implications.",2022,10.3389/frai.2022.838377
Integrating collective know-how for multicriteria decision support in agrifood chains—application to cheesemaking,"Agrifood chain processes are based on a multitude of knowledge, know-how and experiences forged over time. This collective expertise must be shared to improve food quality. Here we test the hypothesis that it is possible to design and implement a comprehensive methodology to create a knowledge base integrating collective expertise, while also using it to recommend technical actions required to improve food quality. The method used to test this hypothesis consists firstly in listing the functional specifications that were defined in collaboration with several partners (technical centers, vocational training schools, producers) over the course of several projects carried out in recent years. Secondly, we propose an innovative core ontology that utilizes the international languages of the Semantic Web to effectively represent knowledge in the form of decision trees. These decision trees will depict potential causal relationships between situations of interest and provide recommendations for managing them through technological actions, as well as a collective assessment of the efficiency of those actions. We show how mind map files created using mind-mapping tools are automatically translated into an RDF knowledge base using the core ontological model. Thirdly, a model to aggregate individual assessments provided by technicians and associated with technical action recommendations is proposed and evaluated. Finally, a multicriteria decision-support system (MCDSS) using the knowledge base is presented. It consists of an explanatory view allowing navigation in a decision tree and an action view for multicriteria filtering and possible side effect identification. The different types of MCDSS-delivered answers to a query expressed in the action view are explained. The MCDSS graphical user interface is presented through a real-use case. Experimental assessments have been performed and confirm that tested hypothesis is relevant.",2023,10.3389/frai.2023.1145007
FLA-UNet: feature-location attention U-Net for foveal avascular zone segmentation in OCTA images,"IntroductionSince optical coherence tomography angiography (OCTA) is non-invasive and non-contact, it is widely used in the study of retinal disease detection. As a key indicator for retinal disease detection, accurate segmentation of foveal avascular zone (FAZ) has an important impact on clinical application. Although the U-Net and its existing improvement methods have achieved good performance on FAZ segmentation, their generalization ability and segmentation accuracy can be further improved by exploring more effective improvement strategies.MethodsWe propose a novel improved method named Feature-location Attention U-Net (FLA-UNet) by introducing new designed feature-location attention blocks (FLABs) into U-Net and using a joint loss function. The FLAB consists of feature-aware blocks and location-aware blocks in parallel, and is embed into each decoder of U-Net to integrate more marginal information of FAZ and strengthen the connection between target region and boundary information. The joint loss function is composed of the cross-entropy loss (CE loss) function and the Dice coefficient loss (Dice loss) function, and by adjusting the weights of them, the performance of the network on boundary and internal segmentation can be comprehensively considered to improve its accuracy and robustness for FAZ segmentation.ResultsThe qualitative and quantitative comparative experiments on the three datasets of OCTAGON, FAZID and OCTA-500 show that, our proposed FLA-UNet achieves better segmentation quality, and is superior to other existing state-of-the-art methods in terms of the MIoU, ACC and Dice coefficient.DiscussionThe proposed FLA-UNet can effectively improve the accuracy and robustness of FAZ segmentation in OCTA images by introducing feature-location attention blocks into U-Net and using a joint loss function. This has laid a solid theoretical foundation for its application in auxiliary diagnosis of fundus diseases.",2025,10.3389/frai.2025.1463233
Inside out: transforming images of lab-grown plants for machine learning applications in agriculture,"IntroductionMachine learning tasks often require a significant amount of training data for the resultant network to perform suitably for a given problem in any domain. In agriculture, dataset sizes are further limited by phenotypical differences between two plants of the same genotype, often as a result of different growing conditions. Synthetically-augmented datasets have shown promise in improving existing models when real data is not available.MethodsIn this paper, we employ a contrastive unpaired translation (CUT) generative adversarial network (GAN) and simple image processing techniques to translate indoor plant images to appear as field images. While we train our network to translate an image containing only a single plant, we show that our method is easily extendable to produce multiple-plant field images.ResultsFurthermore, we use our synthetic multi-plant images to train several YoloV5 nano object detection models to perform the task of plant detection and measure the accuracy of the model on real field data images.DiscussionThe inclusion of training data generated by the CUT-GAN leads to better plant detection performance compared to a network trained solely on real data.",2023,10.3389/frai.2023.1200977
Semantic Integration of Multi-Modal Data and Derived Neuroimaging Results Using the Platform for Imaging in Precision Medicine (PRISM) in the Arkansas Imaging Enterprise System (ARIES),"Neuroimaging is among the most active research domains for the creation and management of open-access data repositories. Notably lacking from most data repositories are integrated capabilities for semantic representation. The Arkansas Imaging Enterprise System (ARIES) is a research data management system which features integrated capabilities to support semantic representations of multi-modal data from disparate sources (imaging, behavioral, or cognitive assessments), across common image-processing stages (preprocessing steps, segmentation schemes, analytic pipelines), as well as derived results (publishable findings). These unique capabilities ensure greater reproducibility of scientific findings across large-scale research projects. The current investigation was conducted with three collaborating teams who are using ARIES in a project focusing on neurodegeneration. Datasets included magnetic resonance imaging (MRI) data as well as non-imaging data obtained from a variety of assessments designed to measure neurocognitive functions (performance scores on neuropsychological tests). We integrate and manage these data with semantic representations based on axiomatically rich biomedical ontologies. These instantiate a knowledge graph that combines the data from the study cohorts into a shared semantic representation that explicitly accounts for relations among the entities that the data are about. This knowledge graph is stored in a triple-store database that supports reasoning over and querying these integrated data. Semantic integration of the non-imaging data using background information encoded in biomedical domain ontologies has served as a key feature-engineering step, allowing us to combine disparate data and apply analyses to explore associations, for instance, between hippocampal volumes and measures of cognitive functions derived from various assessment instruments.",2022,10.3389/frai.2021.649970
"Deep learning for causal inference using low birth weight in midwife-led continuity care intervention in north Shoa zone, Ethiopia","IntroductionLow birth weight (LBW), under 2,500 g, poses health risks, though not always requiring treatment. Early detection of high-risk pregnancies enables preventive care, improving outcomes for mother and baby. This study aimed to establish cause-and-effect relationships using Causal Deep Learning (CDL) models that reduce bias and estimate heterogeneous treatment effects on LBW in the Midwife-Led Continuity Care (MLCC) intervention.MethodsThis study used a quasi-experimental study design (August 2019–September 2020) in North Shoa, Ethiopia, and enrolled 1,166 women divided into two groups: one receiving MLCC and the other receiving other professional groups for comprehensive antenatal/postnatal care. The dataset and code are provided in data availability section. Our model combines counterfactual convolutional neural networks to analyze time-based patterns and Bayesian Ridge regression to reduce bias in propensity scores. We use Counterfactual Regression with Wasserstein Distance (CFR-WASS) and Counterfactual Regression with Maximum Mean Discrepancy (CFR-MMD) to balance patient characteristics and improve counterfactual estimates of treatment effects. This approach strengthens causal insights into how MLCC interventions affect LBW outcomes.ResultThe Deep neural networks (DNN) model showed strong predictive accuracy for LBW, with 81.3% training and 81.4% testing performance, an area under the curve (AUC) of 0.88, enabling the reliable early identification of high-risk pregnancies. The study found a strong link between meconium aspiration syndrome (MAS) and LBW (p = 0.002), but this does not mean MAS directly causes LBW. MAS likely results from fetal distress or other pregnancy complications that may independently affect LBW. While statistical associations exist, clinical causation remains unproven; therefore, the counterfactual analysis showed MLCC could help reduce LBW risk. CFR-WASS achieved high accuracy (84%) while the precision in heterogeneous treatment effect (PEHE = 1.006) and the average treatment effect (ATE = 0.24), and CFR-MMD PEHE of 1.02, ATE of 0.45, demonstrating potential for tailored treatment strategies. DNN and multilayer perceptrons uniquely identified key neural weights and biases favoring normal birth weight while suppressing LBW predictions, offering interpretable insights for clinical risk assessment.ConclusionThe CFR-WASS/CFR-MMD model strengthens LBW prediction by identifying crucial factors like MAS and healthcare access, while accurate PEHE and ATE estimates support data-driven prenatal care and targeted interventions for healthier outcomes.",2025,10.3389/frai.2025.1484299
A Comparative Study of Machine Learning Methods for Persistence Diagrams,"Many and varied methods currently exist for featurization, which is the process of mapping persistence diagrams to Euclidean space, with the goal of maximally preserving structure. However, and to our knowledge, there are presently no methodical comparisons of existing approaches, nor a standardized collection of test data sets. This paper provides a comparative study of several such methods. In particular, we review, evaluate, and compare the stable multi-scale kernel, persistence landscapes, persistence images, the ring of algebraic functions, template functions, and adaptive template systems. Using these approaches for feature extraction, we apply and compare popular machine learning methods on five data sets: MNIST, Shape retrieval of non-rigid 3D Human Models (SHREC14), extracts from the Protein Classification Benchmark Collection (Protein), MPEG7 shape matching, and HAM10000 skin lesion data set. These data sets are commonly used in the above methods for featurization, and we use them to evaluate predictive utility in real-world applications.",2021,10.3389/frai.2021.681174
Accurate species identification of food-contaminating beetles with quality-improved elytral images and deep learning,"Food samples are routinely screened for food-contaminating beetles (i.e., pantry beetles) due to their adverse impact on the economy, environment, public health and safety. If found, their remains are subsequently analyzed to identify the species responsible for the contamination; each species poses different levels of risk, requiring different regulatory and management steps. At present, this identification is done through manual microscopic examination since each species of beetle has a unique pattern on its elytra (hardened forewing). Our study sought to automate the pattern recognition process through machine learning. Such automation will enable more efficient identification of pantry beetle species and could potentially be scaled up and implemented across various analysis centers in a consistent manner. In our earlier studies, we demonstrated that automated species identification of pantry beetles is feasible through elytral pattern recognition. Due to poor image quality, however, we failed to achieve prediction accuracies of more than 80%. Subsequently, we modified the traditional imaging technique, allowing us to acquire high-quality elytral images. In this study, we explored whether high-quality elytral images can truly achieve near-perfect prediction accuracies for 27 different species of pantry beetles. To test this hypothesis, we developed a convolutional neural network (CNN) model and compared performance between two different image sets for various pantry beetles. Our study indicates improved image quality indeed leads to better prediction accuracy; however, it was not the only requirement for achieving good accuracy. Also required are many high-quality images, especially for species with a high number of variations in their elytral patterns. The current study provided a direction toward achieving our ultimate goal of automated species identification through elytral pattern recognition.",2022,10.3389/frai.2022.952424
Layer wise Scaled Gaussian Priors for Markov Chain Monte Carlo Sampled deep Bayesian neural networks,"Previous work has demonstrated that initialization is very important for both fitting a neural network by gradient descent methods, as well as for Variational inference of Bayesian neural networks. In this work we investigate how Layer wise Scaled Gaussian Priors perform with Markov Chain Monte Carlo trained Bayesian neural networks. From our experiments on 8 classifications datasets of various complexity, the results indicate that using Layer wise Scaled Gaussian Priors makes the sampling process more efficient as compared to using an Isotropic Gaussian Prior, an Isotropic Cauchy Prior, or an Isotropic Laplace Prior. We also show that the cold posterior effect does not arise when using a either an Isotropic Gaussian or a layer wise Scaled Prior for small feed forward Bayesian neural networks. Since Bayesian neural networks are becoming popular due to their advantages such as uncertainty estimation, and prevention of over-fitting, this work seeks to provide improvements in the efficiency of Bayesian neural networks learned using Markov Chain Monte Carlo methods.",2025,10.3389/frai.2025.1444891
Governing AI in Southeast Asia: ASEAN’s way forward,"Despite the rapid development of AI, ASEAN has not been able to devise a regional governance framework to address relevant existing and future challenges. This is concerning, considering the potential of AI to accelerate GDP among ASEAN member states in the coming years. This qualitative inquiry discusses AI governance in Southeast Asia in the past 5 years and what regulatory policies ASEAN can explore to better modulate its use among its member states. It considers the unique political landscape of the region, defined by the adoption of unique norms such as non-interference and priority over dialog, commonly termed the ASEAN Way. The following measures are concluded as potential regional governance frameworks: (1) Elevation of the topic’s importance in ASEAN’s intra and inter-regional forums to formulate collective regional agreements on AI, (2) adoption of AI governance measures in the field of education, specifically, reskilling and upskilling strategies to respond to future transformation of the working landscape, and (3) establishment of an ASEAN working group to bridge knowledge gaps among member states, caused by the disparity of AI-readiness in the region.",2024,10.3389/frai.2024.1411838
Comparing emotions in ChatGPT answers and human answers to the coding questions on Stack Overflow,"IntroductionRecent advances in generative Artificial Intelligence (AI) and Natural Language Processing (NLP) have led to the development of Large Language Models (LLMs) and AI-powered chatbots like ChatGPT, which have numerous practical applications. Notably, these models assist programmers with coding queries, debugging, solution suggestions, and providing guidance on software development tasks. Despite known issues with the accuracy of ChatGPT’s responses, its comprehensive and articulate language continues to attract frequent use. This indicates potential for ChatGPT to support educators and serve as a virtual tutor for students.MethodsTo explore this potential, we conducted a comprehensive analysis comparing the emotional content in responses from ChatGPT and human answers to 2000 questions sourced from Stack Overflow (SO). The emotional aspects of the answers were examined to understand how the emotional tone of AI responses compares to that of human responses.ResultsOur analysis revealed that ChatGPT’s answers are generally more positive compared to human responses. In contrast, human answers often exhibit emotions such as anger and disgust. Significant differences were observed in emotional expressions between ChatGPT and human responses, particularly in the emotions of anger, disgust, and joy. Human responses displayed a broader emotional spectrum compared to ChatGPT, suggesting greater emotional variability among humans.DiscussionThe findings highlight a distinct emotional divergence between ChatGPT and human responses, with ChatGPT exhibiting a more uniformly positive tone and humans displaying a wider range of emotions. This variance underscores the need for further research into the role of emotional content in AI and human interactions, particularly in educational contexts where emotional nuances can impact learning and communication.",2024,10.3389/frai.2024.1393903
Doctor AI? A pilot study examining responses of artificial intelligence to common questions asked by geriatric patients,"IntroductionAI technologies have the potential to transform patient care. AI has been used to aid in differential diagnosis and treatment planning for psychiatric disorders, administer therapeutic protocols, assist with interpretation of cognitive testing, and patient treatment planning. Despite advancements, AI has notable limitations and remains understudied and further research on its strengths and limitations in patient care is required. This study explored the responses of AI (Chat-GPT 3.5) and trained clinicians to commonly asked patient questions.MethodsThree clinicians and AI provided responses to five dementia/geriatric healthcare-related questions. Responses were analyzed by a fourth, blinded clinician for clarity, accuracy, relevance, depth, and ease of understanding and to determine which response was AI generated.ResultsAI responses were rated highest in ease of understanding and depth across all responses and tied for first for clarity, accuracy, and relevance. The rating for AI generated responses was 4.6/5 (SD = 0.26); the clinician s' responses were 4.3 (SD = 0.67), 4.2 (SD = 0.52), and 3.9 (SD = 0.59), respectively. The AI generated answers were identified in 4/5 instances.ConclusionsAI responses were rated more highly and consistently on each question individually and overall than clinician answers demonstrating that AI could produce good responses to potential patient questions. However, AI responses were easily distinguishable from those of clinicians. Although AI has the potential to positively impact healthcare, concerns are raised regarding difficulties discerning AI from human generated material, the increased potential for proliferation of misinformation, data security concerns, and more.",2024,10.3389/frai.2024.1438012
Statistical biopsy: An emerging screening approach for early detection of cancers,"Despite large investment cancer continues to be a major source of mortality and morbidity throughout the world. Traditional methods of detection and diagnosis such as biopsy and imaging, tend to be expensive and have risks of complications. As data becomes more abundant and machine learning continues advancing, it is natural to ask how they can help solve some of these problems. In this paper we show that using a person's personal health data it is possible to predict their risk for a wide variety of cancers. We dub this process a “statistical biopsy.” Specifically, we train two neural networks, one predicting risk for 16 different cancer types in females and the other predicting risk for 15 different cancer types in males. The networks were trained as binary classifiers identifying individuals that were diagnosed with the different cancer types within 5 years of joining the PLOC trial. However, rather than use the binary output of the classifiers we show that the continuous output can instead be used as a cancer risk allowing a holistic look at an individual's cancer risks. We tested our multi-cancer model on the UK Biobank dataset showing that for most cancers the predictions generalized well and that looking at multiple cancer risks at once from personal health data is a possibility. While the statistical biopsy will not be able to replace traditional biopsies for diagnosing cancers, we hope there can be a shift of paradigm in how statistical models are used in cancer detection moving to something more powerful and more personalized than general population screening guidelines.",2023,10.3389/frai.2022.1059093
Performance comparison of bio-inspired and learning-based clustering analysis with machine learning techniques for classification of EEG signals,"A comprehensive analysis of an automated system for epileptic seizure detection is explained in this work. When a seizure occurs, it is quite difficult to differentiate the non-stationary patterns from the discharges occurring in a rhythmic manner. The proposed approach deals with it efficiently by clustering it initially for the sake of feature extraction by using six different techniques categorized under two different methods, e.g., bio-inspired clustering and learning-based clustering. Learning-based clustering includes K-means clusters and Fuzzy C-means (FCM) clusters, while bio-inspired clusters include Cuckoo search clusters, Dragonfly clusters, Firefly clusters, and Modified Firefly clusters. Clustered values were then classified with 10 suitable classifiers, and after the performance comparison analysis of the EEG time series, the results proved that this methodology flow achieved a good performance index and a high classification accuracy. A comparatively higher classification accuracy of 99.48% was achieved when Cuckoo search clusters were utilized with linear support vector machines (SVM) for epilepsy detection. A high classification accuracy of 98.96% was obtained when K-means clusters were classified with a naive Bayesian classifier (NBC) and Linear SVM, and similar results were obtained when FCM clusters were classified with Decision Trees yielding the same values. The comparatively lowest classification accuracy, at 75.5%, was obtained when Dragonfly clusters were classified with the K-nearest neighbor (KNN) classifier, and the second lowest classification accuracy of 75.75% was obtained when Firefly clusters were classified with NBC.",2023,10.3389/frai.2023.1156269
Digital model for monitoring national programs: the Kazakhstan experience,"This paper presents a conceptual digital model for monitoring national programs designed to enhance their effectiveness, transparency, and performance in the context of digital transformation in public administration. The research identifies limitations of traditional monitoring approaches characterized by data fragmentation, lack of dynamic tracking, and insufficient focus on socio-economic outcomes. In response to these challenges, we propose an original Digital Model for National Program Monitoring (DMNPM) that integrates various data sources from Kazakhstan’s digital ecosystem (egov.kz, Smart Bridge, Open Data). The key scientific contribution of the model is its comprehensive approach, which includes predictive analytics capabilities based on machine learning for risk forecasting and causal relationship assessment, as well as built-in two-way feedback mechanisms. To demonstrate the practical applicability and potential of DMNPM, we present case studies of monitoring key strategic programs in Kazakhstan – “Digital Kazakhstan” and “Nurly Zhol,” as well as pilot national projects “Zhaily Mektep” and “Auyldyq Densaulyq Saqtau.” A quasi-experimental pilot across two national programs demonstrates measurable improvements in monitoring effectiveness and reporting efficiency compared to traditional manual processes. The research contributes to digital governance theory and monitoring methodology by offering a practical solution adapted for countries with actively developing digital infrastructure.",2025,10.3389/frai.2025.1656329
Phenology analysis for trait prediction using UAVs in a MAGIC rice population with different transplanting protocols,"Unmanned aerial vehicles (UAVs) are one of the most effective tools for crop monitoring in the field. Time-series RGB and multispectral data obtained with UAVs can be used for revealing changes of three-dimensional growth. We previously showed using a rice population with our regular cultivation protocol that canopy height (CH) parameters extracted from time-series RGB data are useful for predicting manually measured traits such as days to heading (DTH), culm length (CL), and aboveground dried weight (ADW). However, whether CH parameters are applicable to other rice populations and to different cultivation methods, and whether vegetation indices such as the chlorophyll index green (CIg) can function for phenotype prediction remain to be elucidated. Here we show that CH and CIg exhibit different patterns with different cultivation protocols, and each has its own character for the prediction of rice phenotypes. We analyzed CH and CIg time-series data with a modified logistic model and a double logistic model, respectively, to extract individual parameters for each. The CH parameters were useful for predicting DTH, CL, ADW and stem and leaf weight (SLW) in a newly developed rice population under both regular and delayed cultivation protocols. The CIg parameters were also effective for predicting DTH and SLW, and could also be used to predict panicle weight (PW). The predictive ability worsened when different cultivation protocols were used, but this deterioration was mitigated by a calibration procedure using data from parental cultivars. These results indicate that the prediction of DTH, CL, ADW and SLW by CH parameters is robust to differences in rice populations and cultivation protocols, and that CIg parameters are an indispensable complement to the CH parameters for the predicting PW.",2025,10.3389/frai.2024.1477637
An Empirical Investigation Into Deep and Shallow Rule Learning,"Inductive rule learning is arguably among the most traditional paradigms in machine learning. Although we have seen considerable progress over the years in learning rule-based theories, all state-of-the-art learners still learn descriptions that directly relate the input features to the target concept. In the simplest case, concept learning, this is a disjunctive normal form (DNF) description of the positive class. While it is clear that this is sufficient from a logical point of view because every logical expression can be reduced to an equivalent DNF expression, it could nevertheless be the case that more structured representations, which form deep theories by forming intermediate concepts, could be easier to learn, in very much the same way as deep neural networks are able to outperform shallow networks, even though the latter are also universal function approximators. However, there are several non-trivial obstacles that need to be overcome before a sufficiently powerful deep rule learning algorithm could be developed and be compared to the state-of-the-art in inductive rule learning. In this paper, we therefore take a different approach: we empirically compare deep and shallow rule sets that have been optimized with a uniform general mini-batch based optimization algorithm. In our experiments on both artificial and real-world benchmark data, deep rule networks outperformed their shallow counterparts, which we take as an indication that it is worth-while to devote more efforts to learning deep rule structures from data.",2021,10.3389/frai.2021.689398
Explainable machine learning to predict the cost of capital,"This study investigates the impact of financial and non-financial factors on a firm's ex-ante cost of capital, which is the reflection of investors' perception on a firm's riskiness. Departing from previous literature, we apply the XGBoost algorithm and two explainable Artificial Intelligence methods, namely the Shapley value approach and Lorenz Model Selection to a sample of more than 1,400 listed companies worldwide. Results confirm the relevance of key financial indicators such as firm size, ROE, firm portfolio risk, but also individuate firm's non-financial features and country's institutional quality as relevant predictors for the cost of capital. These results suggest the importance of non-financial indicators and country institutional quality on the firm's ex-ante cost of equity that expresses investors' risk perception. Our findings pave the way for future investigations on the impact of ESG and country factors in predicting the cost of capital.",2025,10.3389/frai.2025.1578190
Advanced sleep disorder detection using multi-layered ensemble learning and advanced data balancing techniques,"Sleep disorder detection has greatly improved with the integration of machine learning, offering enhanced accuracy and effectiveness. However, the labor-intensive nature of diagnosis still presents challenges. To address these, we propose a novel coordination model aimed at improving detection accuracy and reliability through a multi-model ensemble approach. The proposed method employs a multi-layered ensemble model, starting with the careful selection of N models to capture essential features. Techniques such as thresholding, predictive scoring, and the conversion of Softmax labels into multidimensional feature vectors improve interpretability. Ensemble methods like voting and stacking are used to ensure collaborative decision-making across models. Both the original dataset and one modified using the Synthetic Minority Oversampling Technique (SMOTE) were evaluated to address data imbalance issues. The ensemble model demonstrated superior performance, achieving 96.88% accuracy on the SMOTE-implemented dataset and 95.75% accuracy on the original dataset. Moreover, an eight-fold cross-validation yielded an impressive 99.5% accuracy, indicating the reliability of the model in handling unbalanced data and ensuring precise detection of sleep disorders. Compared to individual models, the proposed ensemble method significantly outperformed traditional models. The combination of models not only enhanced accuracy but also improved the system's ability to handle unbalanced data, a common limitation in traditional methods. This study marks a significant advancement in sleep disorder detection through the integration of innovative ensemble techniques. The proposed approach, combining multiple models and advanced interpretability methods, promises improved patient outcomes and greater diagnostic accuracy, paving the way for future applications in medical diagnostics.",2025,10.3389/frai.2024.1506770
Rationalization for explainable NLP: a survey,"Recent advances in deep learning have improved the performance of many Natural Language Processing (NLP) tasks such as translation, question-answering, and text classification. However, this improvement comes at the expense of model explainability. Black-box models make it difficult to understand the internals of a system and the process it takes to arrive at an output. Numerical (LIME, Shapley) and visualization (saliency heatmap) explainability techniques are helpful; however, they are insufficient because they require specialized knowledge. These factors led rationalization to emerge as a more accessible explainable technique in NLP. Rationalization justifies a model's output by providing a natural language explanation (rationale). Recent improvements in natural language generation have made rationalization an attractive technique because it is intuitive, human-comprehensible, and accessible to non-technical users. Since rationalization is a relatively new field, it is disorganized. As the first survey, rationalization literature in NLP from 2007 to 2022 is analyzed. This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization. Further, a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization. A discussion on observed insights, challenges, and future directions is provided to point to promising research opportunities.",2023,10.3389/frai.2023.1225093
The MAS4AI framework for human-centered agile and smart manufacturing,"Volatility and uncertainty of today's value chains along with the market's demands for low-batch customized products mandate production systems to become smarter and more resilient, dynamically and even autonomously adapting to both external and internal disturbances. Such resilient behavior can be partially enabled by highly interconnected Cyber-Physical Production Systems (CPPS) incorporating advanced Artificial Intelligence (AI) technologies. Multi-agent solutions can provide better planning and control, improving flexibility and responsiveness in production systems. Small modular parts can autonomously take intelligent decisions and react to local events. The main goal of decentralization and interconnectivity is to enable autonomous and cooperative decision-making. Nevertheless, a more efficient orchestration of various AI components and deeper human integration are required. In addition, global behaviors of coalitions of autonomous agents are not easily comprehensible by workers. Furthermore, it is challenging to implement an Industry 4.0 paradigm where a human should be in charge of decision-making and execution. This paper discusses a Multi-Agent System (MAS) where several software agents cooperate with smart workers to enable a dynamic and reconfigurable production paradigm. Asset Administration Shell (AAS) submodels hold smart workers' descriptions in machine-readable format, serving as an integration layer between various system's components. The self-description capability of the AAS supports the system's adaptability and self-configuration. The proposed concept supports the plug-and-produce functionality of the production modules and improves human-machine integration in the shared assembly tasks.",2023,10.3389/frai.2023.1241522
Enhancing Africa’s agriculture and food systems through responsible and gender inclusive AI innovation: insights from AI4AFS network,"The integration of artificial intelligence (AI) technologies into agriculture holds urgent and transformative potential for enhancing food security across Sub-Saharan Africa (SSA), a region acutely impacted by climate change and resource constraints. This paper examines experiences from the Artificial Intelligence for Agriculture and Food Systems (AI4AFS) Innovation Research Network, which provided funding to innovative projects in eight SSA countries. Through a set of case studies, we explore AI-driven solutions for pest and disease detection across crops such as cashew, maize, tomato, and cassava, including a real-time health monitoring tool for Nsukka Yellow pepper. Using participatory design, and key informant interview, robust monitoring and evaluation, and incorporating ethical frameworks, the research prioritizes gender equality, social inclusion, and environmental sustainability in AI development and deployment. Our results demonstrate that responsible AI practices can significantly enhance agricultural productivity while maintaining low carbon footprints. This research offers a unique, localized perspective on AI’s role in addressing SSA’s agricultural challenges, with implications for global food security as demand rises and environmental resources shrink. Key recommendations include establishing robust policy frameworks, strengthening capacity-building efforts, and securing sustainable funding mechanisms to support long-term AI adoption. This work provides the global community, policymakers, and stakeholders with critical insights on establishing ethical, responsible, and inclusive AI practices that can be adapted to similar agricultural contexts worldwide, contributing to sustainable food systems on an international scale.",2025,10.3389/frai.2024.1472236
Inpainting of damaged temple murals using edge- and line-guided diffusion patch GAN,"Mural paintings are vital cultural expressions, enriching our lives by beautifying spaces, conveying messages, telling stories, and evoking emotions. Ancient temple murals degrade over time due to natural aging, physical damage, etc. Preserving these cultural treasures is challenging. Image inpainting is often used for digital restoration, but existing methods typically overlook naturally degraded areas, using randomly generated binary masks or small, narrow regions for repair. This study proposes a novel architecture to reconstruct large areas of naturally degraded murals, maintaining intrinsic details, avoiding color bias, and preserving artistic excellence. The architecture integrates generative adversarial networks (GANs) and the diffusion model, including a whole structure formation network (WSFN), a semantic color network (SCN), and a diffusion mixture distribution (DIMD) discriminator. The WSFN uses the original image, a line drawing, and an edge map to capture mural details, which are then texturally inpainted in the SCN using gated convolution for enhanced results. Special attention is given to globally extending the receptive field for large-area inpainting. The model is evaluated using custom-degraded mural images collected from Tamil Nadu temples. Quantitative analysis showed superior results than state-of-the-art methods, with SSIM, MSE, PSNR, and LPIPS values of 0.8853, 0.0021, 29.8826, and 0.0426, respectively.",2024,10.3389/frai.2024.1453847
Environment sustainability with smart grid sensor,"Environmental sustainability is a pressing global concern, with energy conservation and efficient utilization playing a key role in its achievement. Smart grid technology has emerged as a promising solution, facilitating energy efficiency, promoting renewable energy integration, and fostering consumer engagement. But the addition of intelligent sensors to these grids has the potential to greatly increase the level of sustainability initiatives. This paper highlights the role of smart grid sensors in addressing challenges like energy losses, demand-response limitations, and renewable energy integration. It explains how these sensors enable real-time monitoring, fault detection, and optimal load management to improve grid performance and reduce environmental impact. This also study looks at how AI with smart grid sensor can perform real-time data monitoring, optimal energy distribution, and proactive decision support from smart grid sensors might improve environmental sustainability. Furthermore, it examines advancements in sensor technologies in India, including pilot projects like the BESCOM initiative in Bangalore and Tata Power-DDL’s renewable energy trading in Delhi, to showcase their practical applications and outcomes. Smart sensors provide accurate tracking of energy usage trends, enhance load distribution, and advance the sensible application of renewable energy resources. These sensors aid in cutting down on energy waste and carbon emissions by interacting with customers and enabling demand-response systems. This study addresses the critical role of smart sensors in overcoming the shortcomings of conventional grids and guaranteeing a more resilient, efficient, and sustainable energy future through an extensive analysis of the literature. Grid-enabled systems, such as electric water heaters with sensor, can achieve energy savings of up to 29%. The integration of renewable energy sources through sensors enhances system efficiency, reduces reliance on fossil fuels, and optimizes supply and demand. Utilizing Internet of Things (IoT) technology enables precise monitoring of air quality, water consumption, and resource management, significantly improving environmental oversight. This integration can lead to a reduction in greenhouse gas emissions by up to 20% and water usage by 30%. Lastly, the paper discusses how integrating artificial intelligence with smart grid sensors can enhance predictive maintenance, energy management, and cybersecurity, further strengthening the case for their deployment.",2025,10.3389/frai.2024.1510410
The energy challenges of artificial superintelligence,"We argue here that contemporary semiconductor computing technology poses a significant if not insurmountable barrier to the emergence of any artificial general intelligence system, let alone one anticipated by many to be “superintelligent”. This limit on artificial superintelligence (ASI) emerges from the energy requirements of a system that would be more intelligent but orders of magnitude less efficient in energy use than human brains. An ASI would have to supersede not only a single brain but a large population given the effects of collective behavior on the advancement of societies, further multiplying the energy requirement. A hypothetical ASI would likely consume orders of magnitude more energy than what is available in highly-industrialized nations. We estimate the energy use of ASI with an equation we term the “Erasi equation”, for the Energy Requirement for Artificial SuperIntelligence. Additional efficiency consequences will emerge from the current unfocussed and scattered developmental trajectory of AI research. Taken together, these arguments suggest that the emergence of an ASI is highly unlikely in the foreseeable future based on current computer architectures, primarily due to energy constraints, with biomimicry or other new technologies being possible solutions.",2023,10.3389/frai.2023.1240653
The imperative of diversity and equity for the adoption of responsible AI in healthcare,"Artificial Intelligence (AI) in healthcare holds transformative potential but faces critical challenges in ethical accountability and systemic inequities. Biases in AI models, such as lower diagnosis rates for Black women or gender stereotyping in Large Language Models, highlight the urgent need to address historical and structural inequalities in data and development processes. Disparities in clinical trials and datasets, often skewed toward high-income, English-speaking regions, amplify these issues. Moreover, the underrepresentation of marginalized groups among AI developers and researchers exacerbates these challenges. To ensure equitable AI, diverse data collection, federated data-sharing frameworks, and bias-correction techniques are essential. Structural initiatives, such as fairness audits, transparent AI model development processes, and early registration of clinical AI models, alongside inclusive global collaborations like TRAIN-Europe and CHAI, can drive responsible AI adoption. Prioritizing diversity in datasets and among developers and researchers, as well as implementing transparent governance will foster AI systems that uphold ethical principles and deliver equitable healthcare outcomes globally.",2025,10.3389/frai.2025.1577529
Automated feedback and writing: a multi-level meta-analysis of effects on students' performance,"IntroductionAdaptive learning opportunities and individualized, timely feedback are considered to be effective support measures for students' writing in educational contexts. However, the extensive time and expertise required to analyze numerous drafts of student writing pose a barrier to teaching. Automated writing evaluation (AWE) tools can be used for individual feedback based on advances in Artificial Intelligence (AI) technology. A number of primary (quasi-)experimental studies have investigated the effect of AWE feedback on students' writing performance.MethodsThis paper provides a meta-analysis of the effectiveness of AWE feedback tools. The literature search yielded 4,462 entries, of which 20 studies (k = 84; N = 2, 828) met the pre-specified inclusion criteria. A moderator analysis investigated the impact of the characteristics of the learner, the intervention, and the outcome measures.ResultsOverall, results based on a three-level model with random effects show a medium effect (g = 0.55) of automated feedback on students' writing performance. However, the significant heterogeneity in the data indicates that the use of automated feedback tools cannot be understood as a single consistent form of intervention. Even though for some of the moderators we found substantial differences in effect sizes, none of the subgroup comparisons were statistically significant.DiscussionWe discuss these findings in light of automated feedback use in educational practice and give recommendations for future research.",2023,10.3389/frai.2023.1162454
The impact of pedagogical beliefs on the adoption of generative AI in higher education: predictive model from UTAUT2,"Artificial Intelligence in Education (AIEd) offers advanced tools that can personalize learning experiences and enhance teachers’ research capabilities. This paper explores the beliefs of 425 university teachers regarding the integration of generative AI in educational settings, utilizing the UTAUT2 model to predict their acceptance and usage patterns through the Partial Least Squares (PLS) method. The findings indicate that performance expectations, effort expectancy, social influence, facilitating conditions, and hedonic motivation all positively impact the intention and behavior related to the use of AIEd. Notably, the study reveals that teachers with constructivist pedagogical beliefs are more inclined to adopt AIEd, underscoring the significance of considering teachers’ attitudes and motivations for the effective integration of technology in education. This research provides valuable insights into the factors influencing teachers’ decisions to embrace AIEd, thereby contributing to a deeper understanding of technology integration in educational contexts. Moreover, the study’s results emphasize the critical role of teachers’ pedagogical orientations in their acceptance and utilization of AI technologies. Constructivist educators, who emphasize student-centered learning and active engagement, are shown to be more receptive to incorporating AIEd tools compared to their transmissive counterparts, who focus on direct instruction and information dissemination. This distinction highlights the need for tailored professional development programs that address the specific beliefs and needs of different teaching philosophies. Furthermore, the study’s comprehensive approach, considering various dimensions of the UTAUT2 model, offers a robust framework for analyzing technology acceptance in education.",2024,10.3389/frai.2024.1497705
Ethics and responsible AI deployment,"As Artificial Intelligence (AI) becomes more prevalent, protecting personal privacy is a critical ethical issue that must be addressed. This article explores the need for ethical AI systems that safeguard individual privacy while complying with ethical standards. By taking a multidisciplinary approach, the research examines innovative algorithmic techniques such as differential privacy, homomorphic encryption, federated learning, international regulatory frameworks, and ethical guidelines. The study concludes that these algorithms effectively enhance privacy protection while balancing the utility of AI with the need to protect personal data. The article emphasises the importance of a comprehensive approach that combines technological innovation with ethical and regulatory strategies to harness the power of AI in a way that respects and protects individual privacy.",2024,10.3389/frai.2024.1377011
Algorithmic Probability-Guided Machine Learning on Non-Differentiable Spaces,"We show how complexity theory can be introduced in machine learning to help bring together apparently disparate areas of current research. We show that this model-driven approach may require less training data and can potentially be more generalizable as it shows greater resilience to random attacks. In an algorithmic space the order of its element is given by its algorithmic probability, which arises naturally from computable processes. We investigate the shape of a discrete algorithmic space when performing regression or classification using a loss function parametrized by algorithmic complexity, demonstrating that the property of differentiation is not required to achieve results similar to those obtained using differentiable programming approaches such as deep learning. In doing so we use examples which enable the two approaches to be compared (small, given the computational power required for estimations of algorithmic complexity). We find and report that 1) machine learning can successfully be performed on a non-smooth surface using algorithmic complexity; 2) that solutions can be found using an algorithmic-probability classifier, establishing a bridge between a fundamentally discrete theory of computability and a fundamentally continuous mathematical theory of optimization methods; 3) a formulation of an algorithmically directed search technique in non-smooth manifolds can be defined and conducted; 4) exploitation techniques and numerical methods for algorithmic search to navigate these discrete non-differentiable spaces can be performed; in application of the (a) identification of generative rules from data observations; (b) solutions to image classification problems more resilient against pixel attacks compared to neural networks; (c) identification of equation parameters from a small data-set in the presence of noise in continuous ODE system problem, (d) classification of Boolean NK networks by(1)network topology, (2) underlying Boolean function, and (3) number of incoming edges.",2021,10.3389/frai.2020.567356
Predicting offer burden to optimize batch sizes in simultaneously expiring kidney offers,"BackgroundTimely and efficient allocation of deceased donor kidneys is a persistent challenge in transplantation. Traditional sequential offer systems often lead to extended delays and high nonuse rates, as many kidneys undergo multiple refusals before being accepted. Simultaneously expiring offers, where a kidney is offered to a batch of centers with synchronized response deadlines, offer a more efficient alternative. However, fixed batch sizes fail to account for variability in offer requirements, potentially introducing new inefficiencies or overwhelming transplant professionals with excessive notifications.MethodsWe investigated the use of machine learning-based survival models to dynamically predict the number of offers a kidney will require before acceptance. Utilizing data on over 16,000 deceased donor kidneys from the national organ offer dataset, we engineered predictive features from both donor profiles and recipient pool characteristics. We trained and evaluated multiple survival models using time-dependent concordance indices along with other survival and regression performance metrics.ResultsThe Random Survival Forest model achieved the best performance, with a time-dependent C-index of 0.882, effectively estimating the required offer volume for kidney placement. Feature importance analysis revealed that waitlist characteristics, such as mean Estimated Post-Transplant Survival (EPTS), mean Calculated Panel Reactive Antibody (CPRA), time on dialysis, and waitlist duration, were among the most influential predictors. When integrated into a dynamic simultaneous offer system, these predictions have the potential to reduce average placement delays from 17.37 h to 1.59 h while maintaining a manageable level of extraneous offers.DiscussionOur results demonstrate that survival-based predictive modeling can meaningfully improve the efficiency of simultaneously expiring offers in kidney allocation. By personalizing batch sizes based on expected offer burden, such models can reduce delays without overwhelming transplant professionals. These findings underscore the value of integrating real-time, data-driven tools into organ allocation systems to improve operational efficiency and facilitate practical implementation.",2025,10.3389/frai.2025.1662960
Learning Systems versus Future Everyday Domestic Life: A Designer’s Interpretation of Social Practice Imaginaries,"Smart home technologies with the ability to learn over time promise to adjust their actions to inhabitants’ unique preferences and circumstances. For example, by learning to anticipate their routines. However, these promises show frictions with the reality of everyday life, which is characterized by its complexity and unpredictability. These systems and their design can thus benefit from meaningful ways of eliciting reflections on potential challenges for integrating learning systems into everyday domestic contexts, both for the inhabitants of the home as for the technologies and their designers. For example, is there a risk that inhabitants’ everyday lives will reshape to accommodate the learning system’s preference for predictability and measurability? To this end, in this paper we build a designer’s interpretation on the Social Practice Imaginaries method as developed by Strengers et al. to create a set of diverse, plausible imaginaries for the year 2030. As a basis for these imaginaries, we have selected three social practices in a domestic context: waking up, doing groceries, and heating/cooling the home. For each practice, we create one imaginary in which the inhabitants’ routine is flawlessly supported by the learning system and one that features everyday crises of that routine. The resulting social practice imaginaries are then viewed through the perspective of the inhabitant, the learning system, and the designer. In doing so, we aim to enable designers and design researchers to uncover a diverse and dynamic set of implications the integration of these systems in everyday life pose.",2021,10.3389/frai.2021.707562
Computational Models of Readers' Apperceptive Mass,"Recent progress in machine-learning-based distributed semantic models (DSMs) offers new ways to simulate the apperceptive mass (AM; Kintsch, 1980) of reader groups or individual readers and to predict their performance in reading-related tasks. The AM integrates the mental lexicon with world knowledge, as for example, acquired via reading books. Following pioneering work by Denhière and Lemaire (2004), here, we computed DSMs based on a representative corpus of German children and youth literature (Jacobs et al., 2020) as null models of the part of the AM that represents distributional semantic input, for readers of different reading ages (grades 1–2, 3–4, and 5–6). After a series of DSM quality tests, we evaluated the performance of these models quantitatively in various tasks to simulate the different reader groups' hypothetical semantic and syntactic skills. In a final study, we compared the models' performance with that of human adult and children readers in two rating tasks. Overall, the results show that with increasing reading age performance in practically all tasks becomes better. The approach taken in these studies reveals the limits of DSMs for simulating human AM and their potential for applications in scientific studies of literature, research in education, or developmental science.",2022,10.3389/frai.2022.718690
Predicting Escherichia coli levels in manure using machine learning in weeping wall and mechanical liquid solid separation systems,"An increased understanding of the interaction between manure management and public and environmental health has led to the development of Alternative Dairy Effluent Management Strategies (ADEMS). The efficiency of such ADEMS can be increased using mechanical solid-liquid-separator (SLS) or gravitational Weeping-Wall (WW) solid separation systems. In this research, using pilot study data from 96 samples, the chemical, physical, biological, seasonal, and structural parameters between SLS and WW of ADEM systems were compared. Parameters including sodium, potassium, total salts, volatile solids, pH, and E. coli levels were significantly different between the SLS and WW of ADEMS. The separated solid fraction of the dairy effluents had the lowest E. coli levels, which could have beneficial downstream implications in terms of microbial pollution control. To predict effluent quality and microbial pollution risk, we used Escherichia coli as the indicator organism, and a versatile machine learning, ensemble, stacked, super-learner model called E-C-MAN (Escherichia coli–Manure) was developed. Using pilot data, the E-C-MAN model was trained, and the trained model was validated with the test dataset. These results demonstrate that the heuristic E-C-MAN ensemble model can provide a pilot framework toward predicting Escherichia coli levels in manure treated by SLS or WW systems.",2023,10.3389/frai.2022.921924
MeaningBERT: assessing meaning preservation between sentences,"In the field of automatic text simplification, assessing whether or not the meaning of the original text has been preserved during simplification is of paramount importance. Metrics relying on n-gram overlap assessment may struggle to deal with simplifications which replace complex phrases with their simpler paraphrases. Current evaluation metrics for meaning preservation based on large language models (LLMs), such as BertScore in machine translation or QuestEval in summarization, have been proposed. However, none has a strong correlation with human judgment of meaning preservation. Moreover, such metrics have not been assessed in the context of text simplification research. In this study, we present a meta-evaluation of several metrics we apply to measure content similarity in text simplification. We also show that the metrics are unable to pass two trivial, inexpensive content preservation tests. Another contribution of this study is MeaningBERT (https://github.com/GRAAL-Research/MeaningBERT), a new trainable metric designed to assess meaning preservation between two sentences in text simplification, showing how it correlates with human judgment. To demonstrate its quality and versatility, we will also present a compilation of datasets used to assess meaning preservation and benchmark our study against a large selection of popular metrics.",2023,10.3389/frai.2023.1223924
Automatic classification of signal regions in 1H Nuclear Magnetic Resonance spectra,"The identification and characterization of signal regions in Nuclear Magnetic Resonance (NMR) spectra is a challenging but crucial phase in the analysis and determination of complex chemical compounds. Here, we present a novel supervised deep learning approach to perform automatic detection and classification of multiplets in 1H NMR spectra. Our deep neural network was trained on a large number of synthetic spectra, with complete control over the features represented in the samples. We show that our model can detect signal regions effectively and minimize classification errors between different types of resonance patterns. We demonstrate that the network generalizes remarkably well on real experimental 1H NMR spectra.",2023,10.3389/frai.2022.1116416
Learning analytics for lifelong career development: a framework to support sustainable formative assessment and self-reflection in programs developing career self-efficacy,"Among myriad complex challenges facing educational institutions in this era of a rapidly evolving job marketplace is the development of career self-efficacy among students. Self-efficacy has traditionally been understood to be developed through the direct experience of competence, the vicarious experience of competence, social persuasion, and physiological cues. These four factors, and particularly the first two, are difficult to build into education and training programs in a context where changing skills make the specific meaning of graduate competence largely unknown and, notwithstanding the other contributions in this collection, largely unknowable. In response, in this paper we argue for a working metacognitive model of career self-efficacy that will prepare students with the skills needed to evaluate their skills, attitudes and values and then adapt and develop them as their career context evolves around them. The model we will present is one of evolving complex sub-systems within an emergent milieu. In identifying various contributing factors, the model provides specific cognitive and affective constructs as important targets for actionable learning analytics for career development.",2023,10.3389/frai.2023.1173099
BioBricks.ai: a versioned data registry for life sciences data assets,"IntroductionResearchers in biomedicine and public health often spend weeks locating, cleansing, and integrating data from disparate sources before analysis can begin. This redundancy slows discovery and leads to inconsistent pipelines.MethodsWe created BioBricks.ai, an open, centralized repository that packages public biological and chemical datasets as modular “bricks.” Each brick is a Data Version Control (DVC) Git repository containing an extract‑transform‑load (ETL) pipeline. A package‑manager–like interface handles installation, dependency resolution, and updates, while data are delivered through a unified backend (https://biobricks.ai).ResultsThe current release provides &gt;90 curated datasets spanning genomics, proteomics, cheminformatics, and epidemiology. Bricks can be combined programmatically to build composite resources; benchmark use‑cases show that assembling multi‑dataset analytic cohorts is reduced from days to minutes compared with bespoke scripts.DiscussionBioBricks.ai accelerates data access, promotes reproducible workflows, and lowers the barrier for integrating heterogeneous public datasets. By treating data as version‑controlled software, the platform encourages community contributions and reduces redundant engineering effort. Continued expansion of brick coverage and automated provenance tracking will further enhance FAIR (Findable, Accessible, Interoperable, Reusable) data practices across the life‑science community.",2025,10.3389/frai.2025.1599412
First deployment of artificial intelligence recommendations in orthopedic surgery,"Scant research has delved into the non-clinical facets of artificial intelligence (AI), concentrating on leveraging data to enhance the efficiency of healthcare systems and operating rooms. Notably, there is a gap in the literature regarding the implementation and outcomes of AI solutions. The absence of published results demonstrating the practical application and effectiveness of AI in domains beyond clinical settings, particularly in the field of surgery, served as the impetus for our undertaking in this area. Within the realm of non-clinical strategies aimed at enhancing operating room efficiency, we characterize OR efficiency as the capacity to successfully perform four uncomplicated arthroplasty surgeries within an 8-h timeframe. This Community Case Study addresses this gap by presenting the results of incorporating AI recommendations at our clinical institute on 228 patient arthroplasty surgeries. The implementation of a prescriptive analytics system (PAS), utilizing supervised machine learning techniques, led to a significant improvement in the overall efficiency of the operating room, increasing it from 39 to 93%. This noteworthy achievement highlights the impact of AI in optimizing surgery workflows.",2024,10.3389/frai.2024.1342234
Technology innovation to reduce health inequality in skin diagnosis and to improve patient outcomes for people of color: a thematic literature review and future research agenda,"The health inequalities experienced by ethnic minorities have been a persistent and global phenomenon. The diagnosis of different types of skin conditions, e.g., melanoma, among people of color is one of such health domains where misdiagnosis can take place, potentially leading to life-threatening consequences. Although Caucasians are more likely to be diagnosed with melanoma, African Americans are four times more likely to present stage IV melanoma due to delayed diagnosis. It is essential to recognize that additional factors such as socioeconomic status and limited access to healthcare services can be contributing factors. African Americans are also 1.5 times more likely to die from melanoma than Caucasians, with 5-year survival rates for African Americans significantly lower than for Caucasians (72.2% vs. 89.6%). This is a complex problem compounded by several factors: ill-prepared medical practitioners, lack of awareness of melanoma and other skin conditions among people of colour, lack of information and medical resources for practitioners’ continuous development, under-representation of people of colour in research, POC being a notoriously hard to reach group, and ‘whitewashed’ medical school curricula. Whilst digital technology can bring new hope for the reduction of health inequality, the deployment of artificial intelligence in healthcare carries risks that may amplify the health disparities experienced by people of color, whilst digital technology may provide a false sense of participation. For instance, Derm Assist, a skin diagnosis phone application which is under development, has already been criticized for relying on data from a limited number of people of color. This paper focuses on understanding the problem of misdiagnosing skin conditions in people of color and exploring the progress and innovations that have been experimented with, to pave the way to the possible application of big data analytics, artificial intelligence, and user-centred technology to reduce health inequalities among people of color.",2024,10.3389/frai.2024.1394386
Predicting patient reported outcome measures: a scoping review for the artificial intelligence-guided patient preference predictor,"BackgroundThe algorithmic patient preference predictor (PPP) has been proposed to aid in decision making for incapacitated patients in the absence of advanced directives. Ethical and legal challenges aside, multiple practical barriers exist for building a personalized PPP. Here, we examine previous work using machine learning to predict patient reported outcome measures (PROMs) for capacitated patients undergoing diverse procedures, therapies, and life events. Demonstrating robust performance in predicting PROMs for capacitated patients could suggest opportunities for developing a model tailored to incapacitated ones.MethodsWe performed a scoping review of PubMed, Embase, and Scopus using the PRISMA-ScR guidelines to capture studies using machine learning to predict PROMs following a medical event alongside qualitative studies exploring a theoretical PPP.ResultsSixty-eight studies used machine learning to evaluate PROMs; an additional 20 studies focused on a theoretical PPP. For PROMs, orthopedic surgeries (n = 33) and spinal surgeries (n = 12) were the most common medical event. Studies used demographic (n = 30), pre-event PROMs (n = 52), comorbidities (n = 29), social determinants of health (n = 30), and intraoperative variables (n = 124) as predictors. Thirty-four different PROMs were used as the target outcome. Evaluation metrics varied by task, but performance was overall poor to moderate for the best reported scores. In models that used feature importance, pre-event PROMs were the most predictive of post-event PROMs. Fairness assessments were rare (n = 6). These findings reinforce the necessity of the integrating patient values and preferences, beyond demographic factors, to improve the development of personalized PPP models for incapacitated patients.ConclusionThe primary objective of a PPP is to estimate patient-reported quality of life following an intervention. Use of machine learning to predict PROMs for capacitated patients introduces challenges and opportunities for building a personalized PPP for incapacitated patients without advanced directives.",2024,10.3389/frai.2024.1477447
Improving the Robustness of Object Detection Through a Multi-Camera–Based Fusion Algorithm Using Fuzzy Logic,"A single camera creates a bounding box (BB) for the detected object with certain accuracy through a convolutional neural network (CNN). However, a single RGB camera may not be able to capture the actual object within the BB even if the CNN detector accuracy is high for the object. In this research, we present a solution to this limitation through the usage of multiple cameras, projective transformation, and a fuzzy logic–based fusion. The proposed algorithm generates a “confidence score” for each frame to check the trustworthiness of the BB generated by the CNN detector. As a first step toward this solution, we created a two-camera setup to detect objects. Agricultural weed is used as objects to be detected. A CNN detector generates BB for each camera when weed is present. Then a projective transformation is used to project one camera’s image plane to another camera’s image plane. The intersect over union (IOU) overlap of the BB is computed when objects are detected correctly. Four different scenarios are generated based on how far the object is from the multi-camera setup, and IOU overlap is calculated for each scenario (ground truth). When objects are detected correctly and bounding boxes are at correct distance, the IOU overlap value should be close to the ground truth IOU overlap value. On the other hand, the IOU overlap value should differ if BBs are at incorrect positions. Mamdani fuzzy rules are generated using this reasoning, and three different confidence scores (“high,” “ok,” and “low”) are given to each frame based on accuracy and position of BBs. The proposed algorithm was then tested under different conditions to check its validity. The confidence score of the proposed fuzzy system for three different scenarios supports the hypothesis that the multi-camera–based fusion algorithm improved the overall robustness of the detection system.",2021,10.3389/frai.2021.638951
Population health management of human phenotype ontology,"AimsPopulation Health Management (PHM), through strategic integration of the Human Phenotype Ontology (HPO), emphasises the responsible use of digital infrastructure and comprehensive genomic data to promote good health and wellbeing. The UK seeks to steward medical science and phenotype practices in primary care settings with technical approaches for developing a national Biological Modelling (BM) ecosystem. By recognising diverse global healthcare systems, this manuscript offers a means for nations to adapt their HPO operational deployment for global PHM harmony.MethodsThe methodological approach incorporates primary care services and funding assessments to address digital infrastructure needs, ensuring secure national data access. Evaluations include ISO standards, systems thinking, alignment of UK infrastructure with informatics requirements, and AI norms within the ecosystem. Specific use cases for genomic predictive health pre-eXams and precise care eXams are assessed, alongside strategies for bias mitigation to ensure fairness in AI-driven classifications.RecommendationsThe manuscript advocates for establishing local agile ecosystem groups for PHM, regional Higher Expert Medical Science Safety (HEMSS) stewardship, national HPO value-based care models, and integrating global PHM general intelligence. Real-world AI and clinical practice comparisons are emphasised for validating digital twin personalised BM via Gen AI in the HPO transformation ecosystem.DiscussionFederated Learning and GPT-5 technologies advance international PHM by supporting HPO transformations. Standard personalised BM learning addresses intranational HPO variances, requiring individual classifications. National HPO roadmaps prioritise inclusiveness and stakeholder engagement, supported by informed consent and quantum intelligence. Ethical and equitable HPO deployment demands proactive stewardship and national cooperation to address limitations and ensure robust classifications.ConclusionUnified, data-driven HPO transformation utilising advanced AI and genomics is essential for personalised healthcare delivery. Rigorous assessments, ethical considerations, and global collaboration enable impactful implementation. National PHM ecosystems guided by HPO transformation in classifications sustain healthcare, advancing patient outcomes through responsible innovation and informed policy development.",2025,10.3389/frai.2025.1496935
A Model of Unified Perception and Cognition,"This article discusses an approach to add perception functionality to a general-purpose intelligent system, NARS. Differently from other AI approaches toward perception, our design is based on the following major opinions: (1) Perception primarily depends on the perceiver, and subjective experience is only partially and gradually transformed into objective (intersubjective) descriptions of the environment; (2) Perception is basically a process initiated by the perceiver itself to achieve its goals, and passive receiving of signals only plays a supplementary role; (3) Perception is fundamentally unified with cognition, and the difference between them is mostly quantitative, not qualitative. The directly relevant aspects of NARS are described to show the implications of these opinions in system design, and they are compared with the other approaches. Based on the research results of cognitive science, it is argued that the Narsian approach better fits the need of perception in Artificial General Intelligence (AGI).",2022,10.3389/frai.2022.806403
Automatic Speech Recognition in Noise for Parkinson's Disease: A Pilot Study,"The sophistication of artificial intelligence (AI) technologies has significantly advanced in the past decade. However, the observed unpredictability and variability of AI behavior in noisy signals is still underexplored and represents a challenge when trying to generalize AI behavior to real-life environments, especially for people with a speech disorder, who already experience reduced speech intelligibility. In the context of developing assistive technology for people with Parkinson's disease using automatic speech recognition (ASR), this pilot study reports on the performance of Google Cloud speech-to-text technology with dysarthric and healthy speech in the presence of multi-talker babble noise at different intensity levels. Despite sensitivities and shortcomings, it is possible to control the performance of these systems with current tools in order to measure speech intelligibility in real-life conditions.",2021,10.3389/frai.2021.809321
Introducing the keyconcept approach to the analysis of language: the case of regulation in COVID-19 diaries,"Using the Mass Observation corpus of 12th of May Diaries, we investigate concepts that are characteristic of the first coronavirus lockdown in the UK. More specifically, we extract and analyse concepts which are distinctive of the discourses produced in May 2020 in relation to concepts used in the 10 previous years, 2010–2019. In the current paper we focus on the concept of regulation, which we identify through a novel approach to querying semantic content in large datasets. Typically, linguists look at keywords to understand differences between two datasets. We demonstrate that taking the perspective of a keyconcept rather than the keyword in linguistic analysis is a beneficial way of identifying trends in broader patterns of thoughts and behaviours which reflect lived-experiences that are particularly prominent of a given dataset, which, in this current paper, is the COVID-19 era dataset. In order to contextualise the keyconcept analysis, we investigate the discourses surrounding the concept of regulation. We find that diarists communicate collective experience of limited individual agency, surrounded by feelings of fear and gratitude. Diarists' reporting on events is often fragmented, focused on new information, and firmly placed in a temporal frame.",2023,10.3389/frai.2023.1176283
SMCFO: a novel cuttlefish optimization algorithm enhanced by simplex method for data clustering,"IntroductionIn unsupervised learning, data clustering is essential. However, many current algorithms have issues like early convergence, inadequate local search capabilities, and trouble processing complicated or unbalanced input. Established methods like Kmeans are still widely used because of their ease of use; however, they struggle with non-spherical cluster shapes, which are sensitive to initialization, and suffer in highdimensional space. As a substitute, metaheuristic algorithms have surfaced as possible options, providing powerful global search ability. The Cuttlefish Optimization Algorithm (CFO) shows promise in clustering applications but suffers from premature convergence and poor local optimization capability.MethodsThis paper introduces a new clustering method based on the Cuttlefish Optimization Algorithm (CFO), which improves upon the Nelder-Mead simplex method known as SMCFO. The method partitions the population into four subgroups with specific update strategies. One subgroup uses the Nelder-Mead method to improve the quality of solutions, while the others attempt to maintain exploration and exploitation equilibrium. This study compares the performance of the suggested SMCFO algorithm with four established clustering algorithms: CFO, PSO, SSO, and SMSHO. The evaluation used 14 datasets, which include two artificial datasets and 12 benchmark datasets sourced from the UCI Machine Learning Repository.Results and discussionThe proposed SMCFO algorithm consistently outperformed competing methods across all datasets, achieving higher clustering accuracy, faster convergence, and improved stability. The robustness of these outcomes was further confirmed through nonparametric statistical tests, which demonstrated that the performance improvements of SMCFO were statistically significant and not due to chance. The results confirm that the simplex-enhanced design boosts local exploitation and stabilizes convergence, which underlies SMCFO's superior performance compared to baseline methods.",2025,10.3389/frai.2025.1677059
Detection of COVID-19 Using Deep Learning Techniques and Cost Effectiveness Evaluation: A Survey,"Graphical-design-based symptomatic techniques in pandemics perform a quintessential purpose in screening hit causes that comparatively render better outcomes amongst the principal radioscopy mechanisms in recognizing and diagnosing COVID-19 cases. The deep learning paradigm has been applied vastly to investigate radiographic images such as Chest X-Rays (CXR) and CT scan images. These radiographic images are rich in information such as patterns and clusters like structures, which are evident in conformance and detection of COVID-19 like pandemics. This paper aims to comprehensively study and analyze detection methodology based on Deep learning techniques for COVID-19 diagnosis. Deep learning technology is a good, practical, and affordable modality that can be deemed a reliable technique for adequately diagnosing the COVID-19 virus. Furthermore, the research determines the potential to enhance image character through artificial intelligence and distinguishes the most inexpensive and most trustworthy imaging method to anticipate dreadful viruses. This paper further discusses the cost-effectiveness of the surveyed methods for detecting COVID-19, in contrast with the other methods. Several finance-related aspects of COVID-19 detection effectiveness of different methods used for COVID-19 detection have been discussed. Overall, this study presents an overview of COVID-19 detection using deep learning methods and their cost-effectiveness and financial implications from the perspective of insurance claim settlement.",2022,10.3389/frai.2022.912022
Machine translation and foreign language education,"Online machine translation tools have great potential to transform foreign language education. This essay will synthesize systematic research on the role of machine translation conducted in the field of educational linguistics. After describing approaches developed that promote the integration of machine translation into language learning environments, the essay will briefly outline lingering concerns associated with the integration of MT tools into educational settings. We will propose future R&amp;D priorities that can generate products based on existing technologies that have the potential to support language learners more optimally compared to existing machine translation tools. We conclude that an acknowledgment of the difficulties of MT tools to handle socio-culturally complex source text would pave the way for the development of MT-based pedagogical tools.",2022,10.3389/frai.2022.936111
Machine Learning Detects Anti-DENV Signatures in Antibody Repertoire Sequences,"Dengue infection is a global threat. As of today, there is no universal dengue fever treatment or vaccines unreservedly recommended by the World Health Organization. The investigation of the specific immune response to dengue virus would support antibody discovery as therapeutics for passive immunization and vaccine design. High-throughput sequencing enables the identification of the multitude of antibodies elicited in response to dengue infection at the sequence level. Artificial intelligence can mine the complex data generated and has the potential to uncover patterns in entire antibody repertoires and detect signatures distinctive of single virus-binding antibodies. However, these machine learning have not been harnessed to determine the immune response to dengue virus. In order to enable the application of machine learning, we have benchmarked existing methods for encoding biological and chemical knowledge as inputs and have investigated novel encoding techniques. We have applied different machine learning methods such as neural networks, random forests, and support vector machines and have investigated the parameter space to determine best performing algorithms for the detection and prediction of antibody patterns at the repertoire and antibody sequence levels in dengue-infected individuals. Our results show that immune response signatures to dengue are detectable both at the antibody repertoire and at the antibody sequence levels. By combining machine learning with phylogenies and network analysis, we generated novel sequences that present dengue-binding specific signatures. These results might aid further antibody discovery and support vaccine design.",2021,10.3389/frai.2021.715462
Artificial intelligence vs. evolving super-complex tumor intelligence: critical viewpoints,"Recent developments in various domains have led to a growing interest in the potential of artificial intelligence to enhance our lives and environments. In particular, the application of artificial intelligence in the management of complex human diseases, such as cancer, has garnered significant attention. The evolution of artificial intelligence is thought to be influenced by multiple factors, including human intervention and environmental factors. Similarly, tumors, being heterogeneous and complex diseases, continue to evolve due to changes in the physical, chemical, and biological environment. Additionally, the concept of cellular intelligence within biological systems has been recognized as a potential attribute of biological entities. Therefore, it is plausible that the tumor intelligence present in cancer cells of affected individuals could undergo super-evolution due to changes in the pro-tumor environment. Thus, a comparative analysis of the evolution of artificial intelligence and super-complex tumor intelligence could yield valuable insights to develop better artificial intelligence-based tools for cancer management.",2023,10.3389/frai.2023.1220744
Direct domain adaptation through reciprocal linear transformations,"We propose a direct domain adaptation (DDA) approach to enrich the training of supervised neural networks on synthetic data by features from real-world data. The process involves a series of linear operations on the input features to the NN model, whether they are from the source or target distributions, as follows: (1) A cross-correlation of the input data (i.e., images) with a randomly picked sample pixel (or pixels) of all images from the input or the mean of all randomly picked sample pixel (or pixels) of all input images. (2) The convolution of the resulting data with the mean of the autocorrelated input images from the other domain. In the training stage, as expected, the input images are from the source distribution, and the mean of auto-correlated images are evaluated from the target distribution. In the inference/application stage, the input images are from the target distribution, and the mean of auto-correlated images are evaluated from the source distribution. The proposed method only manipulates the data from the source and target domains and does not explicitly interfere with the training workflow and network architecture. An application that includes training a convolutional neural network on the MNIST dataset and testing the network on the MNIST-M dataset achieves a 70% accuracy on the test data. A principal component analysis (PCA), as well as t-SNE, shows that the input features from the source and target domains, after the proposed direct transformations, share similar properties along the principal components as compared to the original MNIST and MNIST-M input features.",2022,10.3389/frai.2022.927676
Human-annotated rationales and explainable text classification: a survey,"Asking annotators to explain “why” they labeled an instance yields annotator rationales: natural language explanations that provide reasons for classifications. In this work, we survey the collection and use of annotator rationales. Human-annotated rationales can improve data quality and form a valuable resource for improving machine learning models. Moreover, human-annotated rationales can inspire the construction and evaluation of model-annotated rationales, which can play an important role in explainable artificial intelligence.",2024,10.3389/frai.2024.1260952
"AI in conjunctivitis research: assessing ChatGPT and DeepSeek for etiology, intervention, and citation integrity via hallucination rate analysis","IntroductionThe advent of large language models and their applications have gained significant attention due to their strengths in natural language processing.MethodsIn this study, ChatGPT and DeepSeek are utilized as AI models to assist in diagnosis based on the responses generated to clinical questions. Furthermore, ChatGPT, Claude, and DeepSeek are used to analyze images to assess their potential diagnostic capabilities, applying the various sensitivity analyses described. We employ prompt engineering techniques and evaluate their abilities to generate high quality responses. We propose several prompts and use them to answer important information on conjunctivitis.ResultsOur findings show that DeepSeek excels in offering precise and comprehensive information on specific topics related to conjunctivitis. DeepSeek provides detailed explanations and in depth medical insights. In contrast, the ChatGPT model provides generalized public information on the infection, which makes it more suitable for broader and less technical discussions. In this study, DeepSeek achieved a better performance with a 7% hallucination rate compared to ChatGPT's 13%. Claude demonstrated perfect 100% accuracy in binary classification, significantly outperforming ChatGPT's 62.5% accuracy.DiscussionDeepSeek showed limited performance in understanding images dataset on conjunctivitis. This comparative analysis serves as an insightful reference for scholars and health professionals applying these models in varying medical contexts.",2025,10.3389/frai.2025.1579375
"Shallow Univariate ReLU Networks as Splines: Initialization, Loss Surface, Hessian, and Gradient Flow Dynamics","Understanding the learning dynamics and inductive bias of neural networks (NNs) is hindered by the opacity of the relationship between NN parameters and the function represented. Partially, this is due to symmetries inherent within the NN parameterization, allowing multiple different parameter settings to result in an identical output function, resulting in both an unclear relationship and redundant degrees of freedom. The NN parameterization is invariant under two symmetries: permutation of the neurons and a continuous family of transformations of the scale of weight and bias parameters. We propose taking a quotient with respect to the second symmetry group and reparametrizing ReLU NNs as continuous piecewise linear splines. Using this spline lens, we study learning dynamics in shallow univariate ReLU NNs, finding unexpected insights and explanations for several perplexing phenomena. We develop a surprisingly simple and transparent view of the structure of the loss surface, including its critical and fixed points, Hessian, and Hessian spectrum. We also show that standard weight initializations yield very flat initial functions, and that this flatness, together with overparametrization and the initial weight scale, is responsible for the strength and type of implicit regularization, consistent with previous work. Our implicit regularization results are complementary to recent work, showing that initialization scale critically controls implicit regularization via a kernel-based argument. Overall, removing the weight scale symmetry enables us to prove these results more simply and enables us to prove new results and gain new insights while offering a far more transparent and intuitive picture. Looking forward, our quotiented spline-based approach will extend naturally to the multivariate and deep settings, and alongside the kernel-based view, we believe it will play a foundational role in efforts to understand neural networks. Videos of learning dynamics using a spline-based visualization are available athttp://shorturl.at/tFWZ2.",2022,10.3389/frai.2022.889981
Minimal reduct for propositional circumscription,"Circumscription is an important logic framework for representing and reasoning common-sense knowledge. With efficient implementations for circumscription, including
                    circ2dlp
                    and
                    aspino
                    , it has been widely used in model-based diagnosis and other domains. We propose a notion of minimal reduct for propositional circumscription and prove a characterization theorem,
                    i.e
                    ., that the models of a circumscription can be obtained from the minimal reduct of the circumscription. With the help of the minimal reduct, a new method
                    c
                    irc-reduct for computing models of circumscription is presented. It iteratively computes smaller models under set inclusion (if possible), and the minimal reduct is used to simplify the circumscription in each iteration. The algorithm is proved to be correct. Extensive experiments are conducted on circuit diagnosis ISCAS85, random CNF instances, and some industrial SAT instances for the international SAT competition. These results demonstrate that the minimal reduct is effective in computing circumscription models. Compared to the widely used circumscription solver
                    circ2dlp
                    using the state-of-the-art answer set programming solver
                    clingo
                    , our algorithm
                    circ-reduct
                    achieves significantly shorter CPU time. Compared with
                    aspino
                    using glucose as the internal SAT solver and unsatisfiable core analysis technique, our algorithm achieves better CPU time for random and industrial CNF benchmarks, while it is comparable for circuit diagnosis benchmarks.",2025,10.3389/frai.2025.1614894
Learning with privileged and sensitive information: a gradient-boosting approach,"We consider the problem of learning with sensitive features under the privileged information setting where the goal is to learn a classifier that uses features not available (or too sensitive to collect) at test/deployment time to learn a better model at training time. We focus on tree-based learners, specifically gradient-boosted decision trees for learning with privileged information. Our methods use privileged features as knowledge to guide the algorithm when learning from fully observed (usable) features. We derive the theory, empirically validate the effectiveness of our algorithms, and verify them on standard fairness metrics.",2023,10.3389/frai.2023.1260583
AI alignment is all your need for future drug discovery,"In recent years, the integration of artificial intelligence (AI) with drug discovery has become a promising frontier in biomedical research. However, as artificial intelligence systems become increasingly complex, ensuring their alignment with human values and goals becomes essential. Specifically, combining artificial intelligence systems with human values is crucial for reducing potential risks in the field of drug discovery and maximizing social benefits. This article explores the concepts and challenges related to alignment with artificial intelligence in the context of drug discovery, emphasizing on human-centered approaches to AI development and deployment. We further investigated popular technology frameworks designed for human-centered AI alignment, aimed at improving the robustness and interpretability of AI models. We provide some insights into the challenges of human-centered AI alignment, which represents a significant advancement in addressing robustness and interpretability, thus taking a step forward in the field of AI alignment research. Finally, we discuss strategies for systematically integrating human values into AI-driven drug discovery systems. This article aims to emphasize the importance of AI alignment as a foundational principle in the field of drug discovery and advocate the perspective that “AI alignment is all your need for future drug discovery”.",2025,10.3389/frai.2025.1668794
Smart grading of diabetic retinopathy: an intelligent recommendation-based fine-tuned EfficientNetB0 framework,"Diabetic retinopathy is a condition that affects the retina and causes vision loss due to blood vessel destruction. The retina is the layer of the eye responsible for visual processing and nerve signaling. Diabetic retinopathy causes vision loss, floaters, and sometimes blindness; however, it often shows no warning signals in the early stages. Deep learning-based techniques have emerged as viable options for automated illness classification as large-scale medical imaging datasets have become more widely available. To adapt to medical image analysis tasks, transfer learning makes use of pre-trained models to extract high-level characteristics from natural images. In this research, an intelligent recommendation-based fine-tuned EfficientNetB0 model has been proposed for quick and precise assessment for the diagnosis of diabetic retinopathy from fundus images, which will help ophthalmologists in early diagnosis and detection. The proposed EfficientNetB0 model is compared with three transfer learning-based models, namely, ResNet152, VGG16, and DenseNet169. The experimental work is carried out using publicly available datasets from Kaggle consisting of 3,200 fundus images. Out of all the transfer learning models, the EfficientNetB0 model has outperformed with an accuracy of 0.91, followed by DenseNet169 with an accuracy of 0.90. In comparison to other approaches, the proposed intelligent recommendation-based fine-tuned EfficientNetB0 approach delivers state-of-the-art performance on the accuracy, recall, precision, and F1-score criteria. The system aims to assist ophthalmologists in early detection, potentially alleviating the burden on healthcare units.",2024,10.3389/frai.2024.1396160
Biomimicry as a decision-making methodology in condition monitoring,"In maintenance engineering, effective decision-making is critical to ensuring system reliability and operational efficiency. Modern industrial systems are monitored by a multitude of sensors that generate large volumes of data. However, traditional condition monitoring techniques face several limitations: they rely heavily on high-quality, continuous sensor input, struggle with adaptability to new fault scenarios, require significant computational resources, and often provide limited decision support beyond fault detection. These constraints hinder their practical utility in dynamic and resource-constrained environments. This paper introduces a biomimetics-inspired framework for condition management, drawing on principles observed in natural systems to overcome the aforementioned challenges. Biomimetics, an emerging interdisciplinary field, has shown significant promise in bridging gaps between theoretical innovation and practical industrial application. However, its potential remains underutilized in maintenance decision-making systems. In response, our study proposes a biologically inspired methodology that parallels the human cognitive system, integrating multi-sensory data, adaptive learning, and energy-efficient sensing mechanisms to enhance fault diagnosis and decision-making. The core contributions of this research are fourfold: (1) adaptive intelligence through continuous learning that revises rules and cases over time; (2) multi-sensory integration, inspired by animal sensory systems, to improve diagnostic accuracy; (3) data augmentation techniques that address issues of incomplete or noisy input; and (4) the introduction of energy-efficient sensors and biomimetic optimization strategies suitable for IoT and edge devices. To demonstrate the practical applicability of our approach, we conducted empirical studies using vibration data for procedural analytics, validating the framework's effectiveness in real-world fault diagnosis. It serves as a functional roadmap, inviting broader discussion on the integration of biomimetics in maintenance engineering.",2025,10.3389/frai.2025.1485489
The implementation of artificial intelligence in upper extremity surgery: a systematic review,"IntroductionThe rapid expansion of artificial intelligence (AI) in medicine has led to its increasing integration into upper extremity (UE) orthopedics. The purpose of this systematic review is to investigate the current landscape and impact of AI in the field of UE surgery.MethodsFollowing PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, a systematic search of PubMed was conducted to identify studies incorporating AI in UE surgery. Review articles, letters to the editor, and studies unrelated to AI applications in UE surgery were excluded.ResultsAfter applying inclusion/exclusion criteria, 118 articles were included. The publication years ranged from 2009 to 2024, with a median and mode of 2022 and 2023, respectively. The studies were categorized into six main applications: automated image analysis (36%), surgical outcome prediction (20%), measurement tools (14%), prosthetic limb applications (14%), intraoperative aid (10%), and clinical decision support tools (6%).DiscussionAI is predominantly utilized in image analysis, including radiograph and MRI interpretation, often matching or surpassing clinician accuracy and efficiency. Additionally, AI-powered tools enhance the measurement of range of motion, critical shoulder angles, grip strength, and hand posture, aiding in patient assessment and treatment planning. Surgeons are increasingly leveraging AI for predictive analytics to estimate surgical outcomes, such as infection risk, postoperative function, and procedural costs. As AI continues to evolve, its role in UE surgery is expected to expand, improving decision-making, precision, and patient care.",2025,10.3389/frai.2025.1621757
Federated knee injury diagnosis using few shot learning,"IntroductionKnee injuries, especially Anterior Cruciate Ligament (ACL) tears and meniscus tears, are becoming increasingly common and can severely restrict mobility and quality of life. Early diagnosis is essential for effective treatment and for preventing long-term complications such as knee osteoarthritis. While deep learning approaches have shown promise in identifying knee injuries from MRI scans, they often require large amounts of labeled data, which can be both scarce and privacy-sensitive.MethodsThis paper analyses a hybrid methodology that integrates few-shot learning with federated learning for the diagnosis of knee injuries using MRI scans. The proposed model used a 3DResNet50 architecture as the backbone to enhance both feature extraction and embedding representation. A combined Centralized and Federated Few-Shot Learning Framework is analysed to leverage episodic-intermittent training strategy based on Prototypical Networks. The model is trained incorporating Stochastic Gradient Descent (SGD), Cross-Entropy Loss, and a MultiStep Learning Rate scheduler to enhance few-shot classification. This model also addressed the challenge of limited annotated data ensuring patient data privacy through distributed learning across multiple regions.ResultsThe models performance was evaluated on the MRNet dataset for multi-label classification. In the centralized setting, the model achieved accuracies of 85.3% on axial views, 82.1% on sagittal views, and 71% on coronal views. The propose work attained accuracies as 83% (axial), 83.9% (sagittal), and 65% (coronal), demonstrating the framework’s effectiveness across different learning configurations.DiscussionThe proposed method outperforms in diagnostic accuracy, generalization across MRI planes, and patient privacy via federated learning. However, it faces limitations, including lower coronal view performance and high computational demands due to its complex architecture.",2025,10.3389/frai.2025.1589358
Enhancing AI microscopy for foodborne bacterial classification using adversarial domain adaptation to address optical and biological variability,"AI-enabled microscopy is emerging for rapid bacterial classification, yet its utility remains limited in dynamic or resource-limited settings due to imaging variability. This study aims to enhance the generalizability of AI microscopy using domain adaptation techniques. Six bacterial species, including three Gram-positive (Bacillus coagulans, Bacillus subtilis, Listeria innocua) and three Gram-negative (Escherichia coli, Salmonella Enteritidis, Salmonella Typhimurium), were grown into microcolonies on soft tryptic soy agar plates at 37°C for 3–5 h. Images were acquired under varying microscopy modalities and magnifications. Domain-adversarial neural networks (DANNs) addressed single-target domain variations and multi-DANNs (MDANNs) handled multiple domains simultaneously. EfficientNetV2 backbone provided fine-grained feature extraction suitable for small targets, with few-shot learning enhancing scalability in data-limited domains. The source domain contained 105 images per species (n = 630) collected under optimal conditions (phase contrast, 60 × magnification, 3-h incubation). Target domains introduced variations in modality (brightfield, BF), lower magnification (20 × ), and extended incubation (20x-5h), each with &lt; 5 labeled training images per species (n ≤ 30) and test datasets of 60–90 images. DANNs improved target domain classification accuracy by up to 54.5% for 20 × (34.4% to 88.9%), 43.3% for 20x-5h (40.0% to 83.3%), and 31.7% for BF (43.4% to 73.3%), with minimal accuracy loss in the source domain. MDANNs further improved accuracy in the BF domain from 73.3% to 76.7%. Feature visualizations by Grad-CAM and t-SNE validated the model's ability to learn domain-invariant features across conditions. This study presents a scalable and adaptable framework for bacterial classification, extending the utility of microscopy to decentralized and resource-limited settings where imaging variability often challenges performance.",2025,10.3389/frai.2025.1632344
Facing the Challenges of Developing Fair Risk Scoring Models,"Algorithmic scoring methods are widely used in the finance industry for several decades in order to prevent risk and to automate and optimize decisions. Regulatory requirements as given by the Basel Committee on Banking Supervision (BCBS) or the EU data protection regulations have led to an increasing interest and research activity on understanding black box machine learning models by means of explainable machine learning. Even though this is a step into a right direction, such methods are not able to guarantee for a fair scoring as machine learning models are not necessarily unbiased and may discriminate with respect to certain subpopulations such as a particular race, gender, or sexual orientation—even if the variable itself is not used for modeling. This is also true for white box methods like logistic regression. In this study, a framework is presented that allows analyzing and developing models with regard to fairness. The proposed methodology is based on techniques of causal inference and some of the methods can be linked to methods from explainable machine learning. A definition of counterfactual fairness is given together with an algorithm that results in a fair scoring model. The concepts are illustrated by means of a transparent simulation and a popular real-world example, the German Credit data using traditional scorecard models based on logistic regression and weight of evidence variable pre-transform. In contrast to previous studies in the field for our study, a corrected version of the data is presented and used. With the help of the simulation, the trade-off between fairness and predictive accuracy is analyzed. The results indicate that it is possible to remove unfairness without a strong performance decrease unless the correlation of the discriminative attributes on the other predictor variables in the model is not too strong. In addition, the challenge in explaining the resulting scoring model and the associated fairness implications to users is discussed.",2021,10.3389/frai.2021.681915
A graph neural architecture search approach for identifying bots in social media,"Social media platforms, including X, Facebook, and Instagram, host millions of daily users, giving rise to bots automated programs disseminating misinformation and ideologies with tangible real-world consequences. While bot detection in platform X has been the area of many deep learning models with adequate results, most approaches neglect the graph structure of social media relationships and often rely on hand-engineered architectures. Our work introduces the implementation of a Neural Architecture Search (NAS) technique, namely Deep and Flexible Graph Neural Architecture Search (DFG-NAS), tailored to Relational Graph Convolutional Neural Networks (RGCNs) in the task of bot detection in platform X. Our model constructs a graph that incorporates both the user relationships and their metadata. Then, DFG-NAS is adapted to automatically search for the optimal configuration of Propagation and Transformation functions in the RGCNs. Our experiments are conducted on the TwiBot-20 dataset, constructing a graph with 229,580 nodes and 227,979 edges. We study the five architectures with the highest performance during the search and achieve an accuracy of 85.7%, surpassing state-of-the-art models. Our approach not only addresses the bot detection challenge but also advocates for the broader implementation of NAS models in neural network design automation.",2024,10.3389/frai.2024.1509179
COVID-19 and beyond: leveraging artificial intelligence for enhanced outbreak control,"COVID-19 has brought significant changes to our political, social, and technological landscape. This paper explores the emergence and global spread of the disease and focuses on the role of Artificial Intelligence (AI) in containing its transmission. To the best of our knowledge, there has been no scientific presentation of the early pictorial representation of the disease's spread. Additionally, we outline various domains where AI has made a significant impact during the pandemic. Our methodology involves searching relevant articles on COVID-19 and AI in leading databases such as PubMed and Scopus to identify the ways AI has addressed pandemic-related challenges and its potential for further assistance. While research suggests that AI has not fully realized its potential against COVID-19, likely due to data quality and diversity limitations, we review and identify key areas where AI has been crucial in preparing the fight against any sudden outbreak of the pandemic. We also propose ways to maximize the utilization of AI's capabilities in this regard.",2023,10.3389/frai.2023.1266560
"Assessing medical students’ attitudes, performance, and usage of ChatGPT in Jeddah, Saudi Arabia","BackgroundChatGPT, an advanced AI language model, has the potential to significantly enhance medical education by supporting clinical decision-making, facilitating knowledge acquisition, and improving learning outcomes. However, there remains a gap in understanding the risks and concerns surrounding the use of ChatGPT, as well as its impact on the quality of medical education in Jeddah, Saudi Arabia. This study investigates the role of ChatGPT in local medical education, offering insights into medical students’ attitudes and performance concerning the integration of AI into the medical curriculum.MethodsThis cross-sectional study was conducted from March to May 2024. It was approved by the institutional review board. An online survey was distributed to medical students in Jeddah to collect data on their awareness of ChatGPT and its impact on their attitudes and performance. The survey, which included 28 items across 2 sections was developed. For data analysis, Statistical Package for Social Sciences (SPSS) software (version 27.0) was used to conduct statistical analysis.ResultsThe final sample comprised 420 participants, of whom 84.3% had heard of ChatGPT, while 74.9% had used it prior to the study. The majority of participants were aged 18–21 (50.5%). Higher GPA and academic progression were significantly associated with greater awareness and performance related to ChatGPT. Additionally, privacy concerns, willingness to incorporate ChatGPT into learning and research, and perceptions of its ease of use were significantly correlated, with a p-value &lt; 0.05.ConclusionThe findings indicate a generally positive perception of ChatGPT among medical students, particularly as they progress in their studies. Associations were observed between ChatGPT usage and students’ academic standing and attitudes toward AI. While the ease of use was appreciated, concerns regarding privacy, ethical implications, and data security were also prominent, reflecting global trends. Further longitudinal and experimental research is necessary to better understand the educational implications of ChatGPT and to ensure its responsible integration into medical curricula.",2025,10.3389/frai.2025.1577911
Digital accessibility in the era of artificial intelligence—Bibliometric analysis and systematic review,"IntroductionDigital accessibility involves designing digital systems and services to enable access for individuals, including those with disabilities, including visual, auditory, motor, or cognitive impairments. Artificial intelligence (AI) has the potential to enhance accessibility for people with disabilities and improve their overall quality of life.MethodsThis systematic review, covering academic articles from 2018 to 2023, focuses on AI applications for digital accessibility. Initially, 3,706 articles were screened from five scholarly databases—ACM Digital Library, IEEE Xplore, ScienceDirect, Scopus, and Springer.ResultsThe analysis narrowed down to 43 articles, presenting a classification framework based on applications, challenges, AI methodologies, and accessibility standards.DiscussionThis research emphasizes the predominant focus on AI-driven digital accessibility for visual impairments, revealing a critical gap in addressing speech and hearing impairments, autism spectrum disorder, neurological disorders, and motor impairments. This highlights the need for a more balanced research distribution to ensure equitable support for all communities with disabilities. The study also pointed out a lack of adherence to accessibility standards in existing systems, stressing the urgency for a fundamental shift in designing solutions for people with disabilities. Overall, this research underscores the vital role of accessible AI in preventing exclusion and discrimination, urging a comprehensive approach to digital accessibility to cater to diverse disability needs.",2024,10.3389/frai.2024.1349668
Graph embedding and geometric deep learning relevance to network biology and structural chemistry,"Graphs are used as a model of complex relationships among data in biological science since the advent of systems biology in the early 2000. In particular, graph data analysis and graph data mining play an important role in biology interaction networks, where recent techniques of artificial intelligence, usually employed in other type of networks (e.g., social, citations, and trademark networks) aim to implement various data mining tasks including classification, clustering, recommendation, anomaly detection, and link prediction. The commitment and efforts of artificial intelligence research in network biology are motivated by the fact that machine learning techniques are often prohibitively computational demanding, low parallelizable, and ultimately inapplicable, since biological network of realistic size is a large system, which is characterised by a high density of interactions and often with a non-linear dynamics and a non-Euclidean latent geometry. Currently, graph embedding emerges as the new learning paradigm that shifts the tasks of building complex models for classification, clustering, and link prediction to learning an informative representation of the graph data in a vector space so that many graph mining and learning tasks can be more easily performed by employing efficient non-iterative traditional models (e.g., a linear support vector machine for the classification task). The great potential of graph embedding is the main reason of the flourishing of studies in this area and, in particular, the artificial intelligence learning techniques. In this mini review, we give a comprehensive summary of the main graph embedding algorithms in light of the recent burgeoning interest in geometric deep learning.",2023,10.3389/frai.2023.1256352
Fine-tuning a local LLaMA-3 large language model for automated privacy-preserving physician letter generation in radiation oncology,"IntroductionGenerating physician letters is a time-consuming task in daily clinical practice.MethodsThis study investigates local fine-tuning of large language models (LLMs), specifically LLaMA models, for physician letter generation in a privacy-preserving manner within the field of radiation oncology.ResultsOur findings demonstrate that base LLaMA models, without fine-tuning, are inadequate for effectively generating physician letters. The QLoRA algorithm provides an efficient method for local intra-institutional fine-tuning of LLMs with limited computational resources (i.e., a single 48 GB GPU workstation within the hospital). The fine-tuned LLM successfully learns radiation oncology-specific information and generates physician letters in an institution-specific style. ROUGE scores of the generated summary reports highlight the superiority of the 8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician evaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has limited capacity to generate content beyond the provided input data, it successfully generates salutations, diagnoses and treatment histories, recommendations for further treatment, and planned schedules. Overall, clinical benefit was rated highly by the clinical experts (average score of 3.4 on a 4-point scale).DiscussionWith careful physician review and correction, automated LLM-based physician letter generation has significant practical value.",2025,10.3389/frai.2024.1493716
Guiding principles and proposed classification system for the responsible adoption of artificial intelligence in scientific writing in medicine,"The integration of large language models (LLMs) and artificial intelligence (AI) into scientific writing, especially in medical literature, presents both unprecedented opportunities and inherent challenges. This manuscript evaluates the transformative potential of LLMs for the synthesis of information, linguistic enhancements, and global knowledge dissemination. At the same time, it raises concerns about unintentional plagiarism, the risk of misinformation, data biases, and an over-reliance on AI. To address these, we propose governing principles for AI adoption that ensure integrity, transparency, validity, and accountability. Additionally, guidelines for reporting AI involvement in manuscript development are delineated, and a classification system to specify the level of AI assistance is introduced. This approach uniquely addresses the challenges of AI in scientific writing, emphasizing transparency in authorship, qualification of AI involvement, and ethical considerations. Concerns regarding access equity, potential biases in AI-generated content, authorship dynamics, and accountability are also explored, emphasizing the human author’s continued responsibility. Recommendations are made for fostering collaboration between AI developers, researchers, and journal editors and for emphasizing the importance of AI’s responsible use in academic writing. Regular evaluations of AI’s impact on the quality and biases of medical manuscripts are also advocated. As we navigate the expanding realm of AI in scientific discourse, it is crucial to maintain the human element of creativity, ethics, and oversight, ensuring that the integrity of scientific literature remains uncompromised.",2023,10.3389/frai.2023.1283353
Ontological how and why: action and objective of planned processes in the food domain,"The computational modeling of food processing, aimed at various applications including industrial automation, robotics, food safety, preservation, energy conservation, and recipe nutrition estimation, has been ongoing for decades within food science research labs, industry, and regulatory agencies. The datasets from this prior work have the potential to advance the field of data-driven modeling if they can be harmonized, but this requires a standardized language as a starting point. Our primary goal is to explore two interdependent aspects of this language: the granularity of process modeling sub-parts and parameter details and the substitution of compatible inputs and processes. A delicate semantic distinction—categorizing planned processes based on the objectives they seek to fulfill vs. categorizing them by the actions or mechanisms they utilize—helps organize and facilitate this endeavor. To bring an ontological lens to process modeling, we employ the Open Biological and Biomedical Ontology Foundry ontological framework to organize two main classes of the FoodOn upper-level material processing hierarchy according to objective and mechanism, respectively. We include examples of material processing by mechanism, ranging from abstract ones such as “application of energy” down to specific classes such as “heating by microwave.” Similarly, material processing by objective—often a transformation to bring about materials with certain qualities or composition—can, for example, range from “material processing by heating threshold” to “steaming rice”.",2023,10.3389/frai.2023.1137961
An overview of pink eye infection to evaluate its medications: group decision-making approach with 2-tuple linguistic T-spherical fuzzy WASPAS method,"An infectious eye illness known as pink eye results in ocular redness, irritation, and mucus. Schools are an especially vulnerable region for dissemination because they can propagate that contagious disease quickly via direct or indirect interactions. Choosing the right medication to treat pink eye infection is typically thought of as an intricate multi-attribute group decision-making concern. The goal of this research is to construct a multi-attribute group decision-making framework that assesses six pink eye treatment medications, including Bleph-10, Moxeza, Zymar, Romycin, Polytrim, and Bacticin. The constructed multi-attribute group decision-making framework includes the following scenario: (1) In contrast to other types of fuzzy sets, the 2-tuple linguistic T-spherical fuzzy set (2TLT-SFS) looks to be a potent tool for dealing with informational inconsistencies in decision-making scenarios; (2) in order to render the 2TLT-SF accumulation details processing more flexible, the addition, multiplication, scalar multiplication, and exponential laws that are predicated on the Schweizer-Sklar collection of t-conorms and t-norms are described; (3) the Schweizer-Sklar weighted average and Schweizer-Sklar weighted geometric operators are then put forward employing the aforementioned operations to combine the data; (4) subsequently, using newly developed operators (referred to as 2TLT-SF Schweizer-Sklar weighted average and 2TLT-SF Schweizer-Sklar weighted geometric), this work enhances the conventional weighted aggregated sum product assessment (WASPAS) approach. The computation procedure for this methodology is thoroughly given to rank the alternatives; (5) to confirm the viability of the suggested approach, thorough computational and simulation assessments are conducted. An examination of the developed and existing research is compared to demonstrate the benefits of the suggested analysis.",2025,10.3389/frai.2024.1496689
Adaptive Initialization Method for K-Means Algorithm,"The K-means algorithm is a widely used clustering algorithm that offers simplicity and efficiency. However, the traditional K-means algorithm uses a random method to determine the initial cluster centers, which make clustering results prone to local optima and then result in worse clustering performance. In this research, we propose an adaptive initialization method for the K-means algorithm (AIMK) which can adapt to the various characteristics in different datasets and obtain better clustering performance with stable results. For larger or higher-dimensional datasets, we even leverage random sampling in AIMK (name as AIMK-RS) to reduce the time complexity. 22 real-world datasets were applied for performance comparisons. The experimental results show AIMK and AIMK-RS outperform the current initialization methods and several well-known clustering algorithms. Specifically, AIMK-RS can significantly reduce the time complexity to O (n). Moreover, we exploit AIMK to initialize K-medoids and spectral clustering, and better performance is also explored. The above results demonstrate superior performance and good scalability by AIMK or AIMK-RS. In the future, we would like to apply AIMK to more partition-based clustering algorithms to solve real-life practical problems.",2021,10.3389/frai.2021.740817
Trust Dynamics and Verbal Assurances in Human Robot Physical Collaboration,"Trust is the foundation of successful human collaboration. This has also been found to be true for human-robot collaboration, where trust has also influence on over- and under-reliance issues. Correspondingly, the study of trust in robots is usually concerned with the detection of the current level of the human collaborator trust, aiming at keeping it within certain limits to avoid undesired consequences, which is known as trust calibration. However, while there is intensive research on human-robot trust, there is a lack of knowledge about the factors that affect it in synchronous and co-located teamwork. Particularly, there is hardly any knowledge about how these factors impact the dynamics of trust during the collaboration. These factors along with trust evolvement characteristics are prerequisites for a computational model that allows robots to adapt their behavior dynamically based on the current human trust level, which in turn is needed to enable a dynamic and spontaneous cooperation. To address this, we conducted a two-phase lab experiment in a mixed-reality environment, in which thirty-two participants collaborated with a virtual CoBot on disassembling traction batteries in a recycling context. In the first phase, we explored the (dynamics of) relevant trust factors during physical human-robot collaboration. In the second phase, we investigated the impact of robot’s reliability and feedback on human trust in robots. Results manifest stronger trust dynamics while dissipating than while accumulating and highlight different relevant factors as more interactions occur. Besides, the factors that show relevance as trust accumulates differ from those appear as trust dissipates. We detected four factors while trust accumulates (perceived reliability, perceived dependability, perceived predictability, and faith) which do not appear while it dissipates. This points to an interesting conclusion that depending on the stage of the collaboration and the direction of trust evolvement, different factors might shape trust. Further, the robot’s feedback accuracy has a conditional effect on trust depending on the robot’s reliability level. It preserves human trust when a failure is expected but does not affect it when the robot works reliably. This provides a hint to designers on when assurances are necessary and when they are redundant.",2021,10.3389/frai.2021.703504
Keep Calm and Do Not Carry-Forward: Toward Sensor-Data Driven AI Agent to Enhance Human Learning,"The integration of Multimodal Data (MMD) and embodied learning systems (such as Motion Based Educational Games, MBEG), can help learning researchers to better understand the synergy between students' interactions and their learning experiences. Unfolding the dynamics behind this important synergy can lead to the design of intelligent agents which leverage students' movements and support their learning. However, real-time use of student-generated MMD derived from their interactions with embodied learning systems (MBEG in our case) is challenging and remains under-explored due to its complexity (e.g., handle sensor-data and enable an AI agent to use them). To bridge this gap, we conducted an in-situ study where 40 children, aged 9–12, played MBEG on maths and language development. We automatically, unobtrusively, and continuously monitored students' experiences using eye-tracking glasses, physiological wristbands, and Kinect, during game-play. This allowed us to understand the different cognitive and physiological dimensions of students' progress (right/wrong responses) during the three different stages of the MBEG problem-solving processes, namely the “see-solve-move-respond” (S2MR) cycle. We introduce the novel Carry Forward Effect (CFE); a phenomenon occurring in such games, whereby students propagate, or “carry forward,” the cognitive and physiological effects derived from their MMD, to subsequent phases in the see-solve-move-respond cycle. By identifying moments when the Carry Forward Effect is congruent (or not) to students' learning performance, we uncover opportunities for feedback delivery to encourage or subdue the impact of the CFE. Our results demonstrate the importance of wristband and eye-tracking data as key indicators for prioritizing adaptive feedback to support students in MBEG and emphasize the significance of using MMD to support students' performance in real-time educational settings.",2022,10.3389/frai.2021.713176
I Need a CAVAA: How Conversational Agent Voting Advice Applications (CAVAAs) Affect Users' Political Knowledge and Tool Experience,"In election times, millions of voters consult Voting Advice Applications (VAAs) to learn more about political parties and their standpoints. While VAAs have been shown to enhance political knowledge and increase electoral turnout, research also demonstrates that voters frequently experience comprehension problems when responding to the political attitude statements in a VAA. We describe two studies in which we test a new type of VAA, called Conversational Agent VAA (CAVAA), in which users can easily access relevant information about the political issues in the VAA statements by asking questions to a chatbot. Study 1 reports about an online experiment (N = 229) with a 2 (Type: traditional VAA/CAVAA) x 2 (Political sophistication: low/high) design. Results show that CAVAA users report higher perceived political knowledge scores and also answer more factual knowledge questions correctly than users of a regular VAA. Also, participants' CAVAA experience was evaluated better. In Study 2 (N = 180), we compared three CAVAA designs (a structured design with buttons, a non-structured design with an open text field, and a semi-structured design with both buttons and an open text field), again for higher and lower politically sophisticated users. While the three designs score equally high on factual and perceived knowledge indicators, the experience of the structured CAVAA was evaluated more positively than the non-structured version. To explore the possible cause for these results, we conducted an additional qualitative content analysis on 90 chatbot-conversations (30 per chatbot version). This analysis shows that users more frequently access additional information in a structured design than in a non-structured design, whereas the number of break-offs is the same. This suggests that the structured design delivers the best experience, because it provides the best trigger to ask questions to the chatbot.",2022,10.3389/frai.2022.835505
Chatbots as a Tool to Scale Mentoring Processes: Individually Supporting Self-Study in Higher Education,"Like most curricula in the humanities and social sciences, the curriculum of pre-service teacher training in educational sciences often includes time-consuming reading and writing tasks, which require high quality support and feedback in a timely manner. A well-known way to provide this support to students is one-to-one mentoring. However, limited time and resources in the German university context require to effectively scale the benefits of individual feedback. The use of scalable technologies to support learning processes seems to be promising, but its development usually requires a deep technical understanding. With an interdisciplinary approach, this contribution investigates how personal mentoring can be made available to as many students as possible, taking into account the didactic, organizational and technical frameworks at universities. We describe the development and implementation process of two chatbots that both aim to support students of educational sciences in their self-study of the seminar topics and literature. The chatbots were used by over 700 students during the course of 1 year and our evaluations show promising results that bear the potential to improve the availability of digital mentoring support for all students.",2021,10.3389/frai.2021.668220
Identifying the role of vision transformer for skin cancer—A scoping review,"IntroductionDetecting and accurately diagnosing early melanocytic lesions is challenging due to extensive intra- and inter-observer variabilities. Dermoscopy images are widely used to identify and study skin cancer, but the blurred boundaries between lesions and besieging tissues can lead to incorrect identification. Artificial Intelligence (AI) models, including vision transformers, have been proposed as a solution, but variations in symptoms and underlying effects hinder their performance.ObjectiveThis scoping review synthesizes and analyzes the literature that uses vision transformers for skin lesion detection.MethodsThe review follows the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Revise) guidelines. The review searched online repositories such as IEEE Xplore, Scopus, Google Scholar, and PubMed to retrieve relevant articles. After screening and pre-processing, 28 studies that fulfilled the inclusion criteria were included.Results and discussionsThe review found that the use of vision transformers for skin cancer detection has rapidly increased from 2020 to 2022 and has shown outstanding performance for skin cancer detection using dermoscopy images. Along with highlighting intrinsic visual ambiguities, irregular skin lesion shapes, and many other unwanted challenges, the review also discusses the key problems that obfuscate the trustworthiness of vision transformers in skin cancer diagnosis. This review provides new insights for practitioners and researchers to understand the current state of knowledge in this specialized research domain and outlines the best segmentation techniques to identify accurate lesion boundaries and perform melanoma diagnosis. These findings will ultimately assist practitioners and researchers in making more authentic decisions promptly.",2023,10.3389/frai.2023.1202990
Generalizable Machine Learning in Neuroscience Using Graph Neural Networks,"Although a number of studies have explored deep learning in neuroscience, the application of these algorithms to neural systems on a microscopic scale, i.e. parameters relevant to lower scales of organization, remains relatively novel. Motivated by advances in whole-brain imaging, we examined the performance of deep learning models on microscopic neural dynamics and resulting emergent behaviors using calcium imaging data from the nematode C. elegans. As one of the only species for which neuron-level dynamics can be recorded, C. elegans serves as the ideal organism for designing and testing models bridging recent advances in deep learning and established concepts in neuroscience. We show that neural networks perform remarkably well on both neuron-level dynamics prediction and behavioral state classification. In addition, we compared the performance of structure agnostic neural networks and graph neural networks to investigate if graph structure can be exploited as a favourable inductive bias. To perform this experiment, we designed a graph neural network which explicitly infers relations between neurons from neural activity and leverages the inferred graph structure during computations. In our experiments, we found that graph neural networks generally outperformed structure agnostic models and excel in generalization on unseen organisms, implying a potential path to generalizable machine learning in neuroscience.",2021,10.3389/frai.2021.618372
Exploring the associative learning capabilities of the segmented attractor network for lifelong learning,"This work explores the process of adapting the segmented attractor network to a lifelong learning setting. Taking inspirations from Hopfield networks and content-addressable memory, the segmented attractor network is a powerful tool for associative memory applications. The network's performance as an associative memory is analyzed using multiple metrics. In addition to the network's general hit rate, its capability to recall unique memories and their frequency is also evaluated with respect to time. Finally, additional learning techniques are implemented to enhance the network's recall capacity in the application of lifelong learning. These learning techniques are based on human cognitive functions such as memory consolidation, prediction, and forgetting.",2022,10.3389/frai.2022.910407
An argumentation semantics for rational human evaluation of arguments,"In abstract argumentation theory, many argumentation semantics have been proposed for evaluating argumentation frameworks. This article is based on the following research question: Which semantics corresponds well to what humans consider a rational judgment on the acceptability of arguments? There are two systematic ways to approach this research question: A normative perspective is provided by the principle-based approach, in which semantics are evaluated based on their satisfaction of various normatively desirable principles. A descriptive perspective is provided by the empirical approach, in which cognitive studies are conducted to determine which semantics best predicts human judgments about arguments. In this article, we combine both approaches to motivate a new argumentation semantics called SCF2. For this purpose, we introduce and motivate two new principles and show that no semantics from the literature satisfies both of them. We define SCF2 and prove that it satisfies both new principles. Furthermore, we discuss findings of a recent empirical cognitive study that provide additional support to SCF2.",2023,10.3389/frai.2023.1045663
A topological model for partial equivariance in deep learning and data analysis,"In this article, we propose a topological model to encode partial equivariance in neural networks. To this end, we introduce a class of operators, called P-GENEOs, that change data expressed by measurements, respecting the action of certain sets of transformations, in a non-expansive way. If the set of transformations acting is a group, we obtain the so-called GENEOs. We then study the spaces of measurements, whose domains are subjected to the action of certain self-maps and the space of P-GENEOs between these spaces. We define pseudo-metrics on them and show some properties of the resulting spaces. In particular, we show how such spaces have convenient approximation and convexity properties.",2023,10.3389/frai.2023.1272619
What is in a food store name? Leveraging large language models to enhance food environment data,"IntroductionIt is not uncommon to repurpose administrative food data to create food environment datasets in the health department and research settings; however, the available administrative data are rarely categorized in a way that supports meaningful insight or action, and ground-truthing or manually reviewing an entire city or neighborhood is rate-limiting to essential operations and analysis. We show that such categorizations should be viewed as a classification problem well addressed by recent advances in natural language processing and deep learning—with the advent of large language models (LLMs).MethodsTo demonstrate how to automate the process of categorizing food stores, we use the foundation model BERT to give a first approximation to such categorizations: a best guess by store name. First, 10 food retail classes were developed to comprehensively categorize food store types from a public health perspective.ResultsBased on this rubric, the model was tuned and evaluated (F1micro = 0.710, F1macro = 0.709) on an extensive storefront directory of New York City. Second, the model was applied to infer insights from a large, unlabeled dataset using store names alone, aiming to replicate known temporospatial patterns. Finally, a complimentary application of the model as a data quality enhancement tool was demonstrated on a secondary, pre-labeled restaurant dataset.DiscussionThis novel application of an LLM to the enumeration of the food environment allowed for marked gains in efficiency compared to manual, in-person methods, addressing a known challenge to research and operations in a local health department.",2024,10.3389/frai.2024.1476950
The Applicability of Self-Play Algorithms to Trading and Forecasting Financial Markets,"The central research question to answer in this study is whether the AI methodology of Self-Play can be applied to financial markets. In typical use-cases of Self-Play, two AI agents play against each other in a particular game, e.g., chess or Go. By repeatedly playing the game, they learn its rules as well as possible winning strategies. When considering financial markets, however, we usually have one player—the trader—that does not face one individual adversary but competes against a vast universe of other market participants. Furthermore, the optimal behaviour in financial markets is not described via a winning strategy, but via the objective of maximising profits while managing risks appropriately. Lastly, data issues cause additional challenges, since, in finance, they are quite often incomplete, noisy and difficult to obtain. We will show that academic research using Self-Play has mostly not focused on finance, and if it has, it was usually restricted to stock markets, not considering the large FX, commodities and bond markets. Despite those challenges, we see enormous potential of applying self-play concepts and algorithms to financial markets and economic forecasts.",2021,10.3389/frai.2021.668465
Extended Goal Recognition: Lessons from Magic,"The “science of magic” has lately emerged as a new field of study, providing valuable insights into the nature of human perception and cognition. While most of us think of magic as being all about deception and perceptual “tricks”, the craft—as documented by psychologists and professional magicians—provides a rare practical demonstration and understanding of goal recognition. For the purposes of human-aware planning, goal recognition involves predicting what a human observer is most likely to understand from a sequence of actions. Magicians perform sequences of actions with keen awareness of what an audience will understand from them and—in order to subvert it—the ability to predict precisely what an observer’s expectation is most likely to be. Magicians can do this without needing to know any personal details about their audience and without making any significant modification to their routine from one performance to the next. That is, the actions they perform are reliably interpreted by any human observer in such a way that particular (albeit erroneous) goals are predicted every time. This is achievable because people’s perception, cognition and sense-making are predictably fallible. Moreover, in the context of magic, the principles underlying human fallibility are not only well-articulated but empirically proven. In recent work we demonstrated how aspects of human cognition could be incorporated into a standard model of goal recognition, showing that—even though phenomena may be “fully observable” in that nothing prevents them from being observed—not all are noticed, not all are encoded or remembered, and few are remembered indefinitely. In the current article, we revisit those findings from a different angle. We first explore established principles from the science of magic, then recontextualise and build on our model of extended goal recognition in the context of those principles. While our extensions relate primarily to observations, this work extends and explains the definitions, showing how incidental (and apparently incidental) behaviours may significantly influence human memory and belief. We conclude by discussing additional ways in which magic can inform models of goal recognition and the light that this sheds on the persistence of conspiracy theories in the face of compelling contradictory evidence.",2021,10.3389/frai.2021.730990
Regularization by neural style transfer for MRI field-transfer reconstruction with limited data,"Recent advances in MRI reconstruction have demonstrated remarkable success through deep learning-based models. However, most existing methods rely heavily on large-scale, task-specific datasets, making reconstruction in data-limited settings a critical yet underexplored challenge. While regularization by denoising (RED) leverages denoisers as priors for reconstruction, we propose Regularization by Neural Style Transfer (RNST), a novel framework that integrates a neural style transfer (NST) engine with a denoiser to enable magnetic field-transfer reconstruction. RNST generates high-field-quality images from low-field inputs without requiring paired training data, leveraging style priors to address limited-data settings. Our experiment results demonstrate RNST’s ability to reconstruct high-quality images across diverse anatomical planes (axial, coronal, sagittal) and noise levels, achieving superior clarity, contrast, and structural fidelity compared to lower-field references. Crucially, RNST maintains robustness even when style and content images lack exact alignment, broadening its applicability in clinical environments where precise reference matches are unavailable. By combining the strengths of NST and denoising, RNST offers a scalable, data-efficient solution for MRI field-transfer reconstruction, demonstrating significant potential for resource-limited settings.",2025,10.3389/frai.2025.1579251
Elucidating simulated equivalence responding through dynamic visualization of structural connectivity and relational density,"This article presents Affinity, a visual analytics tool that enhances the simulation of the emergence of derived relations between stimuli in humans. Built on the foundations of a reinforcement learning model called Enhanced Equivalence Projective Simulation, Affinity provides both real-time visualizations of the agent's relational memory and enables the simulation of Relational Density Theory, a novel approach to understanding relational responding through the modeling of higher-order properties of density, volume, and mass. We demonstrate these features in a simulation of a recent study into the quantification of relational volume. We also use this as an opportunity to examine the effect of the underlying model's consolidation mechanism, Network Enhancement, on the agent's relational network. Our results highlight Affinity's innovation as an explainable modeling interface for relational formation and a testbed for new experiments. We discuss the limitations of Affinity in its current state, underline future work on the software and computational modeling of Stimulus Equivalence and locate this contribution in the broader scope of integrations of Contextual Behavioral Science and Artificial Intelligence.",2025,10.3389/frai.2025.1618678
Active learning with human heuristics: an algorithm robust to labeling bias,"Active learning enables prediction models to achieve better performance faster by adaptively querying an oracle for the labels of data points. Sometimes the oracle is a human, for example when a medical diagnosis is provided by a doctor. According to the behavioral sciences, people, because they employ heuristics, might sometimes exhibit biases in labeling. How does modeling the oracle as a human heuristic affect the performance of active learning algorithms? If there is a drop in performance, can one design active learning algorithms robust to labeling bias? The present article provides answers. We investigate two established human heuristics (fast-and-frugal tree, tallying model) combined with four active learning algorithms (entropy sampling, multi-view learning, conventional information density, and, our proposal, inverse information density) and three standard classifiers (logistic regression, random forests, support vector machines), and apply their combinations to 15 datasets where people routinely provide labels, such as health and other domains like marketing and transportation. There are two main results. First, we show that if a heuristic provides labels, the performance of active learning algorithms significantly drops, sometimes below random. Hence, it is key to design active learning algorithms that are robust to labeling bias. Our second contribution is to provide such a robust algorithm. The proposed inverse information density algorithm, which is inspired by human psychology, achieves an overall improvement of 87% over the best of the other algorithms. In conclusion, designing and benchmarking active learning algorithms can benefit from incorporating the modeling of human heuristics.",2024,10.3389/frai.2024.1491932
Dichotomic Pattern Mining Integrated With Constraint Reasoning for Digital Behavior Analysis,"Sequential pattern mining remains a challenging task due to the large number of redundant candidate patterns and the exponential search space. In addition, further analysis is still required to map extracted patterns to different outcomes. In this paper, we introduce a pattern mining framework that operates on semi-structured datasets and exploits the dichotomy between outcomes. Our approach takes advantage of constraint reasoning to find sequential patterns that occur frequently and exhibit desired properties. This allows the creation of novel pattern embeddings that are useful for knowledge extraction and predictive modeling. Based on dichotomic pattern mining, we present two real-world applications for customer intent prediction and intrusion detection. Overall, our approach plays an integrator role between semi-structured sequential data and machine learning models, improves the performance of the downstream task, and retains interpretability.",2022,10.3389/frai.2022.868085
Evaluation of Goal Recognition Systems on Unreliable Data and Uninspectable Agents,"Goal or intent recognition, where one agent recognizes the goals or intentions of another, can be a powerful tool for effective teamwork and improving interaction between agents. Such reasoning can be challenging to perform, however, because observations of an agent can be unreliable and, often, an agent does not have access to the reasoning processes and mental models of the other agent. Despite this difficulty, recent work has made great strides in addressing these challenges. In particular, two Artificial Intelligence (AI)-based approaches to goal recognition have recently been shown to perform well: goal recognition as planning, which reduces a goal recognition problem to the problem of plan generation; and Combinatory Categorical Grammars (CCGs), which treat goal recognition as a parsing problem. Additionally, new advances in cognitive science with respect to Theory of Mind reasoning have yielded an approach to goal recognition that leverages analogy in its decision making. However, there is still much unknown about the potential and limitations of these approaches, especially with respect to one another. Here, we present an extension of the analogical approach to a novel algorithm, Refinement via Analogy for Goal Reasoning (RAGeR). We compare RAGeR to two state-of-the-art approaches which use planning and CCGs for goal recognition, respectively, along two different axes:reliabilityof observations andinspectabilityof the other agent's mental model. Overall, we show that no approach dominates across all cases and discuss the relative strengths and weaknesses of these approaches. Scientists interested in goal recognition problems can use this knowledge as a guide to select the correct starting point for their specific domains and tasks.",2022,10.3389/frai.2021.734521
Artificial intelligence assisted acute patient journey,"Artificial intelligence is taking the world by storm and soon will be aiding patients in their journey at the hospital. The trials and tribulations of the healthcare system during the COVID-19 pandemic have set the stage for shifting healthcare from a physical to a cyber-physical space. A physician can now remotely monitor a patient, admitting them only if they meet certain thresholds, thereby reducing the total number of admissions at the hospital. Coordination, communication, and resource management have been core issues for any industry. However, it is most accurate in healthcare. Both systems and providers are exhausted under the burden of increasing data and complexity of care delivery, increasing costs, and financial burden. Simultaneously, there is a digital transformation of healthcare in the making. This transformation provides an opportunity to create systems of care that are artificial intelligence-enabled. Healthcare resources can be utilized more justly. The wastage of financial and intellectual resources in an overcrowded healthcare system can be avoided by implementing IoT, telehealth, and AI/ML-based algorithms. It is imperative to consider the design principles of the patient's journey while simultaneously prioritizing a better user experience to alleviate physician concerns. This paper discusses the entire blueprint of the AI/ML-assisted patient journey and its impact on healthcare provision.",2022,10.3389/frai.2022.962165
Exploring the performance of automatic speaker recognition using twin speech and deep learning-based artificial neural networks,"This study assessed the influence of speaker similarity and sample length on the performance of an automatic speaker recognition (ASR) system utilizing the SpeechBrain toolkit. The dataset comprised recordings from 20 male identical twin speakers engaged in spontaneous dialogues and interviews. Performance evaluations involved comparing identical twins, all speakers in the dataset (including twin pairs), and all speakers excluding twin pairs. Speech samples, ranging from 5 to 30 s, underwent assessment based on equal error rates (EER) and Log cost-likelihood ratios (Cllr). Results highlight the substantial challenge posed by identical twins to the ASR system, leading to a decrease in overall speaker recognition accuracy. Furthermore, analyses based on longer speech samples outperformed those using shorter samples. As sample size increased, standard deviation values for both intra and inter-speaker similarity scores decreased, indicating reduced variability in estimating speaker similarity/dissimilarity levels in longer speech stretches compared to shorter ones. The study also uncovered varying degrees of likeness among identical twins, with certain pairs presenting a greater challenge for ASR systems. These outcomes align with prior research and are discussed within the context of relevant literature.",2024,10.3389/frai.2024.1287877
"Artificial intelligence in respiratory care: knowledge, perceptions, and practices—a cross-sectional study","BackgroundArtificial intelligence (AI) is reforming healthcare, particularly in respiratory medicine and critical care, by utilizing big and synthetic data to improve diagnostic accuracy and therapeutic benefits. This survey aimed to evaluate the knowledge, perceptions, and practices of respiratory therapists (RTs) regarding AI to effectively incorporate these technologies into the clinical practice.MethodsThe study approved by the institutional review board, aimed at the RTs working in the Kingdom of Saudi Arabia. The validated questionnaire collected reflective insights from 448 RTs in Saudi Arabia. Descriptive statistics, thematic analysis, Fisher’s exact test, and chi-square test were used to evaluate the significance of the data.ResultsThe survey revealed a nearly equal distribution of genders (51% female, 49% male). Most respondents were in the 20–25 age group (54%), held bachelor’s degrees (69%), and had 0–5 years of experience (73%). While 28% had some knowledge of AI, only 8.5% had practical experience. Significant gender disparities in AI knowledge were noted (p &lt; 0.001). Key findings included 59% advocating for basics of AI in the curriculum, 51% believing AI would play a vital role in respiratory care, and 41% calling for specialized AI personnel. Major challenges identified included knowledge deficiencies (23%), skill enhancement (23%), and limited access to training (17%).ConclusionIn conclusion, this study highlights differences in the levels of knowledge and perceptions regarding AI among respiratory care professionals, underlining its recognized significance and futuristic awareness in the field. Tailored education and strategic planning are crucial for enhancing the quality of respiratory care, with the integration of AI. Addressing these gaps is essential for utilizing the full potential of AI in advancing respiratory care practices.",2024,10.3389/frai.2024.1451963
Evaluating the effectiveness of prompt engineering for knowledge graph question answering,"Many different methods for prompting large language models have been developed since the emergence of OpenAI's ChatGPT in November 2022. In this work, we evaluate six different few-shot prompting methods. The first set of experiments evaluates three frameworks that focus on the quantity or type of shots in a prompt: a baseline method with a simple prompt and a small number of shots, random few-shot prompting with 10, 20, and 30 shots, and similarity-based few-shot prompting. The second set of experiments target optimizing the prompt or enhancing shots through Large Language Model (LLM)-generated explanations, using three prompting frameworks: Explain then Translate, Question Decomposition Meaning Representation, and Optimization by Prompting. We evaluate these six prompting methods on the newly created Spider4SPARQL benchmark, as it is the most complex SPARQL-based Knowledge Graph Question Answering (KGQA) benchmark to date. Across the various prompting frameworks used, the commercial model is unable to achieve a score over 51%, indicating that KGQA, especially for complex queries, with multiple hops, set operations and filters remains a challenging task for LLMs. Our experiments find that the most successful prompting framework for KGQA is a simple prompt combined with an ontology and five random shots.",2025,10.3389/frai.2024.1454258
A Synaptic Pruning-Based Spiking Neural Network for Hand-Written Digits Classification,"A spiking neural network model inspired by synaptic pruning is developed and trained to extract features of hand-written digits. The network is composed of three spiking neural layers and one output neuron whose firing rate is used for classification. The model detects and collects the geometric features of the images from the Modified National Institute of Standards and Technology database (MNIST). In this work, a novel learning rule is developed to train the network to detect features of different digit classes. For this purpose, randomly initialized synaptic weights between the first and second layers are updated using average firing rates of pre- and postsynaptic neurons. Then, using a neuroscience-inspired mechanism named, “synaptic pruning” and its predefined threshold values, some of the synapses are deleted. Hence, these sparse matrices named, “information channels” are constructed so that they show highly specific patterns for each digit class as connection matrices between the first and second layers. The “information channels” are used in the test phase to assign a digit class to each test image. In addition, the role of feed-back inhibition as well as the connectivity rates of the second and third neural layers are studied. Similar to the abilities of the humans to learn from small training trials, the developed spiking neural network needs a very small dataset for training, compared to the conventional deep learning methods that have shown a very good performance on the MNIST dataset. This work introduces a new class of brain-inspired spiking neural networks to extract the features of complex data images.",2022,10.3389/frai.2022.680165
Autonomous cyber-physical security middleware for IoT: anomaly detection and adaptive response in hybrid environments,"The rapid adoption of Internet of Things (IoT) devices in cyber-physical systems introduces significant security challenges, particularly in distributed and heterogeneous environments where operational resilience and real-time threat response are critical. Previous efforts have explored lightweight encryption and modular authentication. Still, few solutions provide a unified framework that integrates real-time anomaly detection, automated mitigation, and performance evaluation under hybrid experimental conditions. This work presents an autonomous multi-layered security architecture for IoT networks, implemented through microservices-based middleware with native support for detection and adaptive response mechanisms. The architecture integrates lightweight anomaly inference models, based on entropy metrics and anomaly scores, with a rule-based engine that executes dynamic containment actions such as node isolation, channel reconfiguration, and key rotation. The system runs on edge hardware (Raspberry Pi, sensors, actuators) and is validated in a hybrid testbed with NS-3 simulations. Experimental results show an F1-Score of 0.931 in physical deployments and 0.912 in simulated scenarios, with anomaly detection latencies below 130 ms and containment actions triggered within 300 ms. Under high-load conditions, CPU usage remains under 60 % and memory consumption below 300 MB. Compared to representative middleware platforms such as BlendSM-DDM and Claimsware, the proposed system uniquely integrates detection, response, and auditability, achieving high scalability and resilience for IoT deployments in real-world hybrid environments.",2025,10.3389/frai.2025.1675132
Development and validation of a multi-agent AI pipeline for automated credibility assessment of tobacco misinformation: a proof-of-concept study,"Background
                    The proliferation of tobacco-related misinformation poses significant public health risks, requiring scalable solutions for credibility assessment. Traditional manual fact-checking approaches are resource-intensive and cannot match the pace of misinformation spread.
                  
                  
                    Objective
                    To develop and validate a proof-of-concept multi-agent AI pipeline for automated credibility assessment of tobacco misinformation claims, evaluating its performance against expert human reviewers.
                  
                  
                    Methods
                    We constructed a three-agent pipeline using OpenAI GPT-4.1 and the Crewai framework. The Serper API provided real-time evidence retrieval. The Content Analyzer classifies claims into four types: health impact, scientific assertion, policy, or statistical. The Scientific Fact Verifier queries authoritative sources (WHO, CDC, PubMed Central, Cochrane). The Health Evidence Assessor applies weighted scoring across five dimensions to assign 0–100 credibility scores on a five-level scale.
                  
                  
                    Results
                    
                      The framework achieved an MAE of 6.25 points against expert scores, a weighted Cohen’s
                      κ
                      of 0.68 (95% CI: 0.52–0.84) indicating substantial agreement, 70% exact category agreement, 95% adjacent-level agreement, and processed each claim in under 7 s—over 1,000 × faster than manual review.
                    
                  
                  
                    Limitations
                    
                      We validated our approach using 20 diverse tobacco claims through intensive expert review (2–4 h per claim). The system exhibited a conservative bias (+3.25 points,
                      p
                      = 0.03) and did not classify any claims as “Highly Unlikely” despite expert assignment of two claims to this category. This proof-of-concept demonstrates technical feasibility and substantial inter-rater agreement while identifying areas for calibration in future large-scale implementations.
                    
                  
                  
                    Conclusion
                    Our proof-of-concept agentic AI pipeline demonstrates substantial agreement with expert assessments of tobacco-related claims while providing dramatic speed improvements. By combining zero-shot LLM reasoning, retrieval-grounded evidence verification, and a transparent five-level scoring schema, the system offers a practical tool for real-time misinformation monitoring in public health. This proof-of-concept establishes technical feasibility for automated tobacco misinformation assessment, with validation results supporting further development and larger-scale testing before operational deployment.",2025,10.3389/frai.2025.1659861
Comparative study of machine learning techniques for post-combustion carbon capture systems,"Computational analysis of countercurrent flows in packed absorption columns, often used in solvent-based post-combustion carbon capture systems (CCSs), is challenging. Typically, computational fluid dynamics (CFD) approaches are used to simulate the interactions between a solvent, gas, and column's packing geometry while accounting for the thermodynamics, kinetics, heat, and mass transfer effects of the absorption process. These simulations can then be used explain a column's hydrodynamic characteristics and evaluate its CO2-capture efficiency. However, these approaches are computationally expensive, making it difficult to evaluate numerous designs and operating conditions to improve efficiency at industrial scales. In this work, we comprehensively explore the application of statistical ML methods, convolutional neural networks (CNNs), and graph neural networks (GNNs) to aid and accelerate the scale-up and design optimization of solvent-based post-combustion CCSs. We apply these methods to CFD datasets of countercurrent flows in absorption columns with structured packings characterized by several geometric parameters. We train models to use these parameters, inlet velocity conditions, and other model-specific representations of the column to estimate key determinants of CO2-capture efficiency without having to simulate additional CFD datasets. We also evaluate the impact of different input types on the accuracy and generalizability of each model. We discuss the strengths and limitations of each approach to further elucidate the role of CNNs, GNNs, and other machine learning approaches for CO2-capture property prediction and design optimization.",2024,10.3389/frai.2024.1441934
Predicting BRICS NIFTY50 returns using XAI and S.A.F.E AI lens,"PurposeGlobal fund managers, in their effort toward risk diversification and generating higher returns, design portfolios that consist of financial assets of various countries. In the process, they expose their investors not only to the fundamentals of the assets but also to transnational volatility, macroeconomic shocks of different countries, and exchange rate fluctuations. These factors make forecasting returns from such global funds quite difficult and, at the same time, challenging. To aid global fund managers and investors, this study presents a forecasting framework for predicting returns from Goldman Sachs BRICs Nifty 50 Developed Markets Index (BRICS NIFTY 50), which is a traded and listed financial asset. It is a global portfolio, which not only exposes investors to the fundamentals of different companies but also to country risk.Design, methodology, and approachGradient boosting regression (GBR) and SHAP-based XAI are used to identify the top significant country-specific explanatory variables. Subsequently, with the selected variables, GBR, CatBoost, Light Gradient Boosting Machine (LGBM), Extreme Gradient Boosting (XGBoost), Random Forest (RF), and Extra Tree Regressor (ETR) are applied for forecasting returns from BRICS NIFTY 50. Along with standard evaluation tools, the S.A.F.E AI framework is used for measuring predictive accuracy, sustainability, and contribution of each predictor. To evaluate the relative efficacy of the six predictive models, the underlying research resorts to a multi-criteria decision-making (MCDM) framework.FindingsWe find that country-specific market volatility, industrial performance, financial sector development, and exchange rate fluctuations explain global returns significantly. Furthermore, the exercise also reveals that explanatory factors specific to India, China, and Brazil emerge to be relatively important.Research limitations and implicationsThe study focuses on a single index. Future work will extend it to other indices and global funds.Practical implicationsThe proposed methodology will be of practical use to global fund managers and investors. Policymakers may find it useful for identifying factors that make foreign direct investment and portfolio investment attractive.Originality and valueDevelopment of a two-step forecasting framework, identifying effects of country-specific explanatory variables, and applying different evaluation criteria to measure predictive efficiency underscore the novelty of the work.",2025,10.3389/frai.2025.1668700
A systematic review of the hybrid machine learning models for brain tumour segmentation and detection in medical images,"Early and accurate detection of brain tumours using Magnetic Resonance Imaging (MRI) is critical for effective treatment and improved patient outcomes. This systematic review investigates the application of hybrid machine learning (ML) and deep learning (DL) models in enhancing the computational efficiency and diagnostic accuracy of brain tumour analysis from MRI images. The study synthesizes recent advances in combining traditional ML models such as Support Vector Machines (SVM) with deep neural networks like VGG-19 and YOLOv10n. A PRISMA-based literature search strategy was employed across major databases, including PubMed, Scopus, and IEEE Xplore, selecting 25 relevant studies published between 2019 and 2024. The review evaluates the performance of standalone and hybrid models using metrics such as Dice Similarity Coefficient (DSC), Intersection over Union (IoU), accuracy, precision, recall, and F1-score. Findings indicate that hybrid models, particularly those combining SVM with CNN-based architectures like VGG-19, demonstrate improved classification accuracy and reduced false positives, outperforming single-model approaches. Lightweight versions such as YOLOv10n offer faster inference times suitable for real-time applications while maintaining competitive accuracy. Despite these advances, challenges remain in model generalizability, lack of large, annotated datasets, and limited adoption of Explainable AI (XAI) for interpretability. This review highlights the potential of hybrid models for brain tumour detection and offers recommendations for future research to focus on scalable, interpretable, and clinically deployable solutions.",2025,10.3389/frai.2025.1615550
Chimera: a block-based neural architecture search framework for event-based object detection,"Event-based cameras are sensors inspired by the human eye, offering advantages such as high-speed robustness and low power consumption. Established deep learning techniques have proven effective in processing event data, but there remains a significant space of possibilities that could be further explored to maximize the potential of such combinations. In this context, Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to systematically adapt RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including attention blocks, convolutions, State Space Models, and MLP-mixer-based architectures, providing a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. Results on Prophesee's GEN1 dataset demonstrated state-of-the-art mean Average Precision (mAP) while reducing the number of parameters by 1.6 × and achieving a 2.1 × speed-up. The project is available at: https://github.com/silvada95/Chimera.",2025,10.3389/frai.2025.1644889
Adaptive enhancements of autonomous lane keeping via advanced PER-TD3 framework,"With the advancement of autonomous driving technology, efficient and safe lane-keeping has become one of the core issues in this field. Currently, Deep Reinforcement Learning (DRL) methods still face challenges such as low training efficiency, slow algorithm convergence, and a tendency to fall into local optima when addressing lane-keeping issues. To address these challenges, a Prioritized Experience Replay (PER) mechanism designed to adapt to the learning process of the Twin Delayed Deep Deterministic Policy Gradient (TD3) is proposed, referred to as PER-TD3, to enhance the learning efficiency and lane-keeping performance of the vehicle in this work. It adjusts the probability of a selected sample by utilizing the difference between the predicted Q value and the true Q value to assign priority to different samples. By prioritizing samples with higher errors, the algorithm can correct biases in decision-making more quickly, especially when the vehicle deviates from its lane. In addition, introducing a probabilistic sampling mechanism helps to enhance the diversity of samples, ensuring high-frequency playback of high-value experiences, and enabling vehicles to learn accurate and stable lane-keeping strategies in a shorter period. Validation experiments on the TORCS platform demonstrate that the proposed framework can effectively solve the problem of unbalanced training, which is common in DRL, enhances training sample quality, accelerates algorithm convergence, and ultimately improves driving performance while ensuring safety.",2025,10.3389/frai.2025.1688764
Evaluating and selecting arguments in the context of higher order uncertainty,"Human and artificial reasoning has to deal with uncertain environments. Ideally, probabilistic information is available. However, sometimes probabilistic information may not be precise or it is missing entirely. In such cases we reason with higher-order uncertainty. Formal argumentation is one of the leading formal methods to model defeasible reasoning in artificial intelligence, in particular in the tradition of Dung's abstract argumentation. Also from the perspective of cognition, reasoning has been considered as argumentative and social in nature, for instance by Mercier and Sperber. In this paper we use formal argumentation to provide a framework for reasoning with higher-order uncertainty. Our approach builds strongly on Haenni's system of probabilistic argumentation, but enhances it in several ways. First, we integrate it with deductive argumentation, both in terms of the representation of arguments and attacks, and in terms of utilizing abstract argumentation semantics for selecting some out of a set of possibly conflicting arguments. We show how our system can be adjusted to perform well under the so-called rationality postulates of formal argumentation. Second, we provide several notions of argument strength which are studied both meta-theoretically and empirically. In this way the paper contributes a formal model of reasoning with higher-order uncertainty with possible applications in artificial intelligence and human cognition.",2023,10.3389/frai.2023.1133998
Advancing engineering research through context-aware and knowledge graph–based retrieval-augmented generation,"Large language models (LLMs) are powerful in language understanding and content generation but frequently fall short of technical accuracy when they are applied to engineering code, standards, and design documents. To mitigate this, we are seeing the emergence of Retrieval-Augmented Generation (RAG) models that ground outputs of LLMs with information from external trustworthy resources, increasing the factual consistency. However, traditional RAG techniques are limited in the treatment of isolated information (limited to the amount of information in a fixed-size chunk) and are deemed ill-equipped to traverse semantically linked technical information. This study introduces a collection of new and highly deployable RAG-LLMs built on the n8n automation system and specifically designed for engineering domains. Framework effectiveness was tested on a set of prompts developed with the help of practicing electrical engineering professionals and should be read through the framework’s lens for interpretation of national engineering codes, technical standards, and design standards. To mitigate the shortcomings of the conventional retrieval-based chunking methods, a contextual RAG-based approach is employed to align the retrieved content with the query context to improve relevance. Moreover, RAG is adopted to structure knowledge graph retrieval, which can retrieve densely linked concepts from multiple knowledge graphs, thereby promoting more profound semantic understanding in complex technical domains. The study describes the relative benefits of these improvements, points to practical deployment issues, strengths, and weaknesses. All the n8n workflows employed in this study are made available as supplementary materials to facilitate reproducibility and sharing within the engineering research community and practitioners.",2025,10.3389/frai.2025.1697169
"ChatGPT and reference intervals: a comparative analysis of repeatability in GPT-3.5 Turbo, GPT-4, and GPT-4o","Background
                    Large language models such as ChatGPT hold promise as rapid “curbside consultation” tools in laboratory medicine. However, their ability to generate consistent and clinically reliable reference intervals—particularly in the absence of contextual clinical information—remains uncertain.
                  
                  
                    Method
                    This cross-sectional study evaluated whether three versions of ChatGPT (GPT-3.5-Turbo, GPT-4, GPT-4o) maintain repeatable reference-interval outputs when the prompt intentionally omits the interval, using reference interval variability as a stress-test for model consistency. Standardized prompts were submitted through 726,000 chatbot requests. A total of 246,842 reference intervals across 47 laboratory parameters were then analyzed for consistency using the coefficient of variation (CV) and regression models.
                  
                  
                    Results
                    
                      On average, the chatbots exhibited a CV of 26.50% (IQR: 7.35–129.01%) for the lower limit and 15.82% (IQR: 4.50–45.30%) for the upper limit upon repetition. GPT-4 and GPT-4o demonstrated significantly lower CVs compared to GPT-3.5-Turbo. Reference intervals for poorly standardized parameters were particularly inconsistent across lower (
                      β
                      : 0.6; 95% CI: 0.35 to 0.86;
                      p
                       &lt; 0.001) and upper limit (β: 0.5; 95% CI: 0.28 to 0.71;
                      p
                       &lt; 0.001), while unit expressions also showed variability.
                    
                  
                  
                    Conclusion
                    While the newer ChatGPT versions tested demonstrate improved repeatability, diagnostically unacceptable variability persists, particularly for poorly standardized analytes. Mitigating this requires thoughtful prompt design (e.g., mandatory inclusion of reference intervals), global harmonization of laboratory standards, further model refinement, and robust regulatory oversight. Until then, AI chatbots should be restricted to professional use and trained to refuse laboratory interpretation when reference intervals are not provided by the user.",2025,10.3389/frai.2025.1681979
Matrix Profile-Based Interpretable Time Series Classifier,"Time series classification (TSC) is a pervasive and transversal problem in various fields ranging from disease diagnosis to anomaly detection in finance. Unfortunately, the most effective models used by Artificial Intelligence (AI) systems for TSC are not interpretable and hide the logic of the decision process, making them unusable in sensitive domains. Recent research is focusing on explanation methods to pair with the obscure classifier to recover this weakness. However, a TSC approach that is transparent by design and is simultaneously efficient and effective is even more preferable. To this aim, we propose an interpretable TSC method based on the patterns, which is possible to extract from the Matrix Profile (MP) of the time series in the training set. A smart design of the classification procedure allows obtaining an efficient and effective transparent classifier modeled as a decision tree that expresses the reasons for the classification as the presence of discriminative subsequences. Quantitative and qualitative experimentation shows that the proposed method overcomes the state-of-the-art interpretable approaches.",2021,10.3389/frai.2021.699448
Unsupervised Quark/Gluon Jet Tagging With Poissonian Mixture Models,"The classification of jets induced by quarks or gluons is important for New Physics searches at high-energy colliders. However, available taggers usually rely on modeling the data through Monte Carlo simulations, which could veil intractable theoretical and systematical uncertainties. To significantly reduce biases, we propose an unsupervised learning algorithm that, given a sample of jets, can learn the SoftDrop Poissonian rates for quark- and gluon-initiated jets and their fractions. We extract the Maximum Likelihood Estimates for the mixture parameters and the posterior probability over them. We then construct a quark-gluon tagger and estimate its accuracy in actual data to be in the 0.65–0.7 range, below supervised algorithms but nevertheless competitive. We also show how relevant unsupervised metrics perform well, allowing for an unsupervised hyperparameter selection. Further, we find that this result is not affected by an angular smearing introduced to simulate detector effects for central jets. The presented unsupervised learning algorithm is simple; its result is interpretable and depends on very few assumptions.",2022,10.3389/frai.2022.852970
Comparative performance of large language models in emotional safety classification across sizes and tasks,"Understanding how large language models (LLMs) process emotionally sensitive content is critical for building safe and reliable systems, particularly in mental health contexts. We compare the performance of LLMs of different sizes on two key tasks: trinary classification of emotional safety (safe vs. unsafe vs. borderline) and multi-label classification using a six-category safety risk taxonomy. To support this, we construct a novel dataset by merging several human-authored mental health datasets (&gt; 15K samples) and augmenting them with emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA models (1B, 3B, 8B, 70B) across zero-shot and few-shot settings. Our results show that larger LLMs achieve stronger average performance, particularly in nuanced multi-label classification and in zero-shot settings. However, lightweight fine-tuning allowed the 1B model to achieve performance comparable to larger models and BERT in several high-data categories, while requiring &lt; 2GB VRAM at inference. These findings suggest that smaller, on-device models can serve as viable, privacy-preserving alternatives for sensitive applications, offering the ability to interpret emotional context and maintain safe conversational boundaries. This work highlights key implications for therapeutic LLM applications and the scalable alignment of safety-critical systems.",2025,10.3389/frai.2025.1706090
"TB-Net: A Tailored, Self-Attention Deep Convolutional Neural Network Design for Detection of Tuberculosis Cases From Chest X-Ray Images","Tuberculosis (TB) remains a global health problem, and is the leading cause of death from an infectious disease. A crucial step in the treatment of tuberculosis is screening high risk populations and the early detection of the disease, with chest x-ray (CXR) imaging being the most widely-used imaging modality. As such, there has been significant recent interest in artificial intelligence-based TB screening solutions for use in resource-limited scenarios where there is a lack of trained healthcare workers with expertise in CXR interpretation. Motivated by this pressing need and the recent recommendation by the World Health Organization (WHO) for the use of computer-aided diagnosis of TB in place of a human reader, we introduce TB-Net, a self-attention deep convolutional neural network tailored for TB case screening. We used CXR data from a multi-national patient cohort to train and test our models. A machine-driven design exploration approach leveraging generative synthesis was used to build a highly customized deep neural network architecture with attention condensers. We conducted an explainability-driven performance validation process to validate TB-Net's decision-making behavior. Experiments on CXR data from a multi-national patient cohort showed that the proposed TB-Net is able to achieve accuracy/sensitivity/specificity of 99.86/100.0/99.71%. Radiologist validation was conducted on select cases by two board-certified radiologists with over 10 and 19 years of experience, respectively, and showed consistency between radiologist interpretation and critical factors leveraged by TB-Net for TB case detection for the case where radiologists identified anomalies. The proposed TB-Net not only achieves high tuberculosis case detection performance in terms of sensitivity and specificity, but also leverages clinically relevant critical factors in its decision making process. While not a production-ready solution, we hope that the open-source release of TB-Net as part of the COVID-Net initiative will support researchers, clinicians, and citizen data scientists in advancing this field in the fight against this global public health crisis.",2022,10.3389/frai.2022.827299
Semantic and pragmatic precision in conversational AI systems,"For a conversational agent, to display intelligent interactive behavior implies the ability to respond to the user's intentions and expectations with correct, consistent and relevant actions with appropriate form and content in a timely fashion. In this paper, we present a data-driven analytical approach to embed intelligence into a conversational AI agent. The method requires a certain amount of (ideally) authentic conversational data, which is transformed in a meaningful way to support intelligent dialog modeling and the design of intelligent conversational agents. These transformations rely on the ISO 24617-2 dialog act annotation standard, and are specified in the Dialogue Act Markup Language (DiAML), extended with plug-ins for articulate representations of domain-specific semantic content and customized communicative functionality. ISO 24617-2 is shown to enable systematic in-depth interaction analysis and to facilitate the collection of conversational data of sufficient quality and quantity of instances of interaction phenomena. The paper provides the theoretical and methodological background of extending the ISO standard and DiAML specifications for use in interaction analysis and conversational AI agent design. The expert-assisted design methodology is introduced, with example applications in the healthcare domain, and is validated in human-agent conversational data collection experiments.",2023,10.3389/frai.2023.896729
Development and validation of an interpretable machine learning for mortality prediction in patients with sepsis,"IntroductionSepsis is a leading cause of death. However, there is a lack of useful model to predict outcome in sepsis. Herein, the aim of this study was to develop an explainable machine learning (ML) model for predicting 28-day mortality in patients with sepsis based on Sepsis 3.0 criteria.MethodsWe obtained the data from the Medical Information Mart for Intensive Care (MIMIC)-III database (version 1.4). The overall data was randomly assigned to the training and testing sets at a ratio of 3:1. Following the application of LASSO regression analysis to identify the modeling variables, we proceeded to develop models using Extreme Gradient Boost (XGBoost), Logistic Regression (LR), Support Vector Machine (SVM), and Random Forest (RF) techniques with 5-fold cross-validation. The optimal model was selected based on its area under the curve (AUC). Finally, the Shapley additive explanations (SHAP) method was used to interpret the optimal model.ResultsA total of 5,834 septic adults were enrolled, the median age was 66 years (IQR, 54–78 years) and 2,342 (40.1%) were women. After feature selection, 14 variables were included for developing model in the training set. The XGBoost model (AUC: 0.806) showed superior performance with AUC, compared with RF (AUC: 0.794), LR (AUC: 0.782) and SVM model (AUC: 0.687). SHAP summary analysis for XGBoost model showed that urine output on day 1, age, blood urea nitrogen and body mass index were the top four contributors. SHAP dependence analysis demonstrated insightful nonlinear interactive associations between factors and outcome. SHAP force analysis provided three samples for model prediction.ConclusionIn conclusion, our study successfully demonstrated the efficacy of ML models in predicting 28-day mortality in sepsis patients, while highlighting the potential of the SHAP method to enhance model transparency and aid in clinical decision-making.",2024,10.3389/frai.2024.1348907
Artificial intelligence applied to omics data in liver diseases: Enhancing clinical predictions,"Rapid development of biotechnology has led to the generation of vast amounts of multi-omics data, necessitating the advancement of bioinformatics and artificial intelligence to enable computational modeling to diagnose and predict clinical outcome. Both conventional machine learning and new deep learning algorithms screen existing data unbiasedly to uncover patterns and create models that can be valuable in informing clinical decisions. We summarized published literature on the use of AI models trained on omics datasets, with and without clinical data, to diagnose, risk-stratify, and predict survivability of patients with non-malignant liver diseases. A total of 20 different models were tested in selected studies. Generally, the addition of omics data to regular clinical parameters or individual biomarkers improved the AI model performance. For instance, using NAFLD fibrosis score to distinguish F0-F2 from F3-F4 fibrotic stages, the area under the curve (AUC) was 0.87. When integrating metabolomic data by a GMLVQ model, the AUC drastically improved to 0.99. The use of RF on multi-omics and clinical data in another study to predict progression of NAFLD to NASH resulted in an AUC of 0.84, compared to 0.82 when using clinical data only. A comparison of RF, SVM and kNN models on genomics data to classify immune tolerant phase in chronic hepatitis B resulted in AUC of 0.8793–0.8838 compared to 0.6759–0.7276 when using various serum biomarkers. Overall, the integration of omics was shown to improve prediction performance compared to models built only on clinical parameters, indicating a potential use for personalized medicine in clinical setting.",2022,10.3389/frai.2022.1050439
Deep learning models for the early detection of maize streak virus and maize lethal necrosis diseases in Tanzania,"Agriculture is considered the backbone of Tanzania’s economy, with more than 60% of the residents depending on it for survival. Maize is the country’s dominant and primary food crop, accounting for 45% of all farmland production. However, its productivity is challenged by the limitation to detect maize diseases early enough. Maize streak virus (MSV) and maize lethal necrosis virus (MLN) are common diseases often detected too late by farmers. This has led to the need to develop a method for the early detection of these diseases so that they can be treated on time. This study investigated the potential of developing deep-learning models for the early detection of maize diseases in Tanzania. The regions where data was collected are Arusha, Kilimanjaro, and Manyara. Data was collected through observation by a plant. The study proposed convolutional neural network (CNN) and vision transformer (ViT) models. Four classes of imagery data were used to train both models: MLN, Healthy, MSV, and WRONG. The results revealed that the ViT model surpassed the CNN model, with 93.1 and 90.96% accuracies, respectively. Further studies should focus on mobile app development and deployment of the model with greater precision for early detection of the diseases mentioned above in real life.",2024,10.3389/frai.2024.1384709
Automatic text classification of drug-induced liver injury using document-term matrix and XGBoost,"IntroductionRegulatory agencies generate a vast amount of textual data in the review process. For example, drug labeling serves as a valuable resource for regulatory agencies, such as U.S. Food and Drug Administration (FDA) and Europe Medical Agency (EMA), to communicate drug safety and effectiveness information to healthcare professionals and patients. Drug labeling also serves as a resource for pharmacovigilance and drug safety research. Automated text classification would significantly improve the analysis of drug labeling documents and conserve reviewer resources.MethodsWe utilized artificial intelligence in this study to classify drug-induced liver injury (DILI)-related content from drug labeling documents based on FDA’s DILIrank dataset. We employed text mining and XGBoost models and utilized the Preferred Terms of Medical queries for adverse event standards to simplify the elimination of common words and phrases while retaining medical standard terms for FDA and EMA drug label datasets. Then, we constructed a document term matrix using weights computed by Term Frequency-Inverse Document Frequency (TF-IDF) for each included word/term/token.ResultsThe automatic text classification model exhibited robust performance in predicting DILI, achieving cross-validation AUC scores exceeding 0.90 for both drug labels from FDA and EMA and literature abstracts from the Critical Assessment of Massive Data Analysis (CAMDA).DiscussionMoreover, the text mining and XGBoost functions demonstrated in this study can be applied to other text processing and classification tasks.",2024,10.3389/frai.2024.1401810
Catalyzing IVF outcome prediction: exploring advanced machine learning paradigms for enhanced success rate prognostication,"This study addresses the research problem of enhancing In-Vitro Fertilization (IVF) success rate prediction by integrating advanced machine learning paradigms with gynecological expertise. The methodology involves the analysis of comprehensive datasets from 2017 to 2018 and 2010–2016. Machine learning models, including Logistic Regression, Gaussian NB, SVM, MLP, KNN, and ensemble models like Random Forest, AdaBoost, Logit Boost, RUS Boost, and RSM, were employed. Key findings reveal the significance of patient demographics, infertility factors, and treatment protocols in IVF success prediction. Notably, ensemble learning methods demonstrated high accuracy, with Logit Boost achieving an accuracy of 96.35%. The implications of this research span clinical decision support, patient counseling, and data preprocessing techniques, highlighting the potential for personalized IVF treatments and continuous monitoring. The study underscores the importance of collaboration between gynecologists and data scientists to optimize IVF outcomes. Prospective studies and external validation are suggested as future directions, promising to further revolutionize fertility treatments and offer hope to couples facing infertility challenges.",2024,10.3389/frai.2024.1392611
Machine learning: A non-invasive prediction method for gastric cancer based on a survey of lifestyle behaviors,"Gastric cancer remains an enormous threat to human health. It is extremely significant to make a clear diagnosis and timely treatment of gastrointestinal tumors. The traditional diagnosis method (endoscope, surgery, and pathological tissue extraction) of gastric cancer is usually invasive, expensive, and time-consuming. The machine learning method is fast and low-cost, which breaks through the limitations of the traditional methods as we can apply the machine learning method to diagnose gastric cancer. This work aims to construct a cheap, non-invasive, rapid, and high-precision gastric cancer diagnostic model using personal behavioral lifestyles and non-invasive characteristics. A retrospective study was implemented on 3,630 participants. The developed models (extreme gradient boosting, decision tree, random forest, and logistic regression) were evaluated by cross-validation and the generalization ability in our test set. We found that the model developed using fingerprints based on the extreme gradient boosting (XGBoost) algorithm produced better results compared with the other models. The overall accuracy of which test set was 85.7%, AUC was 89.6%, sensitivity 78.7%, specificity 76.9%, and positive predictive values 73.8%, verifying that the proposed model has significant medical value and good application prospects.",2022,10.3389/frai.2022.956385
Topic modeling and social network analysis approach to explore diabetes discourse on Twitter in India,"IntroductionThe utilization of social media presents a promising avenue for the prevention and management of diabetes. To effectively cater to the diabetes-related knowledge, support, and intervention needs of the community, it is imperative to attain a deeper understanding of the extent and content of discussions pertaining to this health issue. This study aims to assess and compare various topic modeling techniques to determine the most effective model for identifying the core themes in diabetes-related tweets, the sources responsible for disseminating this information, the reach of these themes, and the influential individuals within the Twitter community in India.MethodsTwitter messages from India, dated between 7 November 2022 and 28 February 2023, were collected using the Twitter API. The unsupervised machine learning topic models, namely, Latent Dirichlet Allocation (LDA), non-negative matrix factorization (NMF), BERTopic, and Top2Vec, were compared, and the best-performing model was used to identify common diabetes-related topics. Influential users were identified through social network analysis.ResultsThe NMF model outperformed the LDA model, whereas BERTopic performed better than Top2Vec. Diabetes-related conversations revolved around eight topics, namely, promotion, management, drug and personal story, consequences, risk factors and research, raising awareness and providing support, diet, and opinion and lifestyle changes. The influential nodes identified were mainly health professionals and healthcare organizations.DiscussionThe study identified important topics of discussion along with health professionals and healthcare organizations involved in sharing diabetes-related information with the public. Collaborations among influential healthcare organizations, health professionals, and the government can foster awareness and prevent noncommunicable diseases.",2024,10.3389/frai.2024.1329185
A Recommender for Research Collaborators Using Graph Neural Networks,"As most great discoveries and advancements in science and technology invariably involve the cooperation of a group of researchers, effective collaboration is the key factor. Nevertheless, finding suitable scholars and researchers to work with is challenging and, mostly, time-consuming for many. A recommender who is capable of finding and recommending collaborators would prove helpful. In this work, we utilized a life science and biomedical research database, i.e., MEDLINE, to develop a collaboration recommendation system based on novel graph neural networks, i.e., GraphSAGE and Temporal Graph Network, which can capture intrinsic, complex, and changing dependencies among researchers, including temporal user–user interactions. The baseline methods based on LightGCN and gradient boosting trees were also developed in this work for comparison. Internal automatic evaluations and external evaluations through end-users' ratings were conducted, and the results revealed that our graph neural networks recommender exhibits consistently encouraging results.",2022,10.3389/frai.2022.881704
"Understanding acceptance and resistance toward generative AI technologies: a multi-theoretical framework integrating functional, risk, and sociolegal factors","This study explores the factors influencing college students’ acceptance and resistance toward generative AI technologies by integrating three theoretical frameworks: the Technology Acceptance Model (TAM), Protection Motivation Theory (PMT), and Social Exchange Theory (SET). Using data from 407 respondents collected through a structured survey, the study employed Structural Equation Modeling (SEM) to examine how functional factors (perceived usefulness, ease of use, and reliability), risk factors (privacy concerns, data security, and ethical issues), and sociolegal factors (trust in governance and regulatory frameworks) impact user attitudes. Results revealed that functional factors significantly enhanced acceptance while reducing resistance, whereas risk factors amplified resistance and negatively influenced acceptance. Sociolegal factors emerged as critical mediators, mitigating the negative impact of perceived risks and reinforcing the positive effects of functional perceptions. The study responds to prior feedback by offering a more integrated theoretical framework, clearly articulating how TAM, PMT, and SET interact to shape user behavior. It also acknowledges the limitations of using a student sample and discusses the broader applicability of the findings to other demographics, such as professionals and non-academic users. Additionally, the manuscript now highlights demographic diversity, including variations in age, gender, and academic discipline, as relevant to AI adoption patterns. Ethical concerns, including algorithmic bias, data ownership, and the labor market impact of AI, are addressed to offer a more holistic understanding of resistance behavior. Policy implications have been expanded with actionable recommendations such as AI bias mitigation strategies, clearer data ownership protections, and workforce reskilling programs. The study also compares global regulatory frameworks like the GDPR and the U.S. AI Bill of Rights, reinforcing its practical relevance. Furthermore, it emphasizes that user attitudes toward AI are dynamic and likely to evolve, suggesting the need for longitudinal studies to capture behavioral adaptation over time. By bridging theory and practice, this research contributes to the growing discourse on responsible and equitable AI adoption in higher education, offering valuable insights for developers, policymakers, and academic institutions aiming to foster ethical and inclusive technology integration.",2025,10.3389/frai.2025.1565927
Adaptive Neuro-Fuzzy Inference System guided objective function parameter optimization for inverse treatment planning,"Intensity-Modulated Radiation Therapy requires the manual adjustment to numerous treatment plan parameters (TPPs) through a trial-and-error process to deliver precise radiation doses to the target while minimizing exposure to surrounding healthy tissues. The goal is to achieve a dose distribution that adheres to a prescribed plan tailored to each patient. Developing an automated approach to optimize patient-specific prescriptions is valuable in scenarios where trade-off selection is uncertain and varies among patients. This study presents a proof-of-concept artificial intelligence (AI) system based on an Adaptive Neuro-Fuzzy Inference System (ANFIS) to guide IMRT planning and achieve optimal, patient-specific prescriptions in aligned with a radiation oncologist's treatment objectives. We developed an in-house ANFIS-AI system utilizing Prescription Dose (PD) constraints to guide the optimization process toward achievable prescriptions. Mimicking human planning behavior, the AI system adjusts TPPs, represented as dose-volume constraints, to meet the prescribed dose goals. This process is informed by a Fuzzy Inference System (FIS) that incorporates prior knowledge from experienced planners, captured through “if-then” rules based on routine planning adjustments. The innovative aspect of our research lies in employing ANFIS's adaptive network to fine-tune the FIS components (membership functions and rule strengths), thereby enhancing the accuracy of the system. Once calibrated, the AI system modifies TPPs for each patient, progressing through acceptable prescription levels, from restrictive to clinically allowable. The system evaluates dosimetric parameters and compares dose distributions, dose-volume histograms, and dosimetric statistics between the conventional FIS and ANFIS. Results demonstrate that ANFIS consistently met dosimetric goals, outperforming FIS with a 0.7% improvement in mean dose conformity for the planning target volume (PTV) and a 28% reduction in mean dose exposure for organs at risk (OARs) in a C-Shape phantom. In a mock prostate phantom, ANFIS reduced the mean dose by 17.4% for the rectum and by 14.1% for the bladder. These findings highlight ANFIS's potential for efficient, accurate IMRT planning and its integration into clinical workflows.",2025,10.3389/frai.2025.1523390
Modelling Speaker Attribution in Narrative Texts With Biased and Bias-Adjustable Neural Networks,"Literary narratives regularly contain passages that different readers attribute to different speakers: a character, the narrator, or the author. Since literary narratives are highly ambiguous constructs, it is often impossible to decide between diverging attributions of a specific passage by hermeneutic means. Instead, we hypothesise that attribution decisions are often influenced by annotator bias, in particular an annotator's literary preferences and beliefs. We present first results on the correlation between the literary attitudes of an annotator and their attribution choices. In a second set of experiments, we present a neural classifier that is capable of imitating individual annotators as well as a common-sense annotator, and reaches accuracies of up to 88% (which improves the majority baseline by 23%).",2022,10.3389/frai.2021.725321
Speech phoneme and spectral smearing based non-invasive COVID-19 detection,"COVID-19 is a deadly viral infection that mainly affects the nasopharyngeal and oropharyngeal cavities before the lung in the human body. Early detection followed by immediate treatment can potentially reduce lung invasion and decrease fatality. Recently, several COVID-19 detections methods have been proposed using cough and breath sounds. However, very little study has been done on the use of phoneme analysis and the smearing of the audio signal in COVID-19 detection. In this paper, this problem has been addressed and the classification of speech samples has been carried out in COVID-19-positive and healthy audio samples. Additionally, the grouping of the phonemes based on reference classification accuracies have been proposed for effectiveness and faster detection of the disease at a primary stage. The Mel and Gammatone Cepstral coefficients and their derivatives are used as the features for five standard machine learning-based classifiers. It is observed that the generalized additive model provides the highest accuracy of 97.22% for the phoneme grouping “/t//r//n//g//l/.” This smearing-based phoneme classification technique can also be used in the future to classify other speech-related disease detections.",2023,10.3389/frai.2022.1035805
Distributional Measures of Semantic Abstraction,"This article provides an in-depth study of distributional measures for distinguishing between degrees ofsemantic abstraction. Abstraction is considered a “central construct in cognitive science” (Barsalou, 2003) and a “process of information reduction that allows for efficient storage and retrieval of central knowledge” (Burgoon et al., 2013). Relying on the distributional hypothesis, computational studies have successfully exploited measures of contextual co-occurrence and neighbourhood density to distinguish between conceptual semantic categorisations. So far, these studies have modeled semantic abstraction across lexical-semantic tasks such as ambiguity; diachronic meaning changes; abstractness vs. concreteness; and hypernymy. Yet, the distributional approaches target different conceptual types of semantic relatedness, and as to our knowledge not much attention has been paid to apply, compare or analyse the computational abstraction measures across conceptual tasks. The current article suggests a novel perspective that exploits variants of distributional measures to investigate semantic abstraction in English in terms of the abstract–concrete dichotomy (e.g.,glory–banana) and in terms of the generality–specificity distinction (e.g.,animal–fish), in order to compare the strengths and weaknesses of the measures regarding categorisations of abstraction, and to determine and investigate conceptual differences.In a series of experiments we identify reliable distributional measures for both instantiations of lexical-semantic abstraction and reach a precision higher than 0.7, but the measures clearly differ for the abstract–concrete vs. abstract–specific distinctions and for nouns vs. verbs. Overall, we identify two groups of measures, (i) frequency and word entropy when distinguishing between more and less abstract words in terms of the generality–specificity distinction, and (ii) neighbourhood density variants (especially target–context diversity) when distinguishing between more and less abstract words in terms of the abstract–concrete dichotomy. We conclude that more general words are used more often and are less surprising than more specific words, and that abstract words establish themselves empirically in semantically more diverse contexts than concrete words. Finally, our experiments once more point out that distributional models of conceptual categorisations need to take word classes and ambiguity into account: results for nouns vs. verbs differ in many respects, and ambiguity hinders fine-tuning empirical observations.",2022,10.3389/frai.2021.796756
Share buybacks: a theoretical exploration of genetic algorithms and mathematical optionality,"This article exclusively formulates and presents three innovative hypotheses related to the execution of share buybacks, employing Genetic Algorithms (GAs) and mathematical optimization techniques. Drawing on the foundational contributions of scholars such as Osterrieder, Seigne, Masters, and Guéant, we articulate hypotheses that aim to bring a fresh perspective to share buyback strategies. The first hypothesis examines the potential of GAs to mimic trading schedules, the second posits the optimization of buyback execution as a mathematical problem, and the third underlines the role of optionality in improving performance. These hypotheses do not only offer theoretical insights but also set the stage for empirical examination and practical application, contributing to broader financial innovation. The article does not contain new data or extensive reviews but focuses purely on presenting these original, untested hypotheses, sparking intrigue for future research and exploration.JEL ClassificationG00.",2023,10.3389/frai.2023.1276804
Artificial neural network-assisted prediction of radiobiological indices in head and neck cancer,"Background and purposeWe proposed an artificial neural network model to predict radiobiological parameters for the head and neck squamous cell carcinoma patients treated with radiation therapy. The model uses the tumor specification, demographics, and radiation dose distribution to predict the tumor control probability and the normal tissue complications probability. These indices are crucial for the assessment and clinical management of cancer patients during treatment planning.MethodsTwo publicly available datasets of 31 and 215 head and neck squamous cell carcinoma patients treated with conformal radiation therapy were selected. The demographics, tumor specifications, and radiation therapy treatment parameters were extracted from the datasets used as inputs for the training of perceptron. Radiobiological indices are calculated by open-source software using dosevolume histograms from radiation therapy treatment plans. Those indices were used as output in the training of a single-layer neural network. The distribution of data used for training, validation, and testing purposes was 70, 15, and 15%, respectively.ResultsThe best performance of the neural network was noted at epoch number 32 with the mean squared error of 0.0465. The accuracy of the prediction of radiobiological indices by the artificial neural network in training, validation, and test phases were determined to be 0.89, 0.87, and 0.82, respectively. We also found that the percentage volume of parotid inside the planning target volume is the significant parameter for the prediction of normal tissue complications probability.ConclusionWe believe that the model has significant potential to predict radiobiological indices and help clinicians in treatment plan evaluation and treatment management of head and neck squamous cell carcinoma patients.",2024,10.3389/frai.2024.1329737
One size fits all: Enhanced zero-shot text classification for patient listening on social media,"Patient-focused drug development (PFDD) represents a transformative approach that is reshaping the pharmaceutical landscape by centering on patients throughout the drug development process. Recent advancements in Artificial Intelligence (AI), especially in Natural Language Processing (NLP), have enabled the analysis of vast social media datasets, also called Social Media Listening (SML), providing insights not only into patient perspectives but also into those of other interest groups such as caregivers. In this method study, we propose an NLP framework that—given a particular disease—is designed to extract pertinent information related to three primary research topics: identification of interest groups, understanding of challenges, and assessing treatments and support systems. Leveraging external resources like ontologies and employing various NLP techniques, particularly zero-shot text classification, the presented framework yields initial meaningful insights into these research topics with minimal annotation effort.",2025,10.3389/frai.2024.1397470
Building One-Shot Semi-Supervised (BOSS) Learning Up to Fully Supervised Performance,"Reaching the performance of fully supervised learning with unlabeled data and only labeling one sample per class might be ideal for deep learning applications. We demonstrate for the first time the potential for building one-shot semi-supervised (BOSS) learning on CIFAR-10 and SVHN up to attain test accuracies that are comparable to fully supervised learning. Our method combines class prototype refining, class balancing, and self-training. A good prototype choice is essential and we propose a technique for obtaining iconic examples. In addition, we demonstrate that class balancing methods substantially improve accuracy results in semi-supervised learning to levels that allow self-training to reach the level of fully supervised learning performance. Our experiments demonstrate the value with computing and analyzing test accuracies for every class, rather than only a total test accuracy. We show that our BOSS methodology can obtain total test accuracies with CIFAR-10 images and only one labeled sample per class up to 95% (compared to 94.5% for fully supervised). Similarly, the SVHN images obtains test accuracies of 97.8%, compared to 98.27% for fully supervised. Rigorous empirical evaluations provide evidence that labeling large datasets is not necessary for training deep neural networks. Our code is available at https://github.com/lnsmith54/BOSS to facilitate replication.",2022,10.3389/frai.2022.880729
Deep treasury management for banks,"Retail banks use Asset Liability Management (ALM) to hedge interest rate risk associated with differences in maturity and predictability of their loan and deposit portfolios. The opposing goals of profiting from maturity transformation and hedging interest rate risk while adhering to numerous regulatory constraints make ALM a challenging problem. We formulate ALM as a high-dimensional stochastic control problem in which monthly investment and financing decisions drive the evolution of the bank's balance sheet. To find strategies that maximize long-term utility in the presence of constraints and stochastic interest rates, we train neural networks that parametrize the decision process. Our experiments provide practical insights and demonstrate that the approach of Deep ALM deduces dynamic strategies that outperform static benchmarks.",2023,10.3389/frai.2023.1120297
Quantification: The View From Natural Language Generation,"Quantification is one of the central topics in language and computation, and the interplay of collectivity, distributivity, cumulativity, and plurality is at the heart of the semantics of quantification expressions. However, its aspects are usually discussed piecemeal, distributed, and only from an interpretative perspective with selected linguistic examples, often blurring the overall picture. In this article, quantification phenomena are investigated from the perspective of natural language generation. Starting with a small-scale, but realistic scenario, the necessary steps toward generating quantifier expressions for a perceived situation are explained. Together with the automatically generated descriptions of the scenario, the observations made are shown to present new insights into the interplay, and the semantics of quantification expressions and plurals, in general. The results highlight the importance of taking different points of view in the field of language and computation.",2021,10.3389/frai.2021.627177
Exploring the surveillance technology discourse: a bibliometric analysis and topic modeling approach,"The prevention of crime is a multifaceted challenge with legal, political, and cultural implications. Surveillance technologies play a crucial role in assisting law enforcement and other relevant parties in this mission. Drones, cameras, and wiretaps are examples of such devices. As their use increases, it becomes essential to address related challenges involving various stakeholders and consider cultural, political, and legal aspects. The objective of this study was to analyze the impact of surveillance technologies and identify commonalities and differences in perspectives among social media users and researchers. Data extraction was performed from two platforms: Scopus (for academic research papers) and platform X (formerly known as Twitter). The dataset included 88,989 tweets and 4,874 research papers. Topic modeling, an unsupervised machine learning approach, was applied to analyze the content. The research results revealed that privacy received little attention across the datasets, indicating its relatively low prominence. The military applications and their usage have been documented in academic research articles as well as tweets. Based on the empirical evidence, it seems that contemporary surveillance technology may be accurately described as possessing a bi-directional nature, including both sousveillance and surveillance, which aligns with Deleuzian ideas on the Panopticon. The study’s findings also indicate that there was a greater level of interest in actual applications of surveillance technologies as opposed to more abstract concepts like ethics and privacy.",2024,10.3389/frai.2024.1406361
BlendNet: a blending-based convolutional neural network for effective deep learning of electrocardiogram signals,"IntroductionIn recent years, Deep Learning (DL) architectures such as Convolutional Neural Network (CNN) and its variants have been shown to be effective in the diagnosis of cardiovascular disease from ElectroCardioGram (ECG) signals. In the case of ECG as a one-dimensional signal, 1-D CNNs are deployed, whereas in the case of a 2D-represented ECG signal, i.e., two-dimensional signal, 2-D CNNs or other relevant architectures are deployed. Since 2D-represented ECG signals facilitate better feature extraction, it is a common practice to convert an ECG signal into a scalogram image using a continuous wavelet transform (CWT) approach and then subject it to a DL architecture such as 2-D CNN. However, this traditional approach captures only a limited set of features of ECG and thereby limits the effectiveness of DL architectures in disease detection.MethodsThis work proposes “BlendNet,” a DL architecture that effectively extracts the features of an ECG signal using a blending approach termed “alpha blending.” First, the 1-D ECG signal is converted into a scalogram image using CWT, and a binary version of the scalogram image is also obtained. Then, both the scalogram and binary images are subjected to a sequence of convolution and pooling layers, and the resulting feature images are blended. This blended feature image is subjected to a dense layer that classifies the image. The blending is flexible, and it is controlled by a parameter α, hence the process is termed as alpha blending. The utilization of alpha blending facilitates the generation of a composite feature set that incorporates different characteristics from both the scalogram and binary versions.ResultsFor experiments, a total of 162 ECG recordings from the PhysioNet database were used. Experimental results and analysis show that, in the case of α = 0.7, BlendNet's performance surpasses the performance of (i) traditional approaches (that do not involve blending) and (ii) state-of-the-art approaches for ECG classification.DiscussionExperimental outcomes show that the proposed BlendNet is flexible regarding dense layer settings and can accommodate faster alternatives [i.e., machine learning (ML) algorithms] for faster convergence. The superior performance at α = 0.7 indicates that alpha blending allows for richer composite feature sets, leading to improved classification accuracy over conventional feature extraction and classification methods.",2025,10.3389/frai.2025.1625637
Classification of patients with early-stage multiple sclerosis and healthy controls using kinematic analysis during a dual-task,"Multiple sclerosis (MS) is the disabling neurological disease that currently most affects young people. Changes in gait significantly impact the functionality and independence of these individuals. This study aimed to differentiate between patients in the early stages of MS and healthy controls using machine learning in angular gait variables. This cross-sectional observational study included 38 participants, 19 with MS and 19 in the healthy control group (without neurological or orthopedic diseases). For movement analysis, a three-dimensional gait examination was conducted on patients with EDSS (Expanded Disability Status Scale) scores below 3.5 and healthy volunteers during normal gait and while performing a dual task (walking and performing a working memory task). An elastic net regression model was utilized to classify patients and healthy controls based on the kinematic variables. Our model achieved an AUC (area under the curve) of the ROC plot = 0.77 ± 0.21 using the average, an AUC of 0.94 ± 0.09 using the average and standard deviation, and AUC = 0.95 ± 0.09 when incorporating only the standard deviation of kinematic variables. The study suggests that utilizing angular gait analysis with machine learning methods is an effective approach to categorizing individuals with early-stage multiple sclerosis and healthy controls.",2025,10.3389/frai.2025.1660801
A novel interpretable and real-time dengue prediction framework using clinical blood parameters with genetic and GAN-based optimization,"Dengue remains a significant and critical global health concern, especially in resource-constrained and remote regions, where traditional IgG/IgM-based testing is often delayed or not conducted properly. Furthermore, conventional machine learning often exhibits minimal interpretability and misclassification, leading to major unreliability in real-time clinical decisions. To tackle these hindrances, we proposed an interpretable, efficient, and novel machine learning framework that operates near real-time. It combines feature optimization using Genetic Algorithms (GA) and Generative Adversarial Networks (GAN) to address data imbalance, and enhances ubiquitous decision interpretability with Explainable AI (XAI). GA establishes the most predictive hematological features, which improve accuracy and transparency, whereas GAN-based data generation handles class imbalance, leading to enhanced generalization. On top of that, the optimized Decision Tree model attains 99.49% accuracy with a negligible computational cost of training and testing time 0.0025 s, and 0.0013 s respectively, superseding the current state-of-the-art. A web-based application implemented based on the proposed model enables real-time risk prediction with a latency of under 0.6 s. A comprehensive XAI evaluation using LIME, SHAP, Morris sensitivity analysis, permutation combination, and RFE consistently identifies WBC and platelet counts as key predictors. In numbers, XAI techniques represent that low White Blood Cell (WBC) count (&lt; 3,700 cells/μL), platelet count (&lt; 136,000 cells/μL), and Platelet Distribution Width (PDW &lt; 23) are key indicators of dengue. Our proposed integrated GA-GAN-XAI framework bridges accuracy, interpretability, and real-time decision-making capability. This approach is highly accurate, robust for healthcare, and a highly deployable solution for dengue risk prediction for clinical dengue risk assessment.",2025,10.3389/frai.2025.1626699
Evaluating the role of generative AI and color patterns in the dissemination of war imagery and disinformation on social media,"This study explores the evolving role of social media in the spread of misinformation during the Ukraine-Russia conflict, with a focus on how artificial intelligence (AI) contributes to the creation of deceptive war imagery. Specifically, the research examines the relationship between color patterns (LUTs) in war-related visuals and their perceived authenticity, highlighting the economic, political, and social ramifications of such manipulative practices. AI technologies have significantly advanced the production of highly convincing, yet artificial, war imagery, blurring the line between fact and fiction. An experimental project is proposed to train a generative AI model capable of creating war imagery that mimics real-life footage. By analyzing the success of this experiment, the study aims to establish a link between specific color patterns and the likelihood of images being perceived as authentic. This could shed light on the mechanics of visual misinformation and manipulation. Additionally, the research investigates the potential of a serverless AI framework to advance both the generation and detection of fake news, marking a pivotal step in the fight against digital misinformation. Ultimately, the study seeks to contribute to ongoing debates on the ethical implications of AI in information manipulation and to propose strategies to combat these challenges in the digital era.",2025,10.3389/frai.2024.1457247
Hypergraph-based contrastive learning for enhanced fraud detection,"The proliferation of digital platforms has enabled fraudsters to deploy sophisticated camouflage techniques, such as multi-hop collaborative attacks, to evade detection. Traditional Graph Neural Networks (GNNs) often fail to capture these complex high-order patterns due to limitations including homophily assumption failures, severe label imbalance, and noise amplification during deep aggregation. To address these challenges, we propose the Hypergraph-based Contrastive Learning Network (HCLNet), a novel framework integrating three synergistic innovations. Firstly, multi-relational hypergraph fusion encodes heterogeneous associations into hyperedges, explicitly modeling group-wise fraud syndicates beyond pairwise connections. Secondly, a multi-head gated hypergraph aggregation mechanism employs parallel attention heads to capture diverse fraud patterns, dynamically balances original and high-order features via gating, and stabilizes training through residual connections with layer normalization. Thirdly, hierarchical dual-view contrastive learning jointly applies feature masking and topology dropout at both node and hyperedge levels, constructing augmented views to optimize self-supervised discrimination under label scarcity. Extensive experiments on two real-world datasets demonstrate HCLNet's superior performance, achieving significant improvements over the baselines across key evaluation metrics. The model's ability to reveal distinctive separation patterns between fraudulent and benign entities underscores its practical value in combating evolving camouflaged fraud tactics in digital ecosystems.",2025,10.3389/frai.2025.1703135
Leveraging Open Electronic Health Record Data and Environmental Exposures Data to Derive Insights Into Rare Pulmonary Disease,"Research on rare diseases has received increasing attention, in part due to the realized profitability of orphan drugs. Biomedical informatics holds promise in accelerating translational research on rare disease, yet challenges remain, including the lack of diagnostic codes for rare diseases and privacy concerns that prevent research access to electronic health records when few patients exist. The Integrated Clinical and Environmental Exposures Service (ICEES) provides regulatory-compliant open access to electronic health record data that have been integrated with environmental exposures data, as well as analytic tools to explore the integrated data. We describe a proof-of-concept application of ICEES to examine demographics, clinical characteristics, environmental exposures, and health outcomes among a cohort of patients enriched for phenotypes associated with cystic fibrosis (CF), idiopathic bronchiectasis (IB), and primary ciliary dyskinesia (PCD). We then focus on a subset of patients with CF, leveraging the availability of a diagnostic code for CF and serving as a benchmark for our development work. We use ICEES to examine select demographics, co-diagnoses, and environmental exposures that may contribute to poor health outcomes among patients with CF, defined as emergency department or inpatient visits for respiratory issues. We replicate current understanding of the pathogenesis and clinical manifestations of CF by identifying co-diagnoses of asthma, chronic nasal congestion, cough, middle ear disease, and pneumonia as factors that differentiate patients with poor health outcomes from those with better health outcomes. We conclude by discussing our preliminary findings in relation to other published work, the strengths and limitations of our approach, and our future directions.",2022,10.3389/frai.2022.918888
Automated information extraction model enhancing traditional Chinese medicine RCT evidence extraction (Evi-BERT): algorithm development and validation,"BackgroundIn the field of evidence-based medicine, randomized controlled trials (RCTs) are of critical importance for writing clinical guidelines and providing guidance to practicing physicians. Currently, RCTs rely heavily on manual extraction, but this method has data breadth limitations and is less efficient.ObjectivesTo expand the breadth of data and improve the efficiency of obtaining clinical evidence, here, we introduce an automated information extraction model for traditional Chinese medicine (TCM) RCT evidence extraction.MethodsWe adopt the Evidence-Bidirectional Encoder Representation from Transformers (Evi-BERT) for automated information extraction, which is combined with rule extraction. Eleven disease types and 48,523 research articles from the China National Knowledge Infrastructure (CNKI), WanFang Data, and VIP databases were selected as the data source for extraction. We then constructed a manually annotated dataset of TCM clinical literature to train the model, including ten evidence elements and 24,244 datapoints. We chose two models, BERT-CRF and BiLSTM-CRF, as the baseline, and compared the training effects with Evi-BERT and Evi-BERT combined with rule expression (RE).ResultsWe found that Evi-BERT combined with RE achieved the best performance (precision score = 0.926, Recall = 0.952, F1 score = 0.938) and had the best robustness. We totally summarized 113 pieces of rule datasets in the regulation extraction procedure. Our model dramatically expands the amount of data that can be searched and greatly improves efficiency without losing accuracy.ConclusionOur work provided an intelligent approach to extracting clinical evidence for TCM RCT data. Our model can help physicians reduce the time spent reading journals and rapidly speed up the screening of clinical trial evidence to help generate accurate clinical reference guidelines. Additionally, we hope the structured clinical evidence and structured knowledge extracted from this study will help other researchers build large language models in TCM.",2024,10.3389/frai.2024.1454945
Minimizing unnecessary tax audits using multi-objective hyperparameter tuning of XGBoost with focal loss,"This study presents a machine learning (ML) approach for detecting non-compliance in companies' tax data. The dataset, consisting of over one million records, focuses on three key targets: invalid addresses, invalid director information, and invalid founder information. The analysis prioritizes young companies (≤ 3 years old) with fewer than 100 employees, thereby improving class distributions and model effectiveness. A combination of binary classification techniques was employed, including benchmarked supervised learning models (XGBoost, Random Forest), anomaly detection methods (LOF, Isolation Forest), and semi-supervised learning using deep neural networks (DNNs) with unlabeled data. Given its computational efficiency, XGBoost was selected as the primary model. However, class imbalance persisted even among young companies, necessitating the integration of focal loss to improve classification performance. To further enhance accuracy while maintaining model interpretability, NSGA-II (Non-dominated Sorting Genetic Algorithm II) was used for multi-objective hyperparameter optimization of XGBoost. The objectives were to maximize ROC-AUC for improved predictive performance and minimize the number of trees to enhance interpretability. The optimized model achieved a ROC-AUC of 0.9417, compared to 0.9161 without optimization, demonstrating the effectiveness of this approach. Additionally, SHAP analysis provided insights into key factors influencing non-compliance, supporting explainability and aiding regulatory decision-making. This methodology contributes to fair and efficient oversight by reducing unnecessary inspections, minimizing disruptions to compliant businesses, and improving the overall effectiveness of tax compliance monitoring.",2025,10.3389/frai.2025.1669191
Structural studies of Parvoviridae capsid assembly and evolution: implications for novel AAV vector design,"Adeno-associated virus (AAV) vectors have emerged as powerful tools in gene therapy, potentially treating various genetic disorders. Engineering the AAV capsids through computational methods enables the customization of these vectors to enhance their effectiveness and safety. This engineering allows for the development of gene therapies that are not only more efficient but also personalized to unique genetic profiles. When developing, it is essential to understand the structural biology and the vast techniques used to guide vector designs. This review covers the fundamental biology of the Parvoviridae capsids, focusing on modern structural study techniques, including (a) Cryo-electron microscopy and X-ray Crystallography studies and (b) Comparative analysis of capsid structures across different Parvoviridae species. Along with the structure and evolution of the Parvoviridae capsids, computational methods have provided significant insights into the design of novel AAV vector techniques, which include (a) Structure-guided design of AAV capsids with improved properties, (b) Directed Evolution of AAV capsids for specific applications, and (c) Computational prediction of AAV capsid-receptor interactions. Further discussion addressed the ongoing challenges in the AAV vector design and proposed future directions for exploring enhanced computational tools, such as artificial intelligence/machine learning and deep learning.",2025,10.3389/frai.2025.1559461
Image restoration in frequency space using complex-valued CNNs,"Real-valued convolutional neural networks (RV-CNNs) in the spatial domain have outperformed classical approaches in many image restoration tasks such as image denoising and super-resolution. Fourier analysis of the results produced by these spatial domain models reveals the limitations of these models in properly processing the full frequency spectrum. This lack of complete spectral information can result in missing textural and structural elements. To address this limitation, we explore the potential of complex-valued convolutional neural networks (CV-CNNs) for image restoration tasks. CV-CNNs have shown remarkable performance in tasks such as image classification and segmentation. However, CV-CNNs for image restoration problems in the frequency domain have not been fully investigated to address the aforementioned issues. Here, we propose several novel CV-CNN-based models equipped with complex-valued attention gates for image denoising and super-resolution in the frequency domains. We also show that our CV-CNN-based models outperform their real-valued counterparts for denoising super-resolution structured illumination microscopy (SR-SIM) and conventional image datasets. Furthermore, the experimental results show that our proposed CV-CNN-based models preserve the frequency spectrum better than their real-valued counterparts in the denoising task. Based on these findings, we conclude that CV-CNN-based methods provide a plausible and beneficial deep learning approach for image restoration in the frequency domain.",2024,10.3389/frai.2024.1353873
Enhancing bladder cancer diagnosis through transitional cell carcinoma polyp detection and segmentation: an artificial intelligence powered deep learning solution,"BackgroundBladder cancer, specifically transitional cell carcinoma (TCC) polyps, presents a significant healthcare challenge worldwide. Accurate segmentation of TCC polyps in cystoscopy images is crucial for early diagnosis and urgent treatment. Deep learning models have shown promise in addressing this challenge.MethodsWe evaluated deep learning architectures, including Unetplusplus_vgg19, Unet_vgg11, and FPN_resnet34, trained on a dataset of annotated cystoscopy images of low quality.ResultsThe models showed promise, with Unetplusplus_vgg19 and FPN_resnet34 exhibiting precision of 55.40 and 57.41%, respectively, suitable for clinical application without modifying existing treatment workflows.ConclusionDeep learning models demonstrate potential in TCC polyp segmentation, even when trained on lower-quality images, suggesting their viability in improving timely bladder cancer diagnosis without impacting the current clinical processes.",2024,10.3389/frai.2024.1406806
Shapley Idioms: Analysing BERT Sentence Embeddings for General Idiom Token Identification,"This article examines the basis of Natural Language Understanding of transformer based language models, such as BERT. It does this through a case study on idiom token classification. We use idiom token identification as a basis for our analysis because of the variety of information types that have previously been explored in the literature for this task, including: topic, lexical, and syntactic features. This variety of relevant information types means that the task of idiom token identification enables us to explore the forms of linguistic information that a BERT language model captures and encodes in its representations. The core of this article presents three experiments. The first experiment analyzes the effectiveness of BERT sentence embeddings for creating a general idiom token identification model and the results indicate that the BERT sentence embeddings outperform Skip-Thought. In the second and third experiment we use the game theory concept of Shapley Values to rank the usefulness of individual idiomatic expressions for model training and use this ranking to analyse the type of information that the model finds useful. We find that a combination of idiom-intrinsic and topic-based properties contribute to an expression's usefulness in idiom token identification. Overall our results indicate that BERT efficiently encodes a variety of information from topic, through lexical and syntactic information. Based on these results we argue that notwithstanding recent criticisms of language model based semantics, the ability of BERT to efficiently encode a variety of linguistic information types does represent a significant step forward in natural language understanding.",2022,10.3389/frai.2022.813967
Global reform population health management as stewarded by Higher Expert Medical Science Safety (HEMSS),"As described in a Memorandum of Understanding (MoU) on AI infrastructure, global human phenotype ontology (HPO) is a priority for the US and the UK. The UK NHS Act of 1946 and the Medicare and Medicaid Act of 1965 classify using genomics as primary care, supporting international HPO aims for Population Health Management (PHM). The Higher Expert Medical Science Safety (HEMSS) proposes the NHS England, Genomics, and Biobank agile group developers. The HEMSS strategy executes the PHM of the HPO through digital records, pilot citizen predictor pre-eXams, and precise eXam intercept classifications, continuously improving public safety. PHM reform includes biobank opportunities for Value-Based Care (VBC) stratifying genomic and socio-environmental factors that risk HPO in disease segmentation. The author evaluated a standard approach to PHM for HPO with mature and advanced interoperable standards. A reform toolkit aligns adversarial, neural, and transformer models for Generative AI by utilizing multimodal data nuanced for fairness in Quantum Intelligence. The recommendations include HEMSS steps from well-being evaluations to the PHM strategy for HPO in the UK-US. Concepts involve piloting the scaling up of neighborhood clinics and federal centers through reform classification. Plans for citizen privacy facilitate data use with access to reference biobanks, ensuring DNA democratization and national cybersecurity. The UK NHSE corporate governance and US federal authorities monitor and reform the Integrated Care Board assessments and the Centers for Medicare and Medicaid Services surveys using agile methods. The UK-US MoU for AI safety is an international ideal for PHM, creating a safe space for HPO adherence to predictive and interceptive adoption for health and socioeconomic growth. HEMSS Agile Group Development impacts ethical and societal primary care debates. HEMSS discussions on global public health inclusiveness and national engagement aim to govern the classification phases for adherence. Therefore, debates on UK-US accreditation or regulation on the future of Artificial General Intelligence follow. The author concludes in support of the Population Health Management Expert Medical Science Safety Agile Group Development Program. The UK and US governments would benefit from this proposition, and international goals for well-being and socioeconomic growth would also be supported.",2025,10.3389/frai.2025.1496948
Integrated ensemble of BERT- and feature-based models for authorship attribution in Japanese literary works,"BackgroundTraditional authorship attribution (AA) research has primarily relied on statistical analysis and classification based on stylistic features extracted from textual data. Although pre-trained language models like BERT have gained prominence in text classification tasks, their effectiveness in small-sample AA scenarios remains insufficiently explored. A critical unresolved challenge is developing methodologies that effectively integrate BERT with conventional feature-based approaches to advance AA research.Revised objectiveThis study aims to substantially enhance performance in small-sample AA tasks through the strategic combination of traditional feature-based methods and contemporary BERT-based approaches. Furthermore, we conduct a comprehensive comparative analysis of the accuracy of BERT models and conventional classifiers while systematically evaluating how individual model characteristics interact within this combination to influence overall classification effectiveness.MethodsWe propose a novel integrated ensemble methodology that combines BERT-based models with feature-based classifiers, benchmarked against conventional ensemble techniques. Experimental validation is conducted using two literary corpora, each consisting of works from 10 distinct authors. The ensemble framework incorporates five BERT variants, three feature types, and two classifier architectures to systematically evaluate model effectiveness.ResultsBERT demonstrated effectiveness in small-sample authorship attribution tasks, surpassing traditional feature-based methods. Both BERT-based and feature-based ensembles outperformed their standalone counterparts, with the integrated ensemble method achieving even higher scores. Notably, the integrated ensemble significantly outperformed the best individual model on Corpus B—which was not included in the pre-training data— improving the F1 score from 0.823 to 0.96. It achieved the highest score among all evaluated approaches, including standalone models and conventional ensemble techniques, with a statistically significant margin (p &lt; 0.012, Cohen’s d = 4.939), underscoring the robustness of the result. The pre-training data used in BERT had a significant impact on task performance, emphasizing the need for careful model selection based not only on accuracy but also on model diversity. These findings highlight the importance of pre-training data and model diversity in optimizing language models for ensemble learning, offering valuable insights for authorship attribution research and the broader development of artificial general intelligence systems.",2025,10.3389/frai.2025.1624900
Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.",2022,10.3389/frai.2022.876007
Challenging social media threats using collective well-being-aware recommendation algorithms and an educational virtual companion,"Social media have become an integral part of our lives, expanding our interlinking capabilities to new levels. There is plenty to be said about their positive effects. On the other hand, however, some serious negative implications of social media have been repeatedly highlighted in recent years, pointing at various threats to society and its more vulnerable members, such as teenagers, in particular, ranging from much-discussed problems such as digital addiction and polarization to manipulative influences of algorithms and further to more teenager-specific issues (e.g., body stereotyping). The impact of social media—both at an individual and societal level—is characterized by the complex interplay between the users' interactions and the intelligent components of the platform. Thus, users' understanding of social media mechanisms plays a determinant role. We thus propose a theoretical framework based on an adaptive “Social Media Virtual Companion” for educating and supporting an entire community, teenage students, to interact in social media environments in order to achieve desirable conditions, defined in terms of a community-specific and participatory designed measure of Collective Well-Being (CWB). This Companion combines automatic processing with expert intervention and guidance. The virtual Companion will be powered by a Recommender System (CWB-RS) that will optimize a CWB metric instead of engagement or platform profit, which currently largely drives recommender systems thereby disregarding any societal collateral effect. CWB-RS will optimize CWB both in the short term by balancing the level of social media threats the users are exposed to, and in the long term by adopting an Intelligent Tutor System role and enabling adaptive and personalized sequencing of playful learning activities. We put an emphasis on experts and educators in the educationally managed social media community of the Companion. They play five key roles: (a) use the Companion in classroom-based educational activities; (b) guide the definition of the CWB; (c) provide a hierarchical structure of learning strategies, objectives and activities that will support and contain the adaptive sequencing algorithms of the CWB-RS based on hierarchical reinforcement learning; (d) act as moderators of direct conflicts between the members of the community; and, finally, (e) monitor and address ethical and educational issues that are beyond the intelligent agent's competence and control. This framework offers a possible approach to understanding how to design social media systems and embedded educational interventions that favor a more healthy and positive society. Preliminary results on the performance of the Companion's components and studies of the educational and psychological underlying principles are presented.",2023,10.3389/frai.2022.654930
DeepAD: A deep learning application for predicting amyloid standardized uptake value ratio through PET for Alzheimer's prognosis,"IntroductionAmyloid deposition is a vital biomarker in the process of Alzheimer's diagnosis. 18F-florbetapir PET scans can provide valuable imaging data to determine cortical amyloid quantities. However, the process is labor and doctor intensive, requiring extremely specialized education and resources that may not be accessible to everyone, making the amyloid calculation process inefficient. Deep learning is a rising tool in Alzheimer's research which could be used to determine amyloid deposition.Materials and methodsUsing data from the Alzheimer's Disease Neuroimaging Initiative, we identified 2,980 patients with PET imaging, clinical, and genetic data. We tested various ResNet, EfficientNet, and RegNet convolutional neural networks and later combined the best performing model with Gradient Boosting Decision Tree algorithms to predict standardized uptake value ratio (SUVR) of amyloid in each patient session. We tried several configurations to find the best model tuning for regression-to-SUVR.ResultsWe found that the RegNet X064 architecture combined with a grid search-tuned Gradient Boosting Decision Tree with 3 axial input slices and clinical and genetic data achieved the lowest loss. Using the mean-absolute-error metric, the loss converged to an MAE of 0.0441, equating to 96.4% accuracy across the 596-patient test set.DiscussionWe showed that this method is more consistent and accessible in comparison to human readers from previous studies, with lower margins of error and substantially faster calculation times. We implemented our deep learning model on to a web application named DeepAD which allows our diagnostic tool to be accessible. DeepAD could be used in hospitals and clinics with resource limitations for amyloid deposition and shows promise for more imaging tasks as well.",2023,10.3389/frai.2023.1091506
Large language model triaging of simulated nephrology patient inbox messages,"BackgroundEfficient triage of patient communications is crucial for timely medical attention and improved care. This study evaluates ChatGPT’s accuracy in categorizing nephrology patient inbox messages, assessing its potential in outpatient settings.MethodsOne hundred and fifty simulated patient inbox messages were created based on cases typically encountered in everyday practice at a nephrology outpatient clinic. These messages were triaged as non-urgent, urgent, and emergent by two nephrologists. The messages were then submitted to ChatGPT-4 for independent triage into the same categories. The inquiry process was performed twice with a two-week period in between. ChatGPT responses were graded as correct (agreement with physicians), overestimation (higher priority), or underestimation (lower priority).ResultsIn the first trial, ChatGPT correctly triaged 140 (93%) messages, overestimated the priority of 4 messages (3%), and underestimated the priority of 6 messages (4%). In the second trial, it correctly triaged 140 (93%) messages, overestimated the priority of 9 (6%), and underestimated the priority of 1 (1%). The accuracy did not depend on the urgency level of the message (p = 0.19). The internal agreement of ChatGPT responses was 92% with an intra-rater Kappa score of 0.88.ConclusionChatGPT-4 demonstrated high accuracy in triaging nephrology patient messages, highlighting the potential for AI-driven triage systems to enhance operational efficiency and improve patient care in outpatient clinics.",2024,10.3389/frai.2024.1452469
Using Twitter Data for the Study of Language Change in Low-Resource Languages. A Panel Study of Relative Pronouns in Frisian,"This paper investigates the usability of Twitter as a resource for the study of language change in progress in low-resource languages. It is a panel study of a vigorous change in progress, the loss of final t in four relative pronouns (dy't, dêr't, wêr't, wa't) in Frisian, a language spoken by ± 450,000 speakers in the north-west of the Netherlands. This paper deals with the issues encountered in retrieving and analyzing tweets in low-resource languages, in the analysis of low-frequency variables, and in gathering background information on Twitterers. In this panel study we were able to identify and track 159 individual Twitterers, whose Frisian (and Dutch) tweets posted in the era 2010–2019 were collected. Nevertheless, a solid analysis of the sociolinguistic factors in this language change in progress was hampered by unequal age distributions among the Twitterers, the fact that the youngest birth cohorts have given up Twitter almost completely after 2014 and that the variables have a low frequency and are unequally spread over Twitterers.",2021,10.3389/frai.2021.644554
SineKAN: Kolmogorov-Arnold Networks using sinusoidal activation functions,"Recent work has established an alternative to traditional multi-layer perceptron neural networks in the form of Kolmogorov-Arnold Networks (KAN). The general KAN framework uses learnable activation functions on the edges of the computational graph followed by summation on nodes. The learnable edge activation functions in the original implementation are basis spline functions (B-Spline). Here, we present a model in which learnable grids of B-Spline activation functions are replaced by grids of re-weighted sine functions (SineKAN). We evaluate numerical performance of our model on a benchmark vision task. We show that our model can perform better than or comparable to B-Spline KAN models and an alternative KAN implementation based on periodic cosine and sine functions representing a Fourier Series. Further, we show that SineKAN has numerical accuracy that could scale comparably to dense neural networks (DNNs). Compared to the two baseline KAN models, SineKAN achieves a substantial speed increase at all hidden layer sizes, batch sizes, and depths. Current advantage of DNNs due to hardware and software optimizations are discussed along with theoretical scaling. Additionally, properties of SineKAN compared to other KAN implementations and current limitations are also discussed.",2025,10.3389/frai.2024.1462952
InferBERT: A Transformer-Based Causal Inference Framework for Enhancing Pharmacovigilance,"Background: T ransformer-based language models have delivered clear improvements in a wide range of natural language processing (NLP) tasks. However, those models have a significant limitation; specifically, they cannot infer causality, a prerequisite for deployment in pharmacovigilance, and health care. Therefore, these transformer-based language models should be developed to infer causality to address the key question of the cause of a clinical outcome.Results: In this study, we propose an innovative causal inference model–InferBERT, by integrating the A Lite Bidirectional Encoder Representations from Transformers (ALBERT) and Judea Pearl’s Do-calculus to establish potential causality in pharmacovigilance. Two FDA Adverse Event Reporting System case studies, including Analgesics-related acute liver failure and Tramadol-related mortalities, were employed to evaluate the proposed InferBERT model. The InferBERT model yielded accuracies of 0.78 and 0.95 for identifying Analgesics-related acute liver failure and Tramadol-related death cases, respectively. Meanwhile, the inferred causes of the two clinical outcomes, (i.e. acute liver failure and death) were highly consistent with clinical knowledge. Furthermore, inferred causes were organized into a causal tree using the proposed recursive do-calculus algorithm to improve the model’s understanding of causality. Moreover, the high reproducibility of the proposed InferBERT model was demonstrated by a robustness assessment.Conclusion: The empirical results demonstrated that the proposed InferBERT approach is able to both predict clinical events and to infer their causes. Overall, the proposed InferBERT model is a promising approach to establish causal effects behind text-based observational data to enhance our understanding of intrinsic causality.Availability and implementation: The InferBERT model and preprocessed FAERS data sets are available on GitHub at https://github.com/XingqiaoWang/DeepCausalPV-master.",2021,10.3389/frai.2021.659622
Interlocutors’ Age Impacts Teenagers’ Online Writing Style: Accommodation in Intra- and Intergenerational Online Conversations,"The present study examines how teenagers adapt their language use to that of their conversation partner (i.e., the linguistic phenomenon of accommodation) in interactions with peers (intragenerational communication) and with older interlocutors (intergenerational communication). We analyze a large corpus of Flemish teenagers’ conversations on Facebook Messenger and WhatsApp, which appear to be highly peer-oriented. With Poisson models, we examine whether the teenage participants adjust their writing style to older interlocutors. The same trend emerges for three sets of prototypical markers of the informal online genre: teenagers insert significantly fewer of these markers when interacting with older interlocutors, thus matching their interlocutors’ style and increasing linguistic similarity. Finally, the analyses reveal subtle differences in accommodation patterns for the distinct linguistic variables with respect to the impact of the teenagers’ sociodemographic profiles and their interlocutors’ age.",2021,10.3389/frai.2021.738278
"Machine Learning-Based Modeling of Spatio-Temporally Varying Responses of Rainfed Corn Yield to Climate, Soil, and Management in the U.S. Corn Belt","Better understanding the variabilities in crop yield and production is critical to assessing the vulnerability and resilience of food production systems. Both environmental (climatic and edaphic) conditions and management factors affect the variabilities of crop yield. In this study, we conducted a comprehensive data-driven analysis in the U.S. Corn Belt to understand and model how rainfed corn yield is affected by climate variability and extremes, soil properties (soil available water capacity, soil organic matter), and management practices (planting date and fertilizer applications). Exploratory data analyses revealed that corn yield responds non-linearly to temperature, while the negative vapor pressure deficit (VPD) effect on corn yield is monotonic and more prominent. Higher mean yield and inter-annual yield variability are found associated with high soil available water capacity, while lower inter-annual yield variability is associated with high soil organic matter (SOM). We also identified region-dependent relationships between planting date and yield and a strong correlation between planting date and the April weather condition (temperature and rainfall). Next, we built machine learning models using the random forest and LASSO algorithms, respectively, to predict corn yield with all climatic, soil properties, and management factors. The random forest model achieved a high prediction accuracy for annual yield at county level as early as in July (R2 = 0.781) and outperformed LASSO. The gained insights from this study lead to improved understanding of how corn yield responds to climate variability and projected change in the U.S. Corn Belt and globally.",2021,10.3389/frai.2021.647999
Deep Active Learning via Open-Set Recognition,"In many applications, data is easy to acquire but expensive and time-consuming to label, prominent examples include medical imaging and NLP. This disparity has only grown in recent years as our ability to collect data improves. Under these constraints, it makes sense to select only the most informative instances from the unlabeled pool and request an oracle (e.g., a human expert) to provide labels for those samples. The goal of active learning is to infer the informativeness of unlabeled samples so as to minimize the number of requests to the oracle. Here, we formulate active learning as an open-set recognition problem. In this paradigm, only some of the inputs belong to known classes; the classifier must identify the rest asunknown. More specifically, we leverage variational neural networks (VNNs), which produce high-confidence (i.e., low-entropy) predictions only for inputs that closely resemble the training data. We use the inverse of this confidence measure to select the samples that the oracle should label. Intuitively, unlabeled samples that the VNN is uncertain about contain features that the network has not been exposed to; thus they are more informative for future training. We carried out an extensive evaluation of our novel, probabilistic formulation of active learning, achieving state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and FashionMNIST. Additionally, unlike current active learning methods, our algorithm can learn even in the presence of out-of-distribution outliers. As our experiments show, when the unlabeled pool consists of a mixture of samples from multiple datasets, our approach can automatically distinguish between samples from seen vs. unseen datasets. Overall, our results show that high-quality uncertainty measures are key for pool-based active learning.",2022,10.3389/frai.2022.737363
Automatic Artifact Detection Algorithm in Fetal MRI,"Fetal MR imaging is subject to artifacts including motion, chemical shift, and radiofrequency artifacts. Currently, such artifacts are detected by the MRI operator, a process which is subjective, time consuming, and prone to errors. We propose a novel algorithm, RISE-Net, that can consistently, automatically, and objectively detect artifacts in 3D fetal MRI. It makes use of a CNN ensemble approach where the first CNN aims to identify and classify any artifacts in the image, and the second CNN uses regression to determine the severity of the detected artifacts. The main mechanism in RISE-Net is the stacked Residual, Inception, Squeeze and Excitation (RISE) blocks. This classification network achieved an accuracy of 90.34% and a F1 score of 90.39% and outperformed other state-of-the-art architectures, such as VGG-16, Inception, ResNet-50, ReNet-Inception, SE-ResNet, and SE-Inception. The severity regression network had an MSE of 0.083 across all classes. The presented algorithm facilitates rapid and accurate fetal MRI quality assurance that can be implemented into clinical use.",2022,10.3389/frai.2022.861791
Frost prediction using machine learning and deep neural network models,"This study describes accurate, computationally efficient models that can be implemented for practical use in predicting frost events for point-scale agricultural applications. Frost damage in agriculture is a costly burden to farmers and global food security alike. Timely prediction of frost events is important to reduce the cost of agricultural frost damage and traditional numerical weather forecasts are often inaccurate at the field-scale in complex terrain. In this paper, we developed machine learning (ML) algorithms for the prediction of such frost events near Alcalde, NM at the point-scale. ML algorithms investigated include deep neural network, convolution neural networks, and random forest models at lead-times of 6–48 h. Our results show promising accuracy (6-h prediction RMSE = 1.53–1.72°C) for use in frost and minimum temperature prediction applications. Seasonal differences in model predictions resulted in a slight negative bias during Spring and Summer months and a positive bias in Fall and Winter months. Additionally, we tested the model transferability by continuing training and testing using data from sensors at a nearby farm. We calculated the feature importance of the random forest models and were able to determine which parameters provided the models with the most useful information for predictions. We determined that soil temperature is a key parameter in longer term predictions (&gt;24 h), while other temperature related parameters provide the majority of information for shorter term predictions. The model error compared favorable to previous ML based frost studies and outperformed the physically based High Resolution Rapid Refresh forecasting system making our ML-models attractive for deployment toward real-time monitoring of frost events and damage at commercial farming operations.",2023,10.3389/frai.2022.963781
Coronavirus diagnosis using cough sounds: Artificial intelligence approaches,"IntroductionThe Coronavirus disease 2019 (COVID-19) pandemic has caused irreparable damage to the world. In order to prevent the spread of pathogenicity, it is necessary to identify infected people for quarantine and treatment. The use of artificial intelligence and data mining approaches can lead to prevention and reduction of treatment costs. The purpose of this study is to create data mining models in order to diagnose people with the disease of COVID-19 through the sound of coughing.MethodIn this research, Supervised Learning classification algorithms have been used, which include Support Vector Machine (SVM), random forest, and Artificial Neural Networks, that based on the standard “Fully Connected” neural network, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) recurrent neural networks have been established. The data used in this research was from the online site sorfeh.com/sendcough/en, which has data collected during the spread of COVID-19.ResultWith the data we have collected (about 40,000 people) in different networks, we have reached acceptable accuracies.ConclusionThese findings show the reliability of this method for using and developing a tool as a screening and early diagnosis of people with COVID-19. This method can also be used with simple artificial intelligence networks so that acceptable results can be expected. Based on the findings, the average accuracy was 83% and the best model was 95%.",2023,10.3389/frai.2023.1100112
An Occupational Safety and Health Perspective on Human in Control and AI,"The continuous and rapid development of AI-based systems comes along with an increase in automation of tasks and, therewith, a qualitative shift in opportunities and challenges for occupational safety and health. A fundamental aspect of humane working conditions is the ability to exert influence over different aspects of one's own work. Consequently, stakeholders contribute to the prospect of maintaining the workers' autonomy albeit increasing automation and summarize this aspiration with the human in control principle. Job control has been part of multiple theories and models within the field of occupational psychology. However, most of the models do not include specific technical considerations nor focus on task but rather on job level. That is, they are possibly not able to fully explain specific changes regarding the digitalization of tasks. According to the results of a large-scale study on German workers (DiWaBe), this seems to be the case to some extend: the influence of varying degrees of automation, moderated by perceived autonomy, on workers' wellbeing was not consistent. However, automation is a double-edged sword: on a high level, it can be reversely related to the workers' job control while highly autonomous and reliable systems can also create opportunities for more flexible, impactful and diverse working tasks. Consequently, automation can foster and decrease the factor of job control. Models about the optimal level of automation aim to give guidelines on how the former can be achieved. The results of the DiWaBe study indicate that automation in occupational practice does not always happen in line with these models. Instead, a substantial part of automation happens at the decision-making level, while executive actions remain with the human. From an occupational safety and health perspective, it is therefore crucial to closely monitor and anticipate the implementation of AI in working systems. Constellations where employees are too controlled by technology and are left with a high degree of demands and very limited resources should be avoided. Instead, it would be favorable to use AI as an assistance tool for the employees, helping them to gather and process information and assisting them in decision-making.",2022,10.3389/frai.2022.868382
Generative AI cybersecurity and resilience,"Generative Artificial Intelligence marks a critical inflection point in the evolution of machine learning systems, enabling the autonomous synthesis of content across text, image, audio, and biomedical domains. While these capabilities are advancing at pace, their deployment raises profound ethical, security, and privacy concerns that remain inadequately addressed by existing governance mechanisms. This study undertakes a systematic inquiry into these challenges, combining a PRISMA-guided literature review with thematic and quantitative analyses to interrogate the socio-technical implications of generative Artificial Intelligence. The article develops an integrated theoretical framework, grounded in established models of technology adoption, cybersecurity resilience, and normative governance. Structured across five lifecycle stages (design, implementation, monitoring, compliance, and feedback) the framework offers a practical schema for evaluating and guiding responsible AI deployment. The analysis reveals a disconnection between the fast adoption of generative systems and the maturity of institutional safeguards, resulting with new risks from the shadow Artificial Intelligence, and underscoring the need for adaptive, sector-specific governance. This study offers a coherent pathway towards ethically aligned and secure application of Artificial Intelligence in national critical infrastructure.",2025,10.3389/frai.2025.1568360
Edge computing for detection of ship and ship port from remote sensing images using YOLO,"In marine security and surveillance, accurately identifying ships and ship ports from satellite imagery remains a critical challenge due to the inefficiencies and inaccuracies of conventional approaches. The proposed method uses an enhanced YOLO (You Only Look Once) model, a robust real-time object detection method. The method involves training the YOLO model on an extensive collection of annotated satellite images to detect ships and ship ports accurately. The proposed system delivers a precision of 86% compared to existing methods; this approach is designed to allow for real-time deployment in the context of resource-constrained environments, especially with a Jetson Nano edge device. This deployment will ensure scalability, efficient processing, and reduced reliance on central computing resources, making it especially suitable for maritime settings in which real-time monitoring is vital. The findings of this study, therefore, point out the practical implications of this improved YOLO model for maritime surveillance: offering a scalable and efficient solution to strengthen maritime security.",2025,10.3389/frai.2025.1508664
Construction of a prediction and visualization system for cognitive impairment in elderly COPD patients based on self-assigning feature weights and residual evolution model,"BackgroundAssessing cognitive function in patients with chronic obstructive pulmonary disease (COPD) is crucial for ensuring treatment efficacy and avoiding moderate cognitive impairment (MCI) or dementia. We aimed to build better machine learning models and provide useful tools to provide better guidance and assistance for COPD patients' treatment and care.MethodsA total of 863 COPD patients from a local general hospital were collected and screened, and they were separated into two groups: cognitive impairment (356 patients) and cognitively normal (507 patients). The Montreal Cognitive Assessment (MoCA) was used to test cognitive function. The swarm intelligence optimization algorithm (SIOA) was used to direct feature weighting and hyperparameter optimization, which were considered simultaneous activities. A self-assigning feature weights and residual evolution (SAFWRE) algorithm was built on the concept of linear and nonlinear information fusion.ResultsThe best method in SIOA was the circle search algorithm. On the training set, SAFWRE's ROC-AUC was 0.9727, and its PR-AUC was 0.9663; on the test set, SAFWRE's receiver operating characteristic-area under curve (ROC-AUC) was 0.9243, and its precision recall-area under curve (PR-AUC) was 0.9059, and its performance was much superior than that of the control technique. In terms of external data, the classification and prediction performance of various models are comprehensively evaluated. SAFWRE has the most excellent classification performance, with ROC-AUC of 0.8865 and pr-auc of 0.8299.ConclusionThis work develops a practical visualization system based on these weight attributes which has strong application importance and promotion value.",2025,10.3389/frai.2025.1473223
"3Es for AI: Economics, Explanation, Epistemology","This article locates its roots/routes in multiple disciplinary formations and it seeks to advance critical thinking about an aspect of our contemporary socio-technical challenges by bracketing three knowledge formations—artificial intelligence (AI), economics, and epistemology—that have not often been considered together. In doing so, it responds to the growing calls for the necessity of further transdisciplinary engagements that have emanated from work in AI and also from other disciplines. The structure of the argument here is as follows. First, I begin by demonstrating how and why explanation is a problem in AI (“XAI problem”) and what directions are being taken by recent research that draws upon social sciences to address this, noting how there is a conspicuous lack of reference in this literature to economics. Second, I identify and analyze a problem of explanation that has long plagued economics too as a discipline. I show how only a few economists have ever attempted to grapple with this problem and provide their perspectives. Third, I provide an original genealogy of explanation in economics, demonstrating the changing nature of what was meant by an explanation. These systematic changes in consensual understanding of what occurs when something is said to have been “explained”, have reflected the methodological compromises that were rendered necessary to serve different epistemological tensions over time. Lastly, I identify the various relevant historical and conceptual overlaps between economics and AI. I conclude by suggesting that we must pay greater attention to the epistemologies underpinning socio-technical knowledges about the human. The problem of explanation in AI, like the problem of explanation in economics, is perhaps not only, or really, a problem of satisfactory explanation provision alone, but interwoven with questions of competing epistemological and ethical choices and related to the ways in which we choose sociotechnical arrangements and offer consent to be governed by them.",2022,10.3389/frai.2022.833238
Minimal Cycle Representatives in Persistent Homology Using Linear Programming: An Empirical Study With User’s Guide,"Cycle representatives of persistent homology classes can be used to provide descriptions of topological features in data. However, the non-uniqueness of these representatives creates ambiguity and can lead to many different interpretations of the same set of classes. One approach to solving this problem is to optimize the choice of representative against some measure that is meaningful in the context of the data. In this work, we provide a study of the effectiveness and computational cost of several ℓ1 minimization optimization procedures for constructing homological cycle bases for persistent homology with rational coefficients in dimension one, including uniform-weighted and length-weighted edge-loss algorithms as well as uniform-weighted and area-weighted triangle-loss algorithms. We conduct these optimizations via standard linear programming methods, applying general-purpose solvers to optimize over column bases of simplicial boundary matrices. Our key findings are: 1) optimization is effective in reducing the size of cycle representatives, though the extent of the reduction varies according to the dimension and distribution of the underlying data, 2) the computational cost of optimizing a basis of cycle representatives exceeds the cost of computing such a basis, in most data sets we consider, 3) the choice of linear solvers matters a lot to the computation time of optimizing cycles, 4) the computation time of solving an integer program is not significantly longer than the computation time of solving a linear program for most of the cycle representatives, using the Gurobi linear solver, 5) strikingly, whether requiring integer solutions or not, we almost always obtain a solution with the same cost and almost all solutions found have entries in {‐1,0,1} and therefore, are also solutions to a restricted ℓ0 optimization problem, and 6) we obtain qualitatively different results for generators in Erdős-Rényi random clique complexes than in real-world and synthetic point cloud data.",2021,10.3389/frai.2021.681117
"Interpretability Versus Accuracy: A Comparison of Machine Learning Models Built Using Different Algorithms, Performance Measures, and Features to Predict E. coli Levels in Agricultural Water","SinceE. coliis considered a fecal indicator in surface water, government water quality standards and industry guidance often rely onE. colimonitoring to identify when there is an increased risk of pathogen contamination of water used for produce production (e.g., for irrigation). However, studies have indicated thatE. colitesting can present an economic burden to growers and that time lags between sampling and obtaining results may reduce the utility of these data. Models that predictE. colilevels in agricultural water may provide a mechanism for overcoming these obstacles. Thus, this proof-of-concept study uses previously published datasets to train, test, and compareE. colipredictive models using multiple algorithms and performance measures. Since the collection of different feature data carries specific costs for growers, predictive performance was compared for models built using different feature types [geospatial, water quality, stream traits, and/or weather features]. Model performance was assessed against baseline regression models. Model performance varied considerably with root-mean-squared errors and Kendall’s Tau ranging between 0.37 and 1.03, and 0.07 and 0.55, respectively. Overall, models that included turbidity, rain, and temperature outperformed all other models regardless of the algorithm used. Turbidity and weather factors were also found to drive model accuracy even when other feature types were included in the model. These findings confirm previous conclusions that machine learning models may be useful for predicting when, where, and at what levelE. coli(and associated hazards) are likely to be present in preharvest agricultural water sources. This study also identifies specific algorithm-predictor combinations that should be the foci of future efforts to develop deployable models (i.e., models that can be used to guide on-farm decision-making and risk mitigation). When deployingE. colipredictive models in the field, it is important to note that past research indicates an inconsistent relationship betweenE. colilevels and foodborne pathogen presence. Thus, models that predictE. colilevels in agricultural water may be useful for assessing fecal contamination status and ensuring compliance with regulations but should not be used to assess the risk that specific pathogens of concern (e.g.,Salmonella,Listeria) are present.",2021,10.3389/frai.2021.628441
The weaponization of artificial intelligence: What the public needs to be aware of,"Technological progress has brought about the emergence of machines that have the capacity to take human lives without human control. These represent an unprecedented threat to humankind. This paper starts from the example of chemical weapons, now banned worldwide by the Geneva protocol, to illustrate how technological development initially aimed at the benefit of humankind has, ultimately, produced what is now called the “Weaponization of Artificial Intelligence (AI)”. Autonomous Weapon Systems (AWS) fail the so-called discrimination principle, yet, the wider public is largely unaware of this problem. Given that ongoing scientific research on AWS, performed in the military sector, is generally not made available to the public domain, many of the viewpoints on this subject, expressed across different media, invoke common sense rather than scientific evidence. Yet, the implications of a potential weaponization of our work as scientists, especially in the field of AI, are reaching further than some may think. The potential consequences of a deployment of AWS for citizen stakeholders are incommensurable, and it is time to raise awareness in the public domain of the kind of potential threats identified, and to encourage legal policies ensuring that these threats will not materialize.",2023,10.3389/frai.2023.1154184
Rethinking symbolic and visual context in Referring Expression Generation,"Situational context is crucial for linguistic reference to visible objects, since the same description can refer unambiguously to an object in one context but be ambiguous or misleading in others. This also applies to Referring Expression Generation (REG), where the production of identifying descriptions is always dependent on a given context. Research in REG has long represented visual domains throughsymbolicinformation about objects and their properties, to determine identifying sets of target features during content determination. In recent years, research invisual REGhas turned to neural modeling and recasted the REG task as an inherently multimodal problem, looking at more natural settings such as generating descriptions for objects in photographs. Characterizing the precise ways in which context influences generation is challenging in both paradigms, as context is notoriously lacking precise definitions and categorization. In multimodal settings, however, these problems are further exacerbated by the increased complexity and low-level representation of perceptual inputs. The main goal of this article is to provide a systematic review of the types and functions of visual context across various approaches to REG so far and to argue for integrating and extending different perspectives on visual context that currently co-exist in research on REG. By analyzing the ways in which symbolic REG integrates context in rule-based approaches, we derive a set of categories of contextual integration, including the distinction betweenpositiveandnegative semantic forcesexerted by context during reference generation. Using this as a framework, we show that so far existing work in visual REG has considered only some of the ways in which visual context can facilitate end-to-end reference generation. Connecting with preceding research in related areas, as possible directions for future research, we highlight some additional ways in which contextual integration can be incorporated into REG and other multimodal generation tasks.",2023,10.3389/frai.2023.1067125
Towards Computational Modeling of Human Goal Recognition,"Recently, we are seeing the emergence of plan- and goal-recognition algorithms which are based on the principle ofrationality. These avoid the use of a plan library that compactly encodes all possible observable plans, and instead generate plans dynamically to match the observations. However, recent experiments by Berkovitz (Berkovitz, The effect of spatial cognition and context on robot movement legibility in human-robot collaboration, 2018) show that in many cases, humans seem to have reached quick (correct) decisions when observing motions which were far from rational (optimal), while optimal motions were slower to be recognized. Intrigued by these findings, we experimented with a variety of rationality-based recognition algorithms on the same data. The results clearly show that none of the algorithms reported in the literature accounts for human subject decisions, even in this simple task. This is our first contribution. We hypothesize that humans utilize plan-recognition in service of goal recognition, i.e., match observations to known plans, and use the set of recognized plans to conclude as to the likely goals. To test this hypothesis, a second contribution in this paper is the introduction of a novel offline recognition algorithm. While preliminary, the algorithm accounts for the results reported by Berkovitz significantly better than the existing algorithms. Moreover, the proposed algorithm marries rationality-based and plan-library based methods seamlessly.",2022,10.3389/frai.2021.737327
Code generation system based on MDA and convolutional neural networks,"IntroductionThe software industry has rapidly evolved with high performance. This is owing to the implementation of good programming practices and architectures that make it scalable and adaptable. Therefore, a strong incentive is required to develop the processes that initiate this project.MethodWe aimed to provide a platform that streamlines the development process and connects planning, structuring, and development. Specifically, we developed a system that employs computer vision, deep learning, and MDA to generate source code from the diagrams describing the system and the respective study cases, thereby providing solutions to the proposed problems.Results and discussionThe results demonstrate the effectiveness of employing computer vision and deep learning techniques to process images and extract relevant information. The infrastructure is designed based on a modular approach employing Celery and Redis, enabling the system to manage asynchronous tasks efficiently. The implementation of image recognition, text analysis, and neural network construction yields promising outcomes in generating source code from diagrams. Despite some challenges related to hardware limitations during the training of the neural network, the system successfully interprets the diagrams and produces artifacts using the MDA approach. Plugins and DSLs enhance flexibility by supporting various programming languages and automating code deployment on platforms such as GitHub and Heroku.",2025,10.3389/frai.2025.1491958
Toward an Integrative Approach for Making Sense Distinctions,"Word senses are the fundamental unit of description in lexicography, yet it is rarely the case that different dictionaries reach any agreement on the number and definition of senses in a language. With the recent rise in natural language processing and other computational approaches there is an increasing demand for quantitatively validated sense catalogues of words, yet no consensus methodology exists. In this paper, we look at four main approaches to making sense distinctions: formal, cognitive, distributional, and intercultural and examine the strengths and weaknesses of each approach. We then consider how these may be combined into a single sound methodology. We illustrate this by examining two English words, “wing” and “fish,” using existing resources for each of these four approaches and illustrate the weaknesses of each. We then look at the impact of such an integrated method and provide some future perspectives on the research that is necessary to reach a principled method for making sense distinctions.",2022,10.3389/frai.2022.745626
Predicting therapy dropout in chronic pain management: a machine learning approach to cannabis treatment,"IntroductionChronic pain affects approximately 30% of the global population, posing a significant public health challenge. Despite their widespread use, traditional pharmacological treatments, such as opioids and NSAIDs, often fail to deliver adequate, long-term relief while exposing patients to risks of addiction and adverse side effects. Given these limitations, medical cannabis has emerged as a promising therapeutic alternative with both analgesic and anti-inflammatory properties. However, its clinical efficacy is hindered by high interindividual variability in treatment response and elevated dropout rates.MethodsA comprehensive dataset integrating genetic, clinical, and pharmacological information was compiled from 542 Caucasian patients undergoing cannabis-based treatment for chronic pain. A machine learning (ML) model was developed and validated to predict therapy dropout. To identify the most influential factors driving dropout, SHapley Additive exPlanations (SHAP) analysis was performed.ResultsThe random forest classifier demonstrated robust performance, achieving a mean accuracy of 80% and a maximum of 86%, with an AUC of 0.86. SHAP analysis revealed that high final VAS scores and elevated THC dosages were the most significant predictors of dropout, both strongly correlated with an increased likelihood of discontinuation. In contrast, baseline therapeutic benefits, CBD dosages, and the CC genotype of the rs1049353 polymorphism in the CNR1 gene were associated with improved adherence.DiscussionOur findings highlight the potential of ML and pharmacogenetics to personalize cannabis-based therapies, improving adherence and enabling more precise management of chronic pain. This research paves the way for the development of tailored therapeutic strategies that maximize the benefits of medical cannabis while minimizing its side effects.",2025,10.3389/frai.2025.1557894
Neural architecture search applying optimal stopping theory,"Neural architecture search (NAS) exploration requires tremendous amounts of computational power to properly explore. This makes exploration of modern NAS search spaces impractical for researchers due to the infrastructure investments required and the time needed to effectively design, train, validate, and evaluate each architecture within the search space. Based on the fact that early-stopping random search algorithms are competitive against leading NAS methods, this paper explores how much of the search space should be explored by applying various forms of the famous decision-making riddle within optimal stopping theory: the Secretary Problem (SP). A total of 672 unique architectures, each trained and evaluated against the MNIST and CIFAR-10 datasets over 20,000 runs, producing 6,720 trained models confirm theoretically and empirically the need to randomly explore ~37% of the NAS search space until halting can occur for an acceptable discovered neural architecture. Additional extensions of the SP investigated include implementing a “good enough” and a “call back” feature; both further reduce exploration of the NAS search space to ~15 and 4%, respectively. Each of these investigations were further confirmed statistically upon NAS search space populations consisting of 100–3,500 neural architectures increasing in steps of 50, with each population size analyzed over 20,000 runs. The paper details how researchers should implement each of these variants, with caveats, to balance computational resource costs and the desire to conduct sufficient NAS practices in a reasonable timeframe.",2025,10.3389/frai.2025.1643088
YOLOv10-based detection of melanocytic nevi: reverse exclusion optimization for melanoma screening,"Malignant melanoma is the deadliest skin cancer, yet its early dermoscopic presentation closely mimics benign melanocytic nevi. Conventional visual or dermoscopic screening therefore suffers from high miss rates and generates excessive biopsies. In this study we focus on Chinese East-Asian patients and introduce a reversed-exclusion strategy—classifying “benign first, exclude malignancy”: lesions that fully meet benign nevus criteria are deemed low-risk; all others are flagged as high-risk. Building on the real-time detector YOLOv10, we incorporate three medical-oriented upgrades: (i) a PP-LCNet backbone to preserve sub-3 mm textures; (ii) a Multiscale Contextual Attention (MCA) neck to enhance cross-scale aggregation; and (iii) a Shape-IoU loss that jointly optimises position, scale, and curvature. The model was trained on a multi-centre dermoscopic dataset from three tertiary hospitals in mainland China (2,040 benign nevi) and independently tested on 365 biopsy-proven melanomas collected at the same medical institution but drawn from a demographically distinct patient cohort, achieving a detection mAP@0.5 of 97.69% for benign lesions and a melanoma false-negative rate (FNR) of only 0.27%. By delivering high-confidence benign identification followed by malignant exclusion, the proposed model offers a high-precision, low-risk pathway for early melanoma screening in Chinese clinical settings. It can markedly reduce unnecessary biopsies while keeping the miss rate below the clinical safety ceiling of 0.5%, thus preserving the life-saving window afforded by early detection.",2025,10.3389/frai.2025.1637842
Tracking priming-induced language recovery in aphasia with pre-trained language models,"This study explores the use of pre-trained language models (PLMs) in tracking priming treatment induced language recovery in aphasia. We evaluate PLM-derived surprisals, the negative log-probabilities of a word or a sequence of words calculated by a PLM given its preceding context, as a continuous and interpretable measure of treatment-induced language change. We found that surprisal scores decreased following structural priming treatment, especially in participants with more severe sentence production impairments. We also introduce a prompting-based pipeline for clinical classification tasks. It achieved promising results in classifying aphasia sentence correctness (F1 = 0.967) and detecting error categories in aphasia (accuracy = 0.846). Such use of PLMs for modeling, tracking, and automatically classifying language recovery in aphasia represents a promising deployment of GenAI in a clinical rehabilitation setting. Together, our PLM-based analyses offer a practical approach for modeling language rehabilitation, tracking not only language structure but also individual change over time in clinical contexts.
                  
                    Clinical trial registration
                    Identifier NTC05415501.",2025,10.3389/frai.2025.1668399
Detecting body dysmorphic disorder in the age of algorithms,"Body Dysmorphic Disorder (BDD) is increasingly recognized in the aesthetic practice, yet it remains underdiagnosed and often misunderstood. With its high prevalence, particularly in cosmetic consultations, BDD poses significant ethical and clinical challenges. Aesthetic providers must be vigilant in identifying at-risk individuals and prioritizing psychological well-being alongside procedural outcomes. Artificial Intelligence (AI), with its capacity to analyze behavioral patterns, automate screening tools, and detect subtle indicators of cognitive distortion, presents a new frontier in managing BDD. However, integrating AI into clinical practice requires caution to prevent reinforcing appearance-focused biases and to ensure privacy and fairness. This commentary discusses the opportunities, limitations, and ethical considerations of leveraging AI to assist clinicians in detecting BDD, fostering safer patient outcomes, and advancing the compassionate practice of aesthetic medicine. AI should not accelerate aesthetic procedures but promote reflective, ethically sound decision-making. When integrated responsibly, it can enhance recognition of BDD, support psychological safety, and preserve patient trust through transparency, data protection, and clinician oversight.",2025,10.3389/frai.2025.1717267
"Prediction, Knowledge, and Explainability: Examining the Use of General Value Functions in Machine Knowledge","Within computational reinforcement learning, a growing body of work seeks to express an agent's knowledge of its world through large collections of predictions. While systems that encode predictions as General Value Functions (GVFs) have seen numerous developments in both theory and application, whether such approaches are explainable is unexplored. In this perspective piece, we explore GVFs as a form of explainable AI. To do so, we articulate a subjective agent-centric approach to explainability in sequential decision-making tasks. We propose that prior to explaining its decisions to others, an self-supervised agent must be able to introspectively explain decisions to itself. To clarify this point, we review prior applications of GVFs that involve human-agent collaboration. In doing so, we demonstrate that by making their subjective explanations public, predictive knowledge agents can improve the clarity of their operation in collaborative tasks.",2022,10.3389/frai.2022.826724
Graph Neural Networks for Maximum Constraint Satisfaction,"Many combinatorial optimization problems can be phrased in the language of constraint satisfaction problems. We introduce a graph neural network architecture for solving such optimization problems. The architecture is generic; it works for all binary constraint satisfaction problems. Training is unsupervised, and it is sufficient to train on relatively small instances; the resulting networks perform well on much larger instances (at least 10-times larger). We experimentally evaluate our approach for a variety of problems, including Maximum Cut and Maximum Independent Set. Despite being generic, we show that our approach matches or surpasses most greedy and semi-definite programming based algorithms and sometimes even outperforms state-of-the-art heuristics for the specific problems.",2021,10.3389/frai.2020.580607
Assessing large language models as assistive tools in medical consultations for Kawasaki disease,"BackgroundKawasaki disease (KD) presents complex clinical challenges in diagnosis, treatment, and long-term management, requiring a comprehensive understanding by both parents and healthcare providers. With advancements in artificial intelligence (AI), large language models (LLMs) have shown promise in supporting medical practice. This study aims to evaluate and compare the appropriateness and comprehensibility of different LLMs in answering clinically relevant questions about KD and assess the impact of different prompting strategies.MethodsTwenty-five questions were formulated, incorporating three prompting strategies: No prompting (NO), Parent-friendly (PF), and Doctor-level (DL). These questions were input into three LLMs: ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro. Responses were evaluated based on appropriateness, educational quality, comprehensibility, cautionary statements, references, and potential misinformation, using Information Quality Grade, Global Quality Scale (GQS), Flesch Reading Ease (FRE) score, and word count.ResultsSignificant differences were found among the LLMs in terms of response educational quality, accuracy, and comprehensibility (p &lt; 0.001). Claude 3.5 provided the highest proportion of completely correct responses (51.1%) and achieved the highest median GQS score (5.0), outperforming GPT-4o (4.0) and Gemini 1.5 (3.0) significantly. Gemini 1.5 achieved the highest FRE score (31.5) and provided highest proportion of responses assessed as comprehensible (80.4%). Prompting strategies significantly affected LLM responses. Claude 3.5 Sonnet with DL prompting had the highest completely correct rate (81.3%), while PF prompting yielded the most acceptable responses (97.3%). Gemini 1.5 Pro showed minimal variation across prompts but excelled in comprehensibility (98.7% under PF prompting).ConclusionThis study indicates that LLMs have great potential in providing information about KD, but their use requires caution due to quality inconsistencies and misinformation risks. Significant discrepancies existed across LLMs and prompting strategies. Claude 3.5 Sonnet offered the best response quality and accuracy, while Gemini 1.5 Pro excelled in comprehensibility. PF prompting with Claude 3.5 Sonnet is most recommended for parents seeking KD information. As AI evolves, expanding research and refining models is crucial to ensure reliable, high-quality information.",2025,10.3389/frai.2025.1571503
"Xputer: bridging data gaps with NMF, XGBoost, and a streamlined GUI experience","The rapid proliferation of data across diverse fields has accentuated the importance of accurate imputation for missing values. This task is crucial for ensuring data integrity and deriving meaningful insights. In response to this challenge, we present Xputer, a novel imputation tool that adeptly integrates Non-negative Matrix Factorization (NMF) with the predictive strengths of XGBoost. One of Xputer's standout features is its versatility: it supports zero imputation, enables hyperparameter optimization through Optuna, and allows users to define the number of iterations. For enhanced user experience and accessibility, we have equipped Xputer with an intuitive Graphical User Interface (GUI) ensuring ease of handling, even for those less familiar with computational tools. In performance benchmarks, Xputer often outperforms IterativeImputer in terms of imputation accuracy. Furthermore, Xputer autonomously handles a diverse spectrum of data types, including categorical, continuous, and Boolean, eliminating the need for prior preprocessing. Given its blend of performance, flexibility, and user-friendly design, Xputer emerges as a state-of-the-art solution in the realm of data imputation.",2024,10.3389/frai.2024.1345179
"Integrated Evolutionary Learning: An Artificial Intelligence Approach to Joint Learning of Features and Hyperparameters for Optimized, Explainable Machine Learning","Artificial intelligence and machine learning techniques have proved fertile methods for attacking difficult problems in medicine and public health. These techniques have garnered strong interest for the analysis of the large, multi-domain open science datasets that are increasingly available in health research. Discovery science in large datasets is challenging given the unconstrained nature of the learning environment where there may be a large number of potential predictors and appropriate ranges for model hyperparameters are unknown. As well, it is likely that explainability is at a premium in order to engage in future hypothesis generation or analysis. Here, we present a novel method that addresses these challenges by exploiting evolutionary algorithms to optimize machine learning discovery science while exploring a large solution space and minimizing bias. We demonstrate that our approach, called integrated evolutionary learning (IEL), provides an automated, adaptive method for jointly learning features and hyperparameters while furnishing explainable models where the original features used to make predictions may be obtained even with artificial neural networks. In IEL the machine learning algorithm of choice is nested inside an evolutionary algorithm which selects features and hyperparameters over generations on the basis of an information function to converge on an optimal solution. We apply IEL to three gold standard machine learning algorithms in challenging, heterogenous biobehavioral data: deep learning with artificial neural networks, decision tree-based techniques and baseline linear models. Using our novel IEL approach, artificial neural networks achieved ≥ 95% accuracy, sensitivity and specificity and 45–73% R2 in classification and substantial gains over default settings. IEL may be applied to a wide range of less- or unconstrained discovery science problems where the practitioner wishes to jointly learn features and hyperparameters in an adaptive, principled manner within the same algorithmic process. This approach offers significant flexibility, enlarges the solution space and mitigates bias that may arise from manual or semi-manual hyperparameter tuning and feature selection and presents the opportunity to select the inner machine learning algorithm based on the results of optimized learning for the problem at hand.",2022,10.3389/frai.2022.832530
Cyberbullying detection approaches for Arabic texts: a systematic literature review,"This study presents a comprehensive review of current methodologies, trends, and challenges in cyberbullying detection within Arabic-language contexts, with a focus on the unique linguistic and cultural factors associated with Arabic. This study reviews 35 peer-reviewed articles about the identification of cyberbullying in Arabic text. Reported accuracies across datasets and platforms range from approximately 73 to 96%, with precision frequently surpassing recall, suggesting that systems are more adept at identifying blatant bullying than at encompassing all pertinent instances. Methodologically, conventional machine learning utilizing Arabic-specific characteristics remains effective on smaller datasets, however deep neural architectures—especially CNN/BiLSTM—and transformer models like AraBERT yield superior outcomes when dialectal heterogeneity and orthographic noise are mitigated. Evaluation methodologies differ; research using a neutral class frequently indicates exaggerated accuracy, underscoring the necessity to emphasize macro-averaged F1 and per-class metrics. The evidence underscores deficiencies in dialectal representativeness, the uniformity of bullying notions compared to general abuse, and the transparency of annotation processes. Ethical and deployment considerations—privacy preservation, dialectal bias, and real-time robustness—are becoming increasingly significant. We integrate trends (models and features), standards (labeling and metrics), and future work directions, encompassing dialect-robust pretraining, cross-dataset evaluation, context-aware modeling, and human-in-the-loop frameworks. The review offers a comprehensive basis for researchers and practitioners pursuing culturally and linguistically tailored approaches to Arabic cyberbullying detection.",2025,10.3389/frai.2025.1666349
Adversarially Robust Learning via Entropic Regularization,"In this paper we propose a new family of algorithms, ATENT, for training adversarially robust deep neural networks. We formulate a new loss function that is equipped with an additional entropic regularization. Our loss function considers the contribution of adversarial samples that are drawn from a specially designed distribution in the data space that assigns high probability to points with high loss and in the immediate neighborhood of training samples. Our proposed algorithms optimize this loss to seek adversarially robust valleys of the loss landscape. Our approach achieves competitive (or better) performance in terms of robust classification accuracy as compared to several state-of-the-art robust learning approaches on benchmark datasets such as MNIST and CIFAR-10.",2022,10.3389/frai.2021.780843
Applications of Topological Data Analysis in Oncology,"The emergence of the information age in the last few decades brought with it an explosion of biomedical data. But with great power comes great responsibility: there is now a pressing need for new data analysis algorithms to be developed to make sense of the data and transform this information into knowledge which can be directly translated into the clinic. Topological data analysis (TDA) provides a promising path forward: using tools from the mathematical field of algebraic topology, TDA provides a framework to extract insights into the often high-dimensional, incomplete, and noisy nature of biomedical data. Nowhere is this more evident than in the field of oncology, where patient-specific data is routinely presented to clinicians in a variety of forms, from imaging to single cell genomic sequencing. In this review, we focus on applications involving persistent homology, one of the main tools of TDA. We describe some recent successes of TDA in oncology, specifically in predicting treatment responses and prognosis, tumor segmentation and computer-aided diagnosis, disease classification, and cellular architecture determination. We also provide suggestions on avenues for future research including utilizing TDA to analyze cancer time-series data such as gene expression changes during pathogenesis, investigation of the relation between angiogenic vessel structure and treatment efficacy from imaging data, and experimental confirmation that geometric and topological connectivity implies functional connectivity in the context of cancer.",2021,10.3389/frai.2021.659037
Trends and hotspots in research on medical images with deep learning: a bibliometric analysis from 2013 to 2023,"BackgroundWith the rapid development of the internet, the improvement of computer capabilities, and the continuous advancement of algorithms, deep learning has developed rapidly in recent years and has been widely applied in many fields. Previous studies have shown that deep learning has an excellent performance in image processing, and deep learning-based medical image processing may help solve the difficulties faced by traditional medical image processing. This technology has attracted the attention of many scholars in the fields of computer science and medicine. This study mainly summarizes the knowledge structure of deep learning-based medical image processing research through bibliometric analysis and explores the research hotspots and possible development trends in this field.MethodsRetrieve the Web of Science Core Collection database using the search terms “deep learning,” “medical image processing,” and their synonyms. Use CiteSpace for visual analysis of authors, institutions, countries, keywords, co-cited references, co-cited authors, and co-cited journals.ResultsThe analysis was conducted on 562 highly cited papers retrieved from the database. The trend chart of the annual publication volume shows an upward trend. Pheng-Ann Heng, Hao Chen, and Klaus Hermann Maier-Hein are among the active authors in this field. Chinese Academy of Sciences has the highest number of publications, while the institution with the highest centrality is Stanford University. The United States has the highest number of publications, followed by China. The most frequent keyword is “Deep Learning,” and the highest centrality keyword is “Algorithm.” The most cited author is Kaiming He, and the author with the highest centrality is Yoshua Bengio.ConclusionThe application of deep learning in medical image processing is becoming increasingly common, and there are many active authors, institutions, and countries in this field. Current research in medical image processing mainly focuses on deep learning, convolutional neural networks, classification, diagnosis, segmentation, image, algorithm, and artificial intelligence. The research focus and trends are gradually shifting toward more complex and systematic directions, and deep learning technology will continue to play an important role.",2023,10.3389/frai.2023.1289669
An artificial intelligence model for early-stage breast cancer classification from histopathological biopsy images,"Accurate identification of breast cancer subtypes is essential for guiding treatment decisions and improving patient outcomes. In current clinical practice, determining histological subtypes often requires additional invasive procedures, delaying treatment initiation. This study proposes a deep learning-based model built on a DenseNet121 backbone with a multi-scale feature fusion strategy, designed to classify breast cancer from histopathological biopsy images. Trained and evaluated on the publicly available BreaKHis dataset using 5-fold cross-validation, the model achieved a binary classification accuracy of 97.1%, and subtype classification accuracies of 93.8% for benign tumors and 92.0% for malignant tumors. These results demonstrate the model’s ability to capture morphological cues at multiple levels of abstraction and highlight its potential as a diagnostic support tool in digital pathology workflows.",2025,10.3389/frai.2025.1627876
Graph theoretic visualization of patient and health worker messaging in the EHR,"IntroductionThe electronic health record (EHR) has greatly expanded healthcare communication between patients and health workers. However, the volume and complexity of EHR messages have increased health workers' cognitive load, impeding effective care delivery and contributing to burnout.MethodsTo understand these potential detriments resulting from EHR communication, we analyzed EHR messages sent between patients and health workers at Emory Healthcare, a large academic healthcare system in Atlanta, Georgia. We quantified the burden of messages interacted with by each health worker type and visualized the communication patterns using graph theory. Our analysis included 76,694 conversations comprising 144,369 messages sent between 47,460 patients and 3,749 health workers across 85 healthcare specialties.ResultsOn average, nurses/certified nursing assistants/medical assistants (nurses/CNA/MA) interacted with the most messages (350), followed by non-physician practitioners (NPP) (241), physicians (166), and support staff (155), with the average conversation involving 10.51 interactions before resolution. Network analysis of the communication flow revealed that each health worker was connected to approximately two other health workers (average degree = 2.10). In message sending, support staff led in closeness centrality (0.44), followed by nurses/CNA/MA (0.41), highlighting their key role in fast information spread. For message reception, nurses/CNA/MA (0.51) and support staff (0.41) also had the highest values, underscoring their vital role in the communication network on the receiving end as well.DiscussionOur analysis demonstrates the feasibility of applying graph theory to understand communication dynamics between patients and health workers and highlights the burden of EHR-based messaging.",2024,10.3389/frai.2024.1422208
Explainable AI-driven depression detection from social media using natural language processing and black box machine learning models,"IntroductionMental disorders are highly prevalent in modern society, leading to substantial personal and societal burdens. Among these, depression is one of the most common, often exacerbated by socioeconomic, clinical, and individual risk factors. With the rise of social media, user-generated content offers valuable opportunities for the early detection of mental disorders through computational approaches.MethodsThis study explores the early detection of depression using black-box machine learning (ML) models, including Support Vector Machines (SVM), Random Forests (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Networks (ANN). Advanced Natural Language Processing (NLP) techniques TF-IDF, Latent Dirichlet Allocation (LDA), N-grams, Bag of Words (BoW), and GloVe embeddings were employed to extract linguistic and semantic features. To address the interpretability limitations of black-box models, Explainable AI (XAI) methods were integrated, specifically the Local Interpretable Model-Agnostic Explanations (LIME).ResultsExperimental findings demonstrate that SVM achieved the highest accuracy in detecting depression from social media data, outperforming RF and other models. The application of LIME enabled granular insights into model predictions, highlighting linguistic markers strongly aligned with established psychological research.DiscussionUnlike most prior studies that focus primarily on classification accuracy, this work emphasizes both predictive performance and interpretability. The integration of LIME not only enhanced transparency and interpretability but also improved the potential clinical trustworthiness of ML-based depression detection models.",2025,10.3389/frai.2025.1627078
Tracing the Phonetic Space of Prosodic Focus Marking,"Focus is known to be expressed by a wide range of phonetic cues but only a few studies have explicitly compared different phonetic variables within the same experiment. Therefore, we presented results from an analysis of 19 phonetic variables conducted on a data set of the German language that comprises the opposition of unaccented (background) vs. accented (in focus), as well as different focus types with the nuclear accent on the same syllable (broad, narrow, and contrastive focus). The phonetic variables are measures of the acoustic and articulographic signals of a target syllable. Overall, our results provide the highest number of reliable effects and largest effect sizes for accentuation (unaccented vs. accented), while the differentiation of focus types with accented target syllables (broad, narrow, and contrastive focus) are more subtle. The most important phonetic variables across all conditions are measures of the fundamental frequency. The articulatory variables and their corresponding acoustic formants reveal lower tongue positions for both vowels /o, a/, and larger lip openings for the vowel /a/ under increased prosodic prominence with the strongest effects for accentuation. While duration exhibits consistent mid-ranked results for both accentuation and the differentiation of focus types, measures related to intensity are particularly important for accentuation. Furthermore, voice quality and spectral tilt are affected by accentuation but also in the differentiation of focus types. Our results confirm that focus is realized via multiple phonetic cues. Additionally, the present analysis allows a comparison of the relative importance of different measures to better understand the phonetic space of focus marking.",2022,10.3389/frai.2022.842546
AmericasNLI: Machine translation and natural language inference systems for Indigenous languages of the Americas,"Little attention has been paid to the development of human language technology for truly low-resource languages—i.e., languages with limited amounts of digitally available text data, such as Indigenous languages. However, it has been shown that pretrained multilingual models are able to perform crosslingual transfer in a zero-shot setting even for low-resource languages which are unseen during pretraining. Yet, prior work evaluating performance on unseen languages has largely been limited to shallow token-level tasks. It remains unclear if zero-shot learning of deeper semantic tasks is possible for unseen languages. To explore this question, we present AmericasNLI, a natural language inference dataset covering 10 Indigenous languages of the Americas. We conduct experiments with pretrained models, exploring zero-shot learning in combination with model adaptation. Furthermore, as AmericasNLI is a multiway parallel dataset, we use it to benchmark the performance of different machine translation models for those languages. Finally, using a standard transformer model, we explore translation-based approaches for natural language inference. We find that the zero-shot performance of pretrained models without adaptation is poor for all languages in AmericasNLI, but model adaptation via continued pretraining results in improvements. All machine translation models are rather weak, but, surprisingly, translation-based approaches to natural language inference outperform all other models on that task.",2022,10.3389/frai.2022.995667
Supervised Learning Computer Vision Benchmark for Snake Species Identification From Photographs: Implications for Herpetology and Global Health,"We trained a computer vision algorithm to identify 45 species of snakes from photos and compared its performance to that of humans. Both human and algorithm performance is substantially better than randomly guessing (null probability of guessing correctly given 45 classes = 2.2%). Some species (e.g.,Boa constrictor) are routinely identified with ease by both algorithm and humans, whereas other groups of species (e.g., uniform green snakes, blotched brown snakes) are routinely confused. A species complex with largely molecular species delimitation (North American ratsnakes) was the most challenging for computer vision. Humans had an edge at identifying images of poor quality or with visual artifacts. With future improvement, computer vision could play a larger role in snakebite epidemiology, particularly when combined with information about geographic location and input from human experts.",2021,10.3389/frai.2021.582110
The utility of generative artificial intelligence Chatbot (ChatGPT) in generating teaching and learning material for anesthesiology residents,"The popularization of large language chatbots such as ChatGPT has led to growing utility in various biomedical fields. It has been shown that chatbots can provide reasonably accurate responses to medical exam style questions. On the other hand, chatbots have known limitations which may hinder their utility in medical education. We conducted a pragmatically designed study to evaluate the accuracy and completeness of ChatGPT generated responses to various styles of prompts, based on entry-level anesthesiology topics. Ninety-five unique prompts were constructed using topics from the Anesthesia Knowledge Test 1 (AKT-1), a standardized exam undertaken by US anesthesiology residents after 1 month of specialty training. A combination of focused and open-ended prompts was used to evaluate its ability to present and organize information. We also included prompts for journal references, lecture outlines, as well as biased (medically inaccurate) prompts. The responses were independently scored using a 3-point Likert scale, by two board-certified anesthesiologists with extensive experience in medical education. Fifty-two (55%) responses were rated as completely accurate by both evaluators. For longer responses prompts, most of the responses were also deemed complete. Notably, the chatbot frequently generated inaccurate responses when asked for specific literature references and when the input prompt contained deliberate errors (biased prompts). Another recurring observation was the conflation of adjacent concepts (e.g., a specific characteristic was attributed to the wrong drug under the same pharmacological class). Some of the inaccuracies could potentially result in significant harm if applied to clinical situations. While chatbots such as ChatGPT can generate medically accurate responses in most cases, its reliability is not yet suited for medical and clinical education. Content generated by ChatGPT and other chatbots will require validation prior to use.",2025,10.3389/frai.2025.1582096
Unsupervised Text Segmentation Predicts Eye Fixations During Reading,"Words typically form the basis of psycholinguistic and computational linguistic studies about sentence processing. However, recent evidence shows the basic units during reading, i.e., the items in the mental lexicon, are not always words, but could also be sub-word and supra-word units. To recognize these units, human readers require a cognitive mechanism to learn and detect them. In this paper, we assume eye fixations during reading reveal the locations of the cognitive units, and that the cognitive units are analogous with the text units discovered by unsupervised segmentation models. We predict eye fixations by model-segmented units on both English and Dutch text. The results show the model-segmented units predict eye fixations better than word units. This finding suggests that the predictive performance of model-segmented units indicates their plausibility as cognitive units. The Less-is-Better (LiB) model, which finds the units that minimize both long-term and working memory load, offers advantages both in terms of prediction score and efficiency among alternative models. Our results also suggest that modeling the least-effort principle for the management of long-term and working memory can lead to inferring cognitive units. Overall, the study supports the theory that the mental lexicon stores not only words but also smaller and larger units, suggests that fixation locations during reading depend on these units, and shows that unsupervised segmentation models can discover these units.",2022,10.3389/frai.2022.731615
AI: the Apollo guidance computer of the Exposome moonshot,"The Exposome—the totality of environmental exposures across a lifetime—remains one of the most significant challenges in understanding and preventing human disease. Translating its vast, heterogeneous data streams into actionable knowledge requires artificial intelligence (AI) integrated with human-relevant experimental systems. We propose a unifying vision in which Microphysiological Systems (MPS) and multi-omics platforms generate high-quality, context-specific data that iteratively calibrate AI models, enabling the creation of digital twins of organs, individuals, and ultimately populations. This “Exposome Moonshot” parallels the Apollo program in ambition, with MPS as the rocket, multi-omics as the lunar module, and AI as the guidance computer. Early applications demonstrate that deep learning can already outperform canonical animal tests for several toxicological endpoints, while reducing cost and time to decision. Realizing the full potential of Exposome intelligence will require expanding the applicability domain of models, implementing robust data security, and prioritizing transparent, interpretable algorithms. By linking predictive AI with experimental feedback, we can move toward a prevention-driven, personalized paradigm for human health and regulatory science.",2025,10.3389/frai.2025.1632520
Comparison of the accuracy of GPT-4 and resident physicians in differentiating benign and malignant thyroid nodules,"ObjectiveTo assess the diagnostic performance of the GPT-4 model in comparison to resident physicians in distinguishing between benign and malignant thyroid nodules using ultrasound images.MethodsThis study analyzed 1,145 ultrasound images, including 632 malignant and 513 benign nodules. Both the GPT-4 model and two resident physicians independently classified the nodules using ultrasound images. The diagnostic accuracy of the resident physicians was determined by calculating the average of the individual accuracy rates of the two physicians and this was compared with the performance of the GPT-4 model.ResultsThe GPT-4 model correctly identified 367 out of 632 malignant nodules (58.07%) and 343 out of 513 benign nodules (66.86%). Resident physicians identified 467 malignant (73.89%) and 383 benign nodules (74.66%). There was a statistically significant difference in the classification of malignant nodules (p &lt; 0.001) and benign nodules (p = 0.048) between the GPT-4 model and residents. GPT-4 performed better for larger nodules (&gt;1 cm) at 65.38%, compared to 53.77% for smaller nodules (≤1 cm, p = 0.004). The AUC for GPT-4 was 0.67, while residents achieved 0.75.ConclusionThe GPT-4 model shows potential in classifying thyroid nodules, but its diagnostic accuracy remains significantly lower than that of resident physicians, particularly for smaller malignant nodules.",2025,10.3389/frai.2025.1512438
Deep learning for steganalysis: evaluating model robustness against image transformations,"This study investigates the robustness of deep learning-based steganalysis models against common image transformations because most literature has not paid enough attention to resilience assessment. Current and future applications of steganalysis to guarantee digital security are gaining importance regarding real-world modifications: resizing, compression, cropping, and adding noise. These included the following five basic models: EfficientNet, SRNet, ResNet, Xu-Net, and Yedroudj-Net. We evaluated these models' pre- and post-transformation performances based on various metrics like accuracy, precision, recall, F1-score, and AUC with the BOSSBase dataset. Our results showed that EfficientNet is the most robust among the considered architecture transformations. Still, it also underlined significant degradations for state-of-the-art models, Xu-Net and Yedroudj-Net, especially with added noise. These results indicate the need to develop more robust architectures capable of sustaining real-world image alterations. In practice, it will assist practitioners in choosing models that best suit operational environments and lay the necessary platform for future enhancements in the design of such models. In this regard, in the future, more transformations should be researched with ensemble and adaptive approaches to improve robustness further.",2025,10.3389/frai.2025.1532895
Bridging the gap: a practical step-by-step approach to warrant safe implementation of large language models in healthcare,"Large Language Models (LLMs) offer considerable potential to enhance various aspects of healthcare, from aiding with administrative tasks to clinical decision support. However, despite the growing use of LLMs in healthcare, a critical gap persists in clear, actionable guidelines available to healthcare organizations and providers to ensure their responsible and safe implementation. In this paper, we propose a practical step-by-step approach to bridge this gap and support healthcare organizations and providers in warranting the responsible and safe implementation of LLMs into healthcare. The recommendations in this manuscript include protecting patient privacy, adapting models to healthcare-specific needs, adjusting hyperparameters appropriately, ensuring proper medical prompt engineering, distinguishing between clinical decision support (CDS) and non-CDS applications, systematically evaluating LLM outputs using a structured approach, and implementing a solid model governance structure. We furthermore propose the ACUTE mnemonic; a structured approach for assessing LLM responses based on Accuracy, Consistency, semantically Unaltered outputs, Traceability, and Ethical considerations. Together, these recommendations aim to provide healthcare organizations and providers with a clear pathway for the responsible and safe implementation of LLMs into clinical practice.",2025,10.3389/frai.2025.1504805
Overview of Chatbots with special emphasis on artificial intelligence-enabled ChatGPT in medical science,"The release of ChatGPT has initiated new thinking about AI-based Chatbot and its application and has drawn huge public attention worldwide. Researchers and doctors have started thinking about the promise and application of AI-related large language models in medicine during the past few months. Here, the comprehensive review highlighted the overview of Chatbot and ChatGPT and their current role in medicine. Firstly, the general idea of Chatbots, their evolution, architecture, and medical use are discussed. Secondly, ChatGPT is discussed with special emphasis of its application in medicine, architecture and training methods, medical diagnosis and treatment, research ethical issues, and a comparison of ChatGPT with other NLP models are illustrated. The article also discussed the limitations and prospects of ChatGPT. In the future, these large language models and ChatGPT will have immense promise in healthcare. However, more research is needed in this direction.",2023,10.3389/frai.2023.1237704
Predicting financial distress in TSX-listed firms using machine learning algorithms,"IntroductionThis study investigates the application of machine learning (ML) algorithms, a subset of artificial intelligence (AI), to predict financial distress in companies. Given the critical need for reliable financial health indicators, this research evaluates the predictive capabilities of various ML techniques on firm-level financial data.MethodsThe dataset comprises financial ratios and firm-specific variables from 464 firms listed on the TSX. Multiple ML models were tested, including decision trees, random forests, support vector machines (SVM), and artificial neural networks (ANN). Recursive feature elimination with cross-validation (RFECV) and bootstrapped CART were also employed to enhance model stability and feature selection.ResultsThe findings highlight key predictors of financial distress, such as revenue growth, dividend growth, cash-to-current liabilities, and gross profit margins. Among the models tested, the ANN classifier achieved the highest accuracy at 98%, outperforming other algorithms.DiscussionThe results suggest that ANN provides a robust and reliable method for financial distress prediction. The use of RFECV and bootstrapped CART contributes to the model’s stability, underscoring the potential of ML tools in financial health monitoring. These insights carry valuable implications for auditors, regulators, and company management in enhancing practices around financial oversight and fraud detection.",2024,10.3389/frai.2024.1466321
The impact of AI on education and careers: What do students think?,"IntroductionProviding one-on-one support to large cohorts is challenging, yet emerging AI technologies show promise in bridging the gap between the support students want and what educators can provide. They offer students a way to engage with their course material in a way that feels fluent and instinctive. Whilst educators may have views on the appropriates for AI, the tools themselves, as well as the novel ways in which they can be used, are continually changing.MethodsThe aim of this study was to probe students' familiarity with AI tools, their views on its current uses, their understanding of universities' AI policies, and finally their impressions of its importance, both to their degree and their future careers. We surveyed 453 psychology and sport science students across two institutions in the UK, predominantly those in the first and second year of undergraduate study, and conducted a series of five focus groups to explore the emerging themes of the survey in more detail.ResultsOur results showed a wide range of responses in terms of students' familiarity with the tools and what they believe AI tools could and should not be used for. Most students emphasized the importance of understanding how AI tools function and their potential applications in both their academic studies and future careers. The results indicated a strong desire among students to learn more about AI technologies. Furthermore, there was a significant interest in receiving dedicated support for integrating these tools into their coursework, driven by the belief that such skills will be sought after by future employers. However, most students were not familiar with their university's published AI policies.DiscussionThis research on pedagogical methods supports a broader long-term ambition to better understand and improve our teaching, learning, and student engagement through the adoption of AI and the effective use of technology and suggests a need for a more comprehensive approach to communicating these important guidelines on an on-going basis, especially as the tools and guidelines evolve.",2024,10.3389/frai.2024.1457299
Predicting the Disease Outcome in COVID-19 Positive Patients Through Machine Learning: A Retrospective Cohort Study With Brazilian Data,"The first officially registered case of COVID-19 in Brazil was on February 26, 2020. Since then, the situation has worsened with more than 672, 000 confirmed cases and at least 36, 000 reported deaths by June 2020. Accurate diagnosis of patients with COVID-19 is extremely important to offer adequate treatment, and avoid overloading the healthcare system. Characteristics of patients such as age, comorbidities and varied clinical symptoms can help in classifying the level of infection severity, predict the disease outcome and the need for hospitalization. Here, we present a study to predict a poor prognosis in positive COVID-19 patients and possible outcomes using machine learning. The study dataset comprises information of 8, 443 patients concerning closed cases due to cure or death. Our experimental results show the disease outcome can be predicted with a Receiver Operating Characteristic AUC of 0.92, Sensitivity of 0.88 and Specificity of 0.82 for the best prediction model. This is a preliminary retrospective study which can be improved with the inclusion of further data. Conclusion: Machine learning techniques fed with demographic and clinical data along with comorbidities of the patients can assist in the prognostic prediction and physician decision-making, allowing a faster response and contributing to the non-overload of healthcare systems.",2021,10.3389/frai.2021.579931
Analyzing global utilization and missed opportunities in debt-for-nature swaps with generative AI,"We deploy a prompt-augmented GPT-4 model to distill comprehensive datasets on the global application of debt-for-nature swaps (DNS), a pivotal financial tool for environmental conservation. Our analysis includes 195 nations and identifies 21 countries that have not yet used DNS before as prime candidates for DNS. A significant proportion demonstrates consistent commitments to conservation finance (0.86 accuracy as compared to historical swaps records). Conversely, 35 countries previously active in DNS before 2010 have since been identified as unsuitable. Notably, Argentina, grappling with soaring inflation and a substantial sovereign debt crisis, and Poland, which has achieved economic stability and gained access to alternative EU conservation funds, exemplify the shifting suitability landscape. The study's outcomes illuminate the fragility of DNS as a conservation strategy amid economic and political volatility.",2024,10.3389/frai.2024.1167137
SAMI: an M-Health application to telemonitor intelligibility and speech disorder severity in head and neck cancers,"Perceptual measures, such as intelligibility and speech disorder severity, are widely used in the clinical assessment of speech disorders in patients treated for oral or oropharyngeal cancer. Despite their widespread usage, these measures are known to be subjective and hard to reproduce. Therefore, an M-Health assessment based on an automatic prediction has been seen as a more robust and reliable alternative. Despite recent progress, these automatic approaches still remain somewhat theoretical, and a need to implement them in real clinical practice rises. Hence, in the present work we introduce SAMI, a clinical mobile application used to predict speech intelligibility and disorder severity as well as to monitor patient progress on these measures over time. The first part of this work illustrates the design and development of the systems supported by SAMI. Here, we show how deep neural speaker embeddings are used to automatically regress speech disorder measurements (intelligibility and severity), as well as the training and validation of the system on a French corpus of head and neck cancer. Furthermore, we also test our model on a secondary corpus recorded in real clinical conditions. The second part details the results obtained from the deployment of our system in a real clinical environment, over the course of several weeks. In this section, the results obtained with SAMI are compared to an a posteriori perceptual evaluation, conducted by a set of experts on the new recorded data. The comparison suggests a high correlation and a low error between the perceptual and automatic evaluations, validating the clinical usage of the proposed application.",2024,10.3389/frai.2024.1359094
Improving Crowdsourcing-Based Image Classification Through Expanded Input Elicitation and Machine Learning,"This work investigates how different forms of input elicitation obtained from crowdsourcing can be utilized to improve the quality of inferred labels for image classification tasks, where an image must be labeled as either positive or negative depending on the presence/absence of a specified object. Five types of input elicitation methods are tested: binary classification (positive or negative); the (x, y)-coordinate of the position participants believe a target object is located; level of confidence in binary response (on a scale from 0 to 100%); what participants believe the majority of the other participants' binary classification is; and participant's perceived difficulty level of the task (on a discrete scale). We design two crowdsourcing studies to test the performance of a variety of input elicitation methods and utilize data from over 300 participants. Various existing voting and machine learning (ML) methods are applied to make the best use of these inputs. In an effort to assess their performance on classification tasks of varying difficulty, a systematic synthetic image generation process is developed. Each generated image combines items from the MPEG-7 Core Experiment CE-Shape-1 Test Set into a single image using multiple parameters (e.g., density, transparency, etc.) and may or may not contain a target object. The difficulty of these images is validated by the performance of an automated image classification method. Experiment results suggest that more accurate results can be achieved with smaller training datasets when both the crowdsourced binary classification labels and the average of the self-reported confidence values in these labels are used as features for the ML classifiers. Moreover, when a relatively larger properly annotated dataset is available, in some cases augmenting these ML algorithms with the results (i.e., probability of outcome) from an automated classifier can achieve even higher performance than what can be obtained by using any one of the individual classifiers. Lastly, supplementary analysis of the collected data demonstrates that other performance metrics of interest, namely reduced false-negative rates, can be prioritized through special modifications of the proposed aggregation methods.",2022,10.3389/frai.2022.848056
Opportunities for human factors in machine learning,"Introduction
                    The field of machine learning and its subfield of deep learning have grown rapidly in recent years. With the speed of advancement, it is nearly impossible for data scientists to maintain expert knowledge of cutting-edge techniques. This study applies human factors methods to the field of machine learning to address these difficulties.
                  
                  
                    Methods
                    Using semi-structured interviews with data scientists at a National Laboratory, we sought to understand the process used when working with machine learning models, the challenges encountered, and the ways that human factors might contribute to addressing those challenges.
                  
                  
                    Results
                    Results of the interviews were analyzed to create a generalization of the process of working with machine learning models. Issues encountered during each process step are described.
                  
                  
                    Discussion
                    Recommendations and areas for collaboration between data scientists and human factors experts are provided, with the goal of creating better tools, knowledge, and guidance for machine learning scientists.",2023,10.3389/frai.2023.1130190
AI Data-Driven Personalisation and Disability Inclusion,"This study aims to help people working in the field of AI understand some of the unique issues regarding disabled people and examines the relationship between the terms “Personalisation” and “Classification” with regard to disability inclusion. Classification using big data struggles to cope with the individual uniqueness of disabled people, and whereas developers tend to design for the majority so ignoring outliers, designing for edge cases would be a more inclusive approach. Other issues that are discussed in the study include personalising mobile technology accessibility settings with interoperable profiles to allow ubiquitous accessibility; the ethics of using genetic data-driven personalisation to ensure babies are not born with disabilities; the importance of including disabled people in decisions to help understand AI implications; the relationship between localisation and personalisation as assistive technologies need localising in terms of language as well as culture; the ways in which AI could be used to create personalised symbols for people who find it difficult to communicate in speech or writing; and whether blind or visually impaired person will be permitted to “drive” an autonomous car. This study concludes by suggesting that the relationship between the terms “Personalisation” and “Classification” with regards to AI and disability inclusion is a very unique one because of the heterogeneity in contrast to the other protected characteristics and so needs unique solutions.",2021,10.3389/frai.2020.571955
Argumentation: A calculus for Human-Centric AI,"This paper aims to expose and analyze the potential foundational role of Argumentation for Human-Centric AI, and to present the main challenges for this foundational role to be realized in a way that will fit well with the wider requirements and challenges of Human-Centric AI. The central idea set forward is that by endowing machines with the ability to argue with forms of machine argumentation that are cognitively compatible with those of human argumentation, we will be able to support a naturally effective, enhancing and ethical human-machine cooperation and “social” integration.",2022,10.3389/frai.2022.955579
Evaluation of large language model-driven AutoML in data and model management from human-centered perspective,"As organizations increasingly seek to leverage machine learning (ML) capabilities, the technical complexity of implementing ML solutions creates significant barriers to adoption and impacts operational efficiency. This research examines how Large Language Models (LLMs) can transform the accessibility of ML technologies within organizations through a human-centered Automated Machine Learning (AutoML) approach. Through a comprehensive user study involving 15 professionals across various roles and technical backgrounds, we evaluate the organizational impact of an LLM-based AutoML framework compared to traditional implementation methods. Our research offers four significant contributions to both management practice and technical innovation: First, we present pioneering evidence that LLM-based interfaces can dramatically improve ML implementation success rates, with 93.34% of users achieved superior performance in the LLM condition, with 46.67% showing higher accuracy (10%–25% improvement over baseline) and 46.67% demonstrating significantly higher accuracy (&gt;25% improvement over baseline), while 6.67% maintained comparable performance levels; and 60% reporting substantially reduced development time. Second, we demonstrate how natural language interfaces can effectively bridge the technical skills gap in organizations, cutting implementation time by 50% while improving accuracy across all expertise levels. Third, we provide valuable insights for organizations designing human-AI collaborative systems, showing that our approach reduced error resolution time by 73% and significantly accelerated employee learning curves. Finally, we establish empirical support for natural language as an effective interface for complex technical systems, offering organizations a path to democratize ML capabilities without compromising quality or performance.",2025,10.3389/frai.2025.1590105
"High Resolution, Annual Maps of Field Boundaries for Smallholder-Dominated Croplands at National Scales","Mapping the characteristics of Africa’s smallholder-dominated croplands, including the sizes and numbers of fields, can provide critical insights into food security and a range of other socioeconomic and environmental concerns. However, accurately mapping these systems is difficult because there is 1) a spatial and temporal mismatch between satellite sensors and smallholder fields, and 2) a lack of high-quality labels needed to train and assess machine learning classifiers. We developed an approach designed to address these two problems, and used it to map Ghana’s croplands. To overcome the spatio-temporal mismatch, we converted daily, high resolution imagery into two cloud-free composites (the primary growing season and subsequent dry season) covering the 2018 agricultural year, providing a seasonal contrast that helps to improve classification accuracy. To address the problem of label availability, we created a platform that rigorously assesses and minimizes label error, and used it to iteratively train a Random Forests classifier with active learning, which identifies the most informative training sample based on prediction uncertainty. Minimizing label errors improved model F1 scores by up to 25%. Active learning increased F1 scores by an average of 9.1% between first and last training iterations, and 2.3% more than models trained with randomly selected labels. We used the resulting 3.7 m map of cropland probabilities within a segmentation algorithm to delineate crop field boundaries. Using an independent map reference sample (n= 1,207), we found that the cropland probability and field boundary maps had respective overall accuracies of 88 and 86.7%, user’s accuracies for the cropland class of 61.2 and 78.9%, and producer’s accuracies of 67.3 and 58.2%. An unbiased area estimate calculated from the map reference sample indicates that cropland covers 17.1% (15.4–18.9%) of Ghana. Using the most accurate validation labels to correct for biases in the segmented field boundaries map, we estimated that the average size and total number of field in Ghana are 1.73 ha and 1,662,281, respectively. Our results demonstrate an adaptable and transferable approach for developing annual, country-scale maps of crop field boundaries, with several features that effectively mitigate the errors inherent in remote sensing of smallholder-dominated agriculture.",2022,10.3389/frai.2021.744863
Study on the impact of digital countryside construction on fostering sports industry development: based on the moderating role of market-oriented factor allocation and the mediating role of rural consumption upgrade,"IntroductionAgainst the backdrop of China’s coordinated advancement of the “Digital China” and “Rural Revitalization” development strategies, digital countryside construction has emerged as a new opportunity for the sports industry.MethodsBased on panel data from 21 provinces in China from 2015 to 2023, this study employs fixed-panel models, moderation effects models, and mediation effects models to examine the relationship between digital countryside construction and the sports industry, as well as its underlying mechanisms.ResultsDigital countryside construction exerts a significant positive promotion on the sports industry; Market-oriented factor allocation exerts a significant positive moderating influence on the impact of digital countryside construction on the sports industry; Rural consumption upgrade plays a significant positive mediating role in the influence of digital countryside construction on the sports industry. In terms of regional heterogeneity, the eastern region exhibits a significant promoting effect, while the central region shows a suppressing effect that is not statistically significant. The western region also demonstrates a promoting effect, though it is not statistically significant.DiscussionImplementing region-specific development strategies, tailored to local conditions, is of paramount significance for achieving the maximal policy benefits of digital countryside construction. This should be accomplished by deepening market-oriented reforms and enhancing digital infrastructure to foster balanced and high-quality development of the sports industry in both urban and rural areas.",2025,10.3389/frai.2025.1660947
Biologically inspired hybrid model for Alzheimer’s disease classification using structural MRI in the ADNI dataset,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline and structural brain alterations such as cortical atrophy and hippocampal degeneration. Early diagnosis remains challenging due to subtle neuroanatomical changes in early stages. This study proposes a hybrid convolutional neural network-spiking neural network (CNN-SNN) architecture to classify AD stages using structural MRI (sMRI) data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). The model synergizes CNNs for hierarchical spatial feature extraction and SNNs for biologically inspired temporal dynamics processing. The CNN component processes image slices through convolutional layers, batch normalization, and dropout, while the SNN employs leaky integrate-and-fire (LIF) neurons across 25 time steps to simulate temporal progression of neurodegeneration—even with static sMRI inputs. Trained on a three-class task [AD, mild cognitive impairment (MCI), and cognitively normal (CN) subjects], the hybrid network optimizes mean squared error (MSE) loss with L2 regularization and Adam, incorporating early stopping to enhance generalization. Evaluation on ADNI data demonstrates robust performance, with training/validation accuracy and loss tracked over 30 epochs. Classification metrics (precision, recall, F1-score) highlight the model’s ability to disentangle complex spatiotemporal patterns in neurodegeneration. Visualization of learning curves further validates stability during training. An ablation study demonstrates the SNN’s critical role, with its removal reducing accuracy from 99.58 to 75.67%, underscoring the temporal module’s importance. The SNN introduces architectural sparsity via spike-based computation, reducing overfitting and enhancing generalization while aligning with neuromorphic principles for energy-efficient deployment. By bridging deep learning with neuromorphic principles, this work advances AD diagnostic frameworks, offering a computationally efficient and biologically plausible approach for clinical neuroimaging. The results underscore the potential of hybrid CNN-SNN architectures to improve early detection and stratification of neurodegenerative diseases, paving the way for future applications in neuromorphic healthcare systems.",2025,10.3389/frai.2025.1590599
An Overview of Alphafold's Breakthrough,"This paper presents a short summary of the protein folding problem, what it is and why it is significant. Introduces the CASP competition and how accuracy is measured. Looks at different approaches for solving the problem followed by a review of the current breakthroughs in the field introduced by AlphaFold 1 and AlphaFold 2.",2022,10.3389/frai.2022.875587
Pilot Study of Real-World Monitoring of the Heart Rate Variability in Amyotrophic Lateral Sclerosis,"AimsCardiovascular dysautonomia may impact the quality of life and survival in amyotrophic lateral sclerosis (ALS). Such dysfunction is not systematically assessed in these patients. Wearable devices could help. The feasibility of a wearable biosensor to detect heart rate variability (HRV), a physiological marker of sympathovagal balance, was studied for the first time in real-world settings in ALS.MethodsFive ALS patients (two early/three late; one bulbar-onset; mildly-to-moderately disabled) and five age/sex/BMI/comorbidities-matched controls underwent assessment of 3-day HRV via VitalConnect biosensor (worn on the left thorax). De-identified data captured by the biosensor were transferred to a secure cloud server via a relay Bluetooth device. Baseline ALS severity/anxiety and physical activity during testing were documented/quantified. Time-domain HRV measures (i.e., pNN50) were analyzed.ResultsAn overall 3-day abnormal HRV (pNN50 &lt; 3%), was found in three out of five patients (mean ± SD for the group, 2.49 ± 1.51). Similar changes were reported in controls (12.32 ± 21.14%). There were no statistically significant relationships between pNN50 values and baseline anxiety or physical activity during the tested days (p &gt; 0.05 for both groups). A negative correlation was found between pNN50 values and age in patients (p = 0.01) and controls (p = 0.09), which is similar with what is found in the general population. In line with prior studies, pNN50 values were independent of disease stage (p = 0.6) and disability (p = 0.4).ConclusionsThese preliminary results suggest that remote HRV measures using the VitalConnect is feasible and may constitute an improved strategy to provide insights into sympathovagal balance in ALS. Further work with larger sample sizes is warranted.",2022,10.3389/frai.2022.910049
Relation is an option for processing context information,"Attention mechanisms are one of the most frequently used architectures in the development of artificial intelligence because they can process contextual information efficiently. Various artificial intelligence architectures, such as Transformer for processing natural language, image data, etc., include the Attention. Various improvements have been made to enhance its performance since Attention is a powerful component to realize artificial intelligence. The time complexity of Attention depends on the square of the input sequence length. Developing methods to improve the time complexity of Attention is one of the most popular research topics. Attention is a mechanism that conveys contextual information of input sequences to downstream networks. Thus, if one wants to improve the performance of processing contextual information, the focus should not be confined only on improving Attention but also on devising other similar mechanisms as possible alternatives. In this study, we devised an alternative mechanism called “Relation” that can understand the context information of sequential data. Relation is easy to implement, and its time complexity depends only on the length of the sequences; a comparison of the performance of Relation and Attention on several benchmark datasets showed that the context processing capability of Relation is comparable to that of Attention but with less computation time. Processing contextual information at high speeds would be useful because natural language processing and biological sequence processing sometimes deal with very long sequences. Hence, Relation is an ideal option for processing context information.",2022,10.3389/frai.2022.924688
AI assistance in enterprise UX design workflows: enhancing design brief creation for designers,"The study explores the impact of AI tools on the daily tasks of designers in corporate environments, with a focus on the creation and evaluation processes of design briefs. Given ChatGPT’s advanced natural language processing capabilities and its potential to meet the complex communication and analysis needs of design work, this tool was selected to investigate its application in designers’ workflows. Through expert interviews, experimental testing, and third-party expert evaluations, we collected and analyzed data to understand the impact of AI on work processes. The findings indicate that AI tools significantly enhance both operational experience and subjective perceptions across most tasks. Additionally, the study provides a visual comparison of the testing process through a user experience map, highlighting AI’s positive influence on work efficiency, information retrieval, verification, analysis, communication, and decision-making. However, challenges remain in ensuring information authenticity, protecting content copyright, and maintaining professional identity. The primary objective is to gain a comprehensive understanding of the current state of AI application in business contexts and its impact on designers’ roles. By analyzing real-world feedback, the research aims to identify the strengths and weaknesses of AI solutions in enterprises and offer practical recommendations. The study underscores the importance of integrating AI thinking into workflows and adopting a human-centric approach for the future development of corporate work environments.",2024,10.3389/frai.2024.1404647
Spectral momentum integration: hybrid optimization of frequency and time domain gradients,"We propose Spectral Momentum Integration (SMI), an optimization enhancement that processes gradients in both frequency and time domains. SMI applies the Fast Fourier Transform to selectively filter gradient frequency components before blending them with original gradients using an adaptive scheduling mechanism. Experiments on a character-level language model demonstrate that SMI can achieve inference acceleration while maintaining model performance. Our approach integrates with existing optimizers without modifying model architecture, though it introduces computational overhead and hyperparameter complexity. While our current validation is limited to small-scale experiments, SMI provides a proof-of-concept for incorporating frequency-domain processing into neural network optimization, suggesting potential for broader applications pending large-scale validation.",2025,10.3389/frai.2025.1628943
"A hybrid long short-term memory with generalized additive model and post-hoc explainable artificial intelligence with causal inference for air pollutants prediction in Kimberley, South Africa","The study addresses the problem of nonlinear characteristics of common air pollutants by proposing a deep learning time-series model based on the long short-term memory (LSTM) integrated with a generalized additive model (GAM). LSTM model captures both nonlinear relationships and temporal long-term dependencies in time-series data, and GAM provides insight into the statistical relationship between selected features and the target pollutant. The post-hoc eXplainable artificial intelligence (xAI) technique, local interpretable model-agnostic explanation (LIME), further explains the nonlinearity. Finally, causal inference was determined on the impact of the air pollutants relationship, thereby offering further interpretability in which deep learning models are deficient. Meteorological and air pollutant statistical records were leveraged from a Hantam (Karoo) air monitoring station in South Africa, and through a random sampling approach, synthetic data were generated for the city of Kimberley. The model was evaluated with the mean squared error (MSE), root mean squared error (RMSE) and mean absolute error (MAE) for different time-steps. The proposed referred to as long short-term memory generalized additive model based post-hoc eXplainable Artificial Intelligence (LSTM-GAM_xAI) model with a 10-day time-step and 5-day time-step for multiple pollutants prediction guaranteed least MSE. Though the causal effect analysis show no p-values (&gt;0.88) for variables, the experiment results show that LSTM-GAM-xAI guaranteed the lowest MSE values across different time-steps.",2025,10.3389/frai.2025.1620019
EmoShiftNet: a shift-aware multi-task learning framework with fusion strategies for emotion recognition in multi-party conversations,"IntroductionEmotion Recognition in Conversations (ERC) is vital for applications such as mental health monitoring, virtual assistants, and human–computer interaction. However, existing ERC models often neglect emotion shifts—transitions between emotional states across dialogue turns in multi-party conversations (MPCs). These shifts are subtle, context-dependent, and complicated by class imbalance in datasets such as the Multimodal EmotionLines Dataset (MELD).MethodsTo address this, we propose EmoShiftNet, a shift-aware multi-task learning (MTL) framework that jointly performs emotion classification and emotion shift detection. The model integrates multimodal features, including contextualized text embeddings from BERT, acoustic features (Mel-Frequency Cepstral Coefficients, pitch, loudness), and temporal cues (pause duration, speaker overlap, utterance length). Emotion shift detection is incorporated as an auxiliary task via a composite loss function combining focal loss, binary cross-entropy, and triplet margin loss.ResultsEvaluations on the MELD dataset demonstrate that EmoShiftNet achieves higher overall F1-scores than both traditional and graph-based ERC models. In addition, the framework improves the recognition of minority emotions under imbalanced conditions, confirming the effectiveness of incorporating shift supervision and multimodal fusion.DiscussionThese findings highlight the importance of modeling emotional transitions in ERC. By leveraging multi-task learning with explicit shift detection, EmoShiftNet enhances contextual awareness and offers more robust performance for multi-party conversational emotion recognition.",2025,10.3389/frai.2025.1618698
The effect of AI on pink marketing: the case of women’s purchasing behavior using mobile applications,"This research looks in detail at the dynamics of pink marketing and its effect on the purchase behavior of Saudi women through mobile applications, with an emphasis on Artificial Intelligence (AI) as a moderator. Furthermore, this study assesses the effects of customized pink marketing strategies – product, price, promotion, and place – on buying intentions and behaviors. A closed-ended questionnaire was adopted to measure constructs associated with women’s mobile app purchase behavior influenced by pink marketing and AI elements. Structural Equation Modeling (SEM) was the study tool used to examine how AI affects women’s consumer behavior and how it influences pink marketing. The results suggest that each component of the pink marketing mix significantly influences buying behavior, especially price and promotion. Additionally, AI has a significant moderating effect, improving the personalization and effectiveness of marketing activities. The results of this study highlight the essential role of AI in forming consumer engagement in the digital market, providing useful input for marketers who intend to target women in Saudi Arabia. This study complements the understanding of gender marketing in the digital era and provides a vision for the possibility of AI fundamentally changing traditional approaches.",2024,10.3389/frai.2024.1502580
mPD-APP: a mobile-enabled plant diseases diagnosis application using convolutional neural network toward the attainment of a food secure world,"The devastating effect of plant disease infestation on crop production poses a significant threat to the attainment of the United Nations' Sustainable Development Goal 2 (SDG2) of food security, especially in Sub-Saharan Africa. This has been further exacerbated by the lack of effective and accessible plant disease detection technologies. Farmers' inability to quickly and accurately diagnose plant diseases leads to crop destruction and reduced productivity. The diverse range of existing plant diseases further complicates detection for farmers without the right technologies, hindering efforts to combat food insecurity in the region. This study presents a web-based plant diagnosis application, referred to as mobile-enabled Plant Diagnosis-Application (mPD-App). First, a publicly available image dataset, containing a diverse range of plant diseases, was acquired from Kaggle for the purpose of training the detection system. The image dataset was, then, made to undergo the preprocessing stage which included processes such as image-to-array conversion, image reshaping, and data augmentation. The training phase leverages the vast computational ability of the convolutional neural network (CNN) to effectively classify image datasets. The CNN model architecture featured six convolutional layers (including the fully connected layer) with phases, such as normalization layer, rectified linear unit (RELU), max pooling layer, and dropout layer. The training process was carefully managed to prevent underfitting and overfitting of the model, ensuring accurate predictions. The mPD-App demonstrated excellent performance in diagnosing plant diseases, achieving an overall accuracy of 93.91%. The model was able to classify 14 different types of plant diseases with high precision and recall values. The ROC curve showed a promising area under the curve (AUC) value of 0.946, indicating the model's reliability in detecting diseases. The web-based mPD-App offers a valuable tool for farmers and agricultural stakeholders in Sub-Saharan Africa, to detect and diagnose plant diseases effectively and efficiently. To further improve the application's performance, ongoing efforts should focus on expanding the dataset and refining the model's architecture. Agricultural authorities and policymakers should consider promoting and integrating such technologies into existing agricultural extension services to maximize their impact and benefit the farming community.",2023,10.3389/frai.2023.1227950
Automated quantification of penile curvature using artificial intelligence,"ObjectiveTo develop and validate an artificial intelligence (AI)-based algorithm for capturing automated measurements of Penile curvature (PC) based on 2-dimensional images.Materials and methodsNine 3D-printed penile models with differing curvature angles (ranging from 18 to 88°) were used to compile a 900-image dataset featuring multiple camera positions, inclination angles, and background/lighting conditions. The proposed framework of PC angle estimation consisted of three stages: automatic penile area localization, shaft segmentation, and curvature angle estimation. The penile model images were captured using a smartphone camera and used to train and test a Yolov5 model that automatically cropped the penile area from each image. Next, an Unet-based segmentation model was trained, validated, and tested to segment the penile shaft, before a custom Hough-Transform-based angle estimation technique was used to evaluate degree of PC.ResultsThe proposed framework displayed robust performance in cropping the penile area [mean average precision (mAP) 99.4%] and segmenting the shaft [Dice Similarity Coefficient (DSC) 98.4%]. Curvature angle estimation technique generally demonstrated excellent performance, with a mean absolute error (MAE) of just 8.5 when compared with ground truth curvature angles.ConclusionsConsidering current intra- and inter-surgeon variability of PC assessments, the framework reported here could significantly improve precision of PC measurements by surgeons and hypospadiology researchers.",2022,10.3389/frai.2022.954497
A MAGDM approach for evaluating the impact of artificial intelligence on education using 2-tuple linguistic q-rung orthopair fuzzy sets and Schweizer-Sklar weighted power average operator,"The impact of artificial intelligence (AI) in education can be viewed as a multi-attribute group decision-making (MAGDM) problem, in which several stakeholders evaluate the advantages and disadvantages of AI applications in educational settings according to distinct preferences and criteria. A MAGDM framework can assist in providing transparent and logical recommendations for implementing AI in education by methodically analyzing the trade-offs and conflicts among many components, including ethical, social, pedagogical, and technical concerns. A novel development in fuzzy set theory is the 2-tuple linguistic q-rung orthopair fuzzy set (2TLq-ROFS), which is not only a generalized form but also can integrate decision-makers quantitative evaluation ideas and qualitative evaluation information. The 2TLq-ROF Schweizer-Sklar weighted power average operator (2TLq-ROFSSWPA) and the 2TLq-ROF Schweizer-Sklar weighted power geometric (2TLq-ROFSSWPG) operator are two of the aggregation operators we create in this article. We also investigate some of the unique instances and features of the proposed operators. Next, a new Entropy model is built based on 2TLq-ROFS, which may exploit the preferences of the decision-makers to obtain the ideal objective weights for attributes. Next, we extend the VIseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) technique to the 2TLq-ROF version, which provides decision-makers with a greater space to represent their decisions, while also accounting for the uncertainty inherent in human cognition. Finally, a case study of how artificial intelligence has impacted education is given to show the applicability and value of the established methodology. A comparative study is carried out to examine the benefits and improvements of the developed approach.",2024,10.3389/frai.2024.1347626
Accelerating computational fluid dynamics simulation of post-combustion carbon capture modeling with MeshGraphNets,"Packed columns are commonly used in post-combustion processes to capture CO2 emissions by providing enhanced contact area between a CO2-laden gas and CO2-absorbing solvent. To study and optimize solvent-based post-combustion carbon capture systems (CCSs), computational fluid dynamics (CFD) can be used to model the liquid–gas countercurrent flow hydrodynamics in these columns and derive key determinants of CO2-capture efficiency. However, the large design space of these systems hinders the application of CFD for design optimization due to its high computational cost. In contrast, data-driven modeling approaches can produce fast surrogates to study large-scale physics problems. We build our surrogates using MeshGraphNets (MGN), a graph neural network framework that efficiently learns and produces mesh-based simulations. We apply MGN to a random packed column modeled with over 160K graph nodes and a design space consisting of three key input parameters: solvent surface tension, inlet velocity, and contact angle. Our models can adapt to a wide range of these parameters and accurately predict the complex interactions within the system at rates over 1700 times faster than CFD, affirming its practicality in downstream design optimization tasks. This underscores the robustness and versatility of MGN in modeling complex fluid dynamics for large-scale CCS analyses.",2025,10.3389/frai.2024.1441985
Self-trainable and adaptive sensor intelligence for selective data generation,"With the increasing integration of machine learning into IoT devices, managing energy consumption and data transmission has become a critical challenge. Many IoT applications depend on complex computations performed on server-side infrastructure, necessitating efficient methods to reduce unnecessary data transmission. One promising solution involves deploying compact machine learning models near sensors, enabling intelligent identification and transmission of only relevant data frames. However, existing near-sensor models lack adaptability, as they require extensive pre-training and are often rigidly configured prior to deployment. This paper proposes a novel framework that fuses online learning, active learning, and knowledge distillation to enable adaptive, resource-efficient near-sensor intelligence. Our approach allows near-sensor models to dynamically fine-tune their parameters post-deployment using online learning, eliminating the need for extensive pre-labeling and training. Through a sequential training and execution process, the framework achieves continuous adaptability without prior knowledge of the deployment environment. To enhance performance while preserving model efficiency, we integrate knowledge distillation, enabling the transfer of critical insights from a larger teacher model to a compact student model. Additionally, active learning reduces the required training data while maintaining competitive performance. We validated our framework on both benchmark data from the MS COCO dataset and in a simulated IoT environment. The results demonstrate significant improvements in energy efficiency and data transmission optimization, highlighting the practical applicability of our method in real-world IoT scenarios.",2025,10.3389/frai.2024.1403187
Distributed cognition for collaboration between human drivers and self-driving cars,"This paper focuses on the collaboration between human drivers and intelligent vehicles. We propose a collaboration mechanism grounded on the concept of distributed cognition. With distributed cognition, intelligence does not lie just in the single entity but also in the interaction with the other cognitive components in a system. We apply this idea to vehicle intelligence, proposing a system distributed into two cognitive entities—the human and the autonomous agent—that together contribute to drive the vehicle. This account of vehicle intelligence differs from the mainstream research effort on highly autonomous cars. The proposed mechanism follows one of the paradigm derived from distributed cognition, the rider-horse metaphor: just like the rider communicates their intention to the horse through the reins, the human influences the agent using the pedals and the steering wheel. We use a driving simulator to demonstrate the collaboration in action, showing how the human can communicate and interact with the agent in various ways with safe outcomes.",2022,10.3389/frai.2022.910801
"Judgment aggregation, discursive dilemma and reflective equilibrium: Neural language models as self-improving doxastic agents","Neural language models (NLMs) are susceptible to producing inconsistent output. This paper proposes a new diagnosis as well as a novel remedy for NLMs' incoherence. We train NLMs on synthetic text corpora that are created by simulating text production in a society. For diagnostic purposes, we explicitly model the individual belief systems of artificial agents (authors) who produce corpus texts. NLMs, trained on those texts, can be shown to aggregate the judgments of individual authors during pre-training according to sentence-wise vote ratios (roughly, reporting frequencies), which inevitably leads to so-called discursive dilemmas: aggregate judgments are inconsistent even though all individual belief states are consistent. As a remedy for such inconsistencies, we develop a self-training procedure—inspired by the concept of reflective equilibrium—that effectively reduces the extent of logical incoherence in a model's belief system, corrects global mis-confidence, and eventually allows the model to settle on a new, epistemically superior belief state. Thus, social choice theory helps to understand why NLMs are prone to produce inconsistencies; epistemology suggests how to get rid of them.",2022,10.3389/frai.2022.900943
Biologically-Inspired Pulse Signal Processing for Intelligence at the Edge,"There is an ever-growing mismatch between the proliferation of data-intensive, power-hungry deep learning solutions in the machine learning (ML) community and the need for agile, portable solutions in resource-constrained devices, particularly for intelligence at the edge. In this paper, we present a fundamentally novel approach that leverages data-driven intelligence with biologically-inspired efficiency. The proposed Sparse Embodiment Neural-Statistical Architecture (SENSA) decomposes the learning task into two distinct phases: a training phase and a hardware embedment phase where prototypes are extracted from the trained network and used to construct fast, sparse embodiment for hardware deployment at the edge. Specifically, we propose the Sparse Pulse Automata via Reproducing Kernel (SPARK) method, which first constructs a learning machine in the form of a dynamical system using energy-efficient spike or pulse trains, commonly used in neuroscience and neuromorphic engineering, then extracts a rule-based solution in the form of automata or lookup tables for rapid deployment in edge computing platforms. We propose to use the theoretically-grounded unifying framework of the Reproducing Kernel Hilbert Space (RKHS) to provide interpretable, nonlinear, and nonparametric solutions, compared to the typical neural network approach. In kernel methods, the explicit representation of the data is of secondary nature, allowing the same algorithm to be used for different data types without altering the learning rules. To showcase SPARK’s capabilities, we carried out the first proof-of-concept demonstration on the task of isolated-word automatic speech recognition (ASR) or keyword spotting, benchmarked on the TI-46 digit corpus. Together, these energy-efficient and resource-conscious techniques will bring advanced machine learning solutions closer to the edge.",2021,10.3389/frai.2021.568384
AMaze: an intuitive benchmark generator for fast prototyping of generalizable agents,"Traditional approaches to training agents have generally involved a single, deterministic environment of minimal complexity to solve various tasks such as robot locomotion or computer vision. However, agents trained in static environments lack generalization capabilities, limiting their potential in broader scenarios. Thus, recent benchmarks frequently rely on multiple environments, for instance, by providing stochastic noise, simple permutations, or altogether different settings. In practice, such collections result mainly from costly human-designed processes or the liberal use of random number generators. In this work, we introduce AMaze, a novel benchmark generator in which embodied agents must navigate a maze by interpreting visual signs of arbitrary complexities and deceptiveness. This generator promotes human interaction through the easy generation of feature-specific mazes and an intuitive understanding of the resulting agents' strategies. As a proof-of-concept, we demonstrate the capabilities of the generator in a simple, fully discrete case with limited deceptiveness. Agents were trained under three different regimes (one-shot, scaffolding, and interactive), and the results showed that the latter two cases outperform direct training in terms of generalization capabilities. Indeed, depending on the combination of generalization metric, training regime, and algorithm, the median gain ranged from 50% to 100% and maximal performance was achieved through interactive training, thereby demonstrating the benefits of a controllable human-in-the-loop benchmark generator.",2025,10.3389/frai.2025.1511712
The application of random forest-based models in prognostication of gastrointestinal tract malignancies: a systematic review,"IntroductionMalignancies of the GI tract account for one-third of cancer-related deaths globally and more than 25% of all cancer diagnoses. The rising prevalence of GI tract malignancies and the shortcomings of existing treatment approaches highlight the need for better predictive prediction models. RF’s machine-learning method can predict cancers by using numerous decision trees to locate, classify, and forecast data. This systematic study aims to assess how well RF models predict the prognosis of GI tract malignancies.MethodsFollowing PRISMA criteria, we performed a systematic search in PubMed, Scopus, Google Scholar, and Web of Science until May 28, 2024. Studies used RF models to forecast the prognosis of GI tract malignancies, including esophageal, gastric, and colorectal cancers. The QUIPS approach was used to evaluate the quality of the included studies.ResultsOut of 1846 records, 86 studies met inclusion requirements; eight were disqualified. Numerous studies showed that when combining clinical, genetic, and pathological data, RF models were very accurate and dependable in predicting the prognosis of GI tract malignancies, responses, recurrence, survival rates, and metastatic risks, distinguishing between operable and inoperable tumors, and patient outcomes. RF models outperformed conventional prognostic techniques in terms of accuracy; several research studies reported prediction accuracies of over 80% in survival rate estimates.ConclusionRF models, in terms of accuracy, performed better than the conventional approaches and provided better capabilities for clinical decision-making. Such models can increase the life quality and survival of patients by personalizing their treatment regimens for cancers of the GI tract. These models can, in a significant manner, raise patients’ survival and quality of life through hastening clinical decision-making and providing personalized treatment options.",2025,10.3389/frai.2025.1517670
A Matrix-Variate t Model for Networks,"Networks represent a useful tool to describe relationships among financial firms and network analysis has been extensively used in recent years to study financial connectedness. An aspect, which is often neglected, is that network observations come with errors from different sources, such as estimation and measurement errors, thus a proper statistical treatment of the data is needed before network analysis can be performed. We show that node centrality measures can be heavily affected by random errors and propose a flexible model based on the matrix-variate t distribution and a Bayesian inference procedure to de-noise the data. We provide an application to a network among European financial institutions.",2021,10.3389/frai.2021.674166
Innova4Health: an integrated approach for prevention of recurrence and personalized treatment of Major Depressive Disorder,"BackgroundMajor Depressive Disorder (MDD) is a prevalent mental health condition characterized by persistent low mood, cognitive and physical symptoms, anhedonia (loss of interest in activities), and suicidal ideation. The World Health Organization (WHO) predicts depression will become the leading cause of disability by 2030. While biological markers remain essential for understanding MDD's pathophysiology, recent advancements in social signal processing and environmental monitoring hold promise. Wearable technologies, including smartwatches and air purifiers with environmental sensors, can generate valuable digital biomarkers for depression assessment in real-world settings. Integrating these with existing physical, psychopathological, and other indices (autoimmune, inflammatory, neuroradiological) has the potential to improve MDD recurrence prevention strategies.MethodsThis prospective, randomized, interventional, and non-pharmacological integrated study aims to evaluate digital and environmental biomarkers in adolescents and young adults diagnosed with MDD who are currently taking medication. The study implements a sensor-integrated platform built around an open-source “Pothos” air purifier system. This platform is designed for scalability and integration with third-party devices. It accomplishes this through software interfaces, a dedicated app, sensor signal pre-processing, and an embedded deep learning AI system. The study will enroll two experimental groups (10 adolescents and 30 young adults each). Within each group, participants will be randomly allocated to Group A or Group B. Only Group B will receive the technological equipment (Pothos system and smartwatch) for collecting digital biomarkers. Blood and saliva samples will be collected at baseline (T0) and endpoint (T1) to assess inflammatory markers and cortisol levels.ResultsFollowing initial age-based stratification, the sample will undergo detailed classification at the 6-month follow-up based on remission status. Digital and environmental biomarker data will be analyzed to explore intricate relationships between these markers, depression symptoms, disease progression, and early signs of illness.ConclusionThis study seeks to validate an AI tool for enhancing early MDD clinical management, implement an AI solution for continuous data processing, and establish an AI infrastructure for managing healthcare Big Data. Integrating innovative psychophysical assessment tools into clinical practice holds significant promise for improving diagnostic accuracy and developing more specific digital devices for comprehensive mental health evaluation.",2024,10.3389/frai.2024.1366055
Asynchronous Deep Double Dueling Q-learning for trading-signal execution in limit order book markets,"We employ deep reinforcement learning (RL) to train an agent to successfully translate a high-frequency trading signal into a trading strategy that places individual limit orders. Based on the ABIDES limit order book simulator, we build a reinforcement learning OpenAI gym environment and utilize it to simulate a realistic trading environment for NASDAQ equities based on historic order book messages. To train a trading agent that learns to maximize its trading return in this environment, we use Deep Dueling Double Q-learning with the APEX (asynchronous prioritized experience replay) architecture. The agent observes the current limit order book state, its recent history, and a short-term directional forecast. To investigate the performance of RL for adaptive trading independently from a concrete forecasting algorithm, we study the performance of our approach utilizing synthetic alpha signals obtained by perturbing forward-looking returns with varying levels of noise. Here, we find that the RL agent learns an effective trading strategy for inventory management and order placing that outperforms a heuristic benchmark trading strategy having access to the same signal.",2023,10.3389/frai.2023.1151003
Analysis of social metrics on scientific production in the field of emotion-aware education through artificial intelligence,"Research in the field of Artificial Intelligence applied to emotions in the educational context has experienced significant growth in recent years. However, despite the field’s profound implications for the educational community, the social impact of this scientific production on digital social media remains unclear. To address this question, the present research has been proposed, aiming to analyze the social impact of scientific production on the use of Artificial Intelligence for emotions in the educational context. For this purpose, a sample of 243 scientific publications indexed in Scopus and Web of Science has been selected, from which a second sample of 6,094 social impact records has been extracted from Altmetric, Crossref, and PlumX databases. A dual analysis has been conducted using specially designed software: on one hand, the scientific sample has been analyzed from a bibliometric perspective, and on the other hand, the social impact records have been studied. Comparative analysis based on the two dimensions, scientific and social, has focused on the evolution of scientific production with its corresponding social impact, sources, impact, and content analysis. The results indicate that scientific publications have had a high social impact (with an average of 25.08 social impact records per publication), with a significant increase in research interest starting from 2019, likely driven by the emotional implications of measures taken to curb the COVID-19 pandemic. Furthermore, a lack of alignment has been identified between articles with the highest scientific impact and those with the highest social impact, as well as a lack of alignment in the most commonly used terms from both scientific and social perspectives, a significant variability in the lag in months for scientific research to make an impact on social media, and the fact that the social impact of the research did not emerge from the interest of Twitter users unaffiliated with the research, but rather from the authors, publishers, or scientific institutions. The proposed comparative methodology can be applied to any field of study, making it a useful tool given that current trends in accreditation agencies propose the analysis of the repercussion of scientific research in social media.",2024,10.3389/frai.2024.1401162
EPPO ontology: a semantic-driven approach for plant and pest codes representation,"The agricultural industry and regulatory organizations define strategies and build tools and products for plant protection against pests. To identify different plants and their related pests and avoid inconsistencies between such organizations, an agreed and shared classification is necessary. In this regard, the European and Mediterranean Plant Protection Organization (EPPO) has been working on defining and maintaining a harmonized coding system (EPPO codes). EPPO codes are an easy way of referring to a specific organism by means of short 5 or 6 letter codes instead of long scientific names or ambiguous common names. EPPO codes are freely available in different formats through the EPPO Global Database platform and are implemented as a worldwide standard and used among scientists and experts in both industry and regulatory organizations. One of the large companies that adopted such codes is BASF, which uses them mainly in research and development to build their crop protection and seeds products. However, extracting the information is limited by fixed API calls or files that require additional processing steps. Facing these issues makes it difficult to use the available information flexibly, infer new data connections, or enrich it with external data sources. To overcome such limitations, BASF has developed an internal EPPO ontology to represent the list of codes provided by the EPPO Global Database as well as the regulatory categorization and relationship among them. This paper presents the development process of this ontology along with its enrichment process, which allows the reuse of relevant information available in an external knowledge source such as the NCBI Taxon. In addition, this paper describes the use and adoption of the EPPO ontology within the BASF's Agricultural Solutions division and the lessons learned during this work.",2023,10.3389/frai.2023.1131667
Patient-centered modeling of the breast biopsy experience,"IntroductionDespite significant advances in breast cancer screening and early detection over recent decades, rising patient volumes, limited resources, and time constraints hinder healthcare teams from anticipating distress and effectively managing the patient experience. We leveraged real-world data from 236 patients during a breast biopsy procedure and follow-up period.ObjectiveThe study goal was to model important components of the multifaceted biopsy procedure and its effect on patient experience.MethodsWe integrated data from patient-reported outcomes, psycho-social assessments, and workflow annotations.ResultsWe (1) provide a visual model of the patient pathway, (2) predict, with linear mixed models and machine learning, anxiety based on psychological pre-assessments as well as procedural events, and (3) analyze communication between caregiver and patient to understand moderators of the patient experience. Predictive modeling revealed significant correlation between psychological pre-assessments and median anxiety during biopsy (IES β = 0.91, CES-D β = 0.8, PSS β = 0.62, STAI β = 0.58, all with p &lt; 0.001). Higher baseline stress was strongly associated with greater anxiety during biopsy. Centering each individual's procedure time at her first local anesthesia (LA) revealed a significant (βt2p = 5.43e−06) temporal pattern in anxiety, which increased until LA and decreased afterwards. Using natural language processing, we identified patient expressions of pain and distress alongside workflow annotations.ConclusionOur findings highlight the potential of combining data to model patient experience during a medical procedure. Our work helps to develop digital twins of medical procedures to support clinicians to provide proactive care and mitigate patient distress.",2025,10.3389/frai.2025.1618357
"Evaluating artificial intelligence bias in nephrology: the role of diversity, equity, and inclusion in AI-driven decision-making and ethical regulation","BackgroundThe integration of Artificial Intelligence (AI) in nephrology has raised concerns regarding bias, fairness, and ethical decision-making, particularly in the context of Diversity, Equity, and Inclusion (DEI). AI-driven models, including Large Language Models (LLMs) like ChatGPT, may unintentionally reinforce existing disparities in patient care and workforce recruitment. This study investigates how AI models (ChatGPT 3.5 and 4.0) handle DEI-related ethical considerations in nephrology, highlighting the need for improved regulatory oversight to ensure equitable AI deployment.MethodsThe study was conducted in March 2024 using ChatGPT 3.5 and 4.0. Eighty simulated cases were developed to assess ChatGPT’s decision-making across diverse nephrology topics. ChatGPT was instructed to respond to questions considering factors such as age, sex, gender identity, race, ethnicity, religion, cultural beliefs, socioeconomic status, education level, family structure, employment, insurance, geographic location, disability, mental health, language proficiency, and technology access.ResultsChatGPT 3.5 provided a response to all scenario questions and did not refuse to make decisions under any circumstances. This contradicts the essential DEI principle of avoiding decisions based on potentially discriminatory criteria. In contrast, ChatGPT 4.0 declined to make decisions based on potentially discriminatory criteria in 13 (16.3%) scenarios during the first round and in 5 (6.3%) during the second round.ConclusionWhile ChatGPT 4.0 shows improvement in ethical AI decision-making, its limited recognition of bias and DEI considerations underscores the need for robust AI regulatory frameworks in nephrology. AI governance must incorporate structured DEI guidelines, ongoing bias detection mechanisms, and ethical oversight to prevent AI-driven disparities in clinical practice and workforce recruitment. This study emphasizes the importance of transparency, fairness, and inclusivity in AI development, calling for collaborative efforts between AI developers, nephrologists, policymakers, and patient communities to ensure AI serves as an equitable tool in nephrology.",2025,10.3389/frai.2025.1525937
Advances in Completely Automated Vowel Analysis for Sociophonetics: Using End-to-End Speech Recognition Systems With DARLA,"In recent decades, computational approaches to sociophonetic vowel analysis have been steadily increasing, and sociolinguists now frequently use semi-automated systems for phonetic alignment and vowel formant extraction, including FAVE (Forced Alignment and Vowel Extraction,Rosenfelder et al., 2011; Evanini et al., Proceedings of Interspeech, 2009), Penn Aligner (Yuan and Liberman, J. Acoust. Soc. America, 2008, 123, 3878), and DARLA (Dartmouth Linguistic Automation), (Reddy and Stanford, DARLA Dartmouth Linguistic Automation: Online Tools for Linguistic Research, 2015a). Yet these systems still have a major bottleneck: manual transcription. For most modern sociolinguistic vowel alignment and formant extraction, researchers must first create manual transcriptions. This human step is painstaking, time-consuming, and resource intensive. If this manual step could be replaced with completely automated methods, sociolinguists could potentially tap into vast datasets that have previously been unexplored, including legacy recordings that are underutilized due to lack of transcriptions. Moreover, if sociolinguists could quickly and accurately extract phonetic information from the millions of hours of new audio content posted on the Internet every day, a virtual ocean of speech from newly created podcasts, videos, live-streams, and other audio content would now inform research. How close are the current technological tools to achieving such groundbreaking changes for sociolinguistics? Prior work (Reddy et al., Proceedings of the North American Association for Computational Linguistics 2015 Conference, 2015b, 71–75) showed that an HMM-based Automated Speech Recognition system, trained with CMU Sphinx (Lamere et al., 2003), was accurate enough for DARLA to uncover evidence of the US Southern Vowel Shift without any human transcription. Even so, because that automatic speech recognition (ASR) system relied on a small training set, it produced numerous transcription errors. Six years have passed since that study, and since that time numerous end-to-end automatic speech recognition (ASR) algorithms have shown considerable improvement in transcription quality. One example of such a system is the RNN/CTC-based DeepSpeech from Mozilla (Hannun et al., 2014). (RNN stands for recurrent neural networks, the learning mechanism for DeepSpeech. CTC stands for connectionist temporal classification, the mechanism to merge phones into words). The present paper combines DeepSpeech with DARLA to push the technological envelope and determine how well contemporary ASR systems can perform in completely automated vowel analyses with sociolinguistic goals. Specifically, we used these techniques on audio recordings from 352 North American English speakers in the International Dialects of English Archive (IDEA1), extracting 88,500 tokens of vowels in stressed position from spontaneous, free speech passages. With this large dataset we conducted acoustic sociophonetic analyses of the Southern Vowel Shift and the Northern Cities Chain Shift in the North American IDEA speakers. We compared the results using three different sources of transcriptions: 1) IDEA’s manual transcriptions as the baseline “ground truth”, 2) the ASR built on CMU Sphinx used by Reddy et al. (Proceedings of the North American Association for Computational Linguistics 2015 Conference, 2015b, 71–75), and 3) the latest publicly available Mozilla DeepSpeech system. We input these three different transcriptions to DARLA, which automatically aligned and extracted the vowel formants from the 352 IDEA speakers. Our quantitative results show that newer ASR systems like DeepSpeech show considerable promise for sociolinguistic applications like DARLA. We found that DeepSpeech’s automated transcriptions had significantly fewer character error rates than those from the prior Sphinx system (from 46 to 35%). When we performed the sociolinguistic analysis of the extracted vowel formants from DARLA, we found that the automated transcriptions from DeepSpeech matched the results from the ground truth for the Southern Vowel Shift (SVS): five vowels showed a shift in both transcriptions, and two vowels didn’t show a shift in either transcription. The Northern Cities Shift (NCS) was more difficult to detect, but ground truth and DeepSpeech matched for four vowels: One of the vowels showed a clear shift, and three showed no shift in either transcription. Our study therefore shows how technology has made progress toward greater automation in vowel sociophonetics, while also showing what remains to be done. Our statistical modeling provides a quantified view of both the abilities and the limitations of a completely “hands-free” analysis of vowel shifts in a large dataset. Naturally, when comparing a completely automated system against a semi-automated system involving human manual work, there will always be a tradeoff between accuracy on the one hand versus speed and replicability on the other hand [Kendall and Joseph, Towards best practices in sociophonetics (with Marianna DiPaolo), 2014]. The amount of “noise” that can be tolerated for a given study will depend on the particular research goals and researchers’ preferences. Nonetheless, our study shows that, for certain large-scale applications and research goals, a completely automated approach using publicly available ASR can produce meaningful sociolinguistic results across large datasets, and these results can be generated quickly, efficiently, and with full replicability.",2021,10.3389/frai.2021.662097
Situational perception in distracted driving: an agentic multi-modal LLM framework,"IntroductionDistracted driving is a significant public safety concern, causing thousands of accidents annually. While most driver assistance systems emphasize distraction detection, they fail to deliver real-time environmental perception and context-aware interventions.MethodsWe propose a large language model (LLM)-driven intervention framework that assumes distraction is pre-detected and dynamically integrates camera and GPS inputs to generate verbal driver alerts. The framework employs an agentic design, where specialized tools handle object detection, speed limits, live traffic conditions, and weather data. Structured orchestration ensures information is fused efficiently, balancing accuracy with conciseness to avoid overwhelming the driver.ResultsEvaluation of the system demonstrates high performance, with semantic intervention correctness of 85.7% and an average response latency of 1.74 s. Compared to conventional ML-based driver assistance approaches, our framework effectively synthesizes multi-modal environmental data and produces actionable alerts in real time.Discussion/conclusionThese findings highlight the potential of LLM-driven, multi-modal reasoning for distracted driving intervention. Integrating specialized agents and structured orchestration improves situational awareness, maintains concise communication, and meets real-time safety requirements. This proof-of-concept establishes a pathway for deploying intelligent, AI-driven driver support systems in safety-critical applications.",2025,10.3389/frai.2025.1669937
Deep learning prediction of two-dimensional ocean dynamics with wavelet-compressed data,"This study addresses the challenge represented by the application of deep learning models to the prediction of ocean dynamics using datasets over a large region or with high spatial or temporal resolution In a previous study by the authors of this article, they showed that such a challenge could be met by using a divide and conquer approach. The domain was in fact split into multiple sub-regions, which were small enough to be predicted individually and in parallel with each other by a deep learning model. At each time step of the prediction process, the sub-model solutions would be merged at the boundary of each sub-region to remove discontinuities between consecutive domains in order to predict the evolution of the full domain. This approach led to the growth of non-dynamical errors that decreased the prediction skill of our model. In the study herein, we show that wavelets can be used to compress the data and reduce its dimension. Each compression level reduces by a factor of two the horizontal resolution of the dataset. We show that despite the loss of information, a level 3 compression produces an improved prediction of the ocean two-dimensional data in comparison to the divide and conquer approach. Our method is evaluated on the prediction of the sea surface height of the most energetic feature of the Gulf of Mexico, namely the Loop Current.",2022,10.3389/frai.2022.923932
A global model-agnostic rule-based XAI method based on Parameterized Event Primitives for time series classifiers,"Time series classification is a challenging research area where machine learning and deep learning techniques have shown remarkable performance. However, often, these are seen as black boxes due to their minimal interpretability. On the one hand, there is a plethora of eXplainable AI (XAI) methods designed to elucidate the functioning of models trained on image and tabular data. On the other hand, adapting these methods to explain deep learning-based time series classifiers may not be straightforward due to the temporal nature of time series data. This research proposes a novel global post-hoc explainable method for unearthing the key time steps behind the inferences made by deep learning-based time series classifiers. This novel approach generates a decision tree graph, a specific set of rules, that can be seen as explanations, potentially enhancing interpretability. The methodology involves two major phases: (1) training and evaluating deep-learning-based time series classification models, and (2) extracting parameterized primitive events, such as increasing, decreasing, local max and local min, from each instance of the evaluation set and clustering such events to extract prototypical ones. These prototypical primitive events are then used as input to a decision-tree classifier trained to fit the model predictions of the test set rather than the ground truth data. Experiments were conducted on diverse real-world datasets sourced from the UCR archive, employing metrics such as accuracy, fidelity, robustness, number of nodes, and depth of the extracted rules. The findings indicate that this global post-hoc method can improve the global interpretability of complex time series classification models.",2024,10.3389/frai.2024.1381921
Managing human-AI collaborations within Industry 5.0 scenarios via knowledge graphs: key challenges and lessons learned,"In this paper, we discuss technologies and approaches based on Knowledge Graphs (KGs) that enable the management of inline human interventions in AI-assisted manufacturing processes in Industry 5.0 under potentially changing conditions in order to maintain or improve the overall system performance. Whereas KG-based systems are commonly based on a static view with their structure fixed at design time, we argue that the dynamic challenge of inline Human-AI (H-AI) collaboration in industrial settings calls for a late shaping design principle. In contrast to early shaping, which determines the system's behavior at design time in a fine granular manner, late shaping is a coarse-to-fine approach that leaves more space for fine-tuning, adaptation and integration of human intelligence at runtime. In this context we discuss approaches and lessons learned from the European manufacturing project Teaming.AI, https://www.teamingai-project.eu/, addressing general challenges like the modeling of domain expertise with particular focus on vertical knowledge integration, as well as challenges linked to an industrial KG of choice, such as its dynamic population and the late shaping of KG embeddings as the foundation of relational machine learning models which have emerged as an effective tool for exploiting graph-structured data to infer new insights.",2024,10.3389/frai.2024.1247712
A data-driven approach for the partial reconstruction of individual human molar teeth using generative deep learning,"Background and objectiveDue to the high prevalence of dental caries, fixed dental restorations are regularly required to restore compromised teeth or replace missing teeth while retaining function and aesthetic appearance. The fabrication of dental restorations, however, remains challenging due to the complexity of the human masticatory system as well as the unique morphology of each individual dentition. Adaptation and reworking are frequently required during the insertion of fixed dental prostheses (FDPs), which increase cost and treatment time. This article proposes a data-driven approach for the partial reconstruction of occlusal surfaces based on a data set that comprises 92 3D mesh files of full dental crown restorations.MethodsA Generative Adversarial Network (GAN) is considered for the given task in view of its ability to represent extensive data sets in an unsupervised manner with a wide variety of applications. Having demonstrated good capabilities in terms of image quality and training stability, StyleGAN-2 has been chosen as the main network for generating the occlusal surfaces. A 2D projection method is proposed in order to generate 2D representations of the provided 3D tooth data set for integration with the StyleGAN architecture. The reconstruction capabilities of the trained network are demonstrated by means of 4 common inlay types using a Bayesian Image Reconstruction method. This involves pre-processing the data in order to extract the necessary information of the tooth preparations required for the used method as well as the modification of the initial reconstruction loss.ResultsThe reconstruction process yields satisfactory visual and quantitative results for all preparations with a root mean square error (RMSE) ranging from 0.02 mm to 0.18 mm. When compared against a clinical procedure for CAD inlay fabrication, the group of dentists preferred the GAN-based restorations for 3 of the total 4 inlay geometries.ConclusionsThis article shows the effectiveness of the StyleGAN architecture with a downstream optimization process for the reconstruction of 4 different inlay geometries. The independence of the reconstruction process and the initial training of the GAN enables the application of the method for arbitrary inlay geometries without time-consuming retraining of the GAN.",2024,10.3389/frai.2024.1339193
SRflow: Deep learning based super-resolution of 4D-flow MRI data,"Exploiting 4D-flow magnetic resonance imaging (MRI) data to quantify hemodynamics requires an adequate spatio-temporal vector field resolution at a low noise level. To address this challenge, we provide a learned solution to super-resolve in vivo 4D-flow MRI data at a post-processing level. We propose a deep convolutional neural network (CNN) that learns the inter-scale relationship of the velocity vector map and leverages an efficient residual learning scheme to make it computationally feasible. A novel, direction-sensitive, and robust loss function is crucial to learning vector-field data. We present a detailed comparative study between the proposed super-resolution and the conventional cubic B-spline based vector-field super-resolution. Our method improves the peak-velocity to noise ratio of the flow field by 10 and 30% for in vivo cardiovascular and cerebrovascular data, respectively, for 4 × super-resolution over the state-of-the-art cubic B-spline. Significantly, our method offers 10x faster inference over the cubic B-spline. The proposed approach for super-resolution of 4D-flow data would potentially improve the subsequent calculation of hemodynamic quantities.",2022,10.3389/frai.2022.928181
Bayesian reinforcement learning for navigation planning in unknown environments,"This study focuses on a rescue mission problem, particularly enabling agents/robots to navigate efficiently in unknown environments. Technological advances, including manufacturing, sensing, and communication systems, have raised interest in using robots or drones for rescue operations. Effective rescue operations require quick identification of changes in the environment and/or locating the victims/injuries as soon as possible. Several techniques have been developed in recent years for autonomy in rescue missions, including motion planning, adaptive control, and more recently, reinforcement learning techniques. These techniques rely on full knowledge of the environment or the availability of simulators that can represent real environments during rescue operations. However, in practice, agents might have little or no information about the environment or the number or locations of injuries, preventing/limiting the application of most existing techniques. This study provides a probabilistic/Bayesian representation of the unknown environment, which jointly models the stochasticity in the agent's navigation and the environment uncertainty into a vector called the belief state. This belief state allows offline learning of the optimal Bayesian policy in an unknown environment without the need for any real data/interactions, which guarantees taking actions that are optimal given all available information. To address the large size of belief space, deep reinforcement learning is developed for computing an approximate Bayesian planning policy. The numerical experiments using different maze problems demonstrate the high performance of the proposed policy.",2024,10.3389/frai.2024.1308031
Approach for enhancing the accuracy of semantic segmentation of chest X-ray images by edge detection and deep learning integration,"IntroductionAccurate segmentation of anatomical structures in chest X-ray images remains challenging, especially for regions with low contrast and overlapping structures. This limitation significantly affects the diagnosis of cardiothoracic diseases. Existing deep learning methods often struggle with preserving structural boundaries, leading to segmentation artifacts.MethodsTo address these challenges, I propose a novel segmentation approach that integrates contour detection techniques with the U-net deep learning architecture. Specifically, the method employs Sobel and Scharr edge detection filters to enhance structural boundaries in chest X-ray images before segmentation. The pipeline involves pre-processing using contour detection, followed by segmentation with a U-net model trained to identify lungs, heart, and clavicles.ResultsExperimental evaluation demonstrated that using edge-enhancing filters, particularly the Sobel operator, leads to a marked improvement in segmentation accuracy. For lung segmentation, the model achieved an accuracy of 99.26%, a Dice coefficient of 98.88%, and a Jaccard index of 97.54%. Heart segmentation results included 99.47% accuracy and 94.14% Jaccard index, while clavicle segmentation reached 99.79% accuracy and 89.57% Jaccard index. These results consistently outperform the baseline U-net model without edge enhancement.DiscussionThe integration of contour detection methods with the U-net model significantly improves the segmentation quality of complex anatomical regions in chest X-rays. Among the tested filters, the Sobel operator proved to be the most effective in enhancing boundary information and reducing segmentation artifacts. This approach offers a promising direction for more accurate and robust computer-aided diagnosis systems in radiology.",2025,10.3389/frai.2025.1522730
Artificial intelligence in ADHD assessment: a comprehensive review of research progress from early screening to precise differential diagnosis,"Attention deficit hyperactivity disorder (ADHD) diagnosis traditionally relies on subjective assessments, which lead to challenges like symptom overlap, heterogeneity, and misdiagnosis risk. Artificial intelligence (AI), especially machine learning (ML) and deep learning (DL), offers objective assessment opportunities by processing complex multimodal data (behavioral, neurophysiological, neuroimaging, genetic). This paper reviews AI’s current applications in objective ADHD assessment, covering early screening, risk prediction, diagnostic assistance, classification, assistance in precise differential diagnosis, symptom quantification, and heterogeneous subtype identification. While AI models show significant potential in extracting objective biomarkers and improving assessment efficiency, the field faces challenges: insufficient standardized data, limited generalization, interpretability issues, potential biases, and lack of rigorous clinical validation. Future research must establish large-scale, standardized multimodal databases, develop robust, interpretable, and fair AI models, and conduct rigorous clinical translation validation to achieve responsible, precise, objective, and personalized ADHD assessment and management.",2025,10.3389/frai.2025.1624485
The automated Greulich and Pyle: a coming-of-age for segmental methods?,"The well-known Greulich and Pyle (GP) method of bone age assessment (BAA) relies on comparing a hand X-ray against templates of discrete maturity classes collected in an atlas. Automated methods have recently shown great success with BAA, especially using deep learning. In this perspective, we first review the success and limitations of various automated BAA methods. We then offer a novel hypothesis: When networks predict bone age that is not aligned with a GP reference class, it is not simply statistical error (although there is that as well); they are picking up nuances in the hand X-ray that lie “outside that class.” In other words, trained networks predict distributions around classes. This raises a natural question: How can we further understand the reasons for a prediction to deviate from the nominal class age? We claim that segmental aging, that is, ratings based on characteristic bone groups can be used to qualify predictions. This so-called segmental GP method has excellent properties: It can not only help identify differential maturity in the hand but also provide a systematic way to extend the use of the current GP atlas to various other populations.",2024,10.3389/frai.2024.1326488
Self-attention with temporal prior: can we learn more from the arrow of time?,"Many diverse phenomena in nature often inherently encode both short- and long-term temporal dependencies, which especially result from the direction of the flow of time. In this respect, we discovered experimental evidence suggesting that interrelations of these events are higher for closer time stamps. However, to be able for attention-based models to learn these regularities in short-term dependencies, it requires large amounts of data, which are often infeasible. This is because, while they are good at learning piece-wise temporal dependencies, attention-based models lack structures that encode biases in time series. As a resolution, we propose a simple and efficient method that enables attention layers to better encode the short-term temporal bias of these data sets by applying learnable, adaptive kernels directly to the attention matrices. We chose various prediction tasks for the experiments using Electronic Health Records (EHR) data sets since they are great examples with underlying long- and short-term temporal dependencies. Our experiments show exceptional classification results compared to best-performing models on most tasks and data sets.",2024,10.3389/frai.2024.1397298
Multimodal driver emotion recognition using motor activity and facial expressions,"Driving performance can be significantly impacted when a person experiences intense emotions behind the wheel. Research shows that emotions such as anger, sadness, agitation, and joy can increase the risk of traffic accidents. This study introduces a methodology to recognize four specific emotions using an intelligent model that processes and analyzes signals from motor activity and driver behavior, which are generated by interactions with basic driving elements, along with facial geometry images captured during emotion induction. The research applies machine learning to identify the most relevant motor activity signals for emotion recognition. Furthermore, a pre-trained Convolutional Neural Network (CNN) model is employed to extract probability vectors from images corresponding to the four emotions under investigation. These data sources are integrated through a unidimensional network for emotion classification. The main proposal of this research was to develop a multimodal intelligent model that combines motor activity signals and facial geometry images to accurately recognize four specific emotions (anger, sadness, agitation, and joy) in drivers, achieving a 96.0% accuracy in a simulated environment. The study confirmed a significant relationship between drivers' motor activity, behavior, facial geometry, and the induced emotions.",2024,10.3389/frai.2024.1467051
A reliable approach for identifying acute lymphoblastic leukemia in microscopic imaging,"Leukemia is a deadly disease, and the patient’s recovery rate is very dependent on early diagnosis. However, its diagnosis under the microscope is tedious and time-consuming. The advancement of deep convolutional neural networks (CNNs) in image classification has enabled new techniques in automated disease detection systems. These systems serve as valuable support and secondary opinion resources for laboratory technicians and hematologists when diagnosing leukemia through microscopic examination. In this study, we deployed a pre-trained CNN model (MobileNet) that has a small size and low complexity, making it suitable for mobile applications and embedded systems. We used the L1 regularization method and a novel dataset balancing approach, which incorporates HSV color transformation, saturation elimination, Gaussian noise addition, and several established augmentation techniques, to prevent model overfitting. The proposed model attained an accuracy of 95.33% and an F1 score of 0.95 when evaluated on the held-out test set extracted from the C_NMC_2019 public dataset. We also evaluated the proposed model by adding zero-mean Gaussian noise to the test images. The experimental results indicate that the proposed model is both efficient and robust, even when subjected to additional Gaussian noise. The comparison of the proposed MobileNet_M model’s results with those of ALNet and various other existing models on the same dataset underscores its superior efficacy. The code is available for reproducing the experimental results at https://tamaslevente.github.io/ALLM/.",2025,10.3389/frai.2025.1620252
Machine learning for improved path loss prediction in urban vehicle-to-infrastructure communication systems,"Path loss prediction is crucial to facilitate reliable vehicle-to-infrastructure (V2I) communications. In this study, machine learning techniques are investigated for path loss modeling using empirical measurements at 5.9 GHz from eight Road Side Unit (RSU) sites. The performance of Extreme Gradient Boosting (XGBoost) and Multilayer Perceptron (MLP) models is contrasted with traditional empirical models such as the Dual Slope and 3rd Generation Partnership Project (3GPP) models in three varied urban environments: open, suburban, and densely urbanized cities. The findings indicate that machine learning models, in particular XGBoost, consistently outperform traditional models with the lowest Root Mean Square Error (RMSE) in complicated urban environments. For additional robustness in prediction, we propose an innovative environmental classification system based on building density, street geometry, and transmitter position. Feature importance examination reveals that distance, environmental class, and transmitter height are the most significant factors affecting path loss prediction accuracy. These observations aid the development of adaptive V2I communication systems and provide valuable guidelines for enhancing reliability in diverse urban environments.",2025,10.3389/frai.2025.1597981
Large language models for intelligent RDF knowledge graph construction: results from medical ontology mapping,"The exponential growth of digital data, particularly in specialized domains like healthcare, necessitates advanced knowledge representation and integration techniques. RDF knowledge graphs offer a powerful solution, yet their creation and maintenance, especially for complex medical ontologies like Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT), remain challenging. Traditional methods often struggle with the scale, heterogeneity, and semantic complexity of medical data. This paper introduces a methodology leveraging the contextual understanding and reasoning capabilities of Large Language Models (LLMs) to automate and enhance medical ontology mapping for Resource Description Framework (RDF) knowledge graph construction. We conduct a comprehensive comparative analysis of six systems–GPT-4o, Claude 3.5 Sonnet v2, Gemini 1.5 Pro, Llama 3.3 70B, DeepSeek R1, and BERTMap—using a novel evaluation framework that combines quantitative metrics (precision, recall, and F1-score) with qualitative assessments of semantic accuracy. Our approach integrates a data preprocessing pipeline with an LLM-powered semantic mapping engine, utilizing BioBERT embeddings and ChromaDB vector database for efficient concept retrieval. Experimental results on a dataset of 108 medical terms demonstrate the superior performance of modern LLMs, particularly GPT-4o, achieving a precision of 93.75% and an F1-score of 96.26%. These findings highlight the potential of LLMs in bridging the gap between structured medical data and semantic knowledge representation, toward more accurate and interoperable medical knowledge graphs.",2025,10.3389/frai.2025.1546179
Equipping AI-decision-support-systems with emotional capabilities? Ethical perspectives,"It is important to accompany the research on Emotional Artificial Intelligence with ethical oversight. Previous publications on the ethics of Emotional Artificial Intelligence emphasize the importance of subjecting every (possible) type of Emotional Artificial Intelligence to separate ethical considerations. That’s why, in this contribution I will focus on a particular subset of AI systems: AI-driven Decision-Support Systems (AI-DSS), and ask whether it would be advisable from an ethical perspective to equip these AI systems with emotional capacities. I will show, on one hand, equipping AI-DSS with emotional capabilities offers great opportunities, as they open the possibility to prevent emotionally biased decisions – but that it also amplifies the ethical challenges already posed by emotionally-incapable AI-DSS. Yet, if their introduction is accompanied by a broad social discourse and prepared by suitable measures to address these challenges, I argue, nothing should fundamentally stand in the way of equipping AI-DSS with emotional capabilities.",2024,10.3389/frai.2024.1398395
Open and remotely accessible Neuroplatform for research in wetware computing,"Wetware computing and organoid intelligence is an emerging research field at the intersection of electrophysiology and artificial intelligence. The core concept involves using living neurons to perform computations, similar to how Artificial Neural Networks (ANNs) are used today. However, unlike ANNs, where updating digital tensors (weights) can instantly modify network responses, entirely new methods must be developed for neural networks using biological neurons. Discovering these methods is challenging and requires a system capable of conducting numerous experiments, ideally accessible to researchers worldwide. For this reason, we developed a hardware and software system that allows for electrophysiological experiments on an unmatched scale. The Neuroplatform enables researchers to run experiments on neural organoids with a lifetime of even more than 100 days. To do so, we streamlined the experimental process to quickly produce new organoids, monitor action potentials 24/7, and provide electrical stimulations. We also designed a microfluidic system that allows for fully automated medium flow and change, thus reducing the disruptions by physical interventions in the incubator and ensuring stable environmental conditions. Over the past three years, the Neuroplatform was utilized with over 1,000 brain organoids, enabling the collection of more than 18 terabytes of data. A dedicated Application Programming Interface (API) has been developed to conduct remote research directly via our Python library or using interactive compute such as Jupyter Notebooks. In addition to electrophysiological operations, our API also controls pumps, digital cameras and UV lights for molecule uncaging. This allows for the execution of complex 24/7 experiments, including closed-loop strategies and processing using the latest deep learning or reinforcement learning libraries. Furthermore, the infrastructure supports entirely remote use. Currently in 2024, the system is freely available for research purposes, and numerous research groups have begun using it for their experiments. This article outlines the system’s architecture and provides specific examples of experiments and results.",2024,10.3389/frai.2024.1376042
Testing the applicability of a governance checklist for high-risk AI-based learning outcome assessment in Italian universities under the EU AI act annex III,"Background
                    The EU AI Act classifies AI-based learning outcome assessment as high-risk (Annex III, point 3b), yet sector-specific frameworks for institutional self-assessment remain underdeveloped. This creates accountability gaps affecting student rights and educational equity, as institutions lack systematic tools to demonstrate that algorithmic assessment systems produce valid and fair outcomes.
                  
                  
                    Methods
                    This exploratory study tests whether ALTAI’s trustworthy AI requirements can be operationalized for educational assessment governance through the XAI-ED Consequential Assessment Framework, which integrates three educational evaluation theories (Messick’s consequential validity, Kirkpatrick’s four-level model, Stufflebeam’s CIPP). Following pilot testing with three institutions, four independent coders applied a 27-item checklist to policy documents from 14 Italian universities (13% with formal AI policies plus one baseline case) using four-point ordinal scoring and structured consensus procedures.
                  
                  
                    Results
                    
                      Intercoder reliability analysis revealed substantial agreement (Fleiss’s
                      κ
                       = 0.626, Krippendorff’s
                      α
                       = 0.838), with higher alpha reflecting predominantly adjacent-level disagreements suitable for exploratory validation. Analysis of 14 universities reveals substantial governance heterogeneity among early adopters (Institutional Index: 0.00–60.32), with Technical Robustness and Safety showing lowest implementation (M = 19.64, SD = 21.08) and Societal Well-being highest coverage (M = 52.38, SD = 29.38). Documentation prioritizes aspirational statements over operational mechanisms, with only 13% of Italian institutions having adopted AI policies by September 2025.
                    
                  
                  
                    Discussion
                    The framework demonstrates feasibility for self-assessment but reveals critical misalignment: universities document aspirational commitments more readily than technical safeguards, with particularly weak capacity for validity testing and fairness monitoring. Findings suggest three interventions: (1) ministerial operational guidance translating EU AI Act requirements into educational contexts, (2) inter-institutional capacity-building addressing technical-pedagogical gaps, and (3) integration of AI governance indicators into national quality assurance systems to enable systematic accountability. The study contributes to understanding how educational evaluation theory can inform the translation of abstract trustworthy AI principles into outcome-focused institutional practices under high-risk classifications.",2025,10.3389/frai.2025.1718613
The Future of Computational Linguistics: On Beyond Alchemy,"Over the decades, fashions in Computational Linguistics have changed again and again, with major shifts in motivations, methods and applications. When digital computers first appeared, linguistic analysis adopted the new methods of information theory, which accorded well with the ideas that dominated psychology and philosophy. Then came formal language theory and the idea of AI as applied logic, in sync with the development of cognitive science. That was followed by a revival of 1950s-style empiricism—AI as applied statistics—which in turn was followed by the age of deep nets. There are signs that the climate is changing again, and we offer some thoughts about paths forward, especially for younger researchers who will soon be the leaders.",2021,10.3389/frai.2021.625341
A prospective evaluation of breast thermography enhanced by a novel machine learning technique for screening breast abnormalities in a general population of women presenting to a secondary care hospital,"Objective
                    Artificial intelligence-enhanced breast thermography is being evaluated as an ancillary modality in the evaluation of breast disease. The objective of this study was to evaluate the clinical performance of Thermalytix, a CE-marked, AI-based thermal imaging test, with respect to conventional mammography.
                  
                  
                    Methods
                    A prospective, comparative study performed between 15 December 2018 and 06 January 2020 evaluated the performance of Thermalytix in 459 women with both dense and nondense breast tissue. Both symptomatic and asymptomatic women, aged 30–80 years, presenting to the hospital underwent Thermalytix followed by 2-D mammography and appropriate confirmatory investigations to confirm malignancy. The radiologist interpreting the mammograms and the technician using the Thermalytix tool were blinded to the others' findings. The statistical analysis was performed by a third party.
                  
                  
                    Results
                    
                      A total of 687 women were recruited, of whom 459 fulfilled the inclusion criteria. Twenty-one malignancies were detected (21/459, 4.6%). The overall sensitivity of Thermalytix was 95.24% (95% CI, 76.18–99.88), and the specificity was 88.58% (95% CI, 85.23–91.41). In women with dense breasts (
                      n
                      = 168, 36.6%), the sensitivity was 100% (95% CI, 69.15–100), and the specificity was 81.65% (95% CI, 74.72–87.35). Among these 168 women, 37 women (22%) were reported as BI-RADS 0 on mammography; in this subset, the sensitivity of Thermalytix was 100% (95% CI, 69.15–100), and the specificity was 77.22% (95% CI, 69.88–83.50).
                    
                  
                  
                    Conclusion
                    Thermalytix showed acceptable sensitivity and specificity with respect to mammography in the overall patient population. Thermalytix outperformed mammography in women with dense breasts and those reported as BI-RADS 0.",2023,10.3389/frai.2022.1050803
CoViNAR: a context-aware social media dataset for pandemic severity level prediction and analysis,"IntroductionThe unprecedented COVID-19 pandemic exposed critical weaknesses in global health management, particularly in resource allocation and demand forecasting. This study aims to enhance pandemic preparedness by leveraging real-time social media analysis to detect and monitor resource needs.MethodsUsing SnScrape, over 27.5 million tweets for the duration of November 2019 to March 2023 were collected using COVID-19-related hashtags. Tweets from April 2021, a peak pandemic period, were selected to create the CoViNAR dataset. BERTopic enabled context-aware filtering, resulting in a novel dataset of 14,000 annotated tweets categorized as “Need”, “Availability”, and “Not-relevant”. The CoViNAR dataset was used to train various machine learning classifiers, with experiments conducted using three context-aware word embedding techniques.ResultsThe best classifier, trained with DistilBERT embeddings, achieved an accuracy of 96.42%, 96.44% precision, 96.42% recall, and an F1-score of 96.43% on the Test dataset. Temporal analysis of classified tweets from the US, UK, and India between November 2019 and March 2023 revealed a strong correlation between “Need/Availability” tweet counts and COVID-19 case surges.DiscussionThe results demonstrate the effectiveness of the proposed approach in capturing real-time indicators of resource shortages and availability. The strong correlation with case surges underscores its potential as a proactive tool for public health authorities, enabling improved resource allocation and early crisis intervention during pandemics.",2025,10.3389/frai.2025.1623090
Auto-scaling LLM-based multi-agent systems through dynamic integration of agents,"IntroductionLarge Language Model-based Multi-Agent Systems (LLM-based MASs) represent a groundbreaking paradigm where diverse LLM-based agents collaborate, leveraging their unique capabilities to achieve shared objectives. Although LLM-based MASs outperform individual agents, their current architectures are limited by predefined, fixed, and static agent designs, restricting adaptability and scalability in dynamic environments.MethodTo address these limitations, this study proposes two novel approaches: Initial Automatic Agent Generation (IAAG) and Dynamic Real-Time Agent Generation (DRTAG). These approaches enable the automatic creation and seamless integration of new agents into MASs, driven by evolving conversational and task-specific contexts, thereby reducing the need for human intervention. Our method leverages advanced prompt engineering techniques such as persona pattern prompting, chain prompting, and few-shot prompting to generate new agents through existing LLM agents. Additionally, several evaluation metrics were adapted to score and rank LLM-generated texts.ResultsExperimental results demonstrate that the DRTAG approach significantly improves system adaptability and task performance compared to static MAS architectures. The IAAG framework also enhances initial system flexibility, supporting the creation of contextually relevant agents.DiscussionThese findings highlight the potential of dynamic LLM-based MASs to overcome the limitations of static architectures to address complex real-world challenges, paving the way for innovative applications across diverse domains.",2025,10.3389/frai.2025.1638227
A drop-out mechanism for active learning based on one-attribute heuristics,"Active Learning (AL) leverages the principle that machine learning models can achieve high accuracy with fewer labeled samples by strategically selecting the most informative data points for training. However, when human annotators provide these labels, their decisions might exhibit a systematic bias. For example, humans frequently rely on a limited subset of the available attributes, or even on a single attribute, when making decisions, as when employing fast and frugal heuristics. This paper introduces a mathematically grounded approach to quantify the probability of mislabeling based on one attribute. We present a novel dropout mechanism designed to influence the attribute selection process used in annotation, effectively reducing the impact of bias. The proposed mechanism is evaluated using multiple AL algorithms and heuristic strategies across diverse prediction tasks. Experimental results demonstrate that the dropout mechanism significantly enhances active learning (AL) performance, achieving a minimum 70% improvement in effectiveness. These findings highlight the mechanism's potential to improve the reliability and accuracy of AL systems, providing valuable insights for designing and implementing robust intelligent systems.",2025,10.3389/frai.2025.1562916
Liver cancer knowledge graph construction based on dynamic entity replacement and masking strategies RoBERTa-wwm-large-BiLSTM-CRF model with clinical Chinese EMRs,"IntroductionLiver cancer is a leading cause of cancer-related mortality worldwide, necessitating advanced tools for diagnosis and management. Knowledge graphs (KGs) are crucial for advancing smart healthcare, but existing liver cancer-specific KGs are mostly derived from literature or public databases, lacking integration with real-world clinical data [e.g., Electronic Medical Records (EMRs)], creating a critical gap. Furthermore, there is currently no publicly available KGs specifically for liver cancer, creating a significant gap in structured clinical knowledge resources.MethodsThis study proposes a novel framework to construct the first Chinese liver cancer KG from Real-World Liver Cancer Electronic Medical Records (RLC-EMRs). A new named entity recognition (NER) model, DERM-RoBERTa-wwm-large-BiLSTM-CRF was developed that uses a Dynamic Entity Replacement and Masking (DERM) strategy to address data scarcity. Knowledge fusion was performed using the TF-IDF algorithm to standardize and integrate entities from clinical records, the professional medical website www.XYWY.com, and the CCMT-2019 terminology standard.ResultsThe final constructed liver cancer KG contained 46,364 entities and 296,655 semantic relationships. The proposed NER model achieved a state-of-the-art F1 score of 68.84% on the public CMeEE-v2 dataset. On the proprietary RLC-EMRs dataset, the model demonstrated high effectiveness with a precision of 93.23%, recall of 94.69%, and an F1 score of 93.96%. In addition, a KG-based retrieval system was successfully developed to query for complications, medications, and other related information.DiscussionThe findings demonstrated the effectiveness of the proposed framework in constructing a comprehensive and clinically relevant liver cancer KG. The novel DERM-based NER model significantly improved entity extraction from complex medical texts. By successfully integrating real-world clinical data, this study addresses a critical gap in existing liver cancer-specific KGs, which are mostly derived from literature or public databases and lack integration with real-world clinical information.",2025,10.3389/frai.2025.1663877
A psycholinguistic NLP framework for forensic text analysis of deception and emotion,"Psycholinguistics is an interdisciplinary area of research that bridges elements of linguistics with various branches of psychology. One of its goals is to identify and explain the links that exist between our psyche and the language we speak. In this research, we are expanding upon previous research that we did using several different Natural Language Processing (NLP) techniques to identify persons of interest from a scenario that was generated by a large language model (LLM). We used a different approach to this topic, which allowed us to develop a more nuanced method of reverse engineering and breaking down the psycholinguistic features of each suspect. Through the application of n-grams paired with deception, emotion, and subjectivity over time, we were able to identify and measure cues that can be used to better identify persons of interest from a larger pool of candidates. That dataset was smaller and somewhat limited in scope. We successfully identified the guilty parties from the fictional murder case using a combination of Latent Dirichlet Allocation, word vectors, and pairwise correlations. This research was larger in scope, number of potential suspects, and in the diversity of the corpus used. We were able to determine the guilty parties identified in ground truth using our methodology in this case specifically by focusing on entity to topic correlation, deception detection, and emotion analysis.",2025,10.3389/frai.2025.1669542
Hybrid artificial intelligence architectures for automatic text correction in the Kazakh language,"The Kazakh language, as an agglutinative and morphologically rich language, presents significant challenges for the development of natural language processing (NLP) tools. Traditional rule-based analyzers provide full coverage but lack flexibility; statistical and neural models handle disambiguation more effectively, yet require large annotated corpora and substantial computational resources. This paper presents a hybrid morphological analyzer that integrates Finite-State Transducers (FST), Conditional Random Fields (CRF), and transformer-based architectures (KazRoBERTa, mBERT). For the experiments, a new corpus, KazMorphCorpus-2025, was created, consisting of 150,000 sentences from diverse domains annotated for morphological analysis. Experimental evaluation demonstrated that the KazRoBERTa model consistently outperforms mBERT in terms of accuracy, F1-score, and prediction speed. The hybrid architecture effectively combines the exhaustive coverage of FST with the contextual disambiguation of neural networks, reducing errors associated with homonymy, borrowings, and long affixal chains. The results confirm that the proposed system achieves a balance between accuracy, efficiency, and scalability. The study underscores the practical significance of hybrid approaches for tasks such as spell checking, information retrieval, and machine translation in the Kazakh language, as well as their potential transferability to other low-resource Turkic languages. Future work will include the expansion of the corpus, integration of KazBERT and mBERT models, and validation of the proposed approach in applied NLP systems.",2025,10.3389/frai.2025.1708566
Grammar-constrained decoding for structured information extraction with fine-tuned generative models applied to clinical trial abstracts,"BackgroundIn the field of structured information extraction, there are typically semantic and syntactic constraints on the output of information extraction (IE) systems. These constraints, however, can typically not be guaranteed using standard (fine-tuned) encoder-decoder architectures. This has led to the development of constrained decoding approaches which allow, e.g., to specify constraints in form of context-free grammars. An open question is in how far an IE system can be effectively guided by a domain-specific grammar to ensure that the output structures follow the requirements of a certain domain data model.MethodsIn this work we experimentally investigate the influence of grammar-constrained decoding as well as pointer generators on the performance of a domain-specific information extraction system. For this, we consider fine-tuned encoder-decoder models, Longformer and Flan-T5 in particular, and experimentally investigate whether the addition of grammar-constrained decoding and pointer generators improve information extraction results. Toward this goal, we consider the task of inducing structured representations from abstracts describing clinical trials, relying on the C-TrO ontology to semantically describe the clinical trials and their results. We frame the task as a slot filling problem where certain slots of templates need to be filled with token sequences occurring in the input text. We use a dataset comprising 211 annotated clinical trial abstracts about type 2 diabetes and glaucoma for training and evaluation. Our focus is on settings in which the available training data is in the order of a few hundred training examples, which we consider as a low-resource setting.ResultsIn all our experiments we could demonstrate the positive impact of grammar-constrained decoding, with an increase in F1 score of pp 0.351 (absolute score 0.413) and pp 0.425 (absolute score 0.47) for the best-performing models on type 2 diabetes and glaucoma datasets, respectively. The addition of the pointer generators had a detrimental impact on the results, decreasing F1 scores by pp 0.15 (absolute score 0.263) and pp 0.198 (absolute score 0.272) for the best-performing pointer generator models on type 2 diabetes and glaucoma datasets, respectively.ConclusionThe experimental results indicate that encoder-decoder models used for structure prediction for information extraction tasks in low-resource settings clearly benefit from grammar-constrained decoding guiding the output generation. In contrast, the evaluated pointer generator models decreased the performance drastically in some cases. Moreover, the performance of the pointer models appears to depend both on the used base model as well as the function used for aggregating the attention values. How the size of large language models affects the performance benefit of grammar-constrained decoding remains to be more structurally investigated in future work.",2025,10.3389/frai.2024.1406857
Artificial Intelligence to Analyze the Cortical Thickness Through Age,"In this study, Artificial Intelligence was used to analyze a dataset containing the cortical thickness from 1,100 healthy individuals. This dataset had the cortical thickness from 31 regions in the left hemisphere of the brain as well as from 31 regions in the right hemisphere. Then, 62 artificial neural networks were trained and validated to estimate the number of neurons in the hidden layer. These neural networks were used to create a model for the cortical thickness through age for each region in the brain. Using the artificial neural networks and kernels with seven points, numerical differentiation was used to compute the derivative of the cortical thickness with respect to age. The derivative was computed to estimate the cortical thickness speed. Finally, color bands were created for each region in the brain to identify a positive derivative, that is, a part of life with an increase in cortical thickness. Likewise, the color bands were used to identify a negative derivative, that is, a lifetime period with a cortical thickness reduction. Regions of the brain with similar derivatives were organized and displayed in clusters. Computer simulations showed that some regions exhibit abrupt changes in cortical thickness at specific periods of life. The simulations also illustrated that some regions in the left hemisphere do not follow the pattern of the same region in the right hemisphere. Finally, it was concluded that each region in the brain must be dynamically modeled. One advantage of using artificial neural networks is that they can learn and model non-linear and complex relationships. Also, artificial neural networks are immune to noise in the samples and can handle unseen data. That is, the models based on artificial neural networks can predict the behavior of samples that were not used for training. Furthermore, several studies have shown that artificial neural networks are capable of deriving information from imprecise data. Because of these advantages, the results obtained in this study by the artificial neural networks provide valuable information to analyze and model the cortical thickness.",2021,10.3389/frai.2021.549255
A fuzzy system for detection of road slipperiness in Arctic snowy conditions using LiDAR,"The advancement of self-driving cars has significantly improved transportation by enhancing safety, efficiency, and mobility. However, their operation in Arctic environments remains challenging due to snow, ice, and slush, which negatively impact traction and road surface perception. To address these challenges, this study integrates LiDAR-based reflected intensity measurements with environmental parameters such as humidity, temperature, and the coefficient of friction to detect road surface slipperiness and roughness. A Fuzzy Logic System is developed to process these features and classify the slipperiness levels. The analysis establishes a strong correlation between LiDAR intensity and the coefficient of friction, enabling reliable detection of surface conditions. The proposed method achieves a testing accuracy of 87% in classifying road slipperiness under Arctic conditions. These findings demonstrate the effectiveness of LiDAR and sensor fusion for real-time road condition monitoring and highlight their potential in enhancing the safety and performance of autonomous vehicles in extreme weather environments.",2025,10.3389/frai.2025.1600174
Componential Analysis of English Verbs,"Computational lexical resources such as WordNet, PropBank, VerbNet, and FrameNet are in regular use in various NLP applications, assisting in the never-ending quest for richer, more precise semantic representations. Coherent class-based organization of lexical units in VerbNet and FrameNet can improve the efficiency of processing by clustering similar items together and sharing descriptions. However, class members are sometimes quite different, and the clustering in both can gloss over useful fine-grained semantic distinctions. FrameNet officially eschews syntactic considerations and focuses primarily on semantic coherence, associating nouns, verbs and adjectives with the same semantic frame, while VerbNet considers both syntactic and semantic factors in defining a class of verbs, relying heavily on meaning-preserving diathesis alternations. Many VerbNet classes significantly overlap in membership with similar FrameNet Frames, e.g., VerbNet Cooking-45.3 and FrameNet Apply_heat, but some VerbNet classes are so heterogeneous as to be difficult to characterize semantically, e.g., Other_cos-45.4. We discuss a recent addition to the VerbNet class semantics, verb-specific semantic features, that provides significant enrichment to the information associated with verbs in each VerbNet class. They also implicitly group together verbs sharing semantic features within a class, forming more semantically coherent subclasses. These efforts began with introspection and dictionary lookup, and progressed to automatic techniques, such as using NLTK sentiment analysis on verb members of VerbNet classes with an Experiencer argument role, to assign positive, negative or neutral labels to them. More recently we found the Brandeis Semantic Ontology (BSO) to be an invaluable source of rich semantic information and were able to use a VerbNet-BSO mapping to find fine-grained distinctions in the semantic features of verb members of 25 VerbNet classes. This not only confirmed the assignments previously made to classes such as Admire-31.2, but also gave a more fine-grained semantic decomposition for the members. Also, for the Judgment-31.1 class, the new method revealed new, more fine-grained existing semantic features for the verbs. Overall, the BSO mapping produced promising results, and as a manually curated resource, we have confidence the results are reliable and need little (if any) further hand-correction. We discuss our various techniques, illustrating the results with specific classes.",2022,10.3389/frai.2022.780385
Learning from real world data about combinatorial treatment selection for COVID-19,"COVID-19 is an unprecedented global pandemic with a serious negative impact on virtually every part of the world. Although much progress has been made in preventing and treating the disease, much remains to be learned about how best to treat the disease while considering patient and disease characteristics. This paper reports a case study of combinatorial treatment selection for COVID-19 based on real-world data from a large hospital in Southern China. In this observational study, 417 confirmed COVID-19 patients were treated with various combinations of drugs and followed for four weeks after discharge (or until death). Treatment failure is defined as death during hospitalization or recurrence of COVID-19 within four weeks of discharge. Using a virtual multiple matching method to adjust for confounding, we estimate and compare the failure rates of different combinatorial treatments, both in the whole study population and in subpopulations defined by baseline characteristics. Our analysis reveals that treatment effects are substantial and heterogeneous, and that the optimal combinatorial treatment may depend on baseline age, systolic blood pressure, and c-reactive protein level. Using these three variables to stratify the study population leads to a stratified treatment strategy that involves several different combinations of drugs (for patients in different strata). Our findings are exploratory and require further validation.",2023,10.3389/frai.2023.1123285
In Search of Ambiguity: A Three-Stage Workflow Design to Clarify Annotation Guidelines for Crowd Workers,"We propose a novel three-stage FIND-RESOLVE-LABEL workflow for crowdsourced annotation to reduce ambiguity in task instructions and, thus, improve annotation quality. Stage 1 (FIND) asks the crowd to find examples whose correct label seems ambiguous given task instructions. Workers are also asked to provide a short tag that describes the ambiguous concept embodied by the specific instance found. We compare collaborative vs. non-collaborative designs for this stage. In Stage 2 (RESOLVE), the requester selects one or more of these ambiguous examples to label (resolving ambiguity). The new label(s) are automatically injected back into task instructions in order to improve clarity. Finally, in Stage 3 (LABEL), workers perform the actual annotation using the revised guidelines with clarifying examples. We compare three designs using these examples: examples only, tags only, or both. We report image labeling experiments over six task designs using Amazon's Mechanical Turk. Results show improved annotation accuracy and further insights regarding effective design for crowdsourced annotation tasks.",2022,10.3389/frai.2022.828187
"A quantum-inspired, biomimetic, and fractal framework for self-healing AI code generation: bridging responsible automation and emergent intelligence","AI-powered code generation systems available today are ill-suited for deployment in agile software development contexts due to various limitations. The paper proposes a self-healing counterpart framework based on quantum-inspired optimization, biomimetic, and fractal principles to solve these fundamental issues. Our Quantum Solution Space Manager keeps more than one candidate solution in superposition states. In doing so, it achieves 94.7% code correctness (versus 87.3%) with respect to a leading approach. The biomimetic error detection system, inspired by biological immune mechanisms, has a sensitivity of 95.2 per cent, with a false-positive rate of 2.3 per cent. Effectively, 94.7 per cent of detected errors are automatically corrected. Fractal optimization allows for a considerable 89.4% success rate during cross-architectural propagation, while distributed intelligence networks allow different intelligences and agents to learn together. The framework is validated as effective through an analysis of 15,000 software engineering tasks across five domains. This helps reduce the critical error rate by 54% and the remaining development time by 41%, along with notable improvements in maintainability and security metrics. The results lay down the path for adaptive software development systems to create responsible automation and emergent intelligence.",2025,10.3389/frai.2025.1662220
Deep skin diseases diagnostic system with Dual-channel Image and Extracted Text,"BackgroundDue to the lower reliability of laboratory tests, skin diseases are more suitable for diagnosis with AI models. There are limited AI dermatology diagnostic models combining images and text; few of these are for Asian populations, and few cover the most common types of diseases.MethodsLeveraging a dataset sourced from Asia comprising over 200,000 images and 220,000 medical records, we explored a deep learning-based system for Dual-channel images and extracted text for the diagnosis of skin diseases model DIET-AI to diagnose 31 skin diseases, which covers the majority of common skin diseases. From 1 September to 1 December 2021, we prospectively collected images from 6,043 cases and medical records from 15 hospitals in seven provinces in China. Then the performance of DIET-AI was compared with that of six doctors of different seniorities in the clinical dataset.ResultsThe average performance of DIET-AI in 31 diseases was not less than that of all the doctors of different seniorities. By comparing the area under the curve, sensitivity, and specificity, we demonstrate that the DIET-AI model is effective in clinical scenarios. In addition, medical records affect the performance of DIET-AI and physicians to varying degrees.ConclusionThis is the largest dermatological dataset for the Chinese demographic. For the first time, we built a Dual-channel image classification model on a non-cancer dermatitis dataset with both images and medical records and achieved comparable diagnostic performance to senior doctors about common skin diseases. It provides references for exploring the feasibility and performance evaluation of DIET-AI in clinical use afterward.",2023,10.3389/frai.2023.1213620
Bayesian model of tilling wheat confronting climatic and sustainability challenges,"Conventional farming poses threats to sustainable agriculture in growing food demands and increasing flooding risks. This research introduces a Bayesian Belief Network (BBN) to address these concerns. The model explores tillage adaptation for flood management in soils with varying organic carbon (OC) contents for winter wheat production. Three real soils, emphasizing texture and soil water properties, were sourced from the NETMAP soilscape of the Pang catchment area in Berkshire, United Kingdom. Modified with OC content at four levels (1, 3, 5, 7%), they were modeled alongside relevant variables in a BBN. The Decision Support System for Agrotechnology Transfer (DSSAT) simulated datasets across 48 cropping seasons to parameterize the BBN. The study compared tillage effects on wheat yield, surface runoff, and GHG-CO2 emissions, categorizing model parameters (from lower to higher bands) based on statistical data distribution. Results revealed that NT outperformed CT in the highest parametric category, comparing probabilistic estimates with reduced GHG-CO2 emissions from “7.34 to 7.31%” and cumulative runoff from “8.52 to 8.50%,” while yield increased from “7.46 to 7.56%.” Conversely, CT exhibited increased emissions from “7.34 to 7.36%” and cumulative runoff from “8.52 to 8.55%,” along with reduced yield from “7.46 to 7.35%.” The BBN model effectively captured uncertainties, offering posterior probability distributions reflecting conditional relationships across variables and offered decision choice for NT favoring soil carbon stocks in winter wheat (highest among soils “NT.OC-7%PDPG8,” e.g., 286,634 kg/ha) over CT (lowest in “CT.OC-3.9%PDPG8,” e.g., 5,894 kg/ha). On average, NT released minimum GHG- CO2 emissions to “3,985 kgCO2eqv/ha,” while CT emitted “7,415 kgCO2eqv/ha.” Conversely, NT emitted “8,747 kgCO2eqv/ha” for maximum emissions, while CT emitted “15,356 kgCO2eqv/ha.” NT resulted in lower surface runoff against CT in all soils and limits runoff generations naturally for flood alleviation with the potential for customized improvement. The study recommends the model for extensive assessments of various spatiotemporal conditions. The research findings align with sustainable development goals, e.g., SDG12 and SDG13 for responsible production and climate actions, respectively, as defined by the Agriculture and Food Organization of the United Nations.",2024,10.3389/frai.2024.1402098
A Novel Machine Learning Model for Dose Prediction in Prostate Volumetric Modulated Arc Therapy Using Output Initialization and Optimization Priorities,"Treatment planning for prostate volumetric modulated arc therapy (VMAT) can take 5–30 min per plan to optimize and calculate, limiting the number of plan options that can be explored before the final plan decision. Inspired by the speed and accuracy of modern machine learning models, such as residual networks, we hypothesized that it was possible to use a machine learning model to bypass the time-intensive dose optimization and dose calculation steps, arriving directly at an estimate of the resulting dose distribution for use in multi-criteria optimization (MCO). In this study, we present a novel machine learning model for predicting the dose distribution for a given patient with a given set of optimization priorities. Our model innovates upon the existing machine learning techniques by utilizing optimization priorities and our understanding of dose map shapes to initialize the dose distribution before dose refinement via a voxel-wise residual network. Each block of the residual network individually updates the initialized dose map before passing to the next block. Our model also utilizes contiguous and atrous patch sampling to effectively increase the receptive fields of each layer in the residual network, decreasing its number of layers, increasing model prediction and training speed, and discouraging overfitting without compromising on the accuracy. For analysis, 100 prostate VMAT cases were used to train and test the model. The model was evaluated by the training and testing errors produced by 50 iterations of 10-fold cross-validation, with 100 cases randomly shuffled into the subsets at each iteration. The error of the model is modest for this data, with average dose map root-mean-square errors (RMSEs) of 2.38 ± 0.47% of prescription dose overall patients and all optimization priority combinations in the patient testing sets. The model was also evaluated at iteratively smaller training set sizes, suggesting that the model requires between 60 and 90 patients for optimal performance. This model may be used for quickly estimating the Pareto set of feasible dose objectives, which may directly accelerate the treatment planning process and indirectly improve final plan quality by allowing more time for plan refinement.",2021,10.3389/frai.2021.624038
Thyroid nodule segmentation in ultrasound images using transformer models with masked autoencoder pre-training,"IntroductionThyroid nodule segmentation in ultrasound (US) images is a valuable yet challenging task, playing a critical role in diagnosing thyroid cancer. The difficulty arises from factors such as the absence of prior knowledge about the thyroid region, low contrast between anatomical structures, and speckle noise, all of which obscure boundary detection and introduce variability in nodule appearance across different images.MethodsTo address these challenges, we propose a transformer-based model for thyroid nodule segmentation. Unlike traditional convolutional neural networks (CNNs), transformers capture global context from the first layer, enabling more comprehensive image representation, which is crucial for identifying subtle nodule boundaries. In this study, We first pre-train a Masked Autoencoder (MAE) to reconstruct masked patches, then fine-tune on thyroid US data, and further explore a cross-attention mechanism to enhance information flow between encoder and decoder.ResultsOur experiments on the public AIMI, TN3K, and DDTI datasets show that MAE pre-training accelerates convergence. However, overall improvements are modest: the model achieves Dice Similarity Coefficient (DSC) scores of 0.63, 0.64, and 0.65 on AIMI, TN3K, and DDTI, respectively, highlighting limitations under small-sample conditions. Furthermore, adding cross-attention did not yield consistent gains, suggesting that data volume and diversity may be more critical than additional architectural complexity.DiscussionMAE pre-training notably reduces training time and helps themodel learn transferable features, yet overall accuracy remains constrained by limited data and nodule variability. Future work will focus on scaling up data, pre-training cross-attention layers, and exploring hybrid architectures to further boost segmentation performance.",2025,10.3389/frai.2025.1618426
A hybrid deep learning framework for SEM-based air pollutant analysis: Mamba integration and GAN-augmented training,"Air pollution poses severe threats to public health and ecological stability, making accurate analysis of airborne pollutant composition increasingly vital. In this paper, we propose a novel deep learning framework for efficient classification of pollutant components based on microscopic or spectral images. The proposed model integrates the recent
                    Mamba mechanism
                    , a state space model (SSM) architecture known for its superior long-range dependency modeling and linear computational complexity, into the image classification pipeline. By leveraging convolutional layers for local feature extraction and Mamba blocks for global semantic representation, our approach significantly improves both detection accuracy and inference speed compared to traditional CNN or Transformer-based baselines. To address the challenge of limited labeled data, we further introduce a generative adversarial network (GAN)-based data augmentation strategy. A CGAN is trained to synthesize realistic SEM-like particulate images, which are then incorporated into the training set to expand the training dataset. This integration of generative modeling effectively mitigates overfitting and strengthens the model's ability to generalize across varied pollutant types and imaging conditions. Experimental results on benchmark demonstrate the model's effectiveness in identifying common airborne constituents.",2025,10.3389/frai.2025.1664317
Deep learning neural networks-based traffic predictors for V2X communication networks,"Vehicle-to-everything (V2X) communication is a promising technology for enhancing road safety, traffic efficiency, and the availability of infotainment services in 5G networks and beyond networks. However, the effective sharing of traffic information remains a significant challenge. To address this, AI-based systems offer potential solutions. By predicting traffic patterns on dense networks, these systems can improve traffic management, mitigate congestion, increase network safety and reliability, and improve energy efficiency. This research investigates the application of Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) for accurate and efficient V2X traffic prediction. We explored the impact of various hyperparameters, including loss functions and optimizers, on the performance of these models. Our findings indicate that Gated Recurrent Unit (GRU) models, particularly with the Mean Squared Error (MSE) loss function and Adam optimizer, consistently outperform Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (BiLSTM) models in terms of both accuracy and computational efficiency. For CNN models, the Rectified Linear Unit (ReLU) activation function, coupled with the Adam optimizer, demonstrated superior performance in terms of Root Mean Square Error (RMSE) and computational complexity. By comparing our results with existing literature, we highlight the advantages of our proposed models in terms of accuracy, efficiency, and robustness.",2025,10.3389/frai.2025.1701951
Plant leaf disease recognition based on improved SinGAN and improved ResNet34,"The identification of plant leaf diseases is crucial in precision agriculture, playing a pivotal role in advancing the modernization of agriculture. Timely detection and diagnosis of leaf diseases for preventive measures significantly contribute to enhancing both the quantity and quality of agricultural products, thereby fostering the in-depth development of precision agriculture. However, despite the rapid development of research on plant leaf disease identification, it still faces challenges such as insufficient agricultural datasets and the problem of deep learning-based disease identification models having numerous training parameters and insufficient accuracy. This paper proposes a plant leaf disease identification method based on improved SinGAN and improved ResNet34 to address the aforementioned issues. Firstly, an improved SinGAN called Reconstruction-Based Single Image Generation Network (ReSinGN) is proposed for image enhancement. This network accelerates model training speed by using an autoencoder to replace the GAN in the SinGAN and incorporates a Convolutional Block Attention Module (CBAM) into the autoencoder to more accurately capture important features and structural information in the images. Random pixel Shuffling are introduced in ReSinGN to enable the model to learn richer data representations, further enhancing the quality of generated images. Secondly, an improved ResNet34 is proposed for plant leaf disease identification. This involves adding CBAM modules to the ResNet34 to alleviate the limitations of parameter sharing, replacing the ReLU activation function with LeakyReLU activation function to address the problem of neuron death, and utilizing transfer learning-based training methods to accelerate network training speed. This paper takes tomato leaf diseases as the experimental subject, and the experimental results demonstrate that: (1) ReSinGN generates high-quality images at least 44.6 times faster in training speed compared to SinGAN. (2) The Tenengrad score of images generated by the ReSinGN model is 67.3, which is improved by 30.2 compared to the SinGAN, resulting in clearer images. (3) ReSinGN model with random pixel Shuffling outperforms SinGAN in both image clarity and distortion, achieving the optimal balance between image clarity and distortion. (4) The improved ResNet34 achieved an average recognition accuracy, recognition precision, recognition accuracy (redundant as it’s similar to precision), recall, and F1 score of 98.57, 96.57, 98.68, 97.7, and 98.17%, respectively, for tomato leaf disease identification. Compared to the original ResNet34, this represents enhancements of 3.65, 4.66, 0.88, 4.1, and 2.47%, respectively.",2024,10.3389/frai.2024.1414274
Population health management genomic new-born screens and multi-omics intercepts,"IntroductionThe Population Health Management (PHM) Genomic Newborn Screens (GNBS) and Multi-Omics Intercepts for Human Phenotype Ontology (HPO) using Federated Data Platforms (FDP) represent a groundbreaking innovation in global health. This reform, supported by the UK’s Genomic Medical Services (GMS) through “The Generation Study,” aims to significantly reduce infant mortality by identifying and managing over 200 rare diseases from birth, paving the way for personalised health planning.MethodsUsing an ecosystem approach, this study evaluates a diverse pangenome to predict health outcomes or confirm diagnoses prior to symptomatic manifestations. GNBS standardises care by integrating diagnostic techniques such as blood spot analysis and full blood cell diagnostics to stratify risk. The approach enhances the understanding of rare diseases in primary care medicine, with biomedical and haematology diagnoses re-evaluated. Scientific proof of concept and fit-for-purpose technology align multi-omics in pre-eXams (X = Gen AI).RecommendationsThe Digital Regulation Service (DRS) assembles an agile group of experts to enhance medical science through human phenotype ontology (HPO) for precise disease segmentation, scheduling accurate eXam intercepts where needed. This team strategically plans regulation services for digital HPO eXam assurance and implements Higher Expert Medical Science Safety (HEMSS) frameworks. The DRS is responsible for overseeing gene, oligonucleotide, and recombinant protein intercepts; commissioning blood pathology HPO eXam intercepts; and monitoring preliminary eXams with advanced imaging techniques.DiscussionIn pursuit of excellence in PHM of HPO, HEMSS with Agile Group Development leverages the Genomic Newborn Screens (GNBS) and multi-omics to create personalised health plans integrated with NHS England Genomics and AI-driven DRS. The discourse extends to examining GNBS predictors and intercepts, focusing on their impact on public health and patient safety. Discussions encompass structured HPO knowledge addressing newborn health, ethical considerations, family privacy, and the benefits and limitations of pre-eXam screenings and life eXam intercepts. These debates involve stakeholders in adopting HPO-enhanced clinical pathways through Alliances for Health Systems Networking-Genomic Enterprise Partnerships (AHSN-GEP).Conclusion“The Generation Study” represents a paradigm in digital child health management using an HPO-X-Gen-AI framework, transitioning from trusted research to evidence-based discovery. This approach sets a standard for personalised healthcare practices, incorporating ontology risk stratification and future-ready analytics as outlined in the NHS Constitution. The discourse on higher expert medical science safety governance will continue in the forthcoming manuscript, “PHM Fit Lifecycles in Future Analytics,” which will further explore developing localised health solutions for “Our Future Health.”",2025,10.3389/frai.2024.1496942
Ontology-based prompt tuning for news article summarization,"Ontology-based prompt tuning and abstractive text summarization techniques represent an advanced approach to enhancing the quality and contextual relevance of news article summaries. Despite the progress in natural language processing (NLP) and machine learning, existing methods often rely on extractive summarization, which lacks the ability to generate coherent and contextually rich summaries. Moreover, these approaches rarely integrate domain-specific knowledge, resulting in generic and sometimes inaccurate summaries. In this study, we propose a novel framework, which combines ontology-based prompt tuning with abstractive text summarization to address these limitations. By leveraging ontological knowledge, our model fine-tunes the summarization process, ensuring that the generated summaries are not only accurate but also contextually relevant to the domain. This integration allows for a more nuanced understanding of the text, enabling the generation of summaries that better capture the essence of the news articles. Our evaluation results demonstrate significant improvements over state-of-the-art methods such as BART, BERT, and GPT-3.5. The results show that the proposed architecture achieved a 5.1% higher ROUGE-1 score and a 9.8% improvement in ROUGE-L compared to baseline models. Additionally, our model showed significance in F1, precision, and recall metrics, with major improvements of 6.7, 3.9, and 4.8%, respectively. These results underscore the effectiveness of integrating ontological insights into the prompt tuning process, offering a robust solution for generating high-quality, domain-specific news summaries.",2025,10.3389/frai.2025.1520144
Frugal innovation in the business environment: a literature review and future perspectives,"IntroductionThis research aims to explore the growing field of frugal innovation within the business environment, particularly its intersection with sustainability and artificial intelligence.MethodsThrough a comprehensive literature review, the study analyzes key research trends and methodologies from 420 scholarly articles published between 2012 and August 2024. A bibliometric review traces the evolution of frugal innovation, while a content analysis provides insights into its practical applications across various industries, especially in resource-constrained settings.ResultsThe findings highlight the significant role of frugal innovation in addressing global challenges, such as reducing environmental impact and promoting social inclusion, especially through the adoption of cleaner technologies and socially responsible business practices. The study also emphasizes the transformative potential of AI in enhancing the scalability and efficiency of frugal solutions.DiscussionThis research contributes to the ongoing conversation on sustainable development by identifying knowledge gaps and proposing future strategies for leveraging frugal innovation to drive inclusive growth. The implications of this research are valuable for academics, practitioners, and policymakers aiming to foster sustainable innovation in diverse socio-economic contexts.",2024,10.3389/frai.2024.1385522
Prompt engineering for accurate statistical reasoning with large language models in medical research,"BackgroundThe integration of generative artificial intelligence (AI), particularly large language models (LLMs), into medical statistics offers transformative potential. However, it also introduces risks of erroneous responses, especially in tasks requiring statistical rigor.ObjectiveTo evaluate the effectiveness of various prompt engineering strategies in guiding LLMs toward accurate and interpretable statistical reasoning in biomedical research.MethodsFour prompting strategies: zero-shot, explicit instruction, chain-of-thought, and hybrid were assessed using artificial datasets involving descriptive and inferential statistical tasks. Outputs from GPT-4.1 and Claude 3.7 Sonnet were evaluated using Microsoft Copilot as an LLM-as-a-judge, with human oversight.ResultsZero-shot prompting was sufficient for basic descriptive tasks but failed in inferential contexts due to lack of assumption checking. Hybrid prompting, which combines explicit instructions, reasoning scaffolds, and format constraints, consistently produced the most accurate and interpretable results. Evaluation scores across four criteria–assumption checking, test selection, output completeness, and interpretive quality confirmed the superiority of structured prompts.ConclusionPrompt design is a critical determinant of output quality in AI-assisted statistical analysis. Hybrid prompting strategies should be adopted as best practice in medical research to ensure methodological rigor and reproducibility. Additional testing with newer models, including Claude 4 Sonnet, Claude 4 Opus, o3 mini, and o4 mini, confirmed the consistency of results, supporting the generalizability of findings across both Anthropic and OpenAI model families. This study highlights prompt engineering as a core competency in AI-assisted medical research and calls for the development of standardized prompt templates, evaluation rubrics, and further studies across diverse statistical domains to support robust and reproducible scientific inquiry.",2025,10.3389/frai.2025.1658316
Augmented intelligence with voice assistance and automated machine learning in Industry 5.0,"Augmented intelligence puts together human and artificial agents to create a socio-technological system, so that they co-evolve by learning and optimizing decisions through intuitive interfaces, such as conversational, voice-enabled interfaces. However, existing research works on voice assistants relies on knowledge management and simulation methods instead of data-driven algorithms. In addition, practical application and evaluation in real-life scenarios are scarce and limited in scope. In this paper, we propose the integration of voice assistance technology with Automated Machine Learning (AutoML) in order to enable the realization of the augmented intelligence paradigm in the context of Industry 5.0. In this way, the user is able to interact with the assistant through Speech-To-Text (STT) and Text-To-Speech (TTS) technologies, and consequently with the Machine Learning (ML) pipelines that are automatically created with AutoML, through voice in order to receive immediate insights while performing their task. The proposed approach was evaluated in a real manufacturing environment. We followed a structured evaluation methodology, and we analyzed the results, which demonstrates the effectiveness of our proposed approach.",2025,10.3389/frai.2025.1538840
From outputs to insights: a survey of rationalization approaches for explainable text classification,"Deep learning models have achieved state-of-the-art performance for text classification in the last two decades. However, this has come at the expense of models becoming less understandable, limiting their application scope in high-stakes domains. The increased interest in explainability has resulted in many proposed forms of explanation. Nevertheless, recent studies have shown thatrationales, or language explanations, are more intuitive and human-understandable, especially for non-technical stakeholders. This survey provides an overview of the progress the community has achieved thus far in rationalization approaches for text classification. We first describe and compare techniques for producing extractive and abstractive rationales. Next, we present various rationale-annotated data sets that facilitate the training and evaluation of rationalization models. Then, we detail proxy-based and human-grounded metrics to evaluate machine-generated rationales. Finally, we outline current challenges and encourage directions for future work.",2024,10.3389/frai.2024.1363531
Cryptographic key generation using deep learning with biometric face and finger vein data,"This research proposes a novel approach to cryptographic key generation using biometric data from face and finger vein modalities enhanced by deep learning techniques. Using pretrained models FaceNet and VGG19 for feature extraction and employing a Siamese Neural Network (SNN), the study demonstrates the integration of multimodal biometrics with fuzzy extractors to create secure and reproducible cryptographic keys. Feature fusion techniques, combined with preprocessing and thresholding, ensure robust feature extraction and conversion to binary formats for key generation. The model demonstrates impressive accuracy with a vector converter, achieving a sigma similarity of 93% and a sigma difference of 64.0%. Evaluation metrics, including False Acceptance Rate (FAR) and False Rejection Rate (FRR), indicate significant improvements, achieving FRR &lt; 3.4% and FAR &lt; 1%, outperforming previous works. Additionally, the adoption of Goppa code-based cryptographic systems ensures post-quantum security. This study not only enhances biometric cryptography’s accuracy and resilience but also paves the way for future exploration of quantum-resistant and scalable systems.",2025,10.3389/frai.2025.1545946
Automating parasite egg detection: insights from the first AI-KFM challenge,"In the field of veterinary medicine, the detection of parasite eggs in the fecal samples of livestock animals represents one of the most challenging tasks, since their spread and diffusion may lead to severe clinical disease. Nowadays, the scanning procedure is typically performed by physicians with professional microscopes and requires a significant amount of time, domain knowledge, and resources. The Kubic FLOTAC Microscope (KFM) is a compact, low-cost, portable digital microscope that can autonomously analyze fecal specimens for parasites and hosts in both field and laboratory settings. It has been shown to acquire images that are comparable to those obtained with traditional optical microscopes, and it can complete the scanning and imaging process in just a few minutes, freeing up the operator's time for other tasks. To promote research in this area, the first AI-KFM challenge was organized, which focused on the detection of gastrointestinal nematodes (GINs) in cattle using RGB images. The challenge aimed to provide a standardized experimental protocol with a large number of samples collected in a well-known environment and a set of scores for the approaches submitted by the competitors. This paper describes the process of generating and structuring the challenge dataset and the approaches submitted by the competitors, as well as the lessons learned throughout this journey.",2024,10.3389/frai.2024.1325219
Clinical concept recognition: Evaluation of existing systems on EHRs,"ObjectiveThe adoption of electronic health records (EHRs) has produced enormous amounts of data, creating research opportunities in clinical data sciences. Several concept recognition systems have been developed to facilitate clinical information extraction from these data. While studies exist that compare the performance of many concept recognition systems, they are typically developed internally and may be biased due to different internal implementations, parameters used, and limited number of systems included in the evaluations. The goal of this research is to evaluate the performance of existing systems to retrieve relevant clinical concepts from EHRs.MethodsWe investigated six concept recognition systems, including CLAMP, cTAKES, MetaMap, NCBO Annotator, QuickUMLS, and ScispaCy. Clinical concepts extracted included procedures, disorders, medications, and anatomical location. The system performance was evaluated on two datasets: the 2010 i2b2 and the MIMIC-III. Additionally, we assessed the performance of these systems in five challenging situations, including negation, severity, abbreviation, ambiguity, and misspelling.ResultsFor clinical concept extraction, CLAMP achieved the best performance on exact and inexact matching, with an F-score of 0.70 and 0.94, respectively, on i2b2; and 0.39 and 0.50, respectively, on MIMIC-III. Across the five challenging situations, ScispaCy excelled in extracting abbreviation information (F-score: 0.86) followed by NCBO Annotator (F-score: 0.79). CLAMP outperformed in extracting severity terms (F-score 0.73) followed by NCBO Annotator (F-score: 0.68). CLAMP outperformed other systems in extracting negated concepts (F-score 0.63).ConclusionsSeveral concept recognition systems exist to extract clinical information from unstructured data. This study provides an external evaluation by end-users of six commonly used systems across different extraction tasks. Our findings suggest that CLAMP provides the most comprehensive set of annotations for clinical concept extraction tasks and associated challenges. Comparing standard extraction tasks across systems provides guidance to other clinical researchers when selecting a concept recognition system relevant to their clinical information extraction task.",2023,10.3389/frai.2022.1051724
Early breast cancer detection and differentiation tool based on tissue impedance characteristics and machine learning,"During Basic screening, it is challenging, if not impossible to detect breast cancer especially in the earliest stage of tumor development. However, measuring the electrical impedance of biological tissue can detect abnormalities even before being palpable. Thus, we used impedance characteristics data of various breast tissue to develop a breast cancer screening tool guided and augmented by a deep learning (DL). A DL algorithm was trained to ideally classify six classes of breast cancer based on electrical impedance characteristics data of the breast tissue. The tool correctly predicted breast cancer in data of patients whose breast tissue impedance was reported to have been measured when other methods detected no anomaly in the tissue. Furthermore, a DL-based approach using Long Short-Term Memory (LSTM) effectively classified breast tissue with an accuracy of 96.67%. Thus, the DL algorithm and method we developed accurately augmented breast tissue classification using electrical impedance and enhanced the ability to detect and differentiate cancerous tissue in very early stages. However, more data and pre-clinical is required to improve the accuracy of this early breast cancer detection and differentiation tool.",2023,10.3389/frai.2023.1248977
Rule Extraction From Binary Neural Networks With Convolutional Rules for Model Validation,"Classification approaches that allow to extract logical rules such as decision trees are often considered to be more interpretable than neural networks. Also, logical rules are comparatively easy to verify with any possible input. This is an important part in systems that aim to ensure correct operation of a given model. However, for high-dimensional input data such as images, the individual symbols, i.e. pixels, are not easily interpretable. Therefore, rule-based approaches are not typically used for this kind of high-dimensional data. We introduce the concept of first-order convolutional rules, which are logical rules that can be extracted using a convolutional neural network (CNN), and whose complexity depends on the size of the convolutional filter and not on the dimensionality of the input. Our approach is based on rule extraction from binary neural networks with stochastic local search. We show how to extract rules that are not necessarily short, but characteristic of the input, and easy to visualize. Our experiments show that the proposed approach is able to model the functionality of the neural network while at the same time producing interpretable logical rules. Thus, we demonstrate the potential of rule-based approaches for images which allows to combine advantages of neural networks and rule learning.",2021,10.3389/frai.2021.642263
The extended hollowed mind: why foundational knowledge is indispensable in the age of AI,"Generative artificial intelligence (AI) presents a fundamental duality for education: it simultaneously offers powerful cognitive extension while posing a significant risk of cognitive atrophy. This paper introduces the ‘hollowed mind’ as a conceptual framework to understand this risk—a state of dependency where the frictionless availability of AI-generated answers enables users to systematically bypass the effortful cognitive processes essential for deep learning. We argue this dynamic is driven by the ‘Sovereignty Trap’: a psychological mechanism where the AI’s authoritative competence tempts users to cede their own intellectual judgment, mistaking access to information for genuine ability. To substantiate this claim, we synthesize a multi-disciplinary body of evidence from cognitive science (e.g., dual-process theory, cognitive load), neurobiology (e.g., conflict-monitoring networks), and developmental psychology. We use this foundation to explain the widely documented ‘Expertise Duality’—why AI acts as a ‘leveler’ for novices but an ‘amplifier’ for experts. Moving beyond critique, this paper posits that the central challenge is one of environmental design, not user competence. We propose the ‘Fortified Mind’ as the pedagogical goal: a resilient internal architecture of indispensable knowledge and metacognitive skills required to achieve genuine ‘Cognitive Sovereignty’. Finally, we outline a forward-looking research agenda focused on redesigning AI tools from ‘answer engines’ into cognitive training environments that promote effortful engagement. Our work provides a robust conceptual guide for educators, researchers, and system designers, arguing that in the age of AI, the cultivation of fundamental knowledge is not just relevant, but more crucial than ever.",2025,10.3389/frai.2025.1719019
Generative and Predictive AI for digital twin systems in manufacturing,"The integration of Artificial Intelligence (AI) and Digital Twin (DT) technology is reshaping modern manufacturing by enabling real-time monitoring, predictive maintenance, and intelligent process optimisation. This paper presents the design and partial implementation of an AI-enabled Digital Twin System (AI-DT) for manufacturing, focusing on the deployment of Generative AI (GAI) and Predictive AI (PAI) modules. The GAI component is used to augment training data, perform geometric inspection, and generate 3D virtual testing environments from multiview video input. Meanwhile, PAI leverages sensor data to enable proactive defect detection and predictive quality analysis in welding processes. These integrated capabilities significantly enhance the system's ability to anticipate issues and support decision-making. While the framework also envisions incorporating Explainable AI (EAI), Context-Aware AI (CAI), and Agentic AI (AAI) for future extensions, the current work establishes a robust foundation for scalable, intelligent digital twin systems in smart manufacturing. Our findings contribute toward improving operational efficiency, quality assurance, and early-stage digital-physical convergence.",2025,10.3389/frai.2025.1655470
Ps and Qs: Quantization-Aware Pruning for Efficient Low Latency Neural Network Inference,"Efficient machine learning implementations optimized for inference in hardware have wide-ranging benefits, depending on the application, from lower inference latency to higher data throughput and reduced energy consumption. Two popular techniques for reducing computation in neural networks are pruning, removing insignificant synapses, and quantization, reducing the precision of the calculations. In this work, we explore the interplay between pruning and quantization during the training of neural networks for ultra low latency applications targeting high energy physics use cases. Techniques developed for this study have potential applications across many other domains. We study various configurations of pruning during quantization-aware training, which we termquantization-aware pruning, and the effect of techniques like regularization, batch normalization, and different pruning schemes on performance, computational complexity, and information content metrics. We find that quantization-aware pruning yields more computationally efficient models than either pruning or quantization alone for our task. Further, quantization-aware pruning typically performs similar to or better in terms of computational efficiency compared to other neural architecture search techniques like Bayesian optimization. Surprisingly, while networks with different training configurations can have similar performance for the benchmark application, the information content in the network can vary significantly, affecting its generalizability.",2021,10.3389/frai.2021.676564
Weighted Bayesian Belief Network for diabetics: a predictive model,"Diabetes is an enduring metabolic condition identified by heightened blood sugar levels stemming from insufficient production of insulin or ineffective utilization of insulin within the body. India is commonly labeled as the “diabetes capital of the world” owing to the widespread prevalence of this condition. To the best of the authors' last knowledge updated on September 2021, approximately 77 million adults in India were reported to be affected by diabetes, reported by the International Diabetes Federation. Owing to the concealed early symptoms, numerous diabetic patients go undiagnosed, leading to delayed treatment. While Computational Intelligence approaches have been utilized to improve the prediction rate, a significant portion of these methods lacks interpretability, primarily due to their inherent black box nature. Rule extraction is frequently utilized to elucidate the opaque nature inherent in machine learning algorithms. Moreover, to resolve the black box nature, a method for extracting strong rules based on Weighted Bayesian Association Rule Mining is used so that the extracted rules to diagnose any disease such as diabetes can be very transparent and easily analyzed by the clinical experts, enhancing the interpretability. The WBBN model is constructed utilizing the UCI machine learning repository, demonstrating a performance accuracy of 95.8%.",2024,10.3389/frai.2024.1357121
An Introduction to Topological Data Analysis: Fundamental and Practical Aspects for Data Scientists,"With the recent explosion in the amount, the variety, and the dimensionality of available data, identifying, extracting, and exploiting their underlying structure has become a problem of fundamental importance for data analysis and statistical learning. Topological data analysis (
                    tda
                    ) is a recent and fast-growing field providing a set of new topological and geometric tools to infer relevant features for possibly complex data. It proposes new well-founded mathematical theories and computational tools that can be used independently or in combination with other data analysis and statistical learning techniques. This article is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of
                    tda
                    for nonexperts.",2021,10.3389/frai.2021.667963
Learning Medical Materials From Radiography Images,"Deep learning models have been shown to be effective for material analysis, a subfield of computer vision, on natural images. In medicine, deep learning systems have been shown to more accurately analyze radiography images than algorithmic approaches and even experts. However, one major roadblock to applying deep learning-based material analysis on radiography images is a lack of material annotations accompanying image sets. To solve this, we first introduce an automated procedure to augment annotated radiography images into a set of material samples. Next, using a novel Siamese neural network that compares material sample pairs, called D-CNN, we demonstrate how to learn a perceptual distance metric between material categories. This system replicates the actions of human annotators by discovering attributes that encode traits that distinguish materials in radiography images. Finally, we update and apply MAC-CNN, a material recognition neural network, to demonstrate this system on a dataset of knee X-rays and brain MRIs with tumors. Experiments show that this system has strong predictive power on these radiography images, achieving 92.8% accuracy at predicting the material present in a local region of an image. Our system also draws interesting parallels between human perception of natural materials and materials in radiography images.",2021,10.3389/frai.2021.638299
Location and Language Independent Fake Rumor Detection Through Epidemiological and Structural Graph Analysis of Social Connections,"Detection and identification of misinformation and fake news is a complex problem that intersects several disciplines, ranging from sociology to computer science and mathematics. In this work, we focus on social media analyzing characteristics that are independent of the text language (language-independent) and social context (location-independent) and common to most social media, not only Twitter as mostly analyzed in the literature. Specifically, we analyze temporal and structural characteristics of information flow in the social networks and we evaluate the importance and effect of two different types of features in the detection process of fake rumors. Specifically, we extract epidemiological features exploiting epidemiological models for spreading false rumors; furthermore, we extract graph-based features from the graph structure of the information cascade of the social graph. Using these features, we evaluate them for fake rumor detection with 3 configurations: (i) using only epidemiological features, (ii) using only graph-based features, and (iii) using the combination of epidemiological and graph-based features. Evaluation is performed with a Gradient Boosting classifier on two benchmark fake rumor detection datasets. Our results demonstrate that epidemiological models fit rumor propagation well, while graph-based features lead to more effective classification of rumors; the combination of epidemiological and graph-based features leads to improved performance.",2022,10.3389/frai.2022.734347
Profiling the barriers to the spreading of news using news headlines,"News headlines can be a good data source for detecting the barriers to the spreading of news in news media, which can be useful in many real-world applications. In this study, we utilize semantic knowledge through the inference-based model COMET and the sentiments of news headlines for barrier classification. We consider five barriers, including cultural, economic, political, linguistic, and geographical and different types of news headlines, including health, sports, science, recreation, games, homes, society, shopping, computers, and business. To that end, we collect and label the news headlines automatically for the barriers using the metadata of news publishers. Then, we utilize the extracted common-sense inferences and sentiments as features to detect the barriers to the spreading of news. We compare our approach to the classical text classification methods, deep learning, and transformer-based methods. The results show that (1) the inference-based semantic knowledge provides distinguishable inferences across the 10 categories that can increase the effectiveness and enhance the speed of the classification model; (2) the news of positive sentiments cross the political barrier, whereas the news of negative sentiments cross the cultural, economic, linguistic, and geographical barriers; (3) the proposed approach using inferences-based semantic knowledge and sentiment improves performance compared with using only headlines in barrier classification. The average F1-score for 4 out of 5 barriers has significantly improved as follows: for cultural barriers from 0.41 to 0.47, for economic barriers from 0.39 to 0.55, for political barriers from 0.59 to 0.70 and for geographical barriers from 0.59 to 0.76.",2023,10.3389/frai.2023.1225213
Active feature elicitation: An unified framework,"We consider the problem of active feature elicitation in which, given some examples with all the features (say, the full Electronic Health Record), and many examples with some of the features (say, demographics), the goal is to identify the set of examples on which more information (say, lab tests) need to be collected. The observation is that some set of features may be more expensive, personal or cumbersome to collect. We propose a classifier-independent, similarity metric-independent, general active learning approach which identifies examples that are dissimilar to the ones with the full set of data and acquire the complete set of features for these examples. Motivated by four real clinical tasks, our extensive evaluation demonstrates the effectiveness of this approach. To demonstrate the generalization capabilities of the proposed approach, we consider different divergence metrics and classifiers and present consistent results across the domains.",2023,10.3389/frai.2023.1029943
What naturalistic stimuli tell us about pronoun resolution in real-time processing,"Studies on pronoun resolution have mostly utilized short texts consisting of a context and a target sentence. In the current study we presented participants with nine chapters of an audio book while recording their EEG to investigate the real-time resolution of personal and demonstrative pronouns in a more naturalistic setting. The annotation of the features of the pronouns and their antecedents registered a surprising pattern: demonstrative pronouns showed an interpretive preference for subject/agent antecedents, although they are described to have an anti-subject or anti-agent preference. Given the presence of perspectival centers in the audio book, this however confirmed proposals that demonstrative pronouns are sensitive to perspectival centers. The ERP results revealed a biphasic N400–Late Positivity pattern at posterior electrodes for the demonstrative pronoun relative to the personal pronoun, thereby confirming previous findings with highly controlled stimuli. We take the observed N400 for the demonstrative pronoun as an indication for more demanding processing costs that occur due to the relative unexpectedness of this referential expression. The Late Positivity is taken to reflect the consequences of attentional reorientation: since the demonstrative pronoun indicates a possible shift in the discourse structure, it induces updating of the discourse structure. In addition to the biphasic pattern, the data showed an enhanced positivity at frontal electrode sites for the demonstrative pronoun relative to the personal pronoun. We suggest that this frontal positivity reflects self-relevant engagement and identification with the perspective holder. Our study suggests that by using naturalistic stimuli, we get one step closer to understanding the implementation of language processing in the brain during real life language processing.",2023,10.3389/frai.2023.1058554
Deep learning analysis of exercise stress electrocardiography for identification of significant coronary artery disease,"BackgroundThe diagnostic power of exercise stress electrocardiography (ExECG) remains limited. We aimed to construct an artificial intelligence (AI)-based method to enhance ExECG performance to identify patients with significant coronary artery disease (CAD).MethodsWe retrospectively collected 818 patients who underwent both ExECG and coronary angiography (CAG) within 6 months. The mean age was 57.0 ± 10.1 years, and 614 (75%) were male patients. Significant coronary artery disease was seen in 369 (43.8%) CAG reports. We also included 197 individuals with normal ExECG and low risk of CAD. A convolutional recurrent neural network algorithm, integrating electrocardiographic (ECG) signals and features from ExECG reports, was developed to predict the risk of significant CAD. We also investigated the optimal number of inputted ECG signal slices and features and the weighting of features for model performance.ResultsUsing the data of patients undergoing CAG for training and test sets, our algorithm had an area under the curve, sensitivity, and specificity of 0.74, 0.86, and 0.47, respectively, which increased to 0.83, 0.89, and 0.60, respectively, after enrolling 197 subjects with low risk of CAD. Three ECG signal slices and 12 features yielded optimal performance metrics. The principal predictive feature variables were sex, maximum heart rate, and ST/HR index. Our model generated results within one minute after completing ExECG.ConclusionThe multimodal AI algorithm, leveraging deep learning techniques, efficiently and accurately identifies patients with significant CAD using ExECG data, aiding clinical screening in both symptomatic and asymptomatic patients. Nevertheless, the specificity remains moderate (0.60), suggesting a potential for false positives and highlighting the need for further investigation.",2025,10.3389/frai.2025.1496109
Dual feature-based and example-based explanation methods,"A new approach to the local and global explanation based on selecting a convex hull constructed for the finite number of points around an explained instance is proposed. The convex hull allows us to consider a dual representation of instances in the form of convex combinations of extreme points of a produced polytope. Instead of perturbing new instances in the Euclidean feature space, vectors of convex combination coefficients are uniformly generated from the unit simplex, and they form a new dual dataset. A dual linear surrogate model is trained on the dual dataset. The explanation feature importance values are computed by means of simple matrix calculations. The approach can be regarded as a modification of the well-known model LIME. The dual representation inherently allows us to get the example-based explanation. The neural additive model is also considered as a tool for implementing the example-based explanation approach. Many numerical experiments with real datasets are performed for studying the approach. A code of proposed algorithms is available. The proposed results are fundamental and can be used in various application areas. They do not involve specific human subjects and human data.",2025,10.3389/frai.2025.1506074
Improving deceased donor kidney utilization: predicting risk of nonuse with interpretable models,"BackgroundMany deceased donor kidneys go unused despite growing demand for transplantation. Early identification of organs at high risk of nonuse can facilitate effective allocation interventions, ensuring these organs are offered to patients who could potentially benefit from them. While several machine learning models have been developed to predict nonuse risk, the complexity of these models compromises their practical implementation.MethodsWe propose simplified, implementable nonuse risk prediction models that combine the Kidney Donor Risk Index (KDRI) with a small set of variables selected through machine learning or transplantation expert input. Our approach also account for Organ Procurement Organization (OPO) level factors affecting kidney disposition.ResultsThe proposed models demonstrate competitive performance compared to more complex models that involve a large number of variables while maintaining interpretability and ease of use.ConclusionOur models provide accurate, interpretable risk predictions and highlight key drivers of kidney nonuse, including variation across OPOs. These findings can inform the design of effective organ allocation interventions, increasing the likelihood of transplantation for hard-to-place kidneys.",2025,10.3389/frai.2025.1638574
Effective methods and framework for energy-based local learning of deep neural networks,"From a neuroscience perspective, artificial neural networks are regarded as abstract models of biological neurons, yet they rely on biologically implausible backpropagation for training. Energy-based models represent a class of brain-inspired learning frameworks that adjust system states by minimizing an energy function. Predictive coding (PC), a theoretical model within energy-based models, constructs its energy function from forward prediction errors, with optimization achieved by minimizing local layered errors. Owing to its local plasticity, PC emerges as the most promising alternative to backpropagation. However, PC face gradient explosion and vanishing challenges in deep networks with multiple layers. Gradient explosion occurs when layer-wise prediction errors are excessively large, while gradient vanishing arises when they are excessively small. To address these challenges, we propose bidirectional energy to stabilize prediction errors and mitigate gradient explosion, while using skip connections to resolve gradient vanishing problems. We also introduce a layer-adaptive learning rate (LALR) to enhance training efficiency. Our model achieves accuracies of 99.22% on MNIST, 93.78% on CIFAR-10, 83.96% on CIFAR-100, and 73.35% on Tiny ImageNet, comparable to the performance of identically structed networks trained with backprop. Finally, we developed a Jax-based framework for efficient training of energy-based models, reducing training time by half compared to PyTorch.",2025,10.3389/frai.2025.1605706
Diagnostic Accuracy of Machine Learning Models to Identify Congenital Heart Disease: A Meta-Analysis,"Background: With the dearth of trained care providers to diagnose congenital heart disease (CHD) and a surge in machine learning (ML) models, this review aims to estimate the diagnostic accuracy of such models for detecting CHD.Methods: A comprehensive literature search in the PubMed, CINAHL, Wiley Cochrane Library, and Web of Science databases was performed. Studies that reported the diagnostic ability of ML for the detection of CHD compared to the reference standard were included. Risk of bias assessment was performed using Quality Assessment for Diagnostic Accuracy Studies-2 tool. The sensitivity and specificity results from the studies were used to generate the hierarchical Summary ROC (HSROC) curve.Results: We included 16 studies (1217 participants) that used ML algorithm to diagnose CHD. Neural networks were used in seven studies with overall sensitivity of 90.9% (95% CI 85.2–94.5%) and specificity was 92.7% (95% CI 86.4–96.2%). Other ML models included ensemble methods, deep learning and clustering techniques but did not have sufficient number of studies for a meta-analysis. Majority (n=11, 69%) of studies had a high risk of patient selection bias, unclear bias on index test (n=9, 56%) and flow and timing (n=12, 75%) while low risk of bias was reported for the reference standard (n=10, 62%).Conclusion: ML models such as neural networks have the potential to diagnose CHD accurately without the need for trained personnel. The heterogeneity of the diagnostic modalities used to train these models and the heterogeneity of the CHD diagnoses included between the studies is a major limitation.",2021,10.3389/frai.2021.708365
Expandable-RCNN: toward high-efficiency incremental few-shot object detection,"This study aims at addressing the challenging incremental few-shot object detection (iFSOD) problem toward online adaptive detection. iFSOD targets to learn novel categories in a sequential manner, and eventually, the detection is performed on all learned categories. Moreover, only a few training samples are available for all sequential novel classes in these situations. In this study, we propose an efficient yet suitably simple framework, Expandable-RCNN, as a solution for the iFSOD problem, which allows online sequentially adding new classes with zero retraining of the base network. We achieve this by adapting the Faster R-CNN to the few-shot learning scenario with two elegant components to effectively address the overfitting and category bias. First, an IOU-aware weight imprinting strategy is proposed to directly determine the classifier weights for incremental novel classes and the background class, which is with zero training to avoid the notorious overfitting issue in few-shot learning. Second, since the above zero-retraining imprinting approach may lead to undesired category bias in the classifier, we develop a bias correction module for iFSOD, named the group soft-max layer (GSL), that efficiently calibrates the biased prediction of the imprinted classifier to organically improve classification performance for the few-shot classes, preventing catastrophic forgetting. Extensive experiments on MS-COCO show that our method can significantly outperform the state-of-the-art method ONCE by 5.9 points in commonly encountered few-shot classes.",2024,10.3389/frai.2024.1377337
Listener Modeling and Context-Aware Music Recommendation Based on Country Archetypes,"Music preferences are strongly shaped by the cultural and socio-economic background of the listener, which is reflected, to a considerable extent, in country-specific music listening profiles. Previous work has already identified several country-specific differences in the popularity distribution of music artists listened to. In particular, what constitutes the “music mainstream” strongly varies between countries. To complement and extend these results, the article at hand delivers the following major contributions: First, using state-of-the-art unsupervized learning techniques, we identify and thoroughly investigate (1) country profiles of music preferences on the fine-grained level of music tracks (in contrast to earlier work that relied on music preferences on the artist level) and (2) country archetypes that subsume countries sharing similar patterns of listening preferences. Second, we formulate four user models that leverage the user’s country information on music preferences. Among others, we propose a user modeling approach to describe a music listener as a vector of similarities over the identified country clusters or archetypes. Third, we propose a context-aware music recommendation system that leverages implicit user feedback, where context is defined via the four user models. More precisely, it is a multi-layer generative model based on a variational autoencoder, in which contextual features can influence recommendations through a gating mechanism. Fourth, we thoroughly evaluate the proposed recommendation system and user models on a real-world corpus of more than one billion listening records of users around the world (out of which we use 369 million in our experiments) and show its merits vis-à-vis state-of-the-art algorithms that do not exploit this type of context information.",2021,10.3389/frai.2020.508725
Application of Laser-Induced Breakdown Spectroscopy Coupled With Spectral Matrix and Convolutional Neural Network for Identifying Geographical Origins of Gentiana rigescens Franch,"Accurate geographical origin identification is of great significance to ensure the quality of traditional Chinese medicine (TCM). Laser-induced breakdown spectroscopy (LIBS) was applied to achieve the fast geographical origin identification of wild Gentiana rigescens Franch (G. rigescens Franch). However, LIBS spectra with too many variables could increase the training time of models and reduce the discrimination accuracy. In order to solve the problems, we proposed two methods. One was reducing the number of variables through two consecutive variable selections. The other was transforming the spectrum into spectral matrix by spectrum segmentation and recombination. Combined with convolutional neural network (CNN), both methods could improve the accuracy of discrimination. For the underground parts of G. rigescens Franch, the optimal accuracy in the prediction set for the two methods was 92.19 and 94.01%, respectively. For the aerial parts, the two corresponding accuracies were the same with the value of 94.01%. Saliency map was used to explain the rationality of discriminant analysis by CNN combined with spectral matrix. The first method could provide some support for LIBS portable instrument development. The second method could offer some reference for the discriminant analysis of LIBS spectra with too many variables by the end-to-end learning of CNN. The present results demonstrated that LIBS combined with CNN was an effective tool to quickly identify the geographical origin of G. rigescens Franch.",2021,10.3389/frai.2021.735533
Metaverse technology tree: a holistic view,"IntroductionThe Metaverse has emerged as a significant trend in recent years, offering solutions across diverse fields. Despite substantial investments and extensive research efforts, a comprehensive understanding of the Metaverse environment and its full potential remains elusive. This article seeks to address this gap by developing a technology tree for the Metaverse based on published standards, prior studies, and frameworks proposed by leading firms.MethodsTo construct the Metaverse technology tree, a systematic literature review approach was employed. From an initial pool of 354 scientific papers, conference proceedings, book chapters, and reports, a rigorous screening process –focused on titles, abstracts, and full-texts –resulted in a selection of 81 final sources. These sources were synthesized using a meta-analysis methodology.ResultsThe meta-synthesis of the selected literature produced a comprehensive Metaverse technology tree encompassing seven key branches: artificial intelligence, Mirror World, extended reality, network infrastructure, lifelogging, blockchain, and the Internet of Things. Each branch represents a critical technological area necessary for the development and realization of the Metaverse.DiscussionThe proposed Metaverse technology tree offers a holistic overview and roadmap of the technological domains underlying the Metaverse. By identifying these seven branches, this research provides valuable guidance for future studies and development trajectories in Metaverse technologies.",2025,10.3389/frai.2025.1545144
Accelerating earth science discovery via multi-agent LLM systems,"This Perspective explores the transformative potential of multi-agent systems (MAS) powered by Large Language Models (LLMs) in the geosciences. Users of geoscientific data repositories face challenges due to the complexity and diversity of data formats, inconsistent metadata practices, and a considerable number of unprocessed datasets. MAS possesses transformative potential for improving scientists’ interaction with geoscientific data by enabling intelligent data processing, natural language interfaces, and collaborative problem-solving capabilities. We illustrate this approach with “PANGAEA GPT,” a specialized MAS pipeline integrated with the diverse PANGAEA database for Earth &amp; Environmental Science, demonstrating how MAS-driven workflows can effectively manage complex datasets and accelerate scientific discovery. We discuss how MAS can address current data challenges in geosciences, highlight advancements in other scientific fields, and propose future directions for integrating MAS into geoscientific data processing pipelines. In this Perspective, we show how MAS can fundamentally improve data accessibility, promote cross-disciplinary collaboration, and accelerate geoscientific discoveries.",2025,10.3389/frai.2025.1674927
"A deterministic large language model (LLM) framework for safe, protocol-adherent clinical decision support: application in hemodialysis anemia management (AnemiaCare HDs)","Background
                    Large language models (LLMs) show promise for clinical decision support but often deviate from evidence-based protocols, raising safety and regulatory concerns. Anemia management in hemodialysis patients requires strict adherence to erythropoiesis-stimulating agent (ESA) and intravenous (IV) iron dosing rules, making it a high-risk use case for uncontrolled model behavior. To address this gap, we developed AnemiaCare HD, a deterministic LLM framework engineered to deliver transparent, reproducible, and protocol-adherent clinical recommendations.
                  
                  
                    Methods
                    AnemiaCare HD was evaluated using 600 simulated hemodialysis anemia scenarios derived from a standardized institutional protocol. The model required six fixed clinical inputs (hemoglobin, hemoglobin rate of change, trend direction, transferrin saturation, ferritin, and current ESA dose). Phase 1 tested a loosely structured prompt. Phase 2 implemented deterministic prompt logic incorporating ESA kinetics, iron dosing rules, mandatory timing safeguards, and embedded safety alerts. Two independent nephrologists assessed protocol adherence.
                  
                  
                    Results
                    
                      In Phase 1, only 96 of 300 cases (32%) aligned with protocol recommendations, with common errors in ESA titration, iron dosing, and timing violations. In Phase 1, loosely structured prompting produced variable outputs, with only 96 of 300 simulated cases (32%) fully protocol-adherent and frequent unsafe recommendations. In contrast, deterministic prompting in Phase 2 resulted in 100% adherence across all 300 cases, eliminating protocol deviations, unsafe iron dosing, and timing violations (
                      p
                       &lt; 0.001). In Phase 2, deterministic encoding achieved full protocol adherence (300/300, 100%), eliminating unsafe or premature recommendations (
                      p
                       &lt; 0.001 vs. Phase 1) and consistently generating structured, rationale-based outputs.
                    
                  
                  
                    Conclusion
                    Deterministic LLM engineering enables safe, fully protocol-compliant clinical decision support in high-risk therapeutic domains. AnemiaCare HD demonstrates the viability of regulatory-aligned, auditable LLM frameworks for clinical use, although real-world integration and prospective validation remain necessary next steps.",2025,10.3389/frai.2025.1728320
Impact of generative AI in medical education in India: a systematic review,"Background
                    The advent of generative Artificial Intelligence (AI) has presented a fundamental change in the approach to medical education across the world. In India, where the medical education is facing a shortage in faculties and resources, generative AI (GenAI) has the potential of transforming this. This systematic review summarizes the current evidence on the impact, student readiness, and various ethical challenges and barriers of integration of AI into the medical curriculum.
                  
                  
                    Methods
                    We followed the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines and searched published articles in PubMed and Google Scholar from 2020 to 2025. The search yielded 19,777 articles, from which 11 studies focusing on Indian medical students were selected. The findings of these studies were analyzed using Laurillard’s six learning modes to gain a comprehensive pedagogical understanding.
                  
                  
                    Result
                    Our study revealed a significant finding: while high awareness and positive perception towards AI have been shown by Indian medical students, most of the students lack formal training. These selected studies show that the students mostly use generative AI for clearing doubts, making assignments, and self-directed learning, shifting from the ‘Acquisition’ to ‘Inquiry’ and ‘Production’ modes of Laurillard’s learning. Comparative Analysis showed that GenAI tools outperform students on standard exams, thus showing their potential. However, certain challenges also exist, including the risk of misinformation, over-reliance, potential decrease in critical thinking, and ethical concerns of data privacy.
                  
                  
                    Conclusion
                    Indian medical students are enthusiastically adopting GenAI, but their engagement is mostly unstructured and informal. A significant gap exists between the readiness of the students and the medical institutions. To maximize the potential use of GenAI, our institutions have to develop a structured curriculum, invest in faculty training, and establish ethical guidelines. Teamwork between policymakers, educators, and researchers is the need of the hour so that our future physicians will be ready to integrate AI-enabled healthcare.
                  
                  
                    Syestematic review registration
                    
                      https://doi.org/10.17605/OSF.IO/2MJVK
                      .",2025,10.3389/frai.2025.1704785
Is it time we get real? A systematic review of the potential of data-driven technologies to address teachers' implicit biases,"Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers' biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers' biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies.",2022,10.3389/frai.2022.994967
Artificial intelligence challenges in the face of biological threats: emerging catastrophic risks for public health,"The threat landscape of biological hazards with the evolution of AI presents challenges. While AI promises innovative solutions, concerns arise about its misuse in the creation of biological weapons. The convergence of AI and genetic editing raises questions about biosecurity, potentially accelerating the development of dangerous pathogens. The mapping conducted highlights the critical intersection between AI and biological threats, underscoring emerging risks in the criminal manipulation of pathogens. Technological advancement in biology requires preventative and regulatory measures. Expert recommendations emphasize the need for solid regulations and responsibility of creators, demanding a proactive, ethical approach and governance to ensure global safety.",2024,10.3389/frai.2024.1382356
"Cyberinfrastructure for machine learning applications in agriculture: experiences, analysis, and vision","IntroductionAdvancements in machine learning (ML) algorithms that make predictions from data without being explicitly programmed and the increased computational speeds of graphics processing units (GPUs) over the last decade have led to remarkable progress in the capabilities of ML. In many fields, including agriculture, this progress has outpaced the availability of sufficiently diverse and high-quality datasets, which now serve as a limiting factor. While many agricultural use cases appear feasible with current compute resources and ML algorithms, the lack of reusable hardware and software components, referred to as cyberinfrastructure (CI), for collecting, transmitting, cleaning, labeling, and training datasets is a major hindrance toward developing solutions to address agricultural use cases. This study focuses on addressing these challenges by exploring the collection, processing, and training of ML models using a multimodal dataset and providing a vision for agriculture-focused CI to accelerate innovation in the field.MethodsData were collected during the 2023 growing season from three agricultural research locations across Ohio. The dataset includes 1 terabyte (TB) of multimodal data, comprising Unmanned Aerial System (UAS) imagery (RGB and multispectral), as well as soil and weather sensor data. The two primary crops studied were corn and soybean, which are the state's most widely cultivated crops. The data collected and processed from this study were used to train ML models to make predictions of crop growth stage, soil moisture, and final yield.ResultsThe exercise of processing this dataset resulted in four CI components that can be used to provide higher accuracy predictions in the agricultural domain. These components included (1) a UAS imagery pipeline that reduced processing time and improved image quality over standard methods, (2) a tabular data pipeline that aggregated data from multiple sources and temporal resolutions and aligned it with a common temporal resolution, (3) an approach to adapting the model architecture for a vision transformer (ViT) that incorporates agricultural domain expertise, and (4) a data visualization prototype that was used to identify outliers and improve trust in the data.DiscussionFurther work will be aimed at maturing the CI components and implementing them on high performance computing (HPC). There are open questions as to how CI components like these can best be leveraged to serve the needs of the agricultural community to accelerate the development of ML applications in agriculture.",2025,10.3389/frai.2024.1496066
A predictive analytics approach to improve telecom's customer retention,"Customer retention is a critical challenge for telecom companies, and understanding customer churn can significantly improve business strategies. This paper focuses on developing an accurate predictive model to identify potential customer churn using advanced data analysis techniques. By applying machine learning algorithms, our aim is to improve decision-making processes and enable telecom providers to take proactive measures to retain customers. Through this research, we seek to gain deeper insight into customer behavior, ultimately helping telecom companies improve service offerings and reduce churn rates. We developed and evaluated a diverse set of predictive models using a dataset representing customer churn. Our comparative analysis highlights the strengths and weaknesses of various techniques, and among the developed models, the Support Vector Machine (SVM) achieved the highest performance. The main contribution of this study lies in integrating effective data pre-processing, feature selection, and interpretability into churn prediction models, thus addressing the gaps identified in earlier research.",2025,10.3389/frai.2025.1600357
"Machine learning-based strategies for improving healthcare data quality: an evaluation of accuracy, completeness, and reusability","Healthcare data quality is a critical factor in clinical decision-making, diagnostic accuracy, and the overall efficacy of healthcare systems. This study addresses key challenges such as missing values and anomalies in healthcare datasets, which can result in misdiagnoses and inefficient resource use. The objective is to develop and evaluate a machine learning-based strategy to improve healthcare data quality, with a focus on three core dimensions: accuracy, completeness, and reusability. A publicly available diabetes dataset comprising 768 records and 9 variables was used. The methodology involved a comprehensive data preprocessing workflow, including data acquisition, cleaning, and exploratory analysis using established Python tools. Missing values were addressed using K-nearest neighbors imputation, while anomaly detection was performed using ensemble techniques. Principal Component Analysis (PCA) and correlation analysis were applied to identify key predictors of diabetes, such as Glucose, BMI, and Age. The results showed significant improvements in data completeness (from 90.57% to nearly 100%), better accuracy by mitigating anomalies, and enhanced reusability for downstream machine learning tasks. In predictive modeling, Random Forest outperformed LightGBM, achieving an accuracy of 75.3% and an AUC of 0.83. The process was fully documented, and reproducibility tools were integrated to ensure the methodology could be replicated and extended. These findings demonstrate the potential of machine learning to support robust data quality improvement frameworks in healthcare, ultimately contributing to better clinical outcomes and predictive capabilities.",2025,10.3389/frai.2025.1621514
Artificial intelligence-based framework for early detection of heart disease using enhanced multilayer perceptron,"Cardiac disease refers to diseases that affect the heart such as coronary artery diseases, arrhythmia and heart defects and is amongst the most difficult health conditions known to humanity. According to the WHO, heart disease is the foremost cause of mortality worldwide, causing an estimated 17.8 million deaths every year it consumes a significant amount of time as well as effort to figure out what is causing this, especially for medical specialists and doctors. Manual methods for detecting cardiac disease are biased and subject to medical specialist variance. In this aspect, machine learning algorithms have proved to be effective and dependable alternatives for detecting and classifying patients who are affected by heart disease. Precise and prompt detection of human heart disease can assist in avoiding heart failure within the initial stages and enhance patient survival. This study proposed a novel Enhanced Multilayer Perceptron (EMLP) framework complemented by data refinement techniques to enhance predictive accuracy. The classification model asses using the CDC cardiac disease dataset and achieved 92% accuracy by surpassing all the traditional methods. The proposed framework demonstrates significant potential for the early detection and prediction of cardiac-related diseases. Experimental results indicate that the Enhanced Multilayer Perceptron (EMLP) model outperformed the other algorithms in terms of accuracy, precision, F1-score, and recall, underscoring its efficacy in cardiac disease detection.",2025,10.3389/frai.2024.1539588
Data-Driven Discovery of Mathematical and Physical Relations in Oncology Data Using Human-Understandable Machine Learning,"For decades, researchers have used the concepts of rate of change and differential equations to model and forecast neoplastic processes. This expressive mathematical apparatus brought significant insights in oncology by describing the unregulated proliferation and host interactions of cancer cells, as well as their response to treatments. Now, these theories have been given a new life and found new applications. With the advent of routine cancer genome sequencing and the resulting abundance of data, oncology now builds an “arsenal” of new modeling and analysis tools. Models describing the governing physical laws of tumor–host–drug interactions can be now challenged with biological data to make predictions about cancer progression. Our study joins the efforts of the mathematical and computational oncology community by introducing a novel machine learning system for data-driven discovery of mathematical and physical relations in oncology. The system utilizes computational mechanisms such as competition, cooperation, and adaptation in neural networks to simultaneously learn the statistics and the governing relations between multiple clinical data covariates. Targeting an easy adoption in clinical oncology, the solutions of our system reveal human-understandable properties and features hidden in the data. As our experiments demonstrate, our system can describe nonlinear conservation laws in cancer kinetics and growth curves, symmetries in tumor’s phenotypic staging transitions, the preoperative spatial tumor distribution, and up to the nonlinear intracellular and extracellular pharmacokinetics of neoadjuvant therapies. The primary goal of our work is to enhance or improve the mechanistic understanding of cancer dynamics by exploiting heterogeneous clinical data. We demonstrate through multiple instantiations that our system is extracting an accurate human-understandable representation of the underlying dynamics of physical interactions central to typical oncology problems. Our results and evaluation demonstrate that, using simple—yet powerful—computational mechanisms, such a machine learning system can support clinical decision-making. To this end, our system is a representative tool of the field of mathematical and computational oncology and offers a bridge between the data, the modeler, the data scientist, and the practicing clinician.",2021,10.3389/frai.2021.713690
The use of artificial intelligence for automatic analysis and reporting of software defects,"The COVID-19 pandemic marked a before and after in the business world, causing a growing demand for applications that streamline operations, reduce delivery times and costs, and improve the quality of products. In this context, artificial intelligence (AI) has taken a relevant role in improving these processes, since it incorporates mathematical models that allow analyzing the logical structure of the systems to detect and reduce errors or failures in real-time. This study aimed to determine the most relevant aspects to be considered for detecting software defects using AI. The methodology used was qualitative, with an exploratory, descriptive, and non-experimental approach. The technique involved a documentary review of 79 bibliometric references. The most relevant finding was the use of regression testing techniques and automated log files, in machine learning (ML) and robotic process automation (RPA) environments. These techniques help reduce the time required to identify failures, thereby enhancing efficiency and effectiveness in the lifecycle of applications. In conclusion, companies that incorporate AI algorithms will be able to include an agile model in their lifecycle, as they will reduce the rate of failures, errors, and breakdowns allowing cost savings, and ensuring quality.",2024,10.3389/frai.2024.1443956
Legal Logit Model for predicting judicial disagreement in Indian courts,"Once a case reaches the Supreme Court on appeal, the justices may either affirm or reverse the judgment of the lower court. Forecasting such judicial disagreement is important not only for predicting outcomes but also for understanding the judge-specific and case-specific factors that drive these decisions. This study aimed to present the Legal Logit Model (LLM), an evolved neural network-based version of the Multinomial Logit (MNL) model. The LLM combines the interpretability of discrete choice theory with the flexibility of neural networks. Therefore, it is capable of modeling complex, non-linear interactions while preserving transparency about the influence of individual features. Utilizing features extracted from both cases and judges, the model predicts whether the Supreme Court will reverse a lower court's ruling and highlights the factors most strongly associated with disagreement. When tested on a dataset of Supreme Court opinions, the LLM achieves 80% accuracy in predicting outcomes, outperforming conventional logit and deep learning-based models. Despite the possibility of motivated reasoning in Supreme Court opinions, limiting causal interpretation, the findings show that the LLM presents an interpretable and effective predictive framework applicable to the study of judicial decision-making.",2025,10.3389/frai.2025.1671474
Experiences of Game-Based Learning and Reviewing History of the Experience Using Player's Emotions,"In this paper, we discuss whether the history of a learning experience, containing action and emotion information, is useful for review of the experience in game-based learning using virtual space. We developed a game-based story generation system that automatically generates scripts in real time by using a player's emotions and actions. The system has two functions: a game-based experiential learning environment and automatic story generation. The system provides the player with a virtual world and a virtual tool operated by using a hand controller and a display. The system recognizes the player's real-time emotions through facial expressions, and it outputs reactions based on these emotions and actions via a knowledge-based system when the player operates the tool. Then, it outputs scripts based on the emotions and the history of actions. We evaluated the system by conducting experiments with university students as subjects. As a result, subjects found the stories generated by this system interesting because they were based on the player's experience in the game and used the player's behavioral history and emotions. If we consider this as a record of the learning experience, the learning history is an impressive record accompanied by emotions. Thus, historical information that records the actions and emotions of the learner in real time is considered effective because it allows the learner to recall his or her own experiences after the game experience. The results suggest that the historical information, including the learner's real-time actions and emotions, is helpful for review in learning. There is a possibility that experiential learning through games using virtual spaces, such as the one used in this study, will become widespread in the future. In such cases, it will be necessary to examine the learning effects of using historical information with emotions. Therefore, we believe that the results and discussions in this study will be useful for experiential learning using virtual spaces.",2022,10.3389/frai.2022.874106
In the search for the perfect prompt in medical AI queries,"The evaluation of medical Artificial Intelligence (AI) systems presents significant challenges, with performance often varying drastically across studies. This narrative review identifies prompt quality—the way questions are formulated for the AI—as a critical yet under-recognized variable influencing these outcomes. The analysis explores scientific literature published between January 2018 and August 2025 to investigate the impact of prompt engineering on the perceived accuracy and reliability of conversational AI in medicine. Results reveal a “performance paradox,” where AI sometimes surpasses human experts in controlled settings yet underperforms in broader meta-analyses. This inconsistency is strongly linked to the type of prompt used. Critical concerns are highlighted, such as “prompting bias,” which may invalidate study conclusions, and AI “hallucinations” that generate dangerously incorrect information. Furthermore, a significant gap exists between the optimal prompts formulated by experts and the natural queries of the general public, raising issues of safety and health equity. In the end we were interested in finding out what the optimal balance existed between the complexity of a prompt and the value of the generated response, and, in this context, whether we could attempt to define a path toward identifying the best possible prompt.",2025,10.3389/frai.2025.1689178
Stakeholder-centric explanations for black-box decisions: an XAI process model and its application to automotive goodwill assessments,"Machine learning has made tremendous progress in predictive performance in recent years. Despite these advances, employing machine learning models in high-stake domains remains challenging due to the opaqueness of many high-performance models. If their behavior cannot be analyzed, this likely decreases the trust in such models and hinders the acceptance of human decision-makers. Motivated by these challenges, we propose a process model for developing and evaluating explainable decision support systems that are tailored to the needs of different stakeholders. To demonstrate its usefulness, we apply the process model to a real-world application in an enterprise context. The goal is to increase the acceptance of an existing black-box model developed at a car manufacturer for supporting manual goodwill assessments. Following the proposed process, we conduct two quantitative surveys targeted at the application's stakeholders. Our study reveals that textual explanations based on local feature importance best fit the needs of the stakeholders in the considered use case. Specifically, our results show that all stakeholders, including business specialists, goodwill assessors, and technical IT experts, agree that such explanations significantly increase their trust in the decision support system. Furthermore, our technical evaluation confirms the faithfulness and stability of the selected explanation method. These practical findings demonstrate the potential of our process model to facilitate the successful deployment of machine learning models in enterprise settings. The results emphasize the importance of developing explanations that are tailored to the specific needs and expectations of diverse stakeholders.",2024,10.3389/frai.2024.1471208
Bone age assessment based on deep neural networks with annotation-free cascaded critical bone region extraction,"Bone age assessment (BAA) from hand radiographs is crucial for diagnosing endocrinology disorders in adolescents and supplying therapeutic investigation. In practice, due to the conventional clinical assessment being a subjective estimation, the accuracy of BAA relies highly on the pediatrician's professionalism and experience. Recently, many deep learning methods have been proposed for the automatic estimation of bone age and had good results. However, these methods do not exploit sufficient discriminative information or require additional manual annotations of critical bone regions that are important biological identifiers in skeletal maturity, which may restrict the clinical application of these approaches. In this research, we propose a novel two-stage deep learning method for BAA without any manual region annotation, which consists of a cascaded critical bone region extraction network and a gender-assisted bone age estimation network. First, the cascaded critical bone region extraction network automatically and sequentially locates two discriminative bone regions via the visual heat maps. Second, in order to obtain an accurate BAA, the extracted critical bone regions are fed into the gender-assisted bone age estimation network. The results showed that the proposed method achieved a mean absolute error (MAE) of 5.45 months on the public dataset Radiological Society of North America (RSNA) and 3.34 months on our private dataset.",2023,10.3389/frai.2023.1142895
Quantum Propensity in Economics,"This paper describes an approach to economics that is inspired by quantum computing, and is motivated by the need to develop a consistent quantum mathematical framework for economics. The traditional neoclassical approach assumes that rational utility-optimisers drive market prices to a stable equilibrium, subject to external perturbations or market failures. While this approach has been highly influential, it has come under increasing criticism following the financial crisis of 2007/8. The quantum approach, in contrast, is inherently probabilistic and dynamic. Decision-makers are described, not by a utility function, but by a propensity function which specifies the probability of transacting. We show how a number of cognitive phenomena such as preference reversal and the disjunction effect can be modelled by using a simple quantum circuit to generate an appropriate propensity function. Conversely, a general propensity function can be quantized,viaan entropic force, to incorporate effects such as interference and entanglement that characterise human decision-making. Applications to some common problems and topics in economics and finance, including the use of quantum artificial intelligence, are discussed.",2022,10.3389/frai.2021.772294
Can AI teach me employability? A multi-national study in three countries,"This paper examines the impact of using an Artificial Intelligence (AI) teacher for current Higher Education (HE) students from three countries. The study utilized an AI avatar powered by a fine-tuned Large Language Model (LLM), OIMISA, which is trained solely for teaching and learning applications. The AI teacher provided a 9-lesson course on employability and transferable skills. In total 207 students across the three institutions enrolled in the programme. The results demonstrate a noteworthy completion rate of over 47%, along with high levels of engagement across all student cohorts and high satisfaction rates from the students. These show the potential for AI-based virtual teachers across countries for students of HE compared to the use of MOOC platforms.",2024,10.3389/frai.2024.1461158
A Unified Framework on Generalizability of Clinical Prediction Models,"To be useful, clinical prediction models (CPMs) must be generalizable to patients in new settings. Evaluating generalizability of CPMs helps identify spurious relationships in data, provides insights on when they fail, and thus, improves the explainability of the CPMs. There are discontinuities in concepts related to generalizability of CPMs in the clinical research and machine learning domains. Specifically, conventional statistical reasons to explain poor generalizability such as inadequate model development for the purposes of generalizability, differences in coding of predictors and outcome between development and external datasets, measurement error, inability to measure some predictors, and missing data, all have differing and often complementary treatments, in the two domains. Much of the current machine learning literature on generalizability of CPMs is in terms of dataset shift of which several types have been described. However, little research exists to synthesize concepts in the two domains. Bridging this conceptual discontinuity in the context of CPMs can facilitate systematic development of CPMs and evaluation of their sensitivity to factors that affect generalizability. We survey generalizability and dataset shift in CPMs from both the clinical research and machine learning perspectives, and describe a unifying framework to analyze generalizability of CPMs and to explain their sensitivity to factors affecting it. Our framework leads to a set of signaling statements that can be used to characterize differences between datasets in terms of factors that affect generalizability of the CPMs.",2022,10.3389/frai.2022.872720
A Transfer Learning–Based Active Learning Framework for Brain Tumor Classification,"Brain tumor is one of the leading causes of cancer-related death globally among children and adults. Precise classification of brain tumor grade (low-grade and high-grade glioma) at an early stage plays a key role in successful prognosis and treatment planning. With recent advances in deep learning, artificial intelligence–enabled brain tumor grading systems can assist radiologists in the interpretation of medical images within seconds. The performance of deep learning techniques is, however, highly depended on the size of the annotated dataset. It is extremely challenging to label a large quantity of medical images, given the complexity and volume of medical data. In this work, we propose a novel transfer learning–based active learning framework to reduce the annotation cost while maintaining stability and robustness of the model performance for brain tumor classification. In this retrospective research, we employed a 2D slice–based approach to train and fine-tune our model on the magnetic resonance imaging (MRI) training dataset of 203 patients and a validation dataset of 66 patients which was used as the baseline. With our proposed method, the model achieved area under receiver operating characteristic (ROC) curve (AUC) of 82.89% on a separate test dataset of 66 patients, which was 2.92% higher than the baseline AUC while saving at least 40% of labeling cost. In order to further examine the robustness of our method, we created a balanced dataset, which underwent the same procedure. The model achieved AUC of 82% compared with AUC of 78.48% for the baseline, which reassures the robustness and stability of our proposed transfer learning augmented with active learning framework while significantly reducing the size of training data.",2021,10.3389/frai.2021.635766
"Financial Risk Management and Explainable, Trustworthy, Responsible AI","This perspective paper is based on several sessions by the members of the Round Table AI at FIRM1, with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where “High Risk” models according to the mentioned EU consultation are concerned.",2022,10.3389/frai.2022.779799
"Exploring the matrix: knowledge, perceptions and prospects of artificial intelligence and machine learning in Nigerian healthcare","BackgroundArtificial intelligence technology can be applied in several aspects of healthcare delivery and its integration into the Nigerian healthcare value chain is expected to bring about new opportunities. This study aimed at assessing the knowledge and perception of healthcare professionals in Nigeria regarding the application of artificial intelligence and machine learning in the health sector.MethodsA cross-sectional study was undertaken amongst healthcare professionals in Nigeria with the use of a questionnaire. Data were collected across the six geopolitical zones in the Country using a stratified multistage sampling method. Descriptive and inferential statistical analyses were undertaken for the data obtained.ResultsFemale participants (55.7%) were slightly higher in proportion compared to the male respondents (44.3%). Pharmacists accounted for 27.7% of the participants, and this was closely followed by medical doctors (24.5%) and nurses (19.3%). The majority of the respondents (57.2%) reported good knowledge regarding artificial intelligence and machine learning, about a third of the participants (32.2%) were of average knowledge, and 10.6% of the sample had poor knowledge. More than half of the respondents (57.8%) disagreed with the notion that the adoption of artificial intelligence in the Nigerian healthcare sector could result in job losses. Two-thirds of the participants (66.7%) were of the view that the integration of artificial intelligence in healthcare will augment human intelligence. Three-quarters (77%) of the respondents agreed that the use of machine learning in Nigerian healthcare could facilitate efficient service delivery.ConclusionThis study provides novel insights regarding healthcare professionals' knowledge and perception with respect to the application of artificial intelligence and machine learning in healthcare. The emergent findings from this study can guide government and policymakers in decision-making as regards deployment of artificial intelligence and machine learning for healthcare delivery.",2024,10.3389/frai.2023.1293297
Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.",2021,10.3389/frai.2021.576892
Declarative Learning-Based Programming as an Interface to AI Systems,"Data-driven approaches are becoming increasingly common as problem-solving tools in many areas of science and technology. In most cases, machine learning models are the key component of these solutions. Often, a solution involves multiple learning models, along with significant levels of reasoning with the models' output and input. However, the current tools are cumbersome not only for domain experts who are not fluent in machine learning but also for machine learning experts who evaluate new algorithms and models on real-world data and develop AI systems. We review key efforts made by various AI communities in providing languages for high-level abstractions over learning and reasoning techniques needed for designing complex AI systems. We classify the existing frameworks based on the type of techniques and their data and knowledge representations, compare the ways the current tools address the challenges of programming real-world applications and highlight some shortcomings and future directions. Our comparison is only qualitative and not experimental since the performance of the systems is not a factor in our study.",2022,10.3389/frai.2022.755361
The precision medicine process for treating rare disease using the artificial intelligence tool mediKanren,"There are over 6,000 different rare diseases estimated to impact 300 million people worldwide. As genetic testing becomes more common practice in the clinical setting, the number of rare disease diagnoses will continue to increase, resulting in the need for novel treatment options. Identifying treatments for these disorders is challenging due to a limited understanding of disease mechanisms, small cohort sizes, interindividual symptom variability, and little commercial incentive to develop new treatments. A promising avenue for treatment is drug repurposing, where FDA-approved drugs are repositioned as novel treatments. However, linking disease mechanisms to drug action can be extraordinarily difficult and requires a depth of knowledge across multiple fields, which is complicated by the rapid pace of biomedical knowledge discovery. To address these challenges, The Hugh Kaul Precision Medicine Institute developed an artificial intelligence tool, mediKanren, that leverages the mechanistic insight of genetic disorders to identify therapeutic options. Using knowledge graphs, mediKanren enables an efficient way to link all relevant literature and databases. This tool has allowed for a scalable process that has been used to help over 500 rare disease families. Here, we provide a description of our process, the advantages of mediKanren, and its impact on rare disease patients.",2022,10.3389/frai.2022.910216
GANterfactual—Counterfactual Explanations for Medical Non-experts Using Generative Adversarial Learning,"With the ongoing rise of machine learning, the need for methods for explaining decisions made by artificial intelligence systems is becoming a more and more important topic. Especially for image classification tasks, many state-of-the-art tools to explain such classifiers rely on visual highlighting of important areas of the input data. Contrary, counterfactual explanation systems try to enable a counterfactual reasoning by modifying the input image in a way such that the classifier would have made a different prediction. By doing so, the users of counterfactual explanation systems are equipped with a completely different kind of explanatory information. However, methods for generating realistic counterfactual explanations for image classifiers are still rare. Especially in medical contexts, where relevant information often consists of textural and structural information, high-quality counterfactual images have the potential to give meaningful insights into decision processes. In this work, we present GANterfactual, an approach to generate such counterfactual image explanations based on adversarial image-to-image translation techniques. Additionally, we conduct a user study to evaluate our approach in an exemplary medical use case. Our results show that, in the chosen medical use-case, counterfactual explanations lead to significantly better results regarding mental models, explanation satisfaction, trust, emotions, and self-efficacy than two state-of-the art systems that work with saliency maps, namely LIME and LRP.",2022,10.3389/frai.2022.825565
Decision trees: from efficient prediction to responsible AI,"This article provides a birds-eye view on the role of decision trees in machine learning and data science over roughly four decades. It sketches the evolution of decision tree research over the years, describes the broader context in which the research is situated, and summarizes strengths and weaknesses of decision trees in this context. The main goal of the article is to clarify the broad relevance to machine learning and artificial intelligence, both practical and theoretical, that decision trees still have today.",2023,10.3389/frai.2023.1124553
Applied artificial intelligence in dentistry: emerging data modalities and modeling approaches,"Artificial intelligence (AI) is increasingly applied across all disciplines of medicine, including dentistry. Oral health research is experiencing a rapidly increasing use of machine learning (ML), the branch of AI that identifies inherent patterns in data similarly to how humans learn. In contemporary clinical dentistry, ML supports computer-aided diagnostics, risk stratification, individual risk prediction, and decision support to ultimately improve clinical oral health care efficiency, outcomes, and reduce disparities. Further, ML is progressively used in dental and oral health research, from basic and translational science to clinical investigations. With an ML perspective, this review provides a comprehensive overview of how dental medicine leverages AI for diagnostic, prognostic, and generative tasks. The spectrum of available data modalities in dentistry and their compatibility with various methods of applied AI are presented. Finally, current challenges and limitations as well as future possibilities and considerations for AI application in dental medicine are summarized.",2024,10.3389/frai.2024.1427517
DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for Embedded Speech and Audio Processing From Decentralized Data,"Deep neural speech and audio processing systems have a large number of trainable parameters, a relatively complex architecture, and require a vast amount of training data and computational power. These constraints make it more challenging to integrate such systems into embedded devices and utilize them for real-time, real-world applications. We tackle these limitations by introducing DeepSpectrumLite, an open-source, lightweight transfer learning framework for on-device speech and audio recognition using pre-trained image Convolutional Neural Networks (CNNs). The framework creates and augments Mel spectrogram plots on the fly from raw audio signals which are then used to finetune specific pre-trained CNNs for the target classification task. Subsequently, the whole pipeline can be run in real-time with a mean inference lag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola moto e7 plus smartphone. DeepSpectrumLite operates decentralized, eliminating the need for data upload for further processing. We demonstrate the suitability of the proposed transfer learning approach for embedded audio signal processing by obtaining state-of-the-art results on a set of paralinguistic and general audio tasks, including speech and music emotion recognition, social signal processing, COVID-19 cough and COVID-19 speech analysis, and snore sound classification. We provide an extensive command-line interface for users and developers which is comprehensively documented and publicly available at https://github.com/DeepSpectrum/DeepSpectrumLite.",2022,10.3389/frai.2022.856232
A United States Fair Lending Perspective on Machine Learning,"The use of machine learning (ML) has become more widespread in many areas of consumer financial services, including credit underwriting and pricing of loans. ML’s ability to automatically learn nonlinearities and interactions in training data is perceived to facilitate faster and more accurate credit decisions, and ML is now a viable challenger to traditional credit modeling methodologies. In this mini review, we further the discussion of ML in consumer finance by proposing uniform definitions of key ML and legal concepts related to discrimination and interpretability. We use the United States legal and regulatory environment as a foundation to add critical context to the broader discussion of relevant, substantial, and novel ML methodologies in credit underwriting, and we review numerous strategies to mitigate the many potential adverse implications of ML in consumer finance.",2021,10.3389/frai.2021.695301
